#!/usr/bin/env python3
"""
CloudTrail Activity Enricher - 90-Day Activity Validation
=========================================================

Provides CloudTrail-based activity enrichment for VPC endpoints and other AWS resources
to enable evidence-based decommissioning decisions.

Business Need:
- $18K annual VPC Endpoint savings validation (Track 1 completion)
- Prevents accidental deletion of active endpoints protecting critical workloads
- 90-day lookback period for comprehensive activity analysis

Pattern:
- Reuses activity enrichment patterns from activity_enricher.py
- Completes Track 1 CloudTrail validation (45/100 â†’ 100/100)
- Integration with vpc/cloudtrail_activity_analyzer.py

Usage:
    from runbooks.inventory.enrichers.cloudtrail_activity_enricher import CloudTrailActivityEnricher

    enricher = CloudTrailActivityEnricher(
        operational_profile='CENTRALISED_OPS_PROFILE',
        region='ap-southeast-2'
    )

    # Enrich VPC endpoints with CloudTrail activity
    enriched_df = enricher.enrich_resources(
        endpoints_df,
        resource_type='vpc_endpoint',
        lookback_days=90
    )

Author: Runbooks Team
Version: 1.0.0
Strategic Alignment: Track 1 - VPC Endpoint Activity Validation ($18K annual savings)
"""

import logging
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional

import boto3
import pandas as pd
from botocore.exceptions import ClientError

from runbooks.common.profile_utils import (
    get_profile_for_operation,
    create_operational_session,
    create_timeout_protected_client,
)
from runbooks.common.rich_utils import print_info, print_success, print_warning, create_progress_bar, console

logger = logging.getLogger(__name__)


@dataclass
class CloudTrailActivity:
    """CloudTrail activity signal for a resource"""

    resource_id: str
    resource_type: str  # VPC_ENDPOINT, EC2, RDS, etc.
    account_id: str
    region: str
    activity_events: List[Dict]
    last_activity_timestamp: Optional[datetime]
    activity_count_90d: int
    activity_score: int  # 0-100 (0 = no activity, 100 = high activity)
    recommendation: str  # KEEP, INVESTIGATE, DECOMMISSION


class CloudTrailActivityEnricher:
    """
    CloudTrail activity enricher for decommission signal validation.

    Implements 100-point activity scoring system:
    - A1: Events in last 7 days (40 points)
    - A2: Events in last 30 days (30 points)
    - A3: Events in last 90 days (20 points)
    - A4: Event diversity (>1 event type) (10 points)

    Recommendations:
    - Score 0-20: DECOMMISSION (no recent activity)
    - Score 21-50: INVESTIGATE (low activity)
    - Score >50: KEEP (active usage)
    """

    def __init__(self, operational_profile: str, region: str = "ap-southeast-2", timeout_seconds: int = 30):
        """
        Initialize CloudTrail activity enricher.

        Args:
            operational_profile: AWS profile for CloudTrail access
            region: AWS region for CloudTrail queries
            timeout_seconds: Timeout for CloudTrail API calls
        """
        # Resolve profile using standard helpers
        resolved_profile = get_profile_for_operation("operational", operational_profile)

        # Initialize AWS session and CloudTrail client
        self.session = create_operational_session(resolved_profile)
        self.cloudtrail = create_timeout_protected_client(
            self.session, "cloudtrail", region_name=region, timeout=timeout_seconds
        )

        self.region = region
        self.profile = resolved_profile
        self.timeout_seconds = timeout_seconds

        print_info(f"ðŸ” CloudTrailActivityEnricher initialized: profile={resolved_profile}, region={region}")
        print_info("   API: CloudTrail 90-day lookback for activity validation")

    def enrich_resources(self, df: pd.DataFrame, resource_type: str, lookback_days: int = 90) -> pd.DataFrame:
        """
        Enrich resources with CloudTrail activity signals.

        Args:
            df: DataFrame with resource identifiers
            resource_type: Resource type ('vpc_endpoint', 'ec2', 'rds', etc.)
            lookback_days: CloudTrail lookback period (default: 90, max: 90)

        Returns:
            DataFrame with CloudTrail activity columns added:
            - cloudtrail_activity_count: Number of events in lookback period
            - cloudtrail_last_activity: Timestamp of most recent event
            - cloudtrail_days_since_activity: Days since last activity
            - cloudtrail_activity_score: 0-100 activity score
            - cloudtrail_recommendation: KEEP/INVESTIGATE/DECOMMISSION
            - cloudtrail_event_types: Comma-separated list of event names
        """
        print_info(f"ðŸ” CloudTrail: Enriching {len(df)} {resource_type} resources ({lookback_days}-day lookback)...")

        # Validate resource type mapping
        resource_id_col = self._get_resource_id_column(df, resource_type)

        if resource_id_col not in df.columns:
            available_columns = df.columns.tolist()
            raise ValueError(
                f"Required column '{resource_id_col}' not found for {resource_type} resources.\n"
                f"Available columns: {available_columns}"
            )

        # Initialize CloudTrail activity columns
        df["cloudtrail_activity_count"] = 0
        df["cloudtrail_last_activity"] = None
        df["cloudtrail_days_since_activity"] = lookback_days
        df["cloudtrail_activity_score"] = 0
        df["cloudtrail_recommendation"] = "INVESTIGATE"
        df["cloudtrail_event_types"] = ""

        # Calculate time window
        end_time = datetime.now(tz=timezone.utc)
        start_time = end_time - timedelta(days=min(lookback_days, 90))

        # Enrich each resource with CloudTrail activity
        enriched_count = 0

        with create_progress_bar() as progress:
            task = progress.add_task("[cyan]CloudTrail activity enrichment...", total=len(df))

            for idx, row in df.iterrows():
                resource_id = row.get(resource_id_col)

                if not resource_id or resource_id == "N/A":
                    progress.update(task, advance=1)
                    continue

                try:
                    # Query CloudTrail for resource activity
                    events = self._lookup_events(
                        resource_id=resource_id, resource_type=resource_type, start_time=start_time, end_time=end_time
                    )

                    if events:
                        # Extract activity metadata
                        last_activity = max(event["EventTime"] for event in events)
                        event_types = list(set(event["EventName"] for event in events))
                        days_since = (end_time - last_activity).days

                        # Calculate activity score
                        activity_score = self._calculate_activity_score(events, end_time)

                        # Generate recommendation
                        recommendation = self._generate_recommendation(activity_score)

                        # Update DataFrame
                        df.at[idx, "cloudtrail_activity_count"] = len(events)
                        df.at[idx, "cloudtrail_last_activity"] = last_activity.strftime("%Y-%m-%d %H:%M:%S")
                        df.at[idx, "cloudtrail_days_since_activity"] = days_since
                        df.at[idx, "cloudtrail_activity_score"] = activity_score
                        df.at[idx, "cloudtrail_recommendation"] = recommendation
                        df.at[idx, "cloudtrail_event_types"] = ", ".join(event_types[:5])  # Top 5

                        enriched_count += 1

                except ClientError as e:
                    logger.debug(f"CloudTrail lookup failed for {resource_id}: {e}")
                except Exception as e:
                    logger.error(f"Unexpected error enriching {resource_id}: {e}")

                progress.update(task, advance=1)

        # Summary statistics
        inactive_count = (df["cloudtrail_activity_count"] == 0).sum()
        active_count = (df["cloudtrail_activity_count"] > 0).sum()

        print_success(f"âœ… CloudTrail enrichment complete: {enriched_count}/{len(df)} resources with activity")
        print_info(f"   Active (>0 events): {active_count}")
        print_info(f"   Inactive (0 events): {inactive_count}")

        return df

    def _get_resource_id_column(self, df: pd.DataFrame, resource_type: str) -> str:
        """
        Map resource type to DataFrame column name.

        Args:
            df: DataFrame to check for columns
            resource_type: Resource type identifier

        Returns:
            Column name containing resource IDs
        """
        # Resource type to column name mapping
        column_mapping = {
            "vpc_endpoint": "vpce_id",
            "ec2": "instance_id",
            "rds": "db_instance_identifier",
            "lambda": "function_name",
            "s3": "bucket_name",
        }

        # Try mapped column first
        if resource_type in column_mapping:
            mapped_col = column_mapping[resource_type]
            if mapped_col in df.columns:
                return mapped_col

        # Fallback: Look for common patterns
        for col in df.columns:
            if "id" in col.lower() and resource_type.replace("_", "") in col.lower():
                return col

        # Default to first column with 'id'
        id_columns = [col for col in df.columns if "id" in col.lower()]
        if id_columns:
            print_warning(f"Using column '{id_columns[0]}' for {resource_type} resource IDs")
            return id_columns[0]

        raise ValueError(f"Cannot determine resource ID column for {resource_type}")

    def _lookup_events(
        self, resource_id: str, resource_type: str, start_time: datetime, end_time: datetime
    ) -> List[Dict]:
        """
        Query CloudTrail for resource-specific events.

        Args:
            resource_id: Resource identifier
            resource_type: Type of resource
            start_time: Start of lookback period
            end_time: End of lookback period

        Returns:
            List of CloudTrail events
        """
        events = []

        try:
            # Primary strategy: ResourceName lookup
            paginator = self.cloudtrail.get_paginator("lookup_events")

            page_iterator = paginator.paginate(
                LookupAttributes=[{"AttributeKey": "ResourceName", "AttributeValue": resource_id}],
                StartTime=start_time,
                EndTime=end_time,
                PaginationConfig={"MaxItems": 1000},  # Limit to prevent excessive API calls
            )

            for page in page_iterator:
                events.extend(page.get("Events", []))

            # Fallback strategy: ResourceType lookup for VPC endpoints
            if not events and resource_type == "vpc_endpoint":
                events = self._lookup_vpc_endpoint_events_by_type(resource_id, start_time, end_time)

        except ClientError as e:
            if e.response["Error"]["Code"] in ["AccessDenied", "UnauthorizedOperation"]:
                logger.debug(f"CloudTrail access denied for {resource_id}")
            else:
                logger.error(f"CloudTrail API error for {resource_id}: {e}")
        except Exception as e:
            logger.error(f"Unexpected CloudTrail error for {resource_id}: {e}")

        return events

    def _lookup_vpc_endpoint_events_by_type(self, vpce_id: str, start_time: datetime, end_time: datetime) -> List[Dict]:
        """
        Fallback: Query CloudTrail using ResourceType filter for VPC endpoints.

        Args:
            vpce_id: VPC endpoint ID
            start_time: Start of lookback period
            end_time: End of lookback period

        Returns:
            List of CloudTrail events matching the VPC endpoint
        """
        matched_events = []

        try:
            response = self.cloudtrail.lookup_events(
                LookupAttributes=[{"AttributeKey": "ResourceType", "AttributeValue": "AWS::EC2::VPCEndpoint"}],
                StartTime=start_time,
                EndTime=end_time,
                MaxResults=1000,
            )

            # Filter events by resource ID
            for event in response.get("Events", []):
                resources = event.get("Resources", [])
                for resource in resources:
                    if vpce_id in resource.get("ResourceName", ""):
                        matched_events.append(event)
                        break

        except Exception as e:
            logger.debug(f"ResourceType fallback failed for {vpce_id}: {e}")

        return matched_events

    def _calculate_activity_score(self, events: List[Dict], current_time: datetime) -> int:
        """
        Calculate 100-point activity score based on event recency and diversity.

        Scoring:
        - A1: Events in last 7 days (40 points)
        - A2: Events in last 30 days (30 points)
        - A3: Events in last 90 days (20 points)
        - A4: Event diversity >1 type (10 points)

        Args:
            events: List of CloudTrail events
            current_time: Current timestamp

        Returns:
            Activity score (0-100)
        """
        if not events:
            return 0

        score = 0

        # A1: Events in last 7 days (40 points)
        recent_7d = [e for e in events if (current_time - e["EventTime"]).days <= 7]
        if recent_7d:
            score += 40

        # A2: Events in last 30 days (30 points)
        recent_30d = [e for e in events if (current_time - e["EventTime"]).days <= 30]
        if recent_30d:
            score += 30

        # A3: Events in last 90 days (20 points)
        if events:
            score += 20

        # A4: Event diversity (10 points)
        event_types = set(e.get("EventName") for e in events)
        if len(event_types) > 1:
            score += 10

        return min(score, 100)

    def _generate_recommendation(self, activity_score: int) -> str:
        """
        Generate decommission recommendation based on activity score.

        Args:
            activity_score: Activity score (0-100)

        Returns:
            Recommendation string
        """
        if activity_score > 50:
            return "KEEP"
        elif activity_score > 20:
            return "INVESTIGATE"
        else:
            return "DECOMMISSION"


def enrich_vpc_endpoints_with_cloudtrail(
    endpoints_df: pd.DataFrame, operational_profile: str, region: str = "ap-southeast-2", lookback_days: int = 90
) -> pd.DataFrame:
    """
    Convenience function for VPC endpoint CloudTrail enrichment.

    Args:
        endpoints_df: DataFrame with VPC endpoint data
        operational_profile: AWS profile for CloudTrail access
        region: AWS region
        lookback_days: CloudTrail lookback period (default: 90)

    Returns:
        DataFrame with CloudTrail activity columns
    """
    enricher = CloudTrailActivityEnricher(operational_profile=operational_profile, region=region)

    return enricher.enrich_resources(endpoints_df, resource_type="vpc_endpoint", lookback_days=lookback_days)


if __name__ == "__main__":
    # Demo usage
    from runbooks.common.rich_utils import print_header

    print_header("CloudTrail Activity Enricher", "Demo")

    # Example: Enrich VPC endpoints with CloudTrail activity
    import pandas as pd

    # Sample VPC endpoint data
    sample_data = pd.DataFrame(
        {
            "vpce_id": ["vpce-0123456789abcdef0", "vpce-0123456789abcdef1"],
            "vpc_id": ["vpc-abc123", "vpc-def456"],
            "service_name": ["com.amazonaws.ap-southeast-2.s3", "com.amazonaws.ap-southeast-2.dynamodb"],
        }
    )

    enricher = CloudTrailActivityEnricher(operational_profile="CENTRALISED_OPS_PROFILE", region="ap-southeast-2")

    enriched_df = enricher.enrich_resources(sample_data, resource_type="vpc_endpoint", lookback_days=90)

    print_success(f"\nâœ… Enrichment complete!")
    print_info(f"   Total endpoints: {len(enriched_df)}")
    print_info(f"   Active endpoints: {(enriched_df['cloudtrail_activity_count'] > 0).sum()}")
    print_info(f"   Inactive endpoints: {(enriched_df['cloudtrail_activity_count'] == 0).sum()}")
