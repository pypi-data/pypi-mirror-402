#!/usr/bin/env python3
"""
Enterprise Testing Framework - 3-Modes Testing & 2-Ways Validations
===================================================================

DEFINITION OF ENTERPRISE FRAMEWORK:

1. 3-MODES TESTING:
   - Mode 1: CLI Execution (runbooks commands)
   - Mode 2: Papermill (Automated programmatic notebook execution)
   - Mode 3: JupyterLab (Interactive manual notebook execution)

2. 2-WAYS VALIDATIONS:
   - Way 1: Evidence Files (JSON/CSV baseline data)
   - Way 2: AWS APIs (Live verification via boto3)

This module provides EXECUTABLE CODE for validating all claims with:
- Papermill integration for programmatic notebook execution
- AWS API integration for live verification
- MCP validation for cross-validation accuracy ‚â•99.5%

NOT DOCUMENTATION - THIS IS EXECUTABLE CODE.
"""

import json
import subprocess
import tempfile
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import boto3
from rich.console import Console
from rich.table import Table

from runbooks.common.rich_utils import (
    console,
    create_table,
    print_error,
    print_header,
    print_info,
    print_success,
    print_warning,
)


@dataclass
class ThreeModesResult:
    """Result from 3-modes testing execution."""

    mode_1_cli: Dict[str, Any]
    mode_2_papermill: Dict[str, Any]
    mode_3_jupyterlab: Dict[str, Any]
    all_passed: bool
    execution_time: float
    timestamp: str


@dataclass
class TwoWaysResult:
    """Result from 2-ways validation execution."""

    way_1_evidence: Dict[str, Any]
    way_2_aws_api: Dict[str, Any]
    accuracy_percent: float
    validation_passed: bool
    execution_time: float
    timestamp: str


class EnterpriseTestingFramework:
    """
    Enterprise Testing Framework - Executable implementation.

    Provides 3-Modes Testing and 2-Ways Validations as EXECUTABLE CODE.
    """

    def __init__(self, console: Optional[Console] = None):
        """Initialize enterprise testing framework."""
        self.console = console or Console()
        self.test_results: List[Dict[str, Any]] = []

    def three_modes_test(
        self,
        module_name: str,
        cli_command: str,
        notebook_path: Optional[Path] = None,
        test_data: Optional[Dict[str, Any]] = None,
    ) -> ThreeModesResult:
        """
        Execute 3-Modes Testing: CLI + Papermill + JupyterLab.

        Args:
            module_name: Module name (e.g., "vpc", "finops")
            cli_command: CLI command to execute (e.g., "runbooks vpc analyze")
            notebook_path: Path to notebook for Papermill/JupyterLab testing
            test_data: Test data for validation

        Returns:
            ThreeModesResult with execution results

        Example:
            >>> framework = EnterpriseTestingFramework()
            >>> result = framework.three_modes_test(
            ...     module_name="vpc",
            ...     cli_command="runbooks vpc vpce-cleanup --csv-file data.csv",
            ...     notebook_path=Path("notebooks/vpc/vpce-analysis.ipynb")
            ... )
            >>> assert result.all_passed
        """
        print_header("3-Modes Testing", f"{module_name} Module")
        start_time = datetime.now()

        # Mode 1: CLI Execution
        print_info("Mode 1: CLI Execution")
        mode_1_result = self._execute_mode_1_cli(cli_command)

        # Mode 2: Papermill (Automated)
        print_info("Mode 2: Papermill (Automated)")
        mode_2_result = self._execute_mode_2_papermill(notebook_path) if notebook_path else {"status": "skipped"}

        # Mode 3: JupyterLab (Interactive) - validation only
        print_info("Mode 3: JupyterLab (Interactive) - Manual Validation Available")
        mode_3_result = self._validate_mode_3_jupyterlab(notebook_path) if notebook_path else {"status": "skipped"}

        # Calculate overall result
        execution_time = (datetime.now() - start_time).total_seconds()
        all_passed = (
            mode_1_result.get("success", False)
            and (mode_2_result.get("success", True) or mode_2_result.get("status") == "skipped")
            and (mode_3_result.get("valid", True) or mode_3_result.get("status") == "skipped")
        )

        result = ThreeModesResult(
            mode_1_cli=mode_1_result,
            mode_2_papermill=mode_2_result,
            mode_3_jupyterlab=mode_3_result,
            all_passed=all_passed,
            execution_time=execution_time,
            timestamp=datetime.now().isoformat(),
        )

        self._display_three_modes_result(result, module_name)
        return result

    def two_ways_validate(
        self,
        evidence_file: Path,
        aws_validation_func: callable,
        aws_profile: Optional[str] = None,
        accuracy_threshold: float = 99.5,
    ) -> TwoWaysResult:
        """
        Execute 2-Ways Validations: Evidence Files + AWS APIs.

        Args:
            evidence_file: Path to evidence file (JSON/CSV)
            aws_validation_func: Function to query AWS APIs
            aws_profile: AWS profile for API calls
            accuracy_threshold: Required accuracy percent (default: 99.5%)

        Returns:
            TwoWaysResult with validation results

        Example:
            >>> def validate_vpces(profile):
            ...     session = boto3.Session(profile_name=profile)
            ...     ec2 = session.client('ec2', region_name='ap-southeast-2')
            ...     return ec2.describe_vpc_endpoints()
            >>>
            >>> framework = EnterpriseTestingFramework()
            >>> result = framework.two_ways_validate(
            ...     evidence_file=Path("tmp/vpce-cleanup-data.csv"),
            ...     aws_validation_func=validate_vpces,
            ...     aws_profile="${CENTRALISED_OPS_PROFILE}"
            ... )
            >>> assert result.validation_passed
        """
        print_header("2-Ways Validations", "Evidence + AWS APIs")
        start_time = datetime.now()

        # Way 1: Evidence Files
        print_info("Way 1: Evidence Files (Baseline)")
        way_1_result = self._execute_way_1_evidence(evidence_file)

        # Way 2: AWS APIs
        print_info("Way 2: AWS APIs (Live Verification)")
        way_2_result = self._execute_way_2_aws_api(aws_validation_func, aws_profile)

        # Calculate accuracy
        accuracy_percent = self._calculate_validation_accuracy(way_1_result, way_2_result)
        validation_passed = accuracy_percent >= accuracy_threshold

        execution_time = (datetime.now() - start_time).total_seconds()

        result = TwoWaysResult(
            way_1_evidence=way_1_result,
            way_2_aws_api=way_2_result,
            accuracy_percent=accuracy_percent,
            validation_passed=validation_passed,
            execution_time=execution_time,
            timestamp=datetime.now().isoformat(),
        )

        self._display_two_ways_result(result, accuracy_threshold)
        return result

    def _execute_mode_1_cli(self, cli_command: str) -> Dict[str, Any]:
        """Execute Mode 1: CLI command."""
        try:
            result = subprocess.run(cli_command.split(), capture_output=True, text=True, timeout=120, check=False)

            success = result.returncode == 0

            if success:
                print_success(f"‚úÖ Mode 1 CLI: Command executed successfully")
            else:
                print_error(f"‚ùå Mode 1 CLI: Command failed (exit code: {result.returncode})")

            return {
                "success": success,
                "exit_code": result.returncode,
                "stdout_lines": len(result.stdout.splitlines()) if result.stdout else 0,
                "stderr": result.stderr[:200] if result.stderr else None,
                "command": cli_command,
            }

        except subprocess.TimeoutExpired:
            print_error("‚ùå Mode 1 CLI: Command timeout (>120s)")
            return {"success": False, "error": "timeout", "command": cli_command}
        except Exception as e:
            print_error(f"‚ùå Mode 1 CLI: Execution error: {e}")
            return {"success": False, "error": str(e), "command": cli_command}

    def _execute_mode_2_papermill(self, notebook_path: Path) -> Dict[str, Any]:
        """Execute Mode 2: Papermill automated notebook execution."""
        if not notebook_path or not notebook_path.exists():
            return {"status": "skipped", "reason": "notebook_not_found"}

        try:
            # Create temporary output notebook
            with tempfile.NamedTemporaryFile(mode="w", suffix=".ipynb", delete=False) as tmp_output:
                output_path = tmp_output.name

            # Execute with papermill
            result = subprocess.run(
                ["uv", "run", "papermill", str(notebook_path), output_path],
                capture_output=True,
                text=True,
                timeout=300,
                check=False,
            )

            success = result.returncode == 0
            output_size = Path(output_path).stat().st_size if Path(output_path).exists() else 0

            if success:
                print_success(f"‚úÖ Mode 2 Papermill: Notebook executed ({output_size} bytes)")
            else:
                print_error(f"‚ùå Mode 2 Papermill: Execution failed")

            # Cleanup
            if Path(output_path).exists():
                Path(output_path).unlink()

            return {
                "success": success,
                "exit_code": result.returncode,
                "output_size_bytes": output_size,
                "notebook_path": str(notebook_path),
            }

        except subprocess.TimeoutExpired:
            print_error("‚ùå Mode 2 Papermill: Execution timeout (>300s)")
            return {"success": False, "error": "timeout", "notebook_path": str(notebook_path)}
        except Exception as e:
            print_error(f"‚ùå Mode 2 Papermill: Execution error: {e}")
            return {"success": False, "error": str(e), "notebook_path": str(notebook_path)}

    def _validate_mode_3_jupyterlab(self, notebook_path: Path) -> Dict[str, Any]:
        """Validate Mode 3: JupyterLab notebook availability for interactive execution."""
        if not notebook_path or not notebook_path.exists():
            return {"valid": False, "reason": "notebook_not_found"}

        # Check notebook is valid JSON
        try:
            with open(notebook_path, "r") as f:
                nb_data = json.load(f)

            cell_count = len(nb_data.get("cells", []))

            print_info(f"‚úÖ Mode 3 JupyterLab: Notebook available ({cell_count} cells)")
            print_info(f"   Manual execution: jupyter lab {notebook_path}")

            return {"valid": True, "cell_count": cell_count, "notebook_path": str(notebook_path)}

        except Exception as e:
            print_warning(f"‚ö†Ô∏è  Mode 3 JupyterLab: Notebook validation failed: {e}")
            return {"valid": False, "error": str(e), "notebook_path": str(notebook_path)}

    def _execute_way_1_evidence(self, evidence_file: Path) -> Dict[str, Any]:
        """Execute Way 1: Evidence file parsing."""
        try:
            if not evidence_file.exists():
                print_error(f"‚ùå Way 1: Evidence file not found: {evidence_file}")
                return {"success": False, "error": "file_not_found"}

            # Determine file type and parse
            if evidence_file.suffix == ".json":
                with open(evidence_file, "r") as f:
                    data = json.load(f)
                item_count = len(data) if isinstance(data, list) else 1
            elif evidence_file.suffix == ".csv":
                with open(evidence_file, "r") as f:
                    lines = f.readlines()
                item_count = len(lines) - 1  # Exclude header
            else:
                return {"success": False, "error": "unsupported_file_type"}

            print_success(f"‚úÖ Way 1 Evidence: Parsed {item_count} items from {evidence_file.name}")

            return {
                "success": True,
                "item_count": item_count,
                "file_path": str(evidence_file),
                "file_size_bytes": evidence_file.stat().st_size,
            }

        except Exception as e:
            print_error(f"‚ùå Way 1 Evidence: Parsing error: {e}")
            return {"success": False, "error": str(e)}

    def _execute_way_2_aws_api(self, aws_validation_func: callable, aws_profile: Optional[str]) -> Dict[str, Any]:
        """Execute Way 2: AWS API validation."""
        try:
            # Execute AWS validation function
            api_result = aws_validation_func(aws_profile)

            # Determine success based on result structure
            if isinstance(api_result, dict):
                item_count = len(api_result.get("VpcEndpoints", [])) if "VpcEndpoints" in api_result else 0
                success = True
            else:
                item_count = len(api_result) if isinstance(api_result, list) else 0
                success = True

            print_success(f"‚úÖ Way 2 AWS API: Validated {item_count} items via AWS")

            return {"success": success, "item_count": item_count, "profile": aws_profile}

        except Exception as e:
            print_error(f"‚ùå Way 2 AWS API: Validation error: {e}")
            return {"success": False, "error": str(e), "profile": aws_profile}

    def _calculate_validation_accuracy(self, way_1_result: Dict, way_2_result: Dict) -> float:
        """Calculate validation accuracy between evidence and AWS API."""
        if not way_1_result.get("success") or not way_2_result.get("success"):
            return 0.0

        evidence_count = way_1_result.get("item_count", 0)
        api_count = way_2_result.get("item_count", 0)

        if evidence_count == 0 and api_count == 0:
            return 100.0

        if evidence_count == 0 or api_count == 0:
            return 0.0

        # Calculate accuracy as percentage match
        max_count = max(evidence_count, api_count)
        difference = abs(evidence_count - api_count)
        accuracy = ((max_count - difference) / max_count) * 100

        return accuracy

    def _display_three_modes_result(self, result: ThreeModesResult, module_name: str):
        """Display 3-modes testing results in Rich table."""
        table = create_table(
            title=f"3-Modes Testing Results: {module_name}",
            columns=[
                {"name": "Mode", "justify": "left"},
                {"name": "Status", "justify": "center"},
                {"name": "Details", "justify": "left"},
            ],
        )

        # Mode 1: CLI
        mode_1_status = "‚úÖ PASS" if result.mode_1_cli.get("success") else "‚ùå FAIL"
        mode_1_details = f"Exit code: {result.mode_1_cli.get('exit_code', 'N/A')}"
        table.add_row("1. CLI Execution", mode_1_status, mode_1_details)

        # Mode 2: Papermill
        if result.mode_2_papermill.get("status") == "skipped":
            table.add_row("2. Papermill", "‚äù SKIP", "Notebook not provided")
        else:
            mode_2_status = "‚úÖ PASS" if result.mode_2_papermill.get("success") else "‚ùå FAIL"
            mode_2_details = f"Output: {result.mode_2_papermill.get('output_size_bytes', 0)} bytes"
            table.add_row("2. Papermill", mode_2_status, mode_2_details)

        # Mode 3: JupyterLab
        if result.mode_3_jupyterlab.get("status") == "skipped":
            table.add_row("3. JupyterLab", "‚äù SKIP", "Notebook not provided")
        else:
            mode_3_status = "‚úÖ VALID" if result.mode_3_jupyterlab.get("valid") else "‚ö†Ô∏è  WARN"
            mode_3_details = f"Cells: {result.mode_3_jupyterlab.get('cell_count', 0)}"
            table.add_row("3. JupyterLab", mode_3_status, mode_3_details)

        self.console.print(table)

        # Overall result
        if result.all_passed:
            print_success(f"\n‚úÖ 3-Modes Testing: ALL PASSED ({result.execution_time:.1f}s)")
        else:
            print_error(f"\n‚ùå 3-Modes Testing: FAILED ({result.execution_time:.1f}s)")

    def _display_two_ways_result(self, result: TwoWaysResult, threshold: float):
        """Display 2-ways validation results in Rich table."""
        table = create_table(
            title="2-Ways Validation Results",
            columns=[
                {"name": "Way", "justify": "left"},
                {"name": "Status", "justify": "center"},
                {"name": "Details", "justify": "left"},
            ],
        )

        # Way 1: Evidence Files
        way_1_status = "‚úÖ PASS" if result.way_1_evidence.get("success") else "‚ùå FAIL"
        way_1_details = f"Items: {result.way_1_evidence.get('item_count', 0)}"
        table.add_row("1. Evidence Files", way_1_status, way_1_details)

        # Way 2: AWS APIs
        way_2_status = "‚úÖ PASS" if result.way_2_aws_api.get("success") else "‚ùå FAIL"
        way_2_details = f"Items: {result.way_2_aws_api.get('item_count', 0)}"
        table.add_row("2. AWS APIs", way_2_status, way_2_details)

        self.console.print(table)

        # Accuracy result
        if result.validation_passed:
            print_success(f"\n‚úÖ 2-Ways Validation: {result.accuracy_percent:.1f}% accuracy (‚â•{threshold}% threshold)")
        else:
            print_error(f"\n‚ùå 2-Ways Validation: {result.accuracy_percent:.1f}% accuracy (<{threshold}% threshold)")

    def save_test_results(self, output_file: Path):
        """Save all test results to JSON file."""
        results_data = {
            "framework": "enterprise_testing_framework",
            "timestamp": datetime.now().isoformat(),
            "test_results": self.test_results,
        }

        with open(output_file, "w") as f:
            json.dump(results_data, f, indent=2)

        print_success(f"‚úÖ Test results saved: {output_file}")


# Convenience functions for direct usage
def three_modes_test(module_name: str, cli_command: str, notebook_path: Optional[Path] = None) -> ThreeModesResult:
    """
    Execute 3-Modes Testing: CLI + Papermill + JupyterLab.

    Quick function for direct usage without class instantiation.
    """
    framework = EnterpriseTestingFramework()
    return framework.three_modes_test(module_name, cli_command, notebook_path)


def two_ways_validate(
    evidence_file: Path, aws_validation_func: callable, aws_profile: Optional[str] = None
) -> TwoWaysResult:
    """
    Execute 2-Ways Validations: Evidence Files + AWS APIs.

    Quick function for direct usage without class instantiation.
    """
    framework = EnterpriseTestingFramework()
    return framework.two_ways_validate(evidence_file, aws_validation_func, aws_profile)


# CLI integration
if __name__ == "__main__":
    print_header("Enterprise Testing Framework", "Validation Demo")

    # Demo: 3-Modes Testing
    print_info("\nüìã Demo: 3-Modes Testing")
    three_modes_result = three_modes_test(
        module_name="vpc",
        cli_command="runbooks vpc --help",  # Simple help command for demo
    )

    # Demo: 2-Ways Validations
    print_info("\nüìã Demo: 2-Ways Validations")

    def demo_aws_validation(profile):
        """Demo AWS validation function."""
        return {"VpcEndpoints": []}  # Empty result for demo

    # This would fail without actual evidence file, so just print instructions
    print_info("Usage: two_ways_validate(evidence_file, aws_validation_func, aws_profile)")
    print_info("Example in integration tests: tests/vpc/test_enterprise_framework.py")
