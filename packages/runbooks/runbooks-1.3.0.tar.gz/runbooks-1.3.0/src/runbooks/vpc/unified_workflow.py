#!/usr/bin/env python3
"""
Unified AWS Network Discovery & Optimization Workflow
Integrates MCP â†’ Runbooks â†’ Excel â†’ Diagrams â†’ Notebooks â†’ FinOps

This script orchestrates the complete network discovery and optimization workflow:
1. MCP Discovery (via Runbooks NetworkBaselineCollector wrapper)
2. Excel Consolidation (9-11 sheets with FinOps enrichment)
3. Diagram Generation (7 architecture diagrams)
4. Notebook Analysis (Jupyter execution with papermill)
5. FinOps Enrichment (Cost Explorer API integration)

Part of CloudOps-Runbooks VPC optimization framework.

Author: Runbooks Team
Version: 1.1.x
"""

import asyncio
import json
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import boto3
from botocore.exceptions import ClientError

from runbooks.common.rich_utils import (
    Console,
    create_progress_bar,
    print_error,
    print_header,
    print_info,
    print_success,
    print_warning,
)
from runbooks.vpc.cost_engine import NetworkingCostEngine
from runbooks.vpc.network_baseline import NetworkBaselineCollector
from runbooks.vpc.network_discovery_excel_generator import NetworkDiscoveryExcelGenerator


class UnifiedNetworkWorkflow:
    """
    Orchestrates complete network discovery and optimization workflow.

    Integration Points:
    - MCP Servers: AWS discovery via awslabs.core-mcp
    - Runbooks: NetworkBaselineCollector, NetworkingCostEngine
    - Excel: NetworkDiscoveryExcelGenerator (9-11 sheets)
    - Diagrams: Python diagrams library (7 architecture diagrams)
    - Notebooks: Jupyter execution via papermill
    - FinOps: AWS Cost Explorer API integration

    Business Value:
    - <5 minute executive review capability
    - 30% cost optimization opportunities
    - Complete audit trail with SHA256 verification
    - Enterprise compliance validation
    """

    def __init__(
        self,
        profile: str,
        region: str,
        billing_profile: Optional[str] = None,
        console: Optional[Console] = None,
    ):
        """
        Initialize unified workflow orchestrator.

        Args:
            profile: AWS profile for network discovery (management/security account)
            region: AWS region for analysis (e.g., ap-southeast-2)
            billing_profile: AWS profile for Cost Explorer API (defaults to profile)
            console: Rich console for output (auto-created if not provided)
        """
        self.profile = profile
        self.region = region
        self.billing_profile = billing_profile or profile
        self.console = console or Console()
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Initialize AWS sessions
        self.session = boto3.Session(profile_name=self.profile)
        self.billing_session = boto3.Session(profile_name=self.billing_profile)

        # Get account ID
        self.account_id = self._get_account_id()

        # Initialize output directories
        self.artifacts_dir = Path("artifacts")
        self.network_discovery_dir = self.artifacts_dir / "network-discovery"
        self.diagrams_dir = self.artifacts_dir / "diagrams"
        self.finops_dir = self.artifacts_dir / "finops"

        self._create_output_directories()

    def _get_account_id(self) -> str:
        """Get AWS account ID from STS."""
        try:
            sts = self.session.client("sts")
            return sts.get_caller_identity()["Account"]
        except Exception as e:
            print_error("Failed to get AWS account ID", e)
            return "unknown"

    def _create_output_directories(self):
        """Create output directories for artifacts."""
        for directory in [
            self.network_discovery_dir,
            self.diagrams_dir,
            self.finops_dir,
        ]:
            directory.mkdir(parents=True, exist_ok=True)

    async def execute_full_workflow(self) -> Dict[str, Any]:
        """
        Execute complete workflow: Discovery â†’ Excel â†’ FinOps â†’ Diagrams â†’ Analysis.

        Returns:
            Dictionary with all workflow outputs and metadata
        """
        print_header("Unified Network Discovery & Optimization Workflow", version="1.1.x")
        self.console.print(f"\n[cyan]Account:[/cyan] {self.account_id}")
        self.console.print(f"[cyan]Profile:[/cyan] {self.profile}")
        self.console.print(f"[cyan]Region:[/cyan] {self.region}")
        self.console.print(f"[cyan]Billing Profile:[/cyan] {self.billing_profile}")
        self.console.print(f"[cyan]Timestamp:[/cyan] {self.timestamp}\n")

        workflow_results = {
            "account_id": self.account_id,
            "region": self.region,
            "timestamp": self.timestamp,
            "steps": {},
        }

        with create_progress_bar() as progress:
            workflow_task = progress.add_task("[cyan]Executing workflow...", total=6)

            # Step 1: MCP Discovery (via Runbooks wrapper)
            print_header("Step 1: Network Discovery (MCP + Runbooks)")
            baseline_data = await self._step_1_discovery()
            workflow_results["steps"]["discovery"] = baseline_data
            progress.update(workflow_task, advance=1)

            # Step 2: Excel Consolidation
            print_header("Step 2: Excel Consolidation (9 sheets)")
            excel_file = await self._step_2_excel_generation()
            workflow_results["steps"]["excel"] = excel_file
            progress.update(workflow_task, advance=1)

            # Step 3: FinOps Enrichment
            print_header("Step 3: FinOps Enrichment (Cost Explorer)")
            finops_data = await self._step_3_finops_enrichment(excel_file)
            workflow_results["steps"]["finops"] = finops_data
            progress.update(workflow_task, advance=1)

            # Step 4: Diagram Generation
            print_header("Step 4: Architecture Diagrams (7 diagrams)")
            diagram_files = await self._step_4_diagram_generation(excel_file)
            workflow_results["steps"]["diagrams"] = diagram_files
            progress.update(workflow_task, advance=1)

            # Step 5: Notebook Execution
            print_header("Step 5: Jupyter Notebook Analysis")
            notebook_output = await self._step_5_notebook_execution(excel_file)
            workflow_results["steps"]["notebook"] = notebook_output
            progress.update(workflow_task, advance=1)

            # Step 6: Workflow Summary
            print_header("Step 6: Workflow Summary & Validation")
            summary = await self._step_6_workflow_summary(workflow_results)
            workflow_results["summary"] = summary
            progress.update(workflow_task, advance=1)

        self._print_workflow_completion(workflow_results)
        return workflow_results

    async def _step_1_discovery(self) -> Dict[str, Any]:
        """Step 1: Network discovery via NetworkBaselineCollector (wraps MCP calls)."""
        print_info("Collecting network baseline metrics via Runbooks wrapper...")

        try:
            collector = NetworkBaselineCollector(
                profile=self.profile,
                regions=[self.region],
                console=self.console,
            )

            baseline_data = collector.collect_all_metrics()

            # Calculate summary
            region_data = baseline_data.get(self.region, {})
            nat_count = len(region_data.get("nat_gateways", []))
            tgw_count = len(region_data.get("transit_gateways", []))
            vpce_count = len(region_data.get("vpc_endpoints", []))
            vpn_count = len(region_data.get("vpn_connections", []))

            print_success(
                f"Discovery complete: {nat_count} NAT GWs, {tgw_count} TGWs, {vpce_count} VPCEs, {vpn_count} VPNs"
            )

            return {
                "status": "success",
                "region": self.region,
                "nat_gateways": nat_count,
                "transit_gateways": tgw_count,
                "vpc_endpoints": vpce_count,
                "vpn_connections": vpn_count,
                "raw_data": baseline_data,
            }

        except Exception as e:
            print_error("Network discovery failed", e)
            return {"status": "failed", "error": str(e)}

    async def _step_2_excel_generation(self) -> str:
        """Step 2: Generate consolidated Excel with 9 sheets."""
        print_info("Generating consolidated Excel workbook...")

        try:
            excel_gen = NetworkDiscoveryExcelGenerator(
                profile=self.profile,
                region=self.region,
                console=self.console,
            )

            excel_file = excel_gen.generate_consolidated_excel(output_dir=str(self.network_discovery_dir))

            print_success(f"Excel generated: {excel_file}")
            return excel_file

        except Exception as e:
            print_error("Excel generation failed", e)
            return f"ERROR: {str(e)}"

    async def _step_3_finops_enrichment(self, excel_file: str) -> Dict[str, Any]:
        """Step 3: Enrich with FinOps data from Cost Explorer API."""
        print_info("Querying AWS Cost Explorer for FinOps enrichment...")

        try:
            ce_client = self.billing_session.client("ce", region_name="ap-southeast-2")

            # Query last 30 days of VPC/Network costs
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now().replace(day=1)).strftime("%Y-%m-%d")

            response = ce_client.get_cost_and_usage(
                TimePeriod={"Start": start_date, "End": end_date},
                Granularity="MONTHLY",
                Metrics=["BlendedCost"],
                Filter={
                    "Dimensions": {
                        "Key": "SERVICE",
                        "Values": [
                            "Amazon Virtual Private Cloud",
                            "Amazon Elastic Compute Cloud - Compute",
                        ],
                    }
                },
            )

            # Extract costs
            total_cost = 0.0
            for result in response.get("ResultsByTime", []):
                cost = float(result["Total"]["BlendedCost"]["Amount"])
                total_cost += cost

            finops_data = {
                "status": "success",
                "period": f"{start_date} to {end_date}",
                "total_network_cost": total_cost,
                "cost_explorer_response": response,
            }

            # Save FinOps report
            finops_report_file = self.finops_dir / f"cost-analysis-{self.timestamp}.json"
            with open(finops_report_file, "w") as f:
                json.dump(finops_data, f, indent=2, default=str)

            print_success(f"FinOps enrichment complete: ${total_cost:.2f} network costs")

            return finops_data

        except ClientError as e:
            error_code = e.response["Error"]["Code"]
            if error_code == "AccessDeniedException":
                print_warning(f"Cost Explorer access denied for profile {self.billing_profile}")
                print_info("Skipping FinOps enrichment (requires ce:GetCostAndUsage permission)")
            else:
                print_error("Cost Explorer query failed", e)

            return {
                "status": "skipped",
                "reason": "Access denied or permissions issue",
                "error": str(e),
            }

    async def _step_4_diagram_generation(self, excel_file: str) -> List[str]:
        """Step 4: Generate architecture diagrams from Excel data."""
        print_info("Generating architecture diagrams...")

        diagram_scripts = [
            "complete_network_architecture.py",
            "transit_gateway_topology.py",
            "egress_vpc_centralized_nat.py",
            "network_firewall_inspection.py",
            "route53_resolver_dns.py",
            "ipam_workflow.py",
            "direct_connect_topology.py",
        ]

        generated_files = []

        for script in diagram_scripts:
            script_path = self.diagrams_dir / script

            if script_path.exists():
                try:
                    # Execute diagram script
                    result = subprocess.run(
                        [sys.executable, str(script_path)],
                        capture_output=True,
                        text=True,
                        timeout=30,
                    )

                    if result.returncode == 0:
                        png_file = script_path.with_suffix(".png")
                        generated_files.append(str(png_file))
                        print_success(f"Generated: {png_file.name}")
                    else:
                        print_warning(f"Diagram generation failed: {script}")

                except subprocess.TimeoutExpired:
                    print_warning(f"Diagram generation timeout: {script}")
                except Exception as e:
                    print_warning(f"Diagram generation error: {script} - {e}")
            else:
                print_warning(f"Diagram script not found: {script}")

        print_success(f"Diagram generation complete: {len(generated_files)} files")
        return generated_files

    async def _step_5_notebook_execution(self, excel_file: str) -> str:
        """Step 5: Execute Jupyter notebook with papermill."""
        print_info("Executing Jupyter notebook analysis...")

        notebook_input = Path("notebooks/automation/aws/network/vpc_optimization_dashboard.ipynb")
        notebook_output = notebook_input.parent / f"vpc_optimization_dashboard-executed-{self.timestamp}.ipynb"

        if not notebook_input.exists():
            print_warning(f"Notebook not found: {notebook_input}")
            return f"SKIPPED: {notebook_input} not found"

        try:
            # Check if papermill is available
            papermill_check = subprocess.run(
                [sys.executable, "-m", "papermill", "--version"],
                capture_output=True,
                text=True,
            )

            if papermill_check.returncode != 0:
                print_warning("papermill not installed - skipping notebook execution")
                print_info("Install with: uv pip install papermill")
                return "SKIPPED: papermill not available"

            # Execute notebook with papermill
            result = subprocess.run(
                [
                    sys.executable,
                    "-m",
                    "papermill",
                    str(notebook_input),
                    str(notebook_output),
                    "-p",
                    "aws_profile",
                    self.profile,
                    "-p",
                    "aws_region",
                    self.region,
                ],
                capture_output=True,
                text=True,
                timeout=300,
            )

            if result.returncode == 0:
                print_success(f"Notebook executed: {notebook_output}")
                return str(notebook_output)
            else:
                print_warning("Notebook execution failed")
                return f"FAILED: {result.stderr}"

        except subprocess.TimeoutExpired:
            print_warning("Notebook execution timeout (>5 minutes)")
            return "TIMEOUT: Execution exceeded 5 minutes"
        except Exception as e:
            print_warning(f"Notebook execution error: {e}")
            return f"ERROR: {str(e)}"

    async def _step_6_workflow_summary(self, workflow_results: Dict[str, Any]) -> Dict[str, Any]:
        """Step 6: Generate workflow summary and validation."""
        print_info("Generating workflow summary...")

        summary = {
            "workflow_status": "complete",
            "execution_time": datetime.now().isoformat(),
            "account_id": self.account_id,
            "region": self.region,
            "steps_completed": len(workflow_results["steps"]),
            "outputs": {
                "excel": workflow_results["steps"].get("excel"),
                "diagrams_count": len(workflow_results["steps"].get("diagrams", [])),
                "notebook": workflow_results["steps"].get("notebook"),
                "finops_status": workflow_results["steps"].get("finops", {}).get("status"),
            },
        }

        # Save workflow summary
        summary_file = self.artifacts_dir / f"workflow-summary-{self.timestamp}.json"
        with open(summary_file, "w") as f:
            json.dump(workflow_results, f, indent=2, default=str)

        print_success(f"Workflow summary saved: {summary_file}")

        return summary

    def _print_workflow_completion(self, workflow_results: Dict[str, Any]):
        """Print workflow completion summary."""
        self.console.print("\n" + "=" * 80)
        self.console.print("[bold green]âœ… UNIFIED WORKFLOW COMPLETE[/bold green]")
        self.console.print("=" * 80 + "\n")

        self.console.print(f"[cyan]Account:[/cyan] {self.account_id}")
        self.console.print(f"[cyan]Region:[/cyan] {self.region}")
        self.console.print(f"[cyan]Timestamp:[/cyan] {self.timestamp}\n")

        self.console.print("[bold]ðŸ“Š Outputs Generated:[/bold]")

        # Excel
        excel_file = workflow_results["steps"].get("excel")
        if excel_file and not excel_file.startswith("ERROR"):
            self.console.print(f"  â€¢ Excel: {excel_file}")

        # Diagrams
        diagrams = workflow_results["steps"].get("diagrams", [])
        self.console.print(f"  â€¢ Diagrams: {len(diagrams)} files")

        # Notebook
        notebook = workflow_results["steps"].get("notebook")
        if notebook and not notebook.startswith(("SKIPPED", "FAILED", "TIMEOUT", "ERROR")):
            self.console.print(f"  â€¢ Notebook: {notebook}")

        # FinOps
        finops_status = workflow_results["steps"].get("finops", {}).get("status")
        self.console.print(f"  â€¢ FinOps: {finops_status}")

        self.console.print("\n[bold]ðŸš€ Next Steps:[/bold]")
        self.console.print("  1. Review Excel file for executive summary")
        self.console.print("  2. Examine architecture diagrams for topology")
        self.console.print("  3. Analyze notebook for optimization recommendations")
        self.console.print("  4. Review FinOps data for cost projections\n")


# CLI Integration
async def main():
    """CLI entry point for unified workflow execution."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Unified AWS Network Discovery & Optimization Workflow",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic execution with management profile
  python unified_workflow.py vams-au-metering-elec-mass-security-ReadOnly ap-southeast-2

  # With separate billing profile for Cost Explorer
  python unified_workflow.py vams-au-metering-elec-mass-security-ReadOnly ap-southeast-2 vams-billing-profile

Integration Points:
  - MCP Servers: AWS discovery via awslabs.core-mcp
  - Runbooks: NetworkBaselineCollector, NetworkingCostEngine
  - Excel: NetworkDiscoveryExcelGenerator (9-11 sheets)
  - Diagrams: Python diagrams library (7 architecture diagrams)
  - Notebooks: Jupyter execution via papermill
  - FinOps: AWS Cost Explorer API integration
        """,
    )

    parser.add_argument(
        "profile",
        help="AWS profile for network discovery (management/security account)",
    )
    parser.add_argument(
        "region",
        help="AWS region for analysis (e.g., ap-southeast-2)",
    )
    parser.add_argument(
        "billing_profile",
        nargs="?",
        default=None,
        help="AWS profile for Cost Explorer API (defaults to profile)",
    )

    args = parser.parse_args()

    # Execute workflow
    workflow = UnifiedNetworkWorkflow(
        profile=args.profile,
        region=args.region,
        billing_profile=args.billing_profile,
    )

    results = await workflow.execute_full_workflow()

    # Exit with appropriate code
    if results["summary"]["workflow_status"] == "complete":
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
