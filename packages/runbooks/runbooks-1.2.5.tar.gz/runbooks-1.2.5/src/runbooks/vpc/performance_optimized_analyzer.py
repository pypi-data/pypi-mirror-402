#!/usr/bin/env python3
"""
Performance-Optimized VPC Analysis Engine

ðŸŽ¯ SRE Automation Specialist Implementation
Following proven systematic delegation patterns for VPC network operation optimization.

Addresses: VPC Analysis Timeout Issues & Network Operations Performance
Target: Reduce VPC analysis time to <30s from current timeout issues

Features:
- Parallel regional VPC analysis
- Connection pooling for multi-region operations
- Intelligent timeout handling and retry logic
- Memory-efficient large-scale VPC processing
- Rich progress indicators for long-running operations
- Automatic region failover and error recovery
"""

import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Dict, List, Optional, Set, Tuple, Any
import time

import boto3
from botocore.exceptions import ClientError, BotoCoreError
from rich.console import Console
from rich.progress import (
    Progress,
    SpinnerColumn,
    TextColumn,
    BarColumn,
    TimeElapsedColumn,
    TaskProgressColumn,
    MofNCompleteColumn,
)
from rich.panel import Panel
from rich.table import Table
from rich.status import Status

from runbooks.common.rich_utils import (
    console,
    print_header,
    print_success,
    print_warning,
    print_error,
    create_table,
    STATUS_INDICATORS,
)
from runbooks.common.performance_optimization_engine import get_optimization_engine

logger = logging.getLogger(__name__)


@dataclass
class VPCAnalysisResult:
    """VPC analysis result container"""

    vpc_id: str
    region: str
    analysis_data: Dict[str, Any] = field(default_factory=dict)
    subnets: List[Dict] = field(default_factory=list)
    route_tables: List[Dict] = field(default_factory=list)
    security_groups: List[Dict] = field(default_factory=list)
    network_interfaces: List[Dict] = field(default_factory=list)
    nat_gateways: List[Dict] = field(default_factory=list)
    internet_gateways: List[Dict] = field(default_factory=list)
    analysis_duration: float = 0.0
    error_message: Optional[str] = None
    success: bool = True


@dataclass
class RegionalAnalysisMetrics:
    """Metrics for regional analysis performance"""

    region: str
    start_time: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    end_time: Optional[datetime] = None
    duration_seconds: float = 0.0
    vpcs_analyzed: int = 0
    api_calls_made: int = 0
    errors_encountered: int = 0
    timeout_occurred: bool = False
    optimizations_applied: List[str] = field(default_factory=list)


class PerformanceOptimizedVPCAnalyzer:
    """
    Performance-optimized VPC analysis engine with SRE automation patterns

    Addresses VPC analysis timeout issues through:
    - Parallel regional processing with intelligent load balancing
    - Connection pooling and optimized AWS client configuration
    - Configurable timeouts with graceful degradation
    - Memory-efficient batch processing for large VPC environments
    - Real-time progress monitoring with Rich CLI indicators
    """

    # AWS regions for global VPC analysis
    DEFAULT_REGIONS = [
        "ap-southeast-2",
        "ap-southeast-6",
        "us-east-2",
        "us-west-1",
        "eu-west-1",
        "eu-west-2",
        "eu-central-1",
        "eu-north-1",
        "ap-southeast-1",
        "ap-southeast-2",
        "ap-northeast-1",
        "ap-northeast-2",
        "ap-south-1",
        "ca-central-1",
        "sa-east-1",
    ]

    def __init__(
        self,
        operational_profile: str,
        max_workers: int = 15,
        region_timeout_seconds: int = 45,
        overall_timeout_seconds: int = 300,
    ):
        """
        Initialize performance-optimized VPC analyzer

        Args:
            operational_profile: AWS profile for VPC operations
            max_workers: Maximum concurrent workers for parallel analysis
            region_timeout_seconds: Timeout per region analysis
            overall_timeout_seconds: Overall operation timeout
        """
        self.operational_profile = operational_profile
        self.max_workers = max_workers
        self.region_timeout_seconds = region_timeout_seconds
        self.overall_timeout_seconds = overall_timeout_seconds

        # Performance optimization engine
        self.optimization_engine = get_optimization_engine(
            max_workers=max_workers,
            cache_ttl_minutes=60,  # Longer cache for VPC data
            memory_limit_mb=3072,  # Higher limit for VPC analysis
        )

        # Analysis tracking
        self.regional_metrics: Dict[str, RegionalAnalysisMetrics] = {}
        self.vpc_results: Dict[str, List[VPCAnalysisResult]] = {}

    async def analyze_vpcs_globally(
        self, regions: Optional[List[str]] = None, include_detailed_analysis: bool = True
    ) -> Dict[str, Any]:
        """
        Perform global VPC analysis with performance optimization

        Args:
            regions: List of regions to analyze (defaults to all major regions)
            include_detailed_analysis: Whether to include detailed network component analysis

        Returns:
            Comprehensive VPC analysis results with performance metrics
        """
        if regions is None:
            regions = self.DEFAULT_REGIONS

        print_header("Performance-Optimized VPC Analysis", "SRE Automation Engine")

        # Start optimized analysis
        with self.optimization_engine.optimize_operation("global_vpc_analysis", 180.0):
            console.print(
                f"[cyan]ðŸŒ Analyzing VPCs across {len(regions)} regions with SRE optimization patterns[/cyan]"
            )
            console.print(
                f"[dim]Timeout per region: {self.region_timeout_seconds}s, Overall timeout: {self.overall_timeout_seconds}s[/dim]"
            )

            start_time = time.time()

            # Parallel regional analysis with progress tracking
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TaskProgressColumn(),
                MofNCompleteColumn(),
                TimeElapsedColumn(),
                console=console,
            ) as progress:
                analysis_task = progress.add_task("Analyzing VPCs globally...", total=len(regions))

                # Execute parallel regional analysis
                analysis_results = await self._analyze_regions_parallel(
                    regions, include_detailed_analysis, progress, analysis_task
                )

            # Aggregate results
            total_duration = time.time() - start_time
            summary = self._create_analysis_summary(analysis_results, total_duration)

            # Display performance summary
            self._display_performance_summary(summary)

            return summary

    async def _analyze_regions_parallel(
        self, regions: List[str], include_detailed: bool, progress: Progress, task_id
    ) -> Dict[str, Any]:
        """Execute parallel regional VPC analysis with timeout handling"""

        # Initialize regional metrics
        for region in regions:
            self.regional_metrics[region] = RegionalAnalysisMetrics(region=region)

        analysis_results = {}
        successful_regions = 0
        failed_regions = 0

        # Use ThreadPoolExecutor for parallel regional analysis
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit regional analysis tasks
            future_to_region = {
                executor.submit(self._analyze_vpc_region_optimized, region, include_detailed): region
                for region in regions
            }

            # Process completed tasks
            for future in as_completed(future_to_region, timeout=self.overall_timeout_seconds):
                region = future_to_region[future]

                try:
                    # Get result with per-region timeout
                    region_result = future.result(timeout=self.region_timeout_seconds)
                    analysis_results[region] = region_result

                    # Update metrics
                    metrics = self.regional_metrics[region]
                    metrics.end_time = datetime.now(timezone.utc)
                    metrics.duration_seconds = (metrics.end_time - metrics.start_time).total_seconds()
                    metrics.vpcs_analyzed = len(region_result.get("vpcs", []))

                    successful_regions += 1

                    progress.update(
                        task_id,
                        advance=1,
                        description=f"Completed {region} ({metrics.vpcs_analyzed} VPCs, {metrics.duration_seconds:.1f}s)",
                    )

                except TimeoutError:
                    logger.warning(f"VPC analysis timeout for region {region} after {self.region_timeout_seconds}s")
                    analysis_results[region] = {
                        "error": f"Analysis timeout after {self.region_timeout_seconds}s",
                        "vpcs": [],
                        "timeout": True,
                    }

                    # Update timeout metrics
                    metrics = self.regional_metrics[region]
                    metrics.timeout_occurred = True
                    metrics.end_time = datetime.now(timezone.utc)
                    metrics.duration_seconds = self.region_timeout_seconds

                    failed_regions += 1
                    progress.advance(task_id)

                except Exception as e:
                    logger.error(f"VPC analysis failed for region {region}: {e}")
                    analysis_results[region] = {"error": str(e), "vpcs": [], "failed": True}

                    # Update error metrics
                    metrics = self.regional_metrics[region]
                    metrics.errors_encountered += 1
                    metrics.end_time = datetime.now(timezone.utc)
                    metrics.duration_seconds = (metrics.end_time - metrics.start_time).total_seconds()

                    failed_regions += 1
                    progress.advance(task_id)

        return {
            "regional_results": analysis_results,
            "successful_regions": successful_regions,
            "failed_regions": failed_regions,
            "total_regions": len(regions),
        }

    def _analyze_vpc_region_optimized(self, region: str, include_detailed: bool) -> Dict[str, Any]:
        """Optimized VPC analysis for a specific region with performance enhancements"""

        metrics = self.regional_metrics[region]

        try:
            # Get optimized VPC analyzer from performance engine
            optimized_vpc_analysis = self.optimization_engine.optimize_vpc_analysis(
                operational_profile=self.operational_profile
            )

            # Execute regional analysis
            regional_data = optimized_vpc_analysis([region])
            region_vpcs = regional_data.get("vpc_data_by_region", {}).get(region, {})

            if "error" in region_vpcs:
                raise Exception(region_vpcs["error"])

            vpcs = region_vpcs.get("vpcs", [])
            metrics.vpcs_analyzed = len(vpcs)
            metrics.api_calls_made = region_vpcs.get("api_calls", 0)

            # Enhanced VPC analysis if requested
            if include_detailed and vpcs:
                vpcs = self._enrich_vpcs_with_details(vpcs, region)
                metrics.optimizations_applied.append("detailed_enrichment")

            # Apply additional performance optimizations
            if len(vpcs) > 10:
                metrics.optimizations_applied.append("batch_processing")

            metrics.optimizations_applied.extend(
                ["connection_pooling", "intelligent_caching", "parallel_regional_processing"]
            )

            return {
                "vpcs": vpcs,
                "region": region,
                "metrics": {
                    "vpcs_analyzed": metrics.vpcs_analyzed,
                    "api_calls_made": metrics.api_calls_made,
                    "optimizations_applied": metrics.optimizations_applied,
                },
            }

        except Exception as e:
            metrics.errors_encountered += 1
            logger.error(f"Optimized VPC analysis failed for region {region}: {e}")
            raise

    def _enrich_vpcs_with_details(self, vpcs: List[Dict], region: str) -> List[Dict]:
        """Enrich VPC data with detailed network component analysis"""

        try:
            # Use cached client from optimization engine
            ec2_client = self.optimization_engine.client_pool.get_client("ec2", self.operational_profile, region)

            for vpc in vpcs:
                vpc_id = vpc["VpcId"]

                # Get additional VPC components in parallel where possible
                try:
                    # Route tables
                    rt_response = ec2_client.describe_route_tables(Filters=[{"Name": "vpc-id", "Values": [vpc_id]}])
                    vpc["RouteTables"] = rt_response["RouteTables"]

                    # Security groups
                    sg_response = ec2_client.describe_security_groups(Filters=[{"Name": "vpc-id", "Values": [vpc_id]}])
                    vpc["SecurityGroups"] = sg_response["SecurityGroups"]

                    # NAT Gateways
                    nat_response = ec2_client.describe_nat_gateways(Filters=[{"Name": "vpc-id", "Values": [vpc_id]}])
                    vpc["NatGateways"] = nat_response["NatGateways"]

                    # Internet Gateways
                    igw_response = ec2_client.describe_internet_gateways(
                        Filters=[{"Name": "attachment.vpc-id", "Values": [vpc_id]}]
                    )
                    vpc["InternetGateways"] = igw_response["InternetGateways"]

                except Exception as detail_error:
                    logger.debug(f"Failed to get detailed info for VPC {vpc_id}: {detail_error}")
                    # Continue with basic VPC data

        except Exception as e:
            logger.warning(f"VPC enrichment failed for region {region}: {e}")

        return vpcs

    def _create_analysis_summary(self, analysis_results: Dict, total_duration: float) -> Dict[str, Any]:
        """Create comprehensive analysis summary with performance metrics"""

        regional_results = analysis_results.get("regional_results", {})
        successful_regions = analysis_results.get("successful_regions", 0)
        failed_regions = analysis_results.get("failed_regions", 0)

        # Aggregate VPC data
        total_vpcs = 0
        total_api_calls = 0
        regions_with_vpcs = 0
        all_optimizations = set()

        vpc_summary_by_region = {}

        for region, result in regional_results.items():
            if "error" not in result and not result.get("failed", False):
                vpcs = result.get("vpcs", [])
                total_vpcs += len(vpcs)

                if vpcs:
                    regions_with_vpcs += 1

                # Collect metrics
                region_metrics = result.get("metrics", {})
                total_api_calls += region_metrics.get("api_calls_made", 0)
                all_optimizations.update(region_metrics.get("optimizations_applied", []))

                vpc_summary_by_region[region] = {
                    "vpc_count": len(vpcs),
                    "analysis_duration": self.regional_metrics[region].duration_seconds,
                    "optimizations_applied": region_metrics.get("optimizations_applied", []),
                }

        # Performance analysis
        avg_duration_per_region = total_duration / len(regional_results) if regional_results else 0
        performance_grade = "A" if total_duration < 120 else "B" if total_duration < 180 else "C"

        return {
            "analysis_summary": {
                "total_regions_analyzed": len(regional_results),
                "successful_regions": successful_regions,
                "failed_regions": failed_regions,
                "regions_with_vpcs": regions_with_vpcs,
                "total_vpcs_discovered": total_vpcs,
                "total_duration_seconds": total_duration,
                "average_duration_per_region": avg_duration_per_region,
                "performance_grade": performance_grade,
            },
            "vpc_summary_by_region": vpc_summary_by_region,
            "regional_results": regional_results,
            "performance_metrics": {
                "total_api_calls": total_api_calls,
                "optimizations_applied": list(all_optimizations),
                "regional_metrics": {
                    region: {
                        "duration_seconds": metrics.duration_seconds,
                        "vpcs_analyzed": metrics.vpcs_analyzed,
                        "api_calls_made": metrics.api_calls_made,
                        "timeout_occurred": metrics.timeout_occurred,
                        "errors_encountered": metrics.errors_encountered,
                    }
                    for region, metrics in self.regional_metrics.items()
                },
            },
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

    def _display_performance_summary(self, summary: Dict[str, Any]):
        """Display comprehensive performance summary with Rich formatting"""

        analysis_summary = summary["analysis_summary"]
        performance_metrics = summary["performance_metrics"]

        # Performance overview panel
        performance_text = f"""
[bold cyan]ðŸ“Š VPC Analysis Performance Summary[/bold cyan]

[green]âœ… Regions Successful:[/green] {analysis_summary["successful_regions"]}/{analysis_summary["total_regions_analyzed"]}
[yellow]ðŸŒ VPCs Discovered:[/yellow] {analysis_summary["total_vpcs_discovered"]} across {analysis_summary["regions_with_vpcs"]} regions
[blue]â±ï¸  Total Duration:[/blue] {analysis_summary["total_duration_seconds"]:.1f}s (avg: {analysis_summary["average_duration_per_region"]:.1f}s/region)
[magenta]ðŸ“ˆ Performance Grade:[/magenta] {analysis_summary["performance_grade"]}
[dim]ðŸ”§ Optimizations Applied:[/dim] {", ".join(performance_metrics["optimizations_applied"])}
        """

        console.print(
            Panel(
                performance_text.strip(),
                title="[bold green]ðŸš€ SRE Optimization Results[/bold green]",
                border_style="green" if analysis_summary["performance_grade"] in ["A", "B"] else "yellow",
            )
        )

        # Regional performance table
        if summary["vpc_summary_by_region"]:
            table = create_table(
                title="Regional VPC Analysis Performance",
                columns=[
                    {"name": "Region", "style": "cyan", "justify": "left"},
                    {"name": "VPCs", "style": "yellow", "justify": "center"},
                    {"name": "Duration", "style": "white", "justify": "right"},
                    {"name": "Status", "style": "white", "justify": "center"},
                ],
            )

            for region, data in summary["vpc_summary_by_region"].items():
                duration = data["analysis_duration"]
                vpc_count = data["vpc_count"]

                # Determine status
                if duration <= 30:
                    status_icon = f"[green]{STATUS_INDICATORS['success']}[/green]"
                elif duration <= 45:
                    status_icon = f"[yellow]{STATUS_INDICATORS['warning']}[/yellow]"
                else:
                    status_icon = f"[red]{STATUS_INDICATORS['error']}[/red]"

                table.add_row(region, str(vpc_count), f"{duration:.1f}s", status_icon)

            console.print(table)

    def clear_analysis_cache(self):
        """Clear VPC analysis cache"""
        self.optimization_engine.clear_caches()
        self.regional_metrics.clear()
        self.vpc_results.clear()
        print_success("VPC analysis cache cleared")


# Convenience functions
def create_optimized_vpc_analyzer(operational_profile: str, max_workers: int = 15) -> PerformanceOptimizedVPCAnalyzer:
    """Create performance-optimized VPC analyzer instance"""
    return PerformanceOptimizedVPCAnalyzer(
        operational_profile=operational_profile,
        max_workers=max_workers,
        region_timeout_seconds=45,
        overall_timeout_seconds=300,
    )


async def run_optimized_global_vpc_analysis(
    operational_profile: str, regions: Optional[List[str]] = None, include_detailed: bool = True
) -> Dict[str, Any]:
    """Run optimized global VPC analysis"""
    analyzer = create_optimized_vpc_analyzer(operational_profile)
    return await analyzer.analyze_vpcs_globally(regions, include_detailed)


# Export public interface
__all__ = [
    "PerformanceOptimizedVPCAnalyzer",
    "VPCAnalysisResult",
    "RegionalAnalysisMetrics",
    "create_optimized_vpc_analyzer",
    "run_optimized_global_vpc_analysis",
]
