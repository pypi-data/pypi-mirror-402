# coding: utf-8

"""
    Sifflet Backend API

    Requirements: <br>    - [Create your access token through the UI](https://docs.siffletdata.com/docs/generate-an-api-token#create-an-api-token) <br>    - Get your tenant name: if you access to Sifflet with `https://abcdef.siffletdata.com`, then your tenant would be `abcdef`

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
from typing import Any, Dict, List, Optional, Set, Union

from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    StrictStr,
    ValidationError,
    field_validator,
)
from sifflet_sdk.client.models.adf_integration_params import AdfIntegrationParams
from sifflet_sdk.client.models.airflow_integration_params import (
    AirflowIntegrationParams,
)
from sifflet_sdk.client.models.athena_integration_params import AthenaIntegrationParams
from sifflet_sdk.client.models.big_query_integration_params import (
    BigQueryIntegrationParams,
)
from sifflet_sdk.client.models.composer_integration_params import (
    ComposerIntegrationParams,
)
from sifflet_sdk.client.models.databricks_integration_params import (
    DatabricksIntegrationParams,
)
from sifflet_sdk.client.models.databricks_jobs_integration_params import (
    DatabricksJobsIntegrationParams,
)
from sifflet_sdk.client.models.dbt_cloud_integration_params import (
    DbtCloudIntegrationParams,
)
from sifflet_sdk.client.models.dbt_integration_params import DbtIntegrationParams
from sifflet_sdk.client.models.declarative_integration_params import (
    DeclarativeIntegrationParams,
)
from sifflet_sdk.client.models.fivetran_integration_params import (
    FivetranIntegrationParams,
)
from sifflet_sdk.client.models.looker_integration_params import LookerIntegrationParams
from sifflet_sdk.client.models.microstrategy_integration_params import (
    MicrostrategyIntegrationParams,
)
from sifflet_sdk.client.models.mssql_integration_params import MssqlIntegrationParams
from sifflet_sdk.client.models.mwaa_integration_params import MwaaIntegrationParams
from sifflet_sdk.client.models.mysql_integration_params import MysqlIntegrationParams
from sifflet_sdk.client.models.oracle_integration_params import OracleIntegrationParams
from sifflet_sdk.client.models.postgres_integration_params import (
    PostgresIntegrationParams,
)
from sifflet_sdk.client.models.power_bi_integration_params import (
    PowerBiIntegrationParams,
)
from sifflet_sdk.client.models.qlik_integration_params import QlikIntegrationParams
from sifflet_sdk.client.models.quicksight_integration_params import (
    QuicksightIntegrationParams,
)
from sifflet_sdk.client.models.redshift_integration_params import (
    RedshiftIntegrationParams,
)
from sifflet_sdk.client.models.snowflake_integration_params import (
    SnowflakeIntegrationParams,
)
from sifflet_sdk.client.models.synapse_integration_params import (
    SynapseIntegrationParams,
)
from sifflet_sdk.client.models.tableau_integration_params import (
    TableauIntegrationParams,
)
from sifflet_sdk.client.models.unknown_integration_params import (
    UnknownIntegrationParams,
)
from typing_extensions import Literal, Self

DATASOURCEPARAMSINTEGRATIONPARAMS_ONE_OF_SCHEMAS = [
    "AdfIntegrationParams",
    "AirflowIntegrationParams",
    "AthenaIntegrationParams",
    "BigQueryIntegrationParams",
    "ComposerIntegrationParams",
    "DatabricksIntegrationParams",
    "DatabricksJobsIntegrationParams",
    "DbtCloudIntegrationParams",
    "DbtIntegrationParams",
    "DeclarativeIntegrationParams",
    "FivetranIntegrationParams",
    "LookerIntegrationParams",
    "MicrostrategyIntegrationParams",
    "MssqlIntegrationParams",
    "MwaaIntegrationParams",
    "MysqlIntegrationParams",
    "OracleIntegrationParams",
    "PostgresIntegrationParams",
    "PowerBiIntegrationParams",
    "QlikIntegrationParams",
    "QuicksightIntegrationParams",
    "RedshiftIntegrationParams",
    "SnowflakeIntegrationParams",
    "SynapseIntegrationParams",
    "TableauIntegrationParams",
    "UnknownIntegrationParams",
]


class DatasourceParamsIntegrationParams(BaseModel):
    """
    DatasourceParamsIntegrationParams
    """

    # data type: AdfIntegrationParams
    oneof_schema_1_validator: Optional[AdfIntegrationParams] = None
    # data type: AirflowIntegrationParams
    oneof_schema_2_validator: Optional[AirflowIntegrationParams] = None
    # data type: AthenaIntegrationParams
    oneof_schema_3_validator: Optional[AthenaIntegrationParams] = None
    # data type: BigQueryIntegrationParams
    oneof_schema_4_validator: Optional[BigQueryIntegrationParams] = None
    # data type: ComposerIntegrationParams
    oneof_schema_5_validator: Optional[ComposerIntegrationParams] = None
    # data type: DatabricksIntegrationParams
    oneof_schema_6_validator: Optional[DatabricksIntegrationParams] = None
    # data type: DatabricksJobsIntegrationParams
    oneof_schema_7_validator: Optional[DatabricksJobsIntegrationParams] = None
    # data type: DbtCloudIntegrationParams
    oneof_schema_8_validator: Optional[DbtCloudIntegrationParams] = None
    # data type: DbtIntegrationParams
    oneof_schema_9_validator: Optional[DbtIntegrationParams] = None
    # data type: DeclarativeIntegrationParams
    oneof_schema_10_validator: Optional[DeclarativeIntegrationParams] = None
    # data type: FivetranIntegrationParams
    oneof_schema_11_validator: Optional[FivetranIntegrationParams] = None
    # data type: LookerIntegrationParams
    oneof_schema_12_validator: Optional[LookerIntegrationParams] = None
    # data type: MicrostrategyIntegrationParams
    oneof_schema_13_validator: Optional[MicrostrategyIntegrationParams] = None
    # data type: MssqlIntegrationParams
    oneof_schema_14_validator: Optional[MssqlIntegrationParams] = None
    # data type: MwaaIntegrationParams
    oneof_schema_15_validator: Optional[MwaaIntegrationParams] = None
    # data type: MysqlIntegrationParams
    oneof_schema_16_validator: Optional[MysqlIntegrationParams] = None
    # data type: OracleIntegrationParams
    oneof_schema_17_validator: Optional[OracleIntegrationParams] = None
    # data type: PostgresIntegrationParams
    oneof_schema_18_validator: Optional[PostgresIntegrationParams] = None
    # data type: PowerBiIntegrationParams
    oneof_schema_19_validator: Optional[PowerBiIntegrationParams] = None
    # data type: QlikIntegrationParams
    oneof_schema_20_validator: Optional[QlikIntegrationParams] = None
    # data type: QuicksightIntegrationParams
    oneof_schema_21_validator: Optional[QuicksightIntegrationParams] = None
    # data type: RedshiftIntegrationParams
    oneof_schema_22_validator: Optional[RedshiftIntegrationParams] = None
    # data type: SnowflakeIntegrationParams
    oneof_schema_23_validator: Optional[SnowflakeIntegrationParams] = None
    # data type: SynapseIntegrationParams
    oneof_schema_24_validator: Optional[SynapseIntegrationParams] = None
    # data type: TableauIntegrationParams
    oneof_schema_25_validator: Optional[TableauIntegrationParams] = None
    # data type: UnknownIntegrationParams
    oneof_schema_26_validator: Optional[UnknownIntegrationParams] = None
    actual_instance: Optional[
        Union[
            AdfIntegrationParams,
            AirflowIntegrationParams,
            AthenaIntegrationParams,
            BigQueryIntegrationParams,
            ComposerIntegrationParams,
            DatabricksIntegrationParams,
            DatabricksJobsIntegrationParams,
            DbtCloudIntegrationParams,
            DbtIntegrationParams,
            DeclarativeIntegrationParams,
            FivetranIntegrationParams,
            LookerIntegrationParams,
            MicrostrategyIntegrationParams,
            MssqlIntegrationParams,
            MwaaIntegrationParams,
            MysqlIntegrationParams,
            OracleIntegrationParams,
            PostgresIntegrationParams,
            PowerBiIntegrationParams,
            QlikIntegrationParams,
            QuicksightIntegrationParams,
            RedshiftIntegrationParams,
            SnowflakeIntegrationParams,
            SynapseIntegrationParams,
            TableauIntegrationParams,
            UnknownIntegrationParams,
        ]
    ] = None
    one_of_schemas: Set[str] = {
        "AdfIntegrationParams",
        "AirflowIntegrationParams",
        "AthenaIntegrationParams",
        "BigQueryIntegrationParams",
        "ComposerIntegrationParams",
        "DatabricksIntegrationParams",
        "DatabricksJobsIntegrationParams",
        "DbtCloudIntegrationParams",
        "DbtIntegrationParams",
        "DeclarativeIntegrationParams",
        "FivetranIntegrationParams",
        "LookerIntegrationParams",
        "MicrostrategyIntegrationParams",
        "MssqlIntegrationParams",
        "MwaaIntegrationParams",
        "MysqlIntegrationParams",
        "OracleIntegrationParams",
        "PostgresIntegrationParams",
        "PowerBiIntegrationParams",
        "QlikIntegrationParams",
        "QuicksightIntegrationParams",
        "RedshiftIntegrationParams",
        "SnowflakeIntegrationParams",
        "SynapseIntegrationParams",
        "TableauIntegrationParams",
        "UnknownIntegrationParams",
    }

    model_config = ConfigDict(
        validate_assignment=True,
        protected_namespaces=(),
    )

    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator("actual_instance")
    def actual_instance_must_validate_oneof(cls, v):
        instance = DatasourceParamsIntegrationParams.model_construct()
        error_messages = []
        match = 0
        # validate data type: AdfIntegrationParams
        if not isinstance(v, AdfIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AdfIntegrationParams`")
        else:
            match += 1
        # validate data type: AirflowIntegrationParams
        if not isinstance(v, AirflowIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AirflowIntegrationParams`")
        else:
            match += 1
        # validate data type: AthenaIntegrationParams
        if not isinstance(v, AthenaIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AthenaIntegrationParams`")
        else:
            match += 1
        # validate data type: BigQueryIntegrationParams
        if not isinstance(v, BigQueryIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `BigQueryIntegrationParams`")
        else:
            match += 1
        # validate data type: ComposerIntegrationParams
        if not isinstance(v, ComposerIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `ComposerIntegrationParams`")
        else:
            match += 1
        # validate data type: DatabricksIntegrationParams
        if not isinstance(v, DatabricksIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DatabricksIntegrationParams`")
        else:
            match += 1
        # validate data type: DatabricksJobsIntegrationParams
        if not isinstance(v, DatabricksJobsIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DatabricksJobsIntegrationParams`")
        else:
            match += 1
        # validate data type: DbtCloudIntegrationParams
        if not isinstance(v, DbtCloudIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DbtCloudIntegrationParams`")
        else:
            match += 1
        # validate data type: DbtIntegrationParams
        if not isinstance(v, DbtIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DbtIntegrationParams`")
        else:
            match += 1
        # validate data type: DeclarativeIntegrationParams
        if not isinstance(v, DeclarativeIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DeclarativeIntegrationParams`")
        else:
            match += 1
        # validate data type: FivetranIntegrationParams
        if not isinstance(v, FivetranIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `FivetranIntegrationParams`")
        else:
            match += 1
        # validate data type: LookerIntegrationParams
        if not isinstance(v, LookerIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `LookerIntegrationParams`")
        else:
            match += 1
        # validate data type: MicrostrategyIntegrationParams
        if not isinstance(v, MicrostrategyIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MicrostrategyIntegrationParams`")
        else:
            match += 1
        # validate data type: MssqlIntegrationParams
        if not isinstance(v, MssqlIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MssqlIntegrationParams`")
        else:
            match += 1
        # validate data type: MwaaIntegrationParams
        if not isinstance(v, MwaaIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MwaaIntegrationParams`")
        else:
            match += 1
        # validate data type: MysqlIntegrationParams
        if not isinstance(v, MysqlIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MysqlIntegrationParams`")
        else:
            match += 1
        # validate data type: OracleIntegrationParams
        if not isinstance(v, OracleIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `OracleIntegrationParams`")
        else:
            match += 1
        # validate data type: PostgresIntegrationParams
        if not isinstance(v, PostgresIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PostgresIntegrationParams`")
        else:
            match += 1
        # validate data type: PowerBiIntegrationParams
        if not isinstance(v, PowerBiIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PowerBiIntegrationParams`")
        else:
            match += 1
        # validate data type: QlikIntegrationParams
        if not isinstance(v, QlikIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `QlikIntegrationParams`")
        else:
            match += 1
        # validate data type: QuicksightIntegrationParams
        if not isinstance(v, QuicksightIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `QuicksightIntegrationParams`")
        else:
            match += 1
        # validate data type: RedshiftIntegrationParams
        if not isinstance(v, RedshiftIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `RedshiftIntegrationParams`")
        else:
            match += 1
        # validate data type: SnowflakeIntegrationParams
        if not isinstance(v, SnowflakeIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SnowflakeIntegrationParams`")
        else:
            match += 1
        # validate data type: SynapseIntegrationParams
        if not isinstance(v, SynapseIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SynapseIntegrationParams`")
        else:
            match += 1
        # validate data type: TableauIntegrationParams
        if not isinstance(v, TableauIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `TableauIntegrationParams`")
        else:
            match += 1
        # validate data type: UnknownIntegrationParams
        if not isinstance(v, UnknownIntegrationParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `UnknownIntegrationParams`")
        else:
            match += 1
        if match > 1:
            # more than 1 match
            raise ValueError(
                "Multiple matches found when setting `actual_instance` in DatasourceParamsIntegrationParams with oneOf schemas: AdfIntegrationParams, AirflowIntegrationParams, AthenaIntegrationParams, BigQueryIntegrationParams, ComposerIntegrationParams, DatabricksIntegrationParams, DatabricksJobsIntegrationParams, DbtCloudIntegrationParams, DbtIntegrationParams, DeclarativeIntegrationParams, FivetranIntegrationParams, LookerIntegrationParams, MicrostrategyIntegrationParams, MssqlIntegrationParams, MwaaIntegrationParams, MysqlIntegrationParams, OracleIntegrationParams, PostgresIntegrationParams, PowerBiIntegrationParams, QlikIntegrationParams, QuicksightIntegrationParams, RedshiftIntegrationParams, SnowflakeIntegrationParams, SynapseIntegrationParams, TableauIntegrationParams, UnknownIntegrationParams. Details: "
                + ", ".join(error_messages)
            )
        elif match == 0:
            # no match
            raise ValueError(
                "No match found when setting `actual_instance` in DatasourceParamsIntegrationParams with oneOf schemas: AdfIntegrationParams, AirflowIntegrationParams, AthenaIntegrationParams, BigQueryIntegrationParams, ComposerIntegrationParams, DatabricksIntegrationParams, DatabricksJobsIntegrationParams, DbtCloudIntegrationParams, DbtIntegrationParams, DeclarativeIntegrationParams, FivetranIntegrationParams, LookerIntegrationParams, MicrostrategyIntegrationParams, MssqlIntegrationParams, MwaaIntegrationParams, MysqlIntegrationParams, OracleIntegrationParams, PostgresIntegrationParams, PowerBiIntegrationParams, QlikIntegrationParams, QuicksightIntegrationParams, RedshiftIntegrationParams, SnowflakeIntegrationParams, SynapseIntegrationParams, TableauIntegrationParams, UnknownIntegrationParams. Details: "
                + ", ".join(error_messages)
            )
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Union[str, Dict[str, Any]]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        match = 0

        # deserialize data into AdfIntegrationParams
        try:
            instance.actual_instance = AdfIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AirflowIntegrationParams
        try:
            instance.actual_instance = AirflowIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AthenaIntegrationParams
        try:
            instance.actual_instance = AthenaIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into BigQueryIntegrationParams
        try:
            instance.actual_instance = BigQueryIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into ComposerIntegrationParams
        try:
            instance.actual_instance = ComposerIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DatabricksIntegrationParams
        try:
            instance.actual_instance = DatabricksIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DatabricksJobsIntegrationParams
        try:
            instance.actual_instance = DatabricksJobsIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DbtCloudIntegrationParams
        try:
            instance.actual_instance = DbtCloudIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DbtIntegrationParams
        try:
            instance.actual_instance = DbtIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DeclarativeIntegrationParams
        try:
            instance.actual_instance = DeclarativeIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into FivetranIntegrationParams
        try:
            instance.actual_instance = FivetranIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into LookerIntegrationParams
        try:
            instance.actual_instance = LookerIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MicrostrategyIntegrationParams
        try:
            instance.actual_instance = MicrostrategyIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MssqlIntegrationParams
        try:
            instance.actual_instance = MssqlIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MwaaIntegrationParams
        try:
            instance.actual_instance = MwaaIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MysqlIntegrationParams
        try:
            instance.actual_instance = MysqlIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into OracleIntegrationParams
        try:
            instance.actual_instance = OracleIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PostgresIntegrationParams
        try:
            instance.actual_instance = PostgresIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PowerBiIntegrationParams
        try:
            instance.actual_instance = PowerBiIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into QlikIntegrationParams
        try:
            instance.actual_instance = QlikIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into QuicksightIntegrationParams
        try:
            instance.actual_instance = QuicksightIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into RedshiftIntegrationParams
        try:
            instance.actual_instance = RedshiftIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SnowflakeIntegrationParams
        try:
            instance.actual_instance = SnowflakeIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SynapseIntegrationParams
        try:
            instance.actual_instance = SynapseIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into TableauIntegrationParams
        try:
            instance.actual_instance = TableauIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into UnknownIntegrationParams
        try:
            instance.actual_instance = UnknownIntegrationParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError(
                "Multiple matches found when deserializing the JSON string into DatasourceParamsIntegrationParams with oneOf schemas: AdfIntegrationParams, AirflowIntegrationParams, AthenaIntegrationParams, BigQueryIntegrationParams, ComposerIntegrationParams, DatabricksIntegrationParams, DatabricksJobsIntegrationParams, DbtCloudIntegrationParams, DbtIntegrationParams, DeclarativeIntegrationParams, FivetranIntegrationParams, LookerIntegrationParams, MicrostrategyIntegrationParams, MssqlIntegrationParams, MwaaIntegrationParams, MysqlIntegrationParams, OracleIntegrationParams, PostgresIntegrationParams, PowerBiIntegrationParams, QlikIntegrationParams, QuicksightIntegrationParams, RedshiftIntegrationParams, SnowflakeIntegrationParams, SynapseIntegrationParams, TableauIntegrationParams, UnknownIntegrationParams. Details: "
                + ", ".join(error_messages)
            )
        elif match == 0:
            # no match
            raise ValueError(
                "No match found when deserializing the JSON string into DatasourceParamsIntegrationParams with oneOf schemas: AdfIntegrationParams, AirflowIntegrationParams, AthenaIntegrationParams, BigQueryIntegrationParams, ComposerIntegrationParams, DatabricksIntegrationParams, DatabricksJobsIntegrationParams, DbtCloudIntegrationParams, DbtIntegrationParams, DeclarativeIntegrationParams, FivetranIntegrationParams, LookerIntegrationParams, MicrostrategyIntegrationParams, MssqlIntegrationParams, MwaaIntegrationParams, MysqlIntegrationParams, OracleIntegrationParams, PostgresIntegrationParams, PowerBiIntegrationParams, QlikIntegrationParams, QuicksightIntegrationParams, RedshiftIntegrationParams, SnowflakeIntegrationParams, SynapseIntegrationParams, TableauIntegrationParams, UnknownIntegrationParams. Details: "
                + ", ".join(error_messages)
            )
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(
        self,
    ) -> Optional[
        Union[
            Dict[str, Any],
            AdfIntegrationParams,
            AirflowIntegrationParams,
            AthenaIntegrationParams,
            BigQueryIntegrationParams,
            ComposerIntegrationParams,
            DatabricksIntegrationParams,
            DatabricksJobsIntegrationParams,
            DbtCloudIntegrationParams,
            DbtIntegrationParams,
            DeclarativeIntegrationParams,
            FivetranIntegrationParams,
            LookerIntegrationParams,
            MicrostrategyIntegrationParams,
            MssqlIntegrationParams,
            MwaaIntegrationParams,
            MysqlIntegrationParams,
            OracleIntegrationParams,
            PostgresIntegrationParams,
            PowerBiIntegrationParams,
            QlikIntegrationParams,
            QuicksightIntegrationParams,
            RedshiftIntegrationParams,
            SnowflakeIntegrationParams,
            SynapseIntegrationParams,
            TableauIntegrationParams,
            UnknownIntegrationParams,
        ]
    ]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())
