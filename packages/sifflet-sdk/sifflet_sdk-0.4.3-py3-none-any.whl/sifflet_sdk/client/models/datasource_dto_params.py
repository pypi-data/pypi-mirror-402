# coding: utf-8

"""
    Sifflet Backend API

    Requirements: <br>    - [Create your access token through the UI](https://docs.siffletdata.com/docs/generate-an-api-token#create-an-api-token) <br>    - Get your tenant name: if you access to Sifflet with `https://abcdef.siffletdata.com`, then your tenant would be `abcdef`

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
from typing import Any, Dict, List, Optional, Set, Union

from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    StrictStr,
    ValidationError,
    field_validator,
)
from sifflet_sdk.client.models.adf_params import AdfParams
from sifflet_sdk.client.models.airflow_params import AirflowParams
from sifflet_sdk.client.models.athena_params import AthenaParams
from sifflet_sdk.client.models.big_query_params import BigQueryParams
from sifflet_sdk.client.models.composer_params import ComposerParams
from sifflet_sdk.client.models.databricks_jobs_params import DatabricksJobsParams
from sifflet_sdk.client.models.databricks_params import DatabricksParams
from sifflet_sdk.client.models.dbt_cloud_params import DBTCloudParams
from sifflet_sdk.client.models.dbt_params import DBTParams
from sifflet_sdk.client.models.declarative_params import DeclarativeParams
from sifflet_sdk.client.models.fivetran_params import FivetranParams
from sifflet_sdk.client.models.looker_params import LookerParams
from sifflet_sdk.client.models.microstrategy_params import MicrostrategyParams
from sifflet_sdk.client.models.mssql_params import MssqlParams
from sifflet_sdk.client.models.mwaa_params import MwaaParams
from sifflet_sdk.client.models.mysql_params import MysqlParams
from sifflet_sdk.client.models.oracle_params import OracleParams
from sifflet_sdk.client.models.postgres_params import PostgresParams
from sifflet_sdk.client.models.power_bi_params import PowerBiParams
from sifflet_sdk.client.models.qlik_params import QlikParams
from sifflet_sdk.client.models.quick_sight_params import QuickSightParams
from sifflet_sdk.client.models.redshift_params import RedshiftParams
from sifflet_sdk.client.models.snowflake_params import SnowflakeParams
from sifflet_sdk.client.models.synapse_params import SynapseParams
from sifflet_sdk.client.models.tableau_params import TableauParams
from sifflet_sdk.client.models.unknown_datasource_params import UnknownDatasourceParams
from typing_extensions import Literal, Self

DATASOURCEDTOPARAMS_ONE_OF_SCHEMAS = [
    "AdfParams",
    "AirflowParams",
    "AthenaParams",
    "BigQueryParams",
    "ComposerParams",
    "DBTCloudParams",
    "DBTParams",
    "DatabricksJobsParams",
    "DatabricksParams",
    "DeclarativeParams",
    "FivetranParams",
    "LookerParams",
    "MicrostrategyParams",
    "MssqlParams",
    "MwaaParams",
    "MysqlParams",
    "OracleParams",
    "PostgresParams",
    "PowerBiParams",
    "QlikParams",
    "QuickSightParams",
    "RedshiftParams",
    "SnowflakeParams",
    "SynapseParams",
    "TableauParams",
    "UnknownDatasourceParams",
]


class DatasourceDtoParams(BaseModel):
    """
    DatasourceDtoParams
    """

    # data type: AdfParams
    oneof_schema_1_validator: Optional[AdfParams] = None
    # data type: AirflowParams
    oneof_schema_2_validator: Optional[AirflowParams] = None
    # data type: AthenaParams
    oneof_schema_3_validator: Optional[AthenaParams] = None
    # data type: BigQueryParams
    oneof_schema_4_validator: Optional[BigQueryParams] = None
    # data type: ComposerParams
    oneof_schema_5_validator: Optional[ComposerParams] = None
    # data type: DBTCloudParams
    oneof_schema_6_validator: Optional[DBTCloudParams] = None
    # data type: DBTParams
    oneof_schema_7_validator: Optional[DBTParams] = None
    # data type: DatabricksJobsParams
    oneof_schema_8_validator: Optional[DatabricksJobsParams] = None
    # data type: DatabricksParams
    oneof_schema_9_validator: Optional[DatabricksParams] = None
    # data type: DeclarativeParams
    oneof_schema_10_validator: Optional[DeclarativeParams] = None
    # data type: FivetranParams
    oneof_schema_11_validator: Optional[FivetranParams] = None
    # data type: LookerParams
    oneof_schema_12_validator: Optional[LookerParams] = None
    # data type: MicrostrategyParams
    oneof_schema_13_validator: Optional[MicrostrategyParams] = None
    # data type: MssqlParams
    oneof_schema_14_validator: Optional[MssqlParams] = None
    # data type: MwaaParams
    oneof_schema_15_validator: Optional[MwaaParams] = None
    # data type: MysqlParams
    oneof_schema_16_validator: Optional[MysqlParams] = None
    # data type: OracleParams
    oneof_schema_17_validator: Optional[OracleParams] = None
    # data type: PostgresParams
    oneof_schema_18_validator: Optional[PostgresParams] = None
    # data type: PowerBiParams
    oneof_schema_19_validator: Optional[PowerBiParams] = None
    # data type: QlikParams
    oneof_schema_20_validator: Optional[QlikParams] = None
    # data type: QuickSightParams
    oneof_schema_21_validator: Optional[QuickSightParams] = None
    # data type: RedshiftParams
    oneof_schema_22_validator: Optional[RedshiftParams] = None
    # data type: SnowflakeParams
    oneof_schema_23_validator: Optional[SnowflakeParams] = None
    # data type: SynapseParams
    oneof_schema_24_validator: Optional[SynapseParams] = None
    # data type: TableauParams
    oneof_schema_25_validator: Optional[TableauParams] = None
    # data type: UnknownDatasourceParams
    oneof_schema_26_validator: Optional[UnknownDatasourceParams] = None
    actual_instance: Optional[
        Union[
            AdfParams,
            AirflowParams,
            AthenaParams,
            BigQueryParams,
            ComposerParams,
            DBTCloudParams,
            DBTParams,
            DatabricksJobsParams,
            DatabricksParams,
            DeclarativeParams,
            FivetranParams,
            LookerParams,
            MicrostrategyParams,
            MssqlParams,
            MwaaParams,
            MysqlParams,
            OracleParams,
            PostgresParams,
            PowerBiParams,
            QlikParams,
            QuickSightParams,
            RedshiftParams,
            SnowflakeParams,
            SynapseParams,
            TableauParams,
            UnknownDatasourceParams,
        ]
    ] = None
    one_of_schemas: Set[str] = {
        "AdfParams",
        "AirflowParams",
        "AthenaParams",
        "BigQueryParams",
        "ComposerParams",
        "DBTCloudParams",
        "DBTParams",
        "DatabricksJobsParams",
        "DatabricksParams",
        "DeclarativeParams",
        "FivetranParams",
        "LookerParams",
        "MicrostrategyParams",
        "MssqlParams",
        "MwaaParams",
        "MysqlParams",
        "OracleParams",
        "PostgresParams",
        "PowerBiParams",
        "QlikParams",
        "QuickSightParams",
        "RedshiftParams",
        "SnowflakeParams",
        "SynapseParams",
        "TableauParams",
        "UnknownDatasourceParams",
    }

    model_config = ConfigDict(
        validate_assignment=True,
        protected_namespaces=(),
    )

    discriminator_value_class_map: Dict[str, str] = {}

    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator("actual_instance")
    def actual_instance_must_validate_oneof(cls, v):
        instance = DatasourceDtoParams.model_construct()
        error_messages = []
        match = 0
        # validate data type: AdfParams
        if not isinstance(v, AdfParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AdfParams`")
        else:
            match += 1
        # validate data type: AirflowParams
        if not isinstance(v, AirflowParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AirflowParams`")
        else:
            match += 1
        # validate data type: AthenaParams
        if not isinstance(v, AthenaParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AthenaParams`")
        else:
            match += 1
        # validate data type: BigQueryParams
        if not isinstance(v, BigQueryParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `BigQueryParams`")
        else:
            match += 1
        # validate data type: ComposerParams
        if not isinstance(v, ComposerParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `ComposerParams`")
        else:
            match += 1
        # validate data type: DBTCloudParams
        if not isinstance(v, DBTCloudParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DBTCloudParams`")
        else:
            match += 1
        # validate data type: DBTParams
        if not isinstance(v, DBTParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DBTParams`")
        else:
            match += 1
        # validate data type: DatabricksJobsParams
        if not isinstance(v, DatabricksJobsParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DatabricksJobsParams`")
        else:
            match += 1
        # validate data type: DatabricksParams
        if not isinstance(v, DatabricksParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DatabricksParams`")
        else:
            match += 1
        # validate data type: DeclarativeParams
        if not isinstance(v, DeclarativeParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DeclarativeParams`")
        else:
            match += 1
        # validate data type: FivetranParams
        if not isinstance(v, FivetranParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `FivetranParams`")
        else:
            match += 1
        # validate data type: LookerParams
        if not isinstance(v, LookerParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `LookerParams`")
        else:
            match += 1
        # validate data type: MicrostrategyParams
        if not isinstance(v, MicrostrategyParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MicrostrategyParams`")
        else:
            match += 1
        # validate data type: MssqlParams
        if not isinstance(v, MssqlParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MssqlParams`")
        else:
            match += 1
        # validate data type: MwaaParams
        if not isinstance(v, MwaaParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MwaaParams`")
        else:
            match += 1
        # validate data type: MysqlParams
        if not isinstance(v, MysqlParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MysqlParams`")
        else:
            match += 1
        # validate data type: OracleParams
        if not isinstance(v, OracleParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `OracleParams`")
        else:
            match += 1
        # validate data type: PostgresParams
        if not isinstance(v, PostgresParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PostgresParams`")
        else:
            match += 1
        # validate data type: PowerBiParams
        if not isinstance(v, PowerBiParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PowerBiParams`")
        else:
            match += 1
        # validate data type: QlikParams
        if not isinstance(v, QlikParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `QlikParams`")
        else:
            match += 1
        # validate data type: QuickSightParams
        if not isinstance(v, QuickSightParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `QuickSightParams`")
        else:
            match += 1
        # validate data type: RedshiftParams
        if not isinstance(v, RedshiftParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `RedshiftParams`")
        else:
            match += 1
        # validate data type: SnowflakeParams
        if not isinstance(v, SnowflakeParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SnowflakeParams`")
        else:
            match += 1
        # validate data type: SynapseParams
        if not isinstance(v, SynapseParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SynapseParams`")
        else:
            match += 1
        # validate data type: TableauParams
        if not isinstance(v, TableauParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `TableauParams`")
        else:
            match += 1
        # validate data type: UnknownDatasourceParams
        if not isinstance(v, UnknownDatasourceParams):
            error_messages.append(f"Error! Input type `{type(v)}` is not `UnknownDatasourceParams`")
        else:
            match += 1
        if match > 1:
            # more than 1 match
            raise ValueError(
                "Multiple matches found when setting `actual_instance` in DatasourceDtoParams with oneOf schemas: AdfParams, AirflowParams, AthenaParams, BigQueryParams, ComposerParams, DBTCloudParams, DBTParams, DatabricksJobsParams, DatabricksParams, DeclarativeParams, FivetranParams, LookerParams, MicrostrategyParams, MssqlParams, MwaaParams, MysqlParams, OracleParams, PostgresParams, PowerBiParams, QlikParams, QuickSightParams, RedshiftParams, SnowflakeParams, SynapseParams, TableauParams, UnknownDatasourceParams. Details: "
                + ", ".join(error_messages)
            )
        elif match == 0:
            # no match
            raise ValueError(
                "No match found when setting `actual_instance` in DatasourceDtoParams with oneOf schemas: AdfParams, AirflowParams, AthenaParams, BigQueryParams, ComposerParams, DBTCloudParams, DBTParams, DatabricksJobsParams, DatabricksParams, DeclarativeParams, FivetranParams, LookerParams, MicrostrategyParams, MssqlParams, MwaaParams, MysqlParams, OracleParams, PostgresParams, PowerBiParams, QlikParams, QuickSightParams, RedshiftParams, SnowflakeParams, SynapseParams, TableauParams, UnknownDatasourceParams. Details: "
                + ", ".join(error_messages)
            )
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Union[str, Dict[str, Any]]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        match = 0

        # use oneOf discriminator to lookup the data type
        _data_type = json.loads(json_str).get("type")
        if not _data_type:
            raise ValueError("Failed to lookup data type from the field `type` in the input.")

        # check if data type is `AdfParams`
        if _data_type == "AdfParams":
            instance.actual_instance = AdfParams.from_json(json_str)
            return instance

        # check if data type is `AirflowParams`
        if _data_type == "AirflowParams":
            instance.actual_instance = AirflowParams.from_json(json_str)
            return instance

        # check if data type is `AthenaParams`
        if _data_type == "AthenaParams":
            instance.actual_instance = AthenaParams.from_json(json_str)
            return instance

        # check if data type is `BigQueryParams`
        if _data_type == "BigQueryParams":
            instance.actual_instance = BigQueryParams.from_json(json_str)
            return instance

        # check if data type is `ComposerParams`
        if _data_type == "ComposerParams":
            instance.actual_instance = ComposerParams.from_json(json_str)
            return instance

        # check if data type is `DBTCloudParams`
        if _data_type == "DBTCloudParams":
            instance.actual_instance = DBTCloudParams.from_json(json_str)
            return instance

        # check if data type is `DBTParams`
        if _data_type == "DBTParams":
            instance.actual_instance = DBTParams.from_json(json_str)
            return instance

        # check if data type is `DatabricksJobsParams`
        if _data_type == "DatabricksJobsParams":
            instance.actual_instance = DatabricksJobsParams.from_json(json_str)
            return instance

        # check if data type is `DatabricksParams`
        if _data_type == "DatabricksParams":
            instance.actual_instance = DatabricksParams.from_json(json_str)
            return instance

        # check if data type is `DeclarativeParams`
        if _data_type == "DeclarativeParams":
            instance.actual_instance = DeclarativeParams.from_json(json_str)
            return instance

        # check if data type is `FivetranParams`
        if _data_type == "FivetranParams":
            instance.actual_instance = FivetranParams.from_json(json_str)
            return instance

        # check if data type is `LookerParams`
        if _data_type == "LookerParams":
            instance.actual_instance = LookerParams.from_json(json_str)
            return instance

        # check if data type is `MicrostrategyParams`
        if _data_type == "MicrostrategyParams":
            instance.actual_instance = MicrostrategyParams.from_json(json_str)
            return instance

        # check if data type is `MssqlParams`
        if _data_type == "MssqlParams":
            instance.actual_instance = MssqlParams.from_json(json_str)
            return instance

        # check if data type is `MwaaParams`
        if _data_type == "MwaaParams":
            instance.actual_instance = MwaaParams.from_json(json_str)
            return instance

        # check if data type is `MysqlParams`
        if _data_type == "MysqlParams":
            instance.actual_instance = MysqlParams.from_json(json_str)
            return instance

        # check if data type is `OracleParams`
        if _data_type == "OracleParams":
            instance.actual_instance = OracleParams.from_json(json_str)
            return instance

        # check if data type is `PostgresParams`
        if _data_type == "PostgresParams":
            instance.actual_instance = PostgresParams.from_json(json_str)
            return instance

        # check if data type is `PowerBiParams`
        if _data_type == "PowerBiParams":
            instance.actual_instance = PowerBiParams.from_json(json_str)
            return instance

        # check if data type is `QlikParams`
        if _data_type == "QlikParams":
            instance.actual_instance = QlikParams.from_json(json_str)
            return instance

        # check if data type is `QuickSightParams`
        if _data_type == "QuickSightParams":
            instance.actual_instance = QuickSightParams.from_json(json_str)
            return instance

        # check if data type is `RedshiftParams`
        if _data_type == "RedshiftParams":
            instance.actual_instance = RedshiftParams.from_json(json_str)
            return instance

        # check if data type is `SnowflakeParams`
        if _data_type == "SnowflakeParams":
            instance.actual_instance = SnowflakeParams.from_json(json_str)
            return instance

        # check if data type is `SynapseParams`
        if _data_type == "SynapseParams":
            instance.actual_instance = SynapseParams.from_json(json_str)
            return instance

        # check if data type is `TableauParams`
        if _data_type == "TableauParams":
            instance.actual_instance = TableauParams.from_json(json_str)
            return instance

        # check if data type is `UnknownDatasourceParams`
        if _data_type == "UnknownDatasourceParams":
            instance.actual_instance = UnknownDatasourceParams.from_json(json_str)
            return instance

        # deserialize data into AdfParams
        try:
            instance.actual_instance = AdfParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AirflowParams
        try:
            instance.actual_instance = AirflowParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AthenaParams
        try:
            instance.actual_instance = AthenaParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into BigQueryParams
        try:
            instance.actual_instance = BigQueryParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into ComposerParams
        try:
            instance.actual_instance = ComposerParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DBTCloudParams
        try:
            instance.actual_instance = DBTCloudParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DBTParams
        try:
            instance.actual_instance = DBTParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DatabricksJobsParams
        try:
            instance.actual_instance = DatabricksJobsParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DatabricksParams
        try:
            instance.actual_instance = DatabricksParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DeclarativeParams
        try:
            instance.actual_instance = DeclarativeParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into FivetranParams
        try:
            instance.actual_instance = FivetranParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into LookerParams
        try:
            instance.actual_instance = LookerParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MicrostrategyParams
        try:
            instance.actual_instance = MicrostrategyParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MssqlParams
        try:
            instance.actual_instance = MssqlParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MwaaParams
        try:
            instance.actual_instance = MwaaParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MysqlParams
        try:
            instance.actual_instance = MysqlParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into OracleParams
        try:
            instance.actual_instance = OracleParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PostgresParams
        try:
            instance.actual_instance = PostgresParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PowerBiParams
        try:
            instance.actual_instance = PowerBiParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into QlikParams
        try:
            instance.actual_instance = QlikParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into QuickSightParams
        try:
            instance.actual_instance = QuickSightParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into RedshiftParams
        try:
            instance.actual_instance = RedshiftParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SnowflakeParams
        try:
            instance.actual_instance = SnowflakeParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SynapseParams
        try:
            instance.actual_instance = SynapseParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into TableauParams
        try:
            instance.actual_instance = TableauParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into UnknownDatasourceParams
        try:
            instance.actual_instance = UnknownDatasourceParams.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError(
                "Multiple matches found when deserializing the JSON string into DatasourceDtoParams with oneOf schemas: AdfParams, AirflowParams, AthenaParams, BigQueryParams, ComposerParams, DBTCloudParams, DBTParams, DatabricksJobsParams, DatabricksParams, DeclarativeParams, FivetranParams, LookerParams, MicrostrategyParams, MssqlParams, MwaaParams, MysqlParams, OracleParams, PostgresParams, PowerBiParams, QlikParams, QuickSightParams, RedshiftParams, SnowflakeParams, SynapseParams, TableauParams, UnknownDatasourceParams. Details: "
                + ", ".join(error_messages)
            )
        elif match == 0:
            # no match
            raise ValueError(
                "No match found when deserializing the JSON string into DatasourceDtoParams with oneOf schemas: AdfParams, AirflowParams, AthenaParams, BigQueryParams, ComposerParams, DBTCloudParams, DBTParams, DatabricksJobsParams, DatabricksParams, DeclarativeParams, FivetranParams, LookerParams, MicrostrategyParams, MssqlParams, MwaaParams, MysqlParams, OracleParams, PostgresParams, PowerBiParams, QlikParams, QuickSightParams, RedshiftParams, SnowflakeParams, SynapseParams, TableauParams, UnknownDatasourceParams. Details: "
                + ", ".join(error_messages)
            )
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(
        self,
    ) -> Optional[
        Union[
            Dict[str, Any],
            AdfParams,
            AirflowParams,
            AthenaParams,
            BigQueryParams,
            ComposerParams,
            DBTCloudParams,
            DBTParams,
            DatabricksJobsParams,
            DatabricksParams,
            DeclarativeParams,
            FivetranParams,
            LookerParams,
            MicrostrategyParams,
            MssqlParams,
            MwaaParams,
            MysqlParams,
            OracleParams,
            PostgresParams,
            PowerBiParams,
            QlikParams,
            QuickSightParams,
            RedshiftParams,
            SnowflakeParams,
            SynapseParams,
            TableauParams,
            UnknownDatasourceParams,
        ]
    ]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())
