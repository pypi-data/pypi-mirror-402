# coding: utf-8

"""
    Sifflet Backend API

    Requirements: <br>    - [Create your access token through the UI](https://docs.siffletdata.com/docs/generate-an-api-token#create-an-api-token) <br>    - Get your tenant name: if you access to Sifflet with `https://abcdef.siffletdata.com`, then your tenant would be `abcdef`

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
from typing import Any, Dict, List, Optional, Set, Union

from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    StrictStr,
    ValidationError,
    field_validator,
)
from sifflet_sdk.client.models.adf_integration_params_dto import AdfIntegrationParamsDto
from sifflet_sdk.client.models.airflow_integration_params_dto import (
    AirflowIntegrationParamsDto,
)
from sifflet_sdk.client.models.athena_integration_params_dto import (
    AthenaIntegrationParamsDto,
)
from sifflet_sdk.client.models.bigquery_integration_params_dto import (
    BigqueryIntegrationParamsDto,
)
from sifflet_sdk.client.models.composer_integration_params_dto import (
    ComposerIntegrationParamsDto,
)
from sifflet_sdk.client.models.databricks_integration_params_dto import (
    DatabricksIntegrationParamsDto,
)
from sifflet_sdk.client.models.databricks_jobs_integration_params_dto import (
    DatabricksJobsIntegrationParamsDto,
)
from sifflet_sdk.client.models.dbt_integration_params_dto import DbtIntegrationParamsDto
from sifflet_sdk.client.models.dbtcloud_integration_params_dto import (
    DbtcloudIntegrationParamsDto,
)
from sifflet_sdk.client.models.declarative_integration_params_dto import (
    DeclarativeIntegrationParamsDto,
)
from sifflet_sdk.client.models.fivetran_integration_params_dto import (
    FivetranIntegrationParamsDto,
)
from sifflet_sdk.client.models.looker_integration_params_dto import (
    LookerIntegrationParamsDto,
)
from sifflet_sdk.client.models.microstrategy_integration_params_dto import (
    MicrostrategyIntegrationParamsDto,
)
from sifflet_sdk.client.models.mssql_integration_params_dto import (
    MssqlIntegrationParamsDto,
)
from sifflet_sdk.client.models.mwaa_integration_params_dto import (
    MwaaIntegrationParamsDto,
)
from sifflet_sdk.client.models.mysql_integration_params_dto import (
    MysqlIntegrationParamsDto,
)
from sifflet_sdk.client.models.oracle_integration_params_dto import (
    OracleIntegrationParamsDto,
)
from sifflet_sdk.client.models.postgresql_integration_params_dto import (
    PostgresqlIntegrationParamsDto,
)
from sifflet_sdk.client.models.powerbi_integration_params_dto import (
    PowerbiIntegrationParamsDto,
)
from sifflet_sdk.client.models.qlik_integration_params_dto import (
    QlikIntegrationParamsDto,
)
from sifflet_sdk.client.models.quicksight_integration_params_dto import (
    QuicksightIntegrationParamsDto,
)
from sifflet_sdk.client.models.redshift_integration_params_dto import (
    RedshiftIntegrationParamsDto,
)
from sifflet_sdk.client.models.snowflake_integration_params_dto import (
    SnowflakeIntegrationParamsDto,
)
from sifflet_sdk.client.models.synapse_integration_params_dto import (
    SynapseIntegrationParamsDto,
)
from sifflet_sdk.client.models.tableau_integration_params_dto import (
    TableauIntegrationParamsDto,
)
from typing_extensions import Literal, Self

GETALLINTEGRATIONPARAMTYPES200RESPONSEINNER_ONE_OF_SCHEMAS = [
    "AdfIntegrationParamsDto",
    "AirflowIntegrationParamsDto",
    "AthenaIntegrationParamsDto",
    "BigqueryIntegrationParamsDto",
    "ComposerIntegrationParamsDto",
    "DatabricksIntegrationParamsDto",
    "DatabricksJobsIntegrationParamsDto",
    "DbtIntegrationParamsDto",
    "DbtcloudIntegrationParamsDto",
    "DeclarativeIntegrationParamsDto",
    "FivetranIntegrationParamsDto",
    "LookerIntegrationParamsDto",
    "MicrostrategyIntegrationParamsDto",
    "MssqlIntegrationParamsDto",
    "MwaaIntegrationParamsDto",
    "MysqlIntegrationParamsDto",
    "OracleIntegrationParamsDto",
    "PostgresqlIntegrationParamsDto",
    "PowerbiIntegrationParamsDto",
    "QlikIntegrationParamsDto",
    "QuicksightIntegrationParamsDto",
    "RedshiftIntegrationParamsDto",
    "SnowflakeIntegrationParamsDto",
    "SynapseIntegrationParamsDto",
    "TableauIntegrationParamsDto",
]


class GetAllIntegrationParamTypes200ResponseInner(BaseModel):
    """
    GetAllIntegrationParamTypes200ResponseInner
    """

    # data type: AdfIntegrationParamsDto
    oneof_schema_1_validator: Optional[AdfIntegrationParamsDto] = None
    # data type: AirflowIntegrationParamsDto
    oneof_schema_2_validator: Optional[AirflowIntegrationParamsDto] = None
    # data type: AthenaIntegrationParamsDto
    oneof_schema_3_validator: Optional[AthenaIntegrationParamsDto] = None
    # data type: BigqueryIntegrationParamsDto
    oneof_schema_4_validator: Optional[BigqueryIntegrationParamsDto] = None
    # data type: ComposerIntegrationParamsDto
    oneof_schema_5_validator: Optional[ComposerIntegrationParamsDto] = None
    # data type: DatabricksIntegrationParamsDto
    oneof_schema_6_validator: Optional[DatabricksIntegrationParamsDto] = None
    # data type: DatabricksJobsIntegrationParamsDto
    oneof_schema_7_validator: Optional[DatabricksJobsIntegrationParamsDto] = None
    # data type: DbtIntegrationParamsDto
    oneof_schema_8_validator: Optional[DbtIntegrationParamsDto] = None
    # data type: DbtcloudIntegrationParamsDto
    oneof_schema_9_validator: Optional[DbtcloudIntegrationParamsDto] = None
    # data type: DeclarativeIntegrationParamsDto
    oneof_schema_10_validator: Optional[DeclarativeIntegrationParamsDto] = None
    # data type: FivetranIntegrationParamsDto
    oneof_schema_11_validator: Optional[FivetranIntegrationParamsDto] = None
    # data type: LookerIntegrationParamsDto
    oneof_schema_12_validator: Optional[LookerIntegrationParamsDto] = None
    # data type: MicrostrategyIntegrationParamsDto
    oneof_schema_13_validator: Optional[MicrostrategyIntegrationParamsDto] = None
    # data type: MssqlIntegrationParamsDto
    oneof_schema_14_validator: Optional[MssqlIntegrationParamsDto] = None
    # data type: MwaaIntegrationParamsDto
    oneof_schema_15_validator: Optional[MwaaIntegrationParamsDto] = None
    # data type: MysqlIntegrationParamsDto
    oneof_schema_16_validator: Optional[MysqlIntegrationParamsDto] = None
    # data type: OracleIntegrationParamsDto
    oneof_schema_17_validator: Optional[OracleIntegrationParamsDto] = None
    # data type: PostgresqlIntegrationParamsDto
    oneof_schema_18_validator: Optional[PostgresqlIntegrationParamsDto] = None
    # data type: PowerbiIntegrationParamsDto
    oneof_schema_19_validator: Optional[PowerbiIntegrationParamsDto] = None
    # data type: QlikIntegrationParamsDto
    oneof_schema_20_validator: Optional[QlikIntegrationParamsDto] = None
    # data type: QuicksightIntegrationParamsDto
    oneof_schema_21_validator: Optional[QuicksightIntegrationParamsDto] = None
    # data type: RedshiftIntegrationParamsDto
    oneof_schema_22_validator: Optional[RedshiftIntegrationParamsDto] = None
    # data type: SnowflakeIntegrationParamsDto
    oneof_schema_23_validator: Optional[SnowflakeIntegrationParamsDto] = None
    # data type: SynapseIntegrationParamsDto
    oneof_schema_24_validator: Optional[SynapseIntegrationParamsDto] = None
    # data type: TableauIntegrationParamsDto
    oneof_schema_25_validator: Optional[TableauIntegrationParamsDto] = None
    actual_instance: Optional[
        Union[
            AdfIntegrationParamsDto,
            AirflowIntegrationParamsDto,
            AthenaIntegrationParamsDto,
            BigqueryIntegrationParamsDto,
            ComposerIntegrationParamsDto,
            DatabricksIntegrationParamsDto,
            DatabricksJobsIntegrationParamsDto,
            DbtIntegrationParamsDto,
            DbtcloudIntegrationParamsDto,
            DeclarativeIntegrationParamsDto,
            FivetranIntegrationParamsDto,
            LookerIntegrationParamsDto,
            MicrostrategyIntegrationParamsDto,
            MssqlIntegrationParamsDto,
            MwaaIntegrationParamsDto,
            MysqlIntegrationParamsDto,
            OracleIntegrationParamsDto,
            PostgresqlIntegrationParamsDto,
            PowerbiIntegrationParamsDto,
            QlikIntegrationParamsDto,
            QuicksightIntegrationParamsDto,
            RedshiftIntegrationParamsDto,
            SnowflakeIntegrationParamsDto,
            SynapseIntegrationParamsDto,
            TableauIntegrationParamsDto,
        ]
    ] = None
    one_of_schemas: Set[str] = {
        "AdfIntegrationParamsDto",
        "AirflowIntegrationParamsDto",
        "AthenaIntegrationParamsDto",
        "BigqueryIntegrationParamsDto",
        "ComposerIntegrationParamsDto",
        "DatabricksIntegrationParamsDto",
        "DatabricksJobsIntegrationParamsDto",
        "DbtIntegrationParamsDto",
        "DbtcloudIntegrationParamsDto",
        "DeclarativeIntegrationParamsDto",
        "FivetranIntegrationParamsDto",
        "LookerIntegrationParamsDto",
        "MicrostrategyIntegrationParamsDto",
        "MssqlIntegrationParamsDto",
        "MwaaIntegrationParamsDto",
        "MysqlIntegrationParamsDto",
        "OracleIntegrationParamsDto",
        "PostgresqlIntegrationParamsDto",
        "PowerbiIntegrationParamsDto",
        "QlikIntegrationParamsDto",
        "QuicksightIntegrationParamsDto",
        "RedshiftIntegrationParamsDto",
        "SnowflakeIntegrationParamsDto",
        "SynapseIntegrationParamsDto",
        "TableauIntegrationParamsDto",
    }

    model_config = ConfigDict(
        validate_assignment=True,
        protected_namespaces=(),
    )

    discriminator_value_class_map: Dict[str, str] = {}

    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator("actual_instance")
    def actual_instance_must_validate_oneof(cls, v):
        instance = GetAllIntegrationParamTypes200ResponseInner.model_construct()
        error_messages = []
        match = 0
        # validate data type: AdfIntegrationParamsDto
        if not isinstance(v, AdfIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AdfIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: AirflowIntegrationParamsDto
        if not isinstance(v, AirflowIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AirflowIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: AthenaIntegrationParamsDto
        if not isinstance(v, AthenaIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AthenaIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: BigqueryIntegrationParamsDto
        if not isinstance(v, BigqueryIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `BigqueryIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: ComposerIntegrationParamsDto
        if not isinstance(v, ComposerIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `ComposerIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: DatabricksIntegrationParamsDto
        if not isinstance(v, DatabricksIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DatabricksIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: DatabricksJobsIntegrationParamsDto
        if not isinstance(v, DatabricksJobsIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DatabricksJobsIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: DbtIntegrationParamsDto
        if not isinstance(v, DbtIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DbtIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: DbtcloudIntegrationParamsDto
        if not isinstance(v, DbtcloudIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DbtcloudIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: DeclarativeIntegrationParamsDto
        if not isinstance(v, DeclarativeIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DeclarativeIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: FivetranIntegrationParamsDto
        if not isinstance(v, FivetranIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `FivetranIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: LookerIntegrationParamsDto
        if not isinstance(v, LookerIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `LookerIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: MicrostrategyIntegrationParamsDto
        if not isinstance(v, MicrostrategyIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MicrostrategyIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: MssqlIntegrationParamsDto
        if not isinstance(v, MssqlIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MssqlIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: MwaaIntegrationParamsDto
        if not isinstance(v, MwaaIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MwaaIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: MysqlIntegrationParamsDto
        if not isinstance(v, MysqlIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MysqlIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: OracleIntegrationParamsDto
        if not isinstance(v, OracleIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `OracleIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: PostgresqlIntegrationParamsDto
        if not isinstance(v, PostgresqlIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PostgresqlIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: PowerbiIntegrationParamsDto
        if not isinstance(v, PowerbiIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PowerbiIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: QlikIntegrationParamsDto
        if not isinstance(v, QlikIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `QlikIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: QuicksightIntegrationParamsDto
        if not isinstance(v, QuicksightIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `QuicksightIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: RedshiftIntegrationParamsDto
        if not isinstance(v, RedshiftIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `RedshiftIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: SnowflakeIntegrationParamsDto
        if not isinstance(v, SnowflakeIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SnowflakeIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: SynapseIntegrationParamsDto
        if not isinstance(v, SynapseIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SynapseIntegrationParamsDto`")
        else:
            match += 1
        # validate data type: TableauIntegrationParamsDto
        if not isinstance(v, TableauIntegrationParamsDto):
            error_messages.append(f"Error! Input type `{type(v)}` is not `TableauIntegrationParamsDto`")
        else:
            match += 1
        if match > 1:
            # more than 1 match
            raise ValueError(
                "Multiple matches found when setting `actual_instance` in GetAllIntegrationParamTypes200ResponseInner with oneOf schemas: AdfIntegrationParamsDto, AirflowIntegrationParamsDto, AthenaIntegrationParamsDto, BigqueryIntegrationParamsDto, ComposerIntegrationParamsDto, DatabricksIntegrationParamsDto, DatabricksJobsIntegrationParamsDto, DbtIntegrationParamsDto, DbtcloudIntegrationParamsDto, DeclarativeIntegrationParamsDto, FivetranIntegrationParamsDto, LookerIntegrationParamsDto, MicrostrategyIntegrationParamsDto, MssqlIntegrationParamsDto, MwaaIntegrationParamsDto, MysqlIntegrationParamsDto, OracleIntegrationParamsDto, PostgresqlIntegrationParamsDto, PowerbiIntegrationParamsDto, QlikIntegrationParamsDto, QuicksightIntegrationParamsDto, RedshiftIntegrationParamsDto, SnowflakeIntegrationParamsDto, SynapseIntegrationParamsDto, TableauIntegrationParamsDto. Details: "
                + ", ".join(error_messages)
            )
        elif match == 0:
            # no match
            raise ValueError(
                "No match found when setting `actual_instance` in GetAllIntegrationParamTypes200ResponseInner with oneOf schemas: AdfIntegrationParamsDto, AirflowIntegrationParamsDto, AthenaIntegrationParamsDto, BigqueryIntegrationParamsDto, ComposerIntegrationParamsDto, DatabricksIntegrationParamsDto, DatabricksJobsIntegrationParamsDto, DbtIntegrationParamsDto, DbtcloudIntegrationParamsDto, DeclarativeIntegrationParamsDto, FivetranIntegrationParamsDto, LookerIntegrationParamsDto, MicrostrategyIntegrationParamsDto, MssqlIntegrationParamsDto, MwaaIntegrationParamsDto, MysqlIntegrationParamsDto, OracleIntegrationParamsDto, PostgresqlIntegrationParamsDto, PowerbiIntegrationParamsDto, QlikIntegrationParamsDto, QuicksightIntegrationParamsDto, RedshiftIntegrationParamsDto, SnowflakeIntegrationParamsDto, SynapseIntegrationParamsDto, TableauIntegrationParamsDto. Details: "
                + ", ".join(error_messages)
            )
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Union[str, Dict[str, Any]]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        match = 0

        # use oneOf discriminator to lookup the data type
        _data_type = json.loads(json_str).get("type")
        if not _data_type:
            raise ValueError("Failed to lookup data type from the field `type` in the input.")

        # check if data type is `AdfIntegrationParamsDto`
        if _data_type == "AdfIntegrationParamsDto":
            instance.actual_instance = AdfIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `AirflowIntegrationParamsDto`
        if _data_type == "AirflowIntegrationParamsDto":
            instance.actual_instance = AirflowIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `AthenaIntegrationParamsDto`
        if _data_type == "AthenaIntegrationParamsDto":
            instance.actual_instance = AthenaIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `BigqueryIntegrationParamsDto`
        if _data_type == "BigqueryIntegrationParamsDto":
            instance.actual_instance = BigqueryIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `ComposerIntegrationParamsDto`
        if _data_type == "ComposerIntegrationParamsDto":
            instance.actual_instance = ComposerIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `DatabricksIntegrationParamsDto`
        if _data_type == "DatabricksIntegrationParamsDto":
            instance.actual_instance = DatabricksIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `DatabricksJobsIntegrationParamsDto`
        if _data_type == "DatabricksJobsIntegrationParamsDto":
            instance.actual_instance = DatabricksJobsIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `DbtIntegrationParamsDto`
        if _data_type == "DbtIntegrationParamsDto":
            instance.actual_instance = DbtIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `DbtcloudIntegrationParamsDto`
        if _data_type == "DbtcloudIntegrationParamsDto":
            instance.actual_instance = DbtcloudIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `DeclarativeIntegrationParamsDto`
        if _data_type == "DeclarativeIntegrationParamsDto":
            instance.actual_instance = DeclarativeIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `FivetranIntegrationParamsDto`
        if _data_type == "FivetranIntegrationParamsDto":
            instance.actual_instance = FivetranIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `LookerIntegrationParamsDto`
        if _data_type == "LookerIntegrationParamsDto":
            instance.actual_instance = LookerIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `MicrostrategyIntegrationParamsDto`
        if _data_type == "MicrostrategyIntegrationParamsDto":
            instance.actual_instance = MicrostrategyIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `MssqlIntegrationParamsDto`
        if _data_type == "MssqlIntegrationParamsDto":
            instance.actual_instance = MssqlIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `MwaaIntegrationParamsDto`
        if _data_type == "MwaaIntegrationParamsDto":
            instance.actual_instance = MwaaIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `MysqlIntegrationParamsDto`
        if _data_type == "MysqlIntegrationParamsDto":
            instance.actual_instance = MysqlIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `OracleIntegrationParamsDto`
        if _data_type == "OracleIntegrationParamsDto":
            instance.actual_instance = OracleIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `PostgresqlIntegrationParamsDto`
        if _data_type == "PostgresqlIntegrationParamsDto":
            instance.actual_instance = PostgresqlIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `PowerbiIntegrationParamsDto`
        if _data_type == "PowerbiIntegrationParamsDto":
            instance.actual_instance = PowerbiIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `QlikIntegrationParamsDto`
        if _data_type == "QlikIntegrationParamsDto":
            instance.actual_instance = QlikIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `QuicksightIntegrationParamsDto`
        if _data_type == "QuicksightIntegrationParamsDto":
            instance.actual_instance = QuicksightIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `RedshiftIntegrationParamsDto`
        if _data_type == "RedshiftIntegrationParamsDto":
            instance.actual_instance = RedshiftIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `SnowflakeIntegrationParamsDto`
        if _data_type == "SnowflakeIntegrationParamsDto":
            instance.actual_instance = SnowflakeIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `SynapseIntegrationParamsDto`
        if _data_type == "SynapseIntegrationParamsDto":
            instance.actual_instance = SynapseIntegrationParamsDto.from_json(json_str)
            return instance

        # check if data type is `TableauIntegrationParamsDto`
        if _data_type == "TableauIntegrationParamsDto":
            instance.actual_instance = TableauIntegrationParamsDto.from_json(json_str)
            return instance

        # deserialize data into AdfIntegrationParamsDto
        try:
            instance.actual_instance = AdfIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AirflowIntegrationParamsDto
        try:
            instance.actual_instance = AirflowIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AthenaIntegrationParamsDto
        try:
            instance.actual_instance = AthenaIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into BigqueryIntegrationParamsDto
        try:
            instance.actual_instance = BigqueryIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into ComposerIntegrationParamsDto
        try:
            instance.actual_instance = ComposerIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DatabricksIntegrationParamsDto
        try:
            instance.actual_instance = DatabricksIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DatabricksJobsIntegrationParamsDto
        try:
            instance.actual_instance = DatabricksJobsIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DbtIntegrationParamsDto
        try:
            instance.actual_instance = DbtIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DbtcloudIntegrationParamsDto
        try:
            instance.actual_instance = DbtcloudIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DeclarativeIntegrationParamsDto
        try:
            instance.actual_instance = DeclarativeIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into FivetranIntegrationParamsDto
        try:
            instance.actual_instance = FivetranIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into LookerIntegrationParamsDto
        try:
            instance.actual_instance = LookerIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MicrostrategyIntegrationParamsDto
        try:
            instance.actual_instance = MicrostrategyIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MssqlIntegrationParamsDto
        try:
            instance.actual_instance = MssqlIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MwaaIntegrationParamsDto
        try:
            instance.actual_instance = MwaaIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MysqlIntegrationParamsDto
        try:
            instance.actual_instance = MysqlIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into OracleIntegrationParamsDto
        try:
            instance.actual_instance = OracleIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PostgresqlIntegrationParamsDto
        try:
            instance.actual_instance = PostgresqlIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PowerbiIntegrationParamsDto
        try:
            instance.actual_instance = PowerbiIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into QlikIntegrationParamsDto
        try:
            instance.actual_instance = QlikIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into QuicksightIntegrationParamsDto
        try:
            instance.actual_instance = QuicksightIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into RedshiftIntegrationParamsDto
        try:
            instance.actual_instance = RedshiftIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SnowflakeIntegrationParamsDto
        try:
            instance.actual_instance = SnowflakeIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SynapseIntegrationParamsDto
        try:
            instance.actual_instance = SynapseIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into TableauIntegrationParamsDto
        try:
            instance.actual_instance = TableauIntegrationParamsDto.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError(
                "Multiple matches found when deserializing the JSON string into GetAllIntegrationParamTypes200ResponseInner with oneOf schemas: AdfIntegrationParamsDto, AirflowIntegrationParamsDto, AthenaIntegrationParamsDto, BigqueryIntegrationParamsDto, ComposerIntegrationParamsDto, DatabricksIntegrationParamsDto, DatabricksJobsIntegrationParamsDto, DbtIntegrationParamsDto, DbtcloudIntegrationParamsDto, DeclarativeIntegrationParamsDto, FivetranIntegrationParamsDto, LookerIntegrationParamsDto, MicrostrategyIntegrationParamsDto, MssqlIntegrationParamsDto, MwaaIntegrationParamsDto, MysqlIntegrationParamsDto, OracleIntegrationParamsDto, PostgresqlIntegrationParamsDto, PowerbiIntegrationParamsDto, QlikIntegrationParamsDto, QuicksightIntegrationParamsDto, RedshiftIntegrationParamsDto, SnowflakeIntegrationParamsDto, SynapseIntegrationParamsDto, TableauIntegrationParamsDto. Details: "
                + ", ".join(error_messages)
            )
        elif match == 0:
            # no match
            raise ValueError(
                "No match found when deserializing the JSON string into GetAllIntegrationParamTypes200ResponseInner with oneOf schemas: AdfIntegrationParamsDto, AirflowIntegrationParamsDto, AthenaIntegrationParamsDto, BigqueryIntegrationParamsDto, ComposerIntegrationParamsDto, DatabricksIntegrationParamsDto, DatabricksJobsIntegrationParamsDto, DbtIntegrationParamsDto, DbtcloudIntegrationParamsDto, DeclarativeIntegrationParamsDto, FivetranIntegrationParamsDto, LookerIntegrationParamsDto, MicrostrategyIntegrationParamsDto, MssqlIntegrationParamsDto, MwaaIntegrationParamsDto, MysqlIntegrationParamsDto, OracleIntegrationParamsDto, PostgresqlIntegrationParamsDto, PowerbiIntegrationParamsDto, QlikIntegrationParamsDto, QuicksightIntegrationParamsDto, RedshiftIntegrationParamsDto, SnowflakeIntegrationParamsDto, SynapseIntegrationParamsDto, TableauIntegrationParamsDto. Details: "
                + ", ".join(error_messages)
            )
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(
        self,
    ) -> Optional[
        Union[
            Dict[str, Any],
            AdfIntegrationParamsDto,
            AirflowIntegrationParamsDto,
            AthenaIntegrationParamsDto,
            BigqueryIntegrationParamsDto,
            ComposerIntegrationParamsDto,
            DatabricksIntegrationParamsDto,
            DatabricksJobsIntegrationParamsDto,
            DbtIntegrationParamsDto,
            DbtcloudIntegrationParamsDto,
            DeclarativeIntegrationParamsDto,
            FivetranIntegrationParamsDto,
            LookerIntegrationParamsDto,
            MicrostrategyIntegrationParamsDto,
            MssqlIntegrationParamsDto,
            MwaaIntegrationParamsDto,
            MysqlIntegrationParamsDto,
            OracleIntegrationParamsDto,
            PostgresqlIntegrationParamsDto,
            PowerbiIntegrationParamsDto,
            QlikIntegrationParamsDto,
            QuicksightIntegrationParamsDto,
            RedshiftIntegrationParamsDto,
            SnowflakeIntegrationParamsDto,
            SynapseIntegrationParamsDto,
            TableauIntegrationParamsDto,
        ]
    ]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())
