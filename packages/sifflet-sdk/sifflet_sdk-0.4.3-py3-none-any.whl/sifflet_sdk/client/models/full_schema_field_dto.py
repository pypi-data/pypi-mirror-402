# coding: utf-8

"""
    Sifflet Backend API

    Requirements: <br>    - [Create your access token through the UI](https://docs.siffletdata.com/docs/generate-an-api-token#create-an-api-token) <br>    - Get your tenant name: if you access to Sifflet with `https://abcdef.siffletdata.com`, then your tenant would be `abcdef`

    The version of the OpenAPI document: 1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from typing import Any, ClassVar, Dict, List, Optional, Set

from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    StrictBool,
    StrictStr,
    field_validator,
)
from sifflet_sdk.client.models.description_dto import DescriptionDto
from sifflet_sdk.client.models.description_prediction_dto import (
    DescriptionPredictionDto,
)
from sifflet_sdk.client.models.rule_status_dto import RuleStatusDto
from sifflet_sdk.client.models.tag_dto import TagDto
from typing_extensions import Self


class FullSchemaFieldDto(BaseModel):
    """
    FullSchemaFieldDto
    """  # noqa: E501

    description: Optional[StrictStr] = None
    description_predictions: Optional[List[DescriptionPredictionDto]] = Field(
        default=None, alias="descriptionPredictions"
    )
    entity_type: StrictStr = Field(alias="entityType")
    external_descriptions: Optional[List[DescriptionDto]] = Field(default=None, alias="externalDescriptions")
    id: Optional[StrictStr] = None
    monitored: Optional[StrictBool] = None
    name: StrictStr
    parent_dataset_field_id: Optional[StrictStr] = Field(default=None, alias="parentDatasetFieldId")
    predicted_tags_waiting_for_feedback: Optional[List[TagDto]] = Field(
        default=None, alias="predictedTagsWaitingForFeedback"
    )
    rule_statuses: List[RuleStatusDto] = Field(alias="ruleStatuses")
    subfields: Optional[List[FullSchemaFieldDto]] = None
    tags: Optional[List[TagDto]] = None
    terms: Optional[List[TagDto]] = None
    type: StrictStr
    type_category: Optional[StrictStr] = Field(default=None, alias="typeCategory")
    urn: Optional[StrictStr] = None
    __properties: ClassVar[List[str]] = [
        "description",
        "descriptionPredictions",
        "entityType",
        "externalDescriptions",
        "id",
        "monitored",
        "name",
        "parentDatasetFieldId",
        "predictedTagsWaitingForFeedback",
        "ruleStatuses",
        "subfields",
        "tags",
        "terms",
        "type",
        "typeCategory",
        "urn",
    ]

    @field_validator("entity_type")
    def entity_type_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(
            [
                "INTEGRATION",
                "DATASOURCE",
                "DATASOURCE_USAGE",
                "DATASOURCE_INGESTION_RUN",
                "DATASET",
                "DASHBOARD",
                "CHART",
                "COLLECTION",
                "DATASET_FIELD",
                "DAG",
                "DAG_RUN",
                "TRANSFORMATION",
                "TRANSFORMATION_RUN",
                "RULE_RUN",
                "RULE_EXECUTION_SUMMARY",
                "INCIDENT",
                "USER",
                "ACCESS_TOKEN",
                "SIFFLET_RULE",
                "CONFIG",
                "TAG",
                "DOMAIN",
                "ALERTING_HOOK",
                "RULE_MONITORING_RECOMMENDATION",
                "DATAPOINT_QUALIFICATION",
                "DECLARED_ASSET",
                "DECLARED_ASSET_PROPERTIES",
                "WEBHOOK",
                "SIFFLET_AGENT",
                "SIFFLET_AGENT_JOB",
                "SIFFLET_AGENT_DATASOURCE_JOB",
                "SIFFLET_AGENT_DEBUG_JOB",
                "AI_METADATA_PREDICTION",
                "CUSTOM_METADATA",
                "CUSTOM_METADATA_ENTRY",
                "DATA_PRODUCT",
                "METRIC",
                "ASSET_UPDATE_HISTORY_ENTITY",
                "ASSET_USAGE",
                "ASSET_USAGE_HISTORY_RECORD",
                "SAML_REQUEST",
                "SINGLE_USE_TOKEN",
                "FORMATTED_DESCRIPTION",
                "RULE_ROOT_CAUSE_ANALYSIS_RUN",
                "AS_CODE_WORKSPACE",
                "ALERT",
                "SIFFLET_RULE_MODEL_PARAMETERS",
                "CALENDAR",
                "CONNECTION",
                "METADATA_JOB",
                "DATASET_MODEL_PARAMETERS",
                "COLLABORATION_TOOL_ITEM",
                "DBT_IMPACT_ANALYSIS_RUN",
                "INGESTION_STATEMENT_CACHE",
                "LINEAGE",
                "MUTATION_LINK",
                "UPSTREAM_STATE",
                "CHAT_HISTORY",
                "TEAM",
            ]
        ):
            raise ValueError(
                "must be one of enum values ('INTEGRATION', 'DATASOURCE', 'DATASOURCE_USAGE', 'DATASOURCE_INGESTION_RUN', 'DATASET', 'DASHBOARD', 'CHART', 'COLLECTION', 'DATASET_FIELD', 'DAG', 'DAG_RUN', 'TRANSFORMATION', 'TRANSFORMATION_RUN', 'RULE_RUN', 'RULE_EXECUTION_SUMMARY', 'INCIDENT', 'USER', 'ACCESS_TOKEN', 'SIFFLET_RULE', 'CONFIG', 'TAG', 'DOMAIN', 'ALERTING_HOOK', 'RULE_MONITORING_RECOMMENDATION', 'DATAPOINT_QUALIFICATION', 'DECLARED_ASSET', 'DECLARED_ASSET_PROPERTIES', 'WEBHOOK', 'SIFFLET_AGENT', 'SIFFLET_AGENT_JOB', 'SIFFLET_AGENT_DATASOURCE_JOB', 'SIFFLET_AGENT_DEBUG_JOB', 'AI_METADATA_PREDICTION', 'CUSTOM_METADATA', 'CUSTOM_METADATA_ENTRY', 'DATA_PRODUCT', 'METRIC', 'ASSET_UPDATE_HISTORY_ENTITY', 'ASSET_USAGE', 'ASSET_USAGE_HISTORY_RECORD', 'SAML_REQUEST', 'SINGLE_USE_TOKEN', 'FORMATTED_DESCRIPTION', 'RULE_ROOT_CAUSE_ANALYSIS_RUN', 'AS_CODE_WORKSPACE', 'ALERT', 'SIFFLET_RULE_MODEL_PARAMETERS', 'CALENDAR', 'CONNECTION', 'METADATA_JOB', 'DATASET_MODEL_PARAMETERS', 'COLLABORATION_TOOL_ITEM', 'DBT_IMPACT_ANALYSIS_RUN', 'INGESTION_STATEMENT_CACHE', 'LINEAGE', 'MUTATION_LINK', 'UPSTREAM_STATE', 'CHAT_HISTORY', 'TEAM')"
            )
        return value

    @field_validator("type_category")
    def type_category_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(
            [
                "DATE",
                "TIME",
                "DATETIME",
                "BOOLEAN",
                "STRING",
                "INTEGER",
                "FLOAT",
                "ARRAY",
                "JSON",
                "STRUCT",
                "MAP",
                "BINARY",
                "OTHER",
            ]
        ):
            raise ValueError(
                "must be one of enum values ('DATE', 'TIME', 'DATETIME', 'BOOLEAN', 'STRING', 'INTEGER', 'FLOAT', 'ARRAY', 'JSON', 'STRUCT', 'MAP', 'BINARY', 'OTHER')"
            )
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of FullSchemaFieldDto from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in description_predictions (list)
        _items = []
        if self.description_predictions:
            for _item_description_predictions in self.description_predictions:
                if _item_description_predictions:
                    _items.append(_item_description_predictions.to_dict())
            _dict["descriptionPredictions"] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in external_descriptions (list)
        _items = []
        if self.external_descriptions:
            for _item_external_descriptions in self.external_descriptions:
                if _item_external_descriptions:
                    _items.append(_item_external_descriptions.to_dict())
            _dict["externalDescriptions"] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in predicted_tags_waiting_for_feedback (list)
        _items = []
        if self.predicted_tags_waiting_for_feedback:
            for _item_predicted_tags_waiting_for_feedback in self.predicted_tags_waiting_for_feedback:
                if _item_predicted_tags_waiting_for_feedback:
                    _items.append(_item_predicted_tags_waiting_for_feedback.to_dict())
            _dict["predictedTagsWaitingForFeedback"] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in rule_statuses (list)
        _items = []
        if self.rule_statuses:
            for _item_rule_statuses in self.rule_statuses:
                if _item_rule_statuses:
                    _items.append(_item_rule_statuses.to_dict())
            _dict["ruleStatuses"] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in subfields (list)
        _items = []
        if self.subfields:
            for _item_subfields in self.subfields:
                if _item_subfields:
                    _items.append(_item_subfields.to_dict())
            _dict["subfields"] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in tags (list)
        _items = []
        if self.tags:
            for _item_tags in self.tags:
                if _item_tags:
                    _items.append(_item_tags.to_dict())
            _dict["tags"] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in terms (list)
        _items = []
        if self.terms:
            for _item_terms in self.terms:
                if _item_terms:
                    _items.append(_item_terms.to_dict())
            _dict["terms"] = _items
        # set to None if type_category (nullable) is None
        # and model_fields_set contains the field
        if self.type_category is None and "type_category" in self.model_fields_set:
            _dict["typeCategory"] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of FullSchemaFieldDto from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "description": obj.get("description"),
                "descriptionPredictions": (
                    [DescriptionPredictionDto.from_dict(_item) for _item in obj["descriptionPredictions"]]
                    if obj.get("descriptionPredictions") is not None
                    else None
                ),
                "entityType": obj.get("entityType"),
                "externalDescriptions": (
                    [DescriptionDto.from_dict(_item) for _item in obj["externalDescriptions"]]
                    if obj.get("externalDescriptions") is not None
                    else None
                ),
                "id": obj.get("id"),
                "monitored": obj.get("monitored"),
                "name": obj.get("name"),
                "parentDatasetFieldId": obj.get("parentDatasetFieldId"),
                "predictedTagsWaitingForFeedback": (
                    [TagDto.from_dict(_item) for _item in obj["predictedTagsWaitingForFeedback"]]
                    if obj.get("predictedTagsWaitingForFeedback") is not None
                    else None
                ),
                "ruleStatuses": (
                    [RuleStatusDto.from_dict(_item) for _item in obj["ruleStatuses"]]
                    if obj.get("ruleStatuses") is not None
                    else None
                ),
                "subfields": (
                    [FullSchemaFieldDto.from_dict(_item) for _item in obj["subfields"]]
                    if obj.get("subfields") is not None
                    else None
                ),
                "tags": [TagDto.from_dict(_item) for _item in obj["tags"]] if obj.get("tags") is not None else None,
                "terms": [TagDto.from_dict(_item) for _item in obj["terms"]] if obj.get("terms") is not None else None,
                "type": obj.get("type"),
                "typeCategory": obj.get("typeCategory"),
                "urn": obj.get("urn"),
            }
        )
        return _obj


# TODO: Rewrite to not use raise_errors
FullSchemaFieldDto.model_rebuild(raise_errors=False)
