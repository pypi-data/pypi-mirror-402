# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from __future__ import annotations

from typing import Iterable
from typing_extensions import Literal, Required, TypedDict

__all__ = ["MonitorSubmitEventParams", "ModelInput", "ModelInputContext"]


class MonitorSubmitEventParams(TypedDict, total=False):
    model_input: Required[ModelInput]
    """A dictionary of inputs sent to the LLM to generate output.

    The dictionary must contain a `user_prompt` field. For ground_truth_adherence
    guardrail metric, `ground_truth` should be provided.
    """

    model_output: Required[str]
    """Output generated by the LLM to be evaluated."""

    nametag: str
    """An optional, user-defined tag for the event."""

    run_mode: Literal["precision_plus_codex", "precision_plus", "precision", "smart", "economy"]
    """Run mode for the monitor event.

    The run mode allows the user to optimize for speed, accuracy, and cost by
    determining which models are used to evaluate the event. Available run modes
    include `precision_plus_codex`, `precision_plus`, `precision`, `smart`, and
    `economy`. Defaults to `smart`.
    """


class ModelInputContext(TypedDict, total=False):
    content: str
    """The content of the message."""

    role: str
    """The role of the speaker."""


class ModelInput(TypedDict, total=False):
    """A dictionary of inputs sent to the LLM to generate output.

    The dictionary must contain a `user_prompt` field. For ground_truth_adherence  guardrail metric, `ground_truth` should be provided.
    """

    user_prompt: Required[str]
    """The user prompt used to generate the output."""

    context: Iterable[ModelInputContext]
    """
    Any structured information that directly relates to the model’s input and
    expected output—e.g., the recent turn-by-turn history between an AI tutor and a
    student, facts or state passed through an agentic workflow, or other
    domain-specific signals your system already knows and wants the model to
    condition on.
    """

    ground_truth: str
    """The ground truth for evaluating Ground Truth Adherence guardrail."""

    system_prompt: str
    """The system prompt used to generate the output."""
