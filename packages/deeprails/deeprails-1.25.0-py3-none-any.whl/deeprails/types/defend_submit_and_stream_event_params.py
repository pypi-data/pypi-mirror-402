# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from __future__ import annotations

from typing import Dict
from typing_extensions import Literal, Required, TypedDict

__all__ = ["DefendSubmitAndStreamEventParams"]


class DefendSubmitAndStreamEventParams(TypedDict, total=False):
    model_input: Required[Dict[str, object]]
    """The input provided to the model (e.g., prompt, messages)."""

    model_output: Required[str]
    """The output generated by the model to be evaluated."""

    model_used: Required[str]
    """The model that generated the output (e.g., "gpt-4", "claude-3")."""

    run_mode: Required[Literal["fast", "precision", "precision_codex", "precision_max", "precision_max_codex"]]
    """The evaluation run mode.

    Streaming only supports fast, precision, and precision_codex.
    """

    stream: bool
    """Enable SSE streaming for real-time token feedback.

    Only supported for single-model run modes (fast, precision, precision_codex).
    """

    nametag: str
    """Optional tag to identify this event."""
