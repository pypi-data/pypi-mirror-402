# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from __future__ import annotations

from typing import Dict
from typing_extensions import Literal

import httpx

from ..types import (
    defend_submit_event_params,
    defend_create_workflow_params,
    defend_update_workflow_params,
    defend_retrieve_workflow_params,
    defend_submit_and_stream_event_params,
)
from .._types import Body, Omit, Query, Headers, NotGiven, SequenceNotStr, omit, not_given
from .._utils import maybe_transform, async_maybe_transform
from .._compat import cached_property
from .._resource import SyncAPIResource, AsyncAPIResource
from .._response import (
    to_raw_response_wrapper,
    to_streamed_response_wrapper,
    async_to_raw_response_wrapper,
    async_to_streamed_response_wrapper,
)
from .._streaming import Stream, AsyncStream
from .._base_client import make_request_options
from ..types.defend_response import DefendResponse
from ..types.defend_create_response import DefendCreateResponse
from ..types.defend_update_response import DefendUpdateResponse
from ..types.workflow_event_response import WorkflowEventResponse
from ..types.workflow_event_detail_response import WorkflowEventDetailResponse
from ..types.defend_submit_and_stream_event_response import DefendSubmitAndStreamEventResponse

__all__ = ["DefendResource", "AsyncDefendResource"]


class DefendResource(SyncAPIResource):
    @cached_property
    def with_raw_response(self) -> DefendResourceWithRawResponse:
        """
        This property can be used as a prefix for any HTTP method call to return
        the raw response object instead of the parsed content.

        For more information, see https://www.github.com/deeprails/deeprails-sdk-python#accessing-raw-response-data-eg-headers
        """
        return DefendResourceWithRawResponse(self)

    @cached_property
    def with_streaming_response(self) -> DefendResourceWithStreamingResponse:
        """
        An alternative to `.with_raw_response` that doesn't eagerly read the response body.

        For more information, see https://www.github.com/deeprails/deeprails-sdk-python#with_streaming_response
        """
        return DefendResourceWithStreamingResponse(self)

    def create_workflow(
        self,
        *,
        improvement_action: Literal["regen", "fixit", "do_nothing"],
        name: str,
        threshold_type: Literal["automatic", "custom"],
        automatic_hallucination_tolerance_levels: Dict[str, Literal["low", "medium", "high"]] | Omit = omit,
        context_awareness: bool | Omit = omit,
        custom_hallucination_threshold_values: Dict[str, float] | Omit = omit,
        description: str | Omit = omit,
        file_search: SequenceNotStr[str] | Omit = omit,
        max_improvement_attempts: int | Omit = omit,
        web_search: bool | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> DefendCreateResponse:
        """
        Use this endpoint to create a new guardrail workflow by specifying guardrail
        thresholds, an improvement action, and optional extended capabilities.

        Args:
          improvement_action: The action used to improve outputs that fail one or more guardrail metrics for
              the workflow events. May be `regen`, `fixit`, or `do_nothing`. ReGen runs the
              user's input prompt with minor induced variance. FixIt attempts to directly
              address the shortcomings of the output using the guardrail failure rationale. Do
              Nothing does not attempt any improvement.

          name: Name of the workflow.

          threshold_type: Type of thresholds to use for the workflow, either `automatic` or `custom`.
              Automatic thresholds are assigned internally after the user specifies a
              qualitative tolerance for the metrics, whereas custom metrics allow the user to
              set the threshold for each metric as a floating point number between 0.0 and
              1.0.

          automatic_hallucination_tolerance_levels: Mapping of guardrail metrics to hallucination tolerance levels (either `low`,
              `medium`, or `high`). Possible metrics are `completeness`,
              `instruction_adherence`, `context_adherence`, `ground_truth_adherence`, or
              `comprehensive_safety`.

          context_awareness: Context includes any structured information that directly relates to the model’s
              input and expected output—e.g., the recent turn-by-turn history between an AI
              tutor and a student, facts or state passed through an agentic workflow, or other
              domain-specific signals your system already knows and wants the model to
              condition on. This field determines whether to enable context awareness for this
              workflow's evaluations. Defaults to false.

          custom_hallucination_threshold_values: Mapping of guardrail metrics to floating point threshold values. Possible
              metrics are `correctness`, `completeness`, `instruction_adherence`,
              `context_adherence`, `ground_truth_adherence`, or `comprehensive_safety`.

          description: Description for the workflow.

          file_search: An array of file IDs to search in the workflow's evaluations. Files must be
              uploaded via the DeepRails API first.

          max_improvement_attempts: Max. number of improvement action attempts until a given event passes the
              guardrails. Defaults to 10.

          web_search: Whether to enable web search for this workflow's evaluations. Defaults to false.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        return self._post(
            "/defend",
            body=maybe_transform(
                {
                    "improvement_action": improvement_action,
                    "name": name,
                    "threshold_type": threshold_type,
                    "automatic_hallucination_tolerance_levels": automatic_hallucination_tolerance_levels,
                    "context_awareness": context_awareness,
                    "custom_hallucination_threshold_values": custom_hallucination_threshold_values,
                    "description": description,
                    "file_search": file_search,
                    "max_improvement_attempts": max_improvement_attempts,
                    "web_search": web_search,
                },
                defend_create_workflow_params.DefendCreateWorkflowParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=DefendCreateResponse,
        )

    def retrieve_event(
        self,
        event_id: str,
        *,
        workflow_id: str,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> WorkflowEventDetailResponse:
        """
        Use this endpoint to retrieve a specific event of a guardrail workflow

        Args:
          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        if not event_id:
            raise ValueError(f"Expected a non-empty value for `event_id` but received {event_id!r}")
        return self._get(
            f"/defend/{workflow_id}/events/{event_id}",
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=WorkflowEventDetailResponse,
        )

    def retrieve_workflow(
        self,
        workflow_id: str,
        *,
        limit: int | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> DefendResponse:
        """
        Use this endpoint to retrieve the details for a specific defend workflow

        Args:
          limit: Limit the number of returned events associated with this workflow. Defaults
              to 10.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        return self._get(
            f"/defend/{workflow_id}",
            options=make_request_options(
                extra_headers=extra_headers,
                extra_query=extra_query,
                extra_body=extra_body,
                timeout=timeout,
                query=maybe_transform({"limit": limit}, defend_retrieve_workflow_params.DefendRetrieveWorkflowParams),
            ),
            cast_to=DefendResponse,
        )

    def submit_and_stream_event(
        self,
        workflow_id: str,
        *,
        model_input: Dict[str, object],
        model_output: str,
        model_used: str,
        run_mode: Literal["fast", "precision", "precision_codex", "precision_max", "precision_max_codex"],
        stream: bool | Omit = omit,
        nametag: str | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> Stream[DefendSubmitAndStreamEventResponse]:
        """
        Use this endpoint to create a new event for a guardrail workflow with real-time
        streaming feedback via Server-Sent Events (SSE).

        Args:
          model_input: The input provided to the model (e.g., prompt, messages).

          model_output: The output generated by the model to be evaluated.

          model_used: The model that generated the output (e.g., "gpt-4", "claude-3").

          run_mode: The evaluation run mode. Streaming only supports fast, precision, and
              precision_codex.

          stream: Enable SSE streaming for real-time token feedback. Only supported for
              single-model run modes (fast, precision, precision_codex).

          nametag: Optional tag to identify this event.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        extra_headers = {"Accept": "text/event-stream", **(extra_headers or {})}
        return self._post(
            f"/defend/{workflow_id}/events?stream=true",
            body=maybe_transform(
                {
                    "model_input": model_input,
                    "model_output": model_output,
                    "model_used": model_used,
                    "run_mode": run_mode,
                    "nametag": nametag,
                },
                defend_submit_and_stream_event_params.DefendSubmitAndStreamEventParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers,
                extra_query=extra_query,
                extra_body=extra_body,
                timeout=timeout,
                query=maybe_transform(
                    {"stream": stream}, defend_submit_and_stream_event_params.DefendSubmitAndStreamEventParams
                ),
            ),
            cast_to=str,
            stream=True,
            stream_cls=Stream[DefendSubmitAndStreamEventResponse],
        )

    def submit_event(
        self,
        workflow_id: str,
        *,
        model_input: defend_submit_event_params.ModelInput,
        model_output: str,
        model_used: str,
        run_mode: Literal["precision_plus_codex", "precision_plus", "precision", "smart", "economy"],
        nametag: str | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> WorkflowEventResponse:
        """
        Use this endpoint to submit a model input and output pair to a workflow for
        evaluation

        Args:
          model_input: A dictionary of inputs sent to the LLM to generate output. The dictionary must
              contain a `user_prompt` field. For the ground_truth_adherence guardrail metric,
              `ground_truth` should be provided.

          model_output: Output generated by the LLM to be evaluated.

          model_used: Model ID used to generate the output, like `gpt-4o` or `o3`.

          run_mode: Run mode for the workflow event. The run mode allows the user to optimize for
              speed, accuracy, and cost by determining which models are used to evaluate the
              event. Available run modes include `precision_plus_codex`, `precision_plus`,
              `precision`, `smart`, and `economy`. Defaults to `smart`.

          nametag: An optional, user-defined tag for the event.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        return self._post(
            f"/defend/{workflow_id}/events",
            body=maybe_transform(
                {
                    "model_input": model_input,
                    "model_output": model_output,
                    "model_used": model_used,
                    "run_mode": run_mode,
                    "nametag": nametag,
                },
                defend_submit_event_params.DefendSubmitEventParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=WorkflowEventResponse,
        )

    def update_workflow(
        self,
        workflow_id: str,
        *,
        automatic_hallucination_tolerance_levels: Dict[str, Literal["low", "medium", "high"]] | Omit = omit,
        context_awareness: bool | Omit = omit,
        custom_hallucination_threshold_values: Dict[str, float] | Omit = omit,
        description: str | Omit = omit,
        file_search: SequenceNotStr[str] | Omit = omit,
        improvement_action: Literal["regen", "fixit", "do_nothing"] | Omit = omit,
        max_improvement_attempts: int | Omit = omit,
        name: str | Omit = omit,
        threshold_type: Literal["automatic", "custom"] | Omit = omit,
        web_search: bool | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> DefendUpdateResponse:
        """
        Use this endpoint to update an existing defend workflow if its details change.

        Args:
          automatic_hallucination_tolerance_levels: New mapping of guardrail metrics to hallucination tolerance levels (either
              `low`, `medium`, or `high`) to be used when `threshold_type` is set to
              `automatic`. Possible metrics are `completeness`, `instruction_adherence`,
              `context_adherence`, `ground_truth_adherence`, or `comprehensive_safety`.

          context_awareness: Whether to enable context awareness for this workflow's evaluations.

          custom_hallucination_threshold_values: New mapping of guardrail metrics to floating point threshold values to be used
              when `threshold_type` is set to `custom`. Possible metrics are `correctness`,
              `completeness`, `instruction_adherence`, `context_adherence`,
              `ground_truth_adherence`, or `comprehensive_safety`.

          description: New description for the workflow.

          file_search: An array of file IDs to search in the workflow's evaluations. Files must be
              uploaded via the DeepRails API first.

          improvement_action: The new action used to improve outputs that fail one or more guardrail metrics
              for the workflow events. May be `regen`, `fixit`, or `do_nothing`. ReGen runs
              the user's input prompt with minor induced variance. FixIt attempts to directly
              address the shortcomings of the output using the guardrail failure rationale. Do
              Nothing does not attempt any improvement.

          max_improvement_attempts: Max. number of improvement action attempts until a given event passes the
              guardrails. Defaults to 10.

          name: New name for the workflow.

          threshold_type: New type of thresholds to use for the workflow, either `automatic` or `custom`.
              Automatic thresholds are assigned internally after the user specifies a
              qualitative tolerance for the metrics, whereas custom metrics allow the user to
              set the threshold for each metric as a floating point number between 0.0 and
              1.0.

          web_search: Whether to enable web search for this workflow's evaluations.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        return self._put(
            f"/defend/{workflow_id}",
            body=maybe_transform(
                {
                    "automatic_hallucination_tolerance_levels": automatic_hallucination_tolerance_levels,
                    "context_awareness": context_awareness,
                    "custom_hallucination_threshold_values": custom_hallucination_threshold_values,
                    "description": description,
                    "file_search": file_search,
                    "improvement_action": improvement_action,
                    "max_improvement_attempts": max_improvement_attempts,
                    "name": name,
                    "threshold_type": threshold_type,
                    "web_search": web_search,
                },
                defend_update_workflow_params.DefendUpdateWorkflowParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=DefendUpdateResponse,
        )


class AsyncDefendResource(AsyncAPIResource):
    @cached_property
    def with_raw_response(self) -> AsyncDefendResourceWithRawResponse:
        """
        This property can be used as a prefix for any HTTP method call to return
        the raw response object instead of the parsed content.

        For more information, see https://www.github.com/deeprails/deeprails-sdk-python#accessing-raw-response-data-eg-headers
        """
        return AsyncDefendResourceWithRawResponse(self)

    @cached_property
    def with_streaming_response(self) -> AsyncDefendResourceWithStreamingResponse:
        """
        An alternative to `.with_raw_response` that doesn't eagerly read the response body.

        For more information, see https://www.github.com/deeprails/deeprails-sdk-python#with_streaming_response
        """
        return AsyncDefendResourceWithStreamingResponse(self)

    async def create_workflow(
        self,
        *,
        improvement_action: Literal["regen", "fixit", "do_nothing"],
        name: str,
        threshold_type: Literal["automatic", "custom"],
        automatic_hallucination_tolerance_levels: Dict[str, Literal["low", "medium", "high"]] | Omit = omit,
        context_awareness: bool | Omit = omit,
        custom_hallucination_threshold_values: Dict[str, float] | Omit = omit,
        description: str | Omit = omit,
        file_search: SequenceNotStr[str] | Omit = omit,
        max_improvement_attempts: int | Omit = omit,
        web_search: bool | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> DefendCreateResponse:
        """
        Use this endpoint to create a new guardrail workflow by specifying guardrail
        thresholds, an improvement action, and optional extended capabilities.

        Args:
          improvement_action: The action used to improve outputs that fail one or more guardrail metrics for
              the workflow events. May be `regen`, `fixit`, or `do_nothing`. ReGen runs the
              user's input prompt with minor induced variance. FixIt attempts to directly
              address the shortcomings of the output using the guardrail failure rationale. Do
              Nothing does not attempt any improvement.

          name: Name of the workflow.

          threshold_type: Type of thresholds to use for the workflow, either `automatic` or `custom`.
              Automatic thresholds are assigned internally after the user specifies a
              qualitative tolerance for the metrics, whereas custom metrics allow the user to
              set the threshold for each metric as a floating point number between 0.0 and
              1.0.

          automatic_hallucination_tolerance_levels: Mapping of guardrail metrics to hallucination tolerance levels (either `low`,
              `medium`, or `high`). Possible metrics are `completeness`,
              `instruction_adherence`, `context_adherence`, `ground_truth_adherence`, or
              `comprehensive_safety`.

          context_awareness: Context includes any structured information that directly relates to the model’s
              input and expected output—e.g., the recent turn-by-turn history between an AI
              tutor and a student, facts or state passed through an agentic workflow, or other
              domain-specific signals your system already knows and wants the model to
              condition on. This field determines whether to enable context awareness for this
              workflow's evaluations. Defaults to false.

          custom_hallucination_threshold_values: Mapping of guardrail metrics to floating point threshold values. Possible
              metrics are `correctness`, `completeness`, `instruction_adherence`,
              `context_adherence`, `ground_truth_adherence`, or `comprehensive_safety`.

          description: Description for the workflow.

          file_search: An array of file IDs to search in the workflow's evaluations. Files must be
              uploaded via the DeepRails API first.

          max_improvement_attempts: Max. number of improvement action attempts until a given event passes the
              guardrails. Defaults to 10.

          web_search: Whether to enable web search for this workflow's evaluations. Defaults to false.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        return await self._post(
            "/defend",
            body=await async_maybe_transform(
                {
                    "improvement_action": improvement_action,
                    "name": name,
                    "threshold_type": threshold_type,
                    "automatic_hallucination_tolerance_levels": automatic_hallucination_tolerance_levels,
                    "context_awareness": context_awareness,
                    "custom_hallucination_threshold_values": custom_hallucination_threshold_values,
                    "description": description,
                    "file_search": file_search,
                    "max_improvement_attempts": max_improvement_attempts,
                    "web_search": web_search,
                },
                defend_create_workflow_params.DefendCreateWorkflowParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=DefendCreateResponse,
        )

    async def retrieve_event(
        self,
        event_id: str,
        *,
        workflow_id: str,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> WorkflowEventDetailResponse:
        """
        Use this endpoint to retrieve a specific event of a guardrail workflow

        Args:
          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        if not event_id:
            raise ValueError(f"Expected a non-empty value for `event_id` but received {event_id!r}")
        return await self._get(
            f"/defend/{workflow_id}/events/{event_id}",
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=WorkflowEventDetailResponse,
        )

    async def retrieve_workflow(
        self,
        workflow_id: str,
        *,
        limit: int | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> DefendResponse:
        """
        Use this endpoint to retrieve the details for a specific defend workflow

        Args:
          limit: Limit the number of returned events associated with this workflow. Defaults
              to 10.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        return await self._get(
            f"/defend/{workflow_id}",
            options=make_request_options(
                extra_headers=extra_headers,
                extra_query=extra_query,
                extra_body=extra_body,
                timeout=timeout,
                query=await async_maybe_transform(
                    {"limit": limit}, defend_retrieve_workflow_params.DefendRetrieveWorkflowParams
                ),
            ),
            cast_to=DefendResponse,
        )

    async def submit_and_stream_event(
        self,
        workflow_id: str,
        *,
        model_input: Dict[str, object],
        model_output: str,
        model_used: str,
        run_mode: Literal["fast", "precision", "precision_codex", "precision_max", "precision_max_codex"],
        stream: bool | Omit = omit,
        nametag: str | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> AsyncStream[DefendSubmitAndStreamEventResponse]:
        """
        Use this endpoint to create a new event for a guardrail workflow with real-time
        streaming feedback via Server-Sent Events (SSE).

        Args:
          model_input: The input provided to the model (e.g., prompt, messages).

          model_output: The output generated by the model to be evaluated.

          model_used: The model that generated the output (e.g., "gpt-4", "claude-3").

          run_mode: The evaluation run mode. Streaming only supports fast, precision, and
              precision_codex.

          stream: Enable SSE streaming for real-time token feedback. Only supported for
              single-model run modes (fast, precision, precision_codex).

          nametag: Optional tag to identify this event.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        extra_headers = {"Accept": "text/event-stream", **(extra_headers or {})}
        return await self._post(
            f"/defend/{workflow_id}/events?stream=true",
            body=await async_maybe_transform(
                {
                    "model_input": model_input,
                    "model_output": model_output,
                    "model_used": model_used,
                    "run_mode": run_mode,
                    "nametag": nametag,
                },
                defend_submit_and_stream_event_params.DefendSubmitAndStreamEventParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers,
                extra_query=extra_query,
                extra_body=extra_body,
                timeout=timeout,
                query=await async_maybe_transform(
                    {"stream": stream}, defend_submit_and_stream_event_params.DefendSubmitAndStreamEventParams
                ),
            ),
            cast_to=str,
            stream=True,
            stream_cls=AsyncStream[DefendSubmitAndStreamEventResponse],
        )

    async def submit_event(
        self,
        workflow_id: str,
        *,
        model_input: defend_submit_event_params.ModelInput,
        model_output: str,
        model_used: str,
        run_mode: Literal["precision_plus_codex", "precision_plus", "precision", "smart", "economy"],
        nametag: str | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> WorkflowEventResponse:
        """
        Use this endpoint to submit a model input and output pair to a workflow for
        evaluation

        Args:
          model_input: A dictionary of inputs sent to the LLM to generate output. The dictionary must
              contain a `user_prompt` field. For the ground_truth_adherence guardrail metric,
              `ground_truth` should be provided.

          model_output: Output generated by the LLM to be evaluated.

          model_used: Model ID used to generate the output, like `gpt-4o` or `o3`.

          run_mode: Run mode for the workflow event. The run mode allows the user to optimize for
              speed, accuracy, and cost by determining which models are used to evaluate the
              event. Available run modes include `precision_plus_codex`, `precision_plus`,
              `precision`, `smart`, and `economy`. Defaults to `smart`.

          nametag: An optional, user-defined tag for the event.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        return await self._post(
            f"/defend/{workflow_id}/events",
            body=await async_maybe_transform(
                {
                    "model_input": model_input,
                    "model_output": model_output,
                    "model_used": model_used,
                    "run_mode": run_mode,
                    "nametag": nametag,
                },
                defend_submit_event_params.DefendSubmitEventParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=WorkflowEventResponse,
        )

    async def update_workflow(
        self,
        workflow_id: str,
        *,
        automatic_hallucination_tolerance_levels: Dict[str, Literal["low", "medium", "high"]] | Omit = omit,
        context_awareness: bool | Omit = omit,
        custom_hallucination_threshold_values: Dict[str, float] | Omit = omit,
        description: str | Omit = omit,
        file_search: SequenceNotStr[str] | Omit = omit,
        improvement_action: Literal["regen", "fixit", "do_nothing"] | Omit = omit,
        max_improvement_attempts: int | Omit = omit,
        name: str | Omit = omit,
        threshold_type: Literal["automatic", "custom"] | Omit = omit,
        web_search: bool | Omit = omit,
        # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.
        # The extra values given here take precedence over values defined on the client or passed to this method.
        extra_headers: Headers | None = None,
        extra_query: Query | None = None,
        extra_body: Body | None = None,
        timeout: float | httpx.Timeout | None | NotGiven = not_given,
    ) -> DefendUpdateResponse:
        """
        Use this endpoint to update an existing defend workflow if its details change.

        Args:
          automatic_hallucination_tolerance_levels: New mapping of guardrail metrics to hallucination tolerance levels (either
              `low`, `medium`, or `high`) to be used when `threshold_type` is set to
              `automatic`. Possible metrics are `completeness`, `instruction_adherence`,
              `context_adherence`, `ground_truth_adherence`, or `comprehensive_safety`.

          context_awareness: Whether to enable context awareness for this workflow's evaluations.

          custom_hallucination_threshold_values: New mapping of guardrail metrics to floating point threshold values to be used
              when `threshold_type` is set to `custom`. Possible metrics are `correctness`,
              `completeness`, `instruction_adherence`, `context_adherence`,
              `ground_truth_adherence`, or `comprehensive_safety`.

          description: New description for the workflow.

          file_search: An array of file IDs to search in the workflow's evaluations. Files must be
              uploaded via the DeepRails API first.

          improvement_action: The new action used to improve outputs that fail one or more guardrail metrics
              for the workflow events. May be `regen`, `fixit`, or `do_nothing`. ReGen runs
              the user's input prompt with minor induced variance. FixIt attempts to directly
              address the shortcomings of the output using the guardrail failure rationale. Do
              Nothing does not attempt any improvement.

          max_improvement_attempts: Max. number of improvement action attempts until a given event passes the
              guardrails. Defaults to 10.

          name: New name for the workflow.

          threshold_type: New type of thresholds to use for the workflow, either `automatic` or `custom`.
              Automatic thresholds are assigned internally after the user specifies a
              qualitative tolerance for the metrics, whereas custom metrics allow the user to
              set the threshold for each metric as a floating point number between 0.0 and
              1.0.

          web_search: Whether to enable web search for this workflow's evaluations.

          extra_headers: Send extra headers

          extra_query: Add additional query parameters to the request

          extra_body: Add additional JSON properties to the request

          timeout: Override the client-level default timeout for this request, in seconds
        """
        if not workflow_id:
            raise ValueError(f"Expected a non-empty value for `workflow_id` but received {workflow_id!r}")
        return await self._put(
            f"/defend/{workflow_id}",
            body=await async_maybe_transform(
                {
                    "automatic_hallucination_tolerance_levels": automatic_hallucination_tolerance_levels,
                    "context_awareness": context_awareness,
                    "custom_hallucination_threshold_values": custom_hallucination_threshold_values,
                    "description": description,
                    "file_search": file_search,
                    "improvement_action": improvement_action,
                    "max_improvement_attempts": max_improvement_attempts,
                    "name": name,
                    "threshold_type": threshold_type,
                    "web_search": web_search,
                },
                defend_update_workflow_params.DefendUpdateWorkflowParams,
            ),
            options=make_request_options(
                extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
            ),
            cast_to=DefendUpdateResponse,
        )


class DefendResourceWithRawResponse:
    def __init__(self, defend: DefendResource) -> None:
        self._defend = defend

        self.create_workflow = to_raw_response_wrapper(
            defend.create_workflow,
        )
        self.retrieve_event = to_raw_response_wrapper(
            defend.retrieve_event,
        )
        self.retrieve_workflow = to_raw_response_wrapper(
            defend.retrieve_workflow,
        )
        self.submit_and_stream_event = to_raw_response_wrapper(
            defend.submit_and_stream_event,
        )
        self.submit_event = to_raw_response_wrapper(
            defend.submit_event,
        )
        self.update_workflow = to_raw_response_wrapper(
            defend.update_workflow,
        )


class AsyncDefendResourceWithRawResponse:
    def __init__(self, defend: AsyncDefendResource) -> None:
        self._defend = defend

        self.create_workflow = async_to_raw_response_wrapper(
            defend.create_workflow,
        )
        self.retrieve_event = async_to_raw_response_wrapper(
            defend.retrieve_event,
        )
        self.retrieve_workflow = async_to_raw_response_wrapper(
            defend.retrieve_workflow,
        )
        self.submit_and_stream_event = async_to_raw_response_wrapper(
            defend.submit_and_stream_event,
        )
        self.submit_event = async_to_raw_response_wrapper(
            defend.submit_event,
        )
        self.update_workflow = async_to_raw_response_wrapper(
            defend.update_workflow,
        )


class DefendResourceWithStreamingResponse:
    def __init__(self, defend: DefendResource) -> None:
        self._defend = defend

        self.create_workflow = to_streamed_response_wrapper(
            defend.create_workflow,
        )
        self.retrieve_event = to_streamed_response_wrapper(
            defend.retrieve_event,
        )
        self.retrieve_workflow = to_streamed_response_wrapper(
            defend.retrieve_workflow,
        )
        self.submit_and_stream_event = to_streamed_response_wrapper(
            defend.submit_and_stream_event,
        )
        self.submit_event = to_streamed_response_wrapper(
            defend.submit_event,
        )
        self.update_workflow = to_streamed_response_wrapper(
            defend.update_workflow,
        )


class AsyncDefendResourceWithStreamingResponse:
    def __init__(self, defend: AsyncDefendResource) -> None:
        self._defend = defend

        self.create_workflow = async_to_streamed_response_wrapper(
            defend.create_workflow,
        )
        self.retrieve_event = async_to_streamed_response_wrapper(
            defend.retrieve_event,
        )
        self.retrieve_workflow = async_to_streamed_response_wrapper(
            defend.retrieve_workflow,
        )
        self.submit_and_stream_event = async_to_streamed_response_wrapper(
            defend.submit_and_stream_event,
        )
        self.submit_event = async_to_streamed_response_wrapper(
            defend.submit_event,
        )
        self.update_workflow = async_to_streamed_response_wrapper(
            defend.update_workflow,
        )
