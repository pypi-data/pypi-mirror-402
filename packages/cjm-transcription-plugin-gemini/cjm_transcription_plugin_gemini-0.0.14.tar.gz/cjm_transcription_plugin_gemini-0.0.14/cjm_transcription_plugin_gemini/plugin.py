"""Plugin implementation for Google Gemini API transcription"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/plugin.ipynb.

# %% auto #0
__all__ = ['GeminiPluginConfig', 'GeminiPlugin']

# %% ../nbs/plugin.ipynb #f9a2bc9f
import sqlite3
import json
import time
import os
import sys
from uuid import uuid4
import logging
import tempfile
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Union, Tuple
import re

import numpy as np

from fastcore.basics import patch

try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    from cjm_ffmpeg_utils.core import FFMPEG_AVAILABLE
    from cjm_ffmpeg_utils.audio import downsample_audio
except ImportError:
    FFMPEG_AVAILABLE = False
    
# Import domain-specific plugin interface from migrated system
from cjm_transcription_plugin_system.plugin_interface import TranscriptionPlugin
from cjm_transcription_plugin_system.core import AudioData, TranscriptionResult
from cjm_plugin_system.utils.validation import (
    dict_to_config, config_to_dict, validate_config, dataclass_to_jsonschema,
    SCHEMA_TITLE, SCHEMA_DESC, SCHEMA_MIN, SCHEMA_MAX, SCHEMA_ENUM
)

from cjm_transcription_plugin_gemini.meta import (
    get_plugin_metadata
)

# %% ../nbs/plugin.ipynb #adc2fb86-7489-41e2-9018-4d434ef6bdb7
@dataclass
class GeminiPluginConfig:
    """Configuration for Gemini transcription plugin."""
    model:str = field(
        default="gemini-2.5-flash",
        metadata={
            SCHEMA_TITLE: "Model",
            SCHEMA_DESC: "Gemini model to use for transcription",
            SCHEMA_ENUM: [
                "gemini-2.5-flash", "gemini-2.5-flash-preview-05-20",
                "gemini-2.5-pro", "gemini-2.5-pro-preview-05-06",
                "gemini-2.0-flash", "gemini-2.0-flash-exp",
                "gemini-1.5-flash", "gemini-1.5-flash-latest",
                "gemini-1.5-pro", "gemini-1.5-pro-latest"
            ]
        }
    )
    api_key:Optional[str] = field(
        default=None,
        metadata={
            SCHEMA_TITLE: "API Key",
            SCHEMA_DESC: "Google API key (defaults to GEMINI_API_KEY env var)"
        }
    )
    prompt:str = field(
        default="Generate a transcription of the audio, only extract speech and ignore background audio.",
        metadata={
            SCHEMA_TITLE: "Prompt",
            SCHEMA_DESC: "Prompt for transcription"
        }
    )
    temperature:float = field(
        default=0.0,
        metadata={
            SCHEMA_TITLE: "Temperature",
            SCHEMA_DESC: "Sampling temperature",
            SCHEMA_MIN: 0.0,
            SCHEMA_MAX: 2.0
        }
    )
    top_p:float = field(
        default=0.95,
        metadata={
            SCHEMA_TITLE: "Top P",
            SCHEMA_DESC: "Top-p sampling parameter",
            SCHEMA_MIN: 0.0,
            SCHEMA_MAX: 1.0
        }
    )
    max_output_tokens:int = field(
        default=65536,
        metadata={
            SCHEMA_TITLE: "Max Output Tokens",
            SCHEMA_DESC: "Maximum number of output tokens",
            SCHEMA_MIN: 1,
            SCHEMA_MAX: 65536
        }
    )
    seed:Optional[int] = field(
        default=None,
        metadata={
            SCHEMA_TITLE: "Seed",
            SCHEMA_DESC: "Random seed for reproducibility"
        }
    )
    response_mime_type:str = field(
        default="text/plain",
        metadata={
            SCHEMA_TITLE: "Response MIME Type",
            SCHEMA_DESC: "Response MIME type",
            SCHEMA_ENUM: ["text/plain", "application/json"]
        }
    )
    downsample_audio:bool = field(
        default=False,
        metadata={
            SCHEMA_TITLE: "Downsample Audio",
            SCHEMA_DESC: "Downsample audio before uploading (requires ffmpeg)"
        }
    )
    downsample_rate:int = field(
        default=16000,
        metadata={
            SCHEMA_TITLE: "Downsample Rate",
            SCHEMA_DESC: "Target sample rate for downsampling",
            SCHEMA_ENUM: [8000, 16000, 22050, 44100]
        }
    )
    downsample_channels:int = field(
        default=1,
        metadata={
            SCHEMA_TITLE: "Downsample Channels",
            SCHEMA_DESC: "Number of audio channels (1=mono, 2=stereo)",
            SCHEMA_ENUM: [1, 2]
        }
    )
    safety_settings:str = field(
        default="OFF",
        metadata={
            SCHEMA_TITLE: "Safety Settings",
            SCHEMA_DESC: "Safety filter threshold",
            SCHEMA_ENUM: ["OFF", "BLOCK_NONE", "BLOCK_FEW", "BLOCK_SOME", "BLOCK_MOST"]
        }
    )
    auto_refresh_models:bool = field(
        default=True,
        metadata={
            SCHEMA_TITLE: "Auto Refresh Models",
            SCHEMA_DESC: "Automatically refresh available models list"
        }
    )
    model_filter:List[str] = field(
        default_factory=list,
        metadata={
            SCHEMA_TITLE: "Model Filter",
            SCHEMA_DESC: "Keywords to exclude from model names (e.g., ['tts', 'image'])"
        }
    )
    use_file_upload:bool = field(
        default=False,
        metadata={
            SCHEMA_TITLE: "Use File Upload",
            SCHEMA_DESC: "Upload audio files to Gemini API instead of embedding in request"
        }
    )
    use_streaming:bool = field(
        default=False,
        metadata={
            SCHEMA_TITLE: "Use Streaming",
            SCHEMA_DESC: "Use streaming response for transcription"
        }
    )
    delete_uploaded_files:bool = field(
        default=True,
        metadata={
            SCHEMA_TITLE: "Delete Uploaded Files",
            SCHEMA_DESC: "Delete uploaded files after transcription"
        }
    )

# %% ../nbs/plugin.ipynb #fcfcb260-d962-49ae-8bb9-d521a723f201
class GeminiPlugin(TranscriptionPlugin):
    """Google Gemini API transcription plugin."""
    
    config_class = GeminiPluginConfig
    
    # Default audio-capable models (can be overridden)
    DEFAULT_AUDIO_MODELS = [
        "gemini-2.5-flash",
        "gemini-2.5-flash-preview-05-20",
        "gemini-2.5-pro",
        "gemini-2.5-pro-preview-05-06",
        "gemini-2.0-flash",
        "gemini-2.0-flash-exp",
        "gemini-1.5-flash",
        "gemini-1.5-flash-latest",
        "gemini-1.5-pro",
        "gemini-1.5-pro-latest",
    ]
    
    def __init__(self):
        """Initialize the Gemini plugin with default configuration."""
        self.logger = logging.getLogger(f"{__name__}.{type(self).__name__}")
        self.config: GeminiPluginConfig = None
        self.client = None
        self.available_models = []
        self.model_token_limits = {}  # Store model name -> output_token_limit mapping
        self.uploaded_files = []  # Track uploaded files for cleanup
        self._current_api_key = None  # Track API key for change detection
    
    @property
    def name(self) -> str: # Plugin name identifier
        """Return the plugin name identifier."""
        return "gemini"
    
    @property
    def version(self) -> str: # Plugin version string
        """Return the plugin version string."""
        return "1.0.0"
    
    @property
    def supported_formats(self) -> List[str]: # List of supported audio formats
        """Return list of supported audio file formats."""
        return ["wav", "mp3", "aiff", "aac", "ogg", "flac"]

    def get_current_config(self) -> Dict[str, Any]: # Current configuration as dictionary
        """Return current configuration state."""
        if not self.config:
            return {}
        return config_to_dict(self.config)

    def get_config_schema(self) -> Dict[str, Any]: # JSON Schema for configuration
        """Return JSON Schema for UI generation."""
        return dataclass_to_jsonschema(GeminiPluginConfig)

    @staticmethod
    def get_config_dataclass() -> GeminiPluginConfig: # Configuration dataclass
        """Return dataclass describing the plugin's configuration options."""
        return GeminiPluginConfig
    
    def initialize(
        self,
        config: Optional[Any] = None # Configuration dataclass, dict, or None
    ) -> None:
        """Initialize or re-configure the plugin (idempotent)."""
        # Parse new config
        new_config = dict_to_config(GeminiPluginConfig, config or {})
        
        # Determine if we need to reinitialize client
        needs_client_reinit = False
        
        if self.config:
            # Check if API key changed
            new_api_key = new_config.api_key or os.environ.get("GEMINI_API_KEY")
            if new_api_key != self._current_api_key:
                self.logger.info("Config change: API key changed, reinitializing client")
                needs_client_reinit = True
        else:
            # First initialization
            needs_client_reinit = True
        
        # Apply new config
        self.config = new_config
        
        # Initialize or reinitialize client if needed
        if needs_client_reinit:
            try:
                api_key = self._get_api_key()
                self._current_api_key = api_key
                self.client = genai.Client(api_key=api_key)
                
                # Refresh available models if enabled
                if self.config.auto_refresh_models:
                    self.available_models = self._refresh_available_models()
                else:
                    self.available_models = self.DEFAULT_AUDIO_MODELS
                
                self.logger.info(f"Initialized Gemini client with model '{self.config.model}'")
                
            except Exception as e:
                self.logger.error(f"Failed to initialize Gemini client: {e}")
                raise
        
        # Update max_output_tokens based on selected model's limit
        self._update_max_tokens_for_model(self.config.model)
        
        self.logger.info(f"Gemini plugin configured with model '{self.config.model}'")
    
    def _init_db(self):
        """Ensure table exists."""
        db_path = get_plugin_metadata()["db_path"]
        with sqlite3.connect(db_path) as con:
            con.execute("""
                CREATE TABLE IF NOT EXISTS transcriptions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    job_id TEXT,
                    audio_path TEXT,
                    text TEXT,
                    segments JSON,
                    metadata JSON,
                    created_at REAL
                )
            """)
            con.execute("CREATE INDEX IF NOT EXISTS idx_job_id ON transcriptions(job_id)")

    def _save_to_db(self, result: TranscriptionResult, audio_path: str, **kwargs) -> None:
        """Save result to SQLite."""
        try:
            self._init_db()
            db_path = get_plugin_metadata()["db_path"]
            
            # Extract a job_id if provided, else gen random
            job_id = kwargs.get("job_id", str(uuid4()))
            
            # Serialize complex objects
            segments_json = json.dumps(result.segments) if result.segments else None
            metadata_json = json.dumps(result.metadata)
            
            with sqlite3.connect(db_path) as con:
                con.execute(
                    """
                    INSERT INTO transcriptions 
                    (job_id, audio_path, text, segments, metadata, created_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                    """,
                    (job_id, str(audio_path), result.text, segments_json, metadata_json, time.time())
                )
                self.logger.info(f"Saved result to DB (Job: {job_id})")
                
        except Exception as e:
            self.logger.error(f"Failed to save to DB: {e}")

    def execute(
        self,
        audio: Union[AudioData, str, Path], # Audio data object or path to audio file
        **kwargs # Additional arguments to override config
    ) -> TranscriptionResult: # Transcription result object
        """Transcribe audio using Gemini."""
        if not self.client:
            raise RuntimeError("Plugin not initialized. Call initialize() first.")
        
        # Check if model is being overridden at execution time
        if "model" in kwargs and kwargs["model"] != self.config.model:
            self._update_max_tokens_for_model(kwargs["model"])
        
        # Prepare audio file
        audio_path, temp_created = self._prepare_audio(audio)
        uploaded_file = None
        
        try:
            # Get config values, allowing kwargs overrides
            model = kwargs.get("model", self.config.model)
            temperature = kwargs.get("temperature", self.config.temperature)
            top_p = kwargs.get("top_p", self.config.top_p)
            max_output_tokens = kwargs.get("max_output_tokens", self.config.max_output_tokens)
            seed = kwargs.get("seed", self.config.seed)
            response_mime_type = kwargs.get("response_mime_type", self.config.response_mime_type)
            safety_settings = kwargs.get("safety_settings", self.config.safety_settings)
            prompt = kwargs.get("prompt", self.config.prompt)
            use_file_upload = kwargs.get("use_file_upload", self.config.use_file_upload)
            use_streaming = kwargs.get("use_streaming", self.config.use_streaming)
            delete_uploaded_files = kwargs.get("delete_uploaded_files", self.config.delete_uploaded_files)
            
            # Decide whether to upload file or embed in request
            if use_file_upload:
                # Upload audio file to Gemini API
                uploaded_file = self._upload_audio_file(audio_path)
                audio_content = uploaded_file
            else:
                # Read audio file and embed in request (existing behavior)
                with open(audio_path, 'rb') as f:
                    audio_bytes = f.read()
                
                # Determine MIME type
                suffix = audio_path.suffix.lower()
                mime_map = {
                    '.wav': 'audio/wav',
                    '.mp3': 'audio/mp3',
                    '.aiff': 'audio/aiff',
                    '.aac': 'audio/aac',
                    '.ogg': 'audio/ogg',
                    '.flac': 'audio/flac'
                }
                mime_type = mime_map.get(suffix, 'audio/wav')
                
                # Create audio content part
                audio_content = types.Part.from_bytes(
                    data=audio_bytes,
                    mime_type=mime_type
                )
            
            # Prepare generation config
            generate_config = types.GenerateContentConfig(
                response_mime_type=response_mime_type,
                temperature=temperature,
                top_p=top_p,
                max_output_tokens=max_output_tokens,
                seed=seed,
                safety_settings=[
                    types.SafetySetting(
                        category="HARM_CATEGORY_HATE_SPEECH",
                        threshold=safety_settings
                    ),
                    types.SafetySetting(
                        category="HARM_CATEGORY_DANGEROUS_CONTENT",
                        threshold=safety_settings
                    ),
                    types.SafetySetting(
                        category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        threshold=safety_settings
                    ),
                    types.SafetySetting(
                        category="HARM_CATEGORY_HARASSMENT",
                        threshold=safety_settings
                    )
                ]
            )
            
            # Prepare contents
            contents = [prompt, audio_content]
            
            # Generate transcription
            self.logger.info(f"Transcribing with Gemini model: {model} (max_tokens: {max_output_tokens})")
            
            # Use streaming or regular generation
            if use_streaming:
                # Use streaming response
                transcribed_text = ""
                for chunk in self.client.models.generate_content_stream(
                    model=model,
                    contents=contents,
                    config=generate_config
                ):
                    if hasattr(chunk, 'text'):
                        transcribed_text += chunk.text
                self.logger.info("Streaming transcription completed")
            else:
                # Use regular response (existing behavior)
                response = self.client.models.generate_content(
                    model=model,
                    contents=contents,
                    config=generate_config
                )
                transcribed_text = response.text if hasattr(response, 'text') else str(response)

            # Capture provenance metadata passed via kwargs
            provenance_meta = {
                k: v for k, v in kwargs.items() 
                if k in ['source_start_time', 'source_end_time']
            }
            
            # Create result
            result = TranscriptionResult(
                text=transcribed_text.strip(),
                confidence=None,  # Gemini doesn't provide confidence scores
                segments=None,  # Gemini doesn't provide segments by default
                metadata={
                    "model": model,
                    **provenance_meta, #
                    "temperature": temperature,
                    "top_p": top_p,
                    "max_output_tokens": max_output_tokens,
                    "prompt": prompt,
                    "use_file_upload": use_file_upload,
                    "use_streaming": use_streaming
                }
            )
            
            # Capture original path for DB
            original_path = str(audio)
            if hasattr(audio, 'to_temp_file'): original_path = "in_memory_data"
            
            # Save to database
            self._save_to_db(result, original_path, **kwargs)
            
            self.logger.info(f"Transcription completed: {len(transcribed_text.split())} words")
            return result
            
        finally:
            # Clean up uploaded file if configured to do so
            if uploaded_file and delete_uploaded_files:
                try:
                    self._delete_uploaded_file(uploaded_file.name)
                    # Remove from tracking list
                    self.uploaded_files = [f for f in self.uploaded_files if f.name != uploaded_file.name]
                except Exception as e:
                    self.logger.warning(f"Failed to cleanup uploaded file: {e}")
            
            # Clean up temporary file
            if temp_created:
                try:
                    audio_path.unlink()
                except Exception:
                    pass

    def is_available(self) -> bool: # True if the Gemini API is available
        """Check if Gemini API is available."""
        return GEMINI_AVAILABLE

    def cleanup(
        self
    ) -> None:
        """Clean up resources."""
        # Clean up any remaining uploaded files
        if self.config and self.config.delete_uploaded_files:
            for uploaded_file in self.uploaded_files:
                try:
                    self._delete_uploaded_file(uploaded_file.name)
                except Exception as e:
                    self.logger.warning(f"Failed to delete file during cleanup: {e}")
        
        self.uploaded_files = []
        self.client = None
        self.logger.info("Cleanup completed")

# %% ../nbs/plugin.ipynb #54a46385-4987-4ead-9be7-f0ef0e49e3cc
from dataclasses import replace as dataclass_replace

@patch
def _get_api_key(
    self:GeminiPlugin
) -> str:  # The API key string
    """Get API key from config or environment."""
    api_key = self.config.api_key if self.config else None
    if not api_key:
        api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("No API key provided. Set GEMINI_API_KEY environment variable or provide api_key in config")
    return api_key

@patch
def _refresh_available_models(
    self:GeminiPlugin
) -> List[str]:  # List of available model names
    """Fetch and filter available models from Gemini API."""
    try:
        if not self.client:
            return self.DEFAULT_AUDIO_MODELS
        
        # Get all models that support content generation
        all_models = list(self.client.models.list())
        gen_models = [model for model in all_models if 'generateContent' in model.supported_actions]
        
        # Extract model names and apply filters
        model_filter = self.config.model_filter if self.config.model_filter else ['tts', 'image', 'learn']
        
        filtered_names = []
        self.model_token_limits = {}  # Reset token limits
        
        for model in gen_models:
            model_name = model.name.removeprefix('models/')
            # Skip if any filter keyword is in the model name
            if not any(keyword in model_name.lower() for keyword in model_filter):
                filtered_names.append(model_name)
                # Store the output token limit for this model
                self.model_token_limits[model_name] = model.output_token_limit
        
        # Sort with newest/best models first
        filtered_names.sort(reverse=True)
        
        self.logger.info(f"Found {len(filtered_names)} audio-capable models")
        return filtered_names if filtered_names else self.DEFAULT_AUDIO_MODELS
        
    except Exception as e:
        self.logger.warning(f"Could not fetch models from API: {e}. Using defaults.")
        return self.DEFAULT_AUDIO_MODELS

@patch
def _update_max_tokens_for_model(
    self:GeminiPlugin,
    model_name: str  # Model name to update tokens for
) -> None:
    """Update max_output_tokens config based on the model's token limit."""
    if model_name in self.model_token_limits:
        token_limit = self.model_token_limits[model_name]
        self.config = dataclass_replace(self.config, max_output_tokens=token_limit)
        self.logger.info(f"Updated max_output_tokens to {token_limit} for model '{model_name}'")
    else:
        # Use a sensible default if we don't have the limit
        default_limit = 65536  # Common default for newer models
        self.config = dataclass_replace(self.config, max_output_tokens=default_limit)
        self.logger.info(f"Using default max_output_tokens of {default_limit} for model '{model_name}'")

# %% ../nbs/plugin.ipynb #f3e50ea0-61eb-42bf-a4e5-3e6780a97b6d
@patch
def update_config(
    self:GeminiPlugin,
    config: Union[Dict[str, Any], GeminiPluginConfig]  # New configuration values
) -> None:
    """Update plugin configuration, adjusting max_tokens if model changes."""
    old_model = self.config.model if self.config else None
    
    # Handle different input types
    if isinstance(config, dict):
        # Merge with existing config using replace
        self.config = dataclass_replace(self.config, **config)
    elif isinstance(config, GeminiPluginConfig):
        self.config = config
    else:
        raise TypeError(f"Expected dict or GeminiPluginConfig, got {type(config).__name__}")
    
    # If model changed, update max_output_tokens
    if self.config.model and self.config.model != old_model:
        self._update_max_tokens_for_model(self.config.model)

@patch
def _prepare_audio(
    self:GeminiPlugin,
    audio: Union[AudioData, str, Path]  # Audio data object or path to audio file
) -> Tuple[Path, bool]:  # Tuple of (processed audio path, whether temp file was created)
    """Prepare audio file for upload."""
    temp_created = False
    
    if isinstance(audio, (str, Path)):
        audio_path = Path(audio)
    elif isinstance(audio, AudioData):
        # Save AudioData to temporary file
        import soundfile as sf
        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        
        audio_array = audio.samples
        # Convert to mono if stereo
        if audio_array.ndim > 1:
            audio_array = audio_array.mean(axis=1)
        
        # Ensure float32 and normalized
        if audio_array.dtype != np.float32:
            audio_array = audio_array.astype(np.float32)
        if audio_array.max() > 1.0:
            audio_array = audio_array / np.abs(audio_array).max()
        
        sf.write(temp_file.name, audio_array, audio.sample_rate)
        audio_path = Path(temp_file.name)
        temp_created = True
    else:
        raise ValueError(f"Unsupported audio input type: {type(audio)}")
    
    # Optionally downsample audio
    if self.config.downsample_audio and FFMPEG_AVAILABLE:
        try:
            downsampled = audio_path.with_stem(f"{audio_path.stem}_downsampled")
            downsample_audio(
                audio_path,
                downsampled,
                sample_rate=self.config.downsample_rate,
                channels=self.config.downsample_channels
            )
            
            # Clean up original temp file if created
            if temp_created:
                audio_path.unlink()
            
            audio_path = downsampled
            temp_created = True
            self.logger.info(f"Downsampled audio to {self.config.downsample_rate}Hz")
            
        except Exception as e:
            self.logger.warning(f"Failed to downsample audio: {e}")
    
    return audio_path, temp_created

@patch
def _upload_audio_file(
    self:GeminiPlugin,
    audio_path: Path  # Path to audio file to upload
) -> Any:  # Uploaded file object
    """Upload audio file to Gemini API."""
    try:
        self.logger.info(f"Uploading audio file: {audio_path}")
        uploaded_file = self.client.files.upload(file=audio_path)
        self.uploaded_files.append(uploaded_file)  # Track for cleanup
        self.logger.info(f"Successfully uploaded file: {uploaded_file.name}")
        return uploaded_file
    except Exception as e:
        self.logger.error(f"Failed to upload audio file: {e}")
        raise

@patch
def _delete_uploaded_file(
    self:GeminiPlugin,
    file_name: str  # Name of file to delete
) -> None:
    """Delete an uploaded file from Gemini API."""
    try:
        self.client.files.delete(name=file_name)
        self.logger.info(f"Deleted uploaded file: {file_name}")
    except Exception as e:
        self.logger.warning(f"Failed to delete uploaded file {file_name}: {e}")

# %% ../nbs/plugin.ipynb #5e0932b0
@patch
def get_available_models(
    self:GeminiPlugin
) -> List[str]:  # List of available model names
    """Get list of available audio-capable models."""
    if self.config and self.config.auto_refresh_models and self.client:
        self.available_models = self._refresh_available_models()
    return self.available_models

@patch
def get_model_info(
    self:GeminiPlugin,
    model_name: Optional[str] = None  # Model name to get info for, defaults to current model
) -> Dict[str, Any]:  # Dict with model information
    """Get information about a specific model including token limits."""
    if model_name is None:
        model_name = self.config.model if self.config else "gemini-2.5-flash"
    
    return {
        "name": model_name,
        "output_token_limit": self.model_token_limits.get(model_name, 65536),
        "current_max_output_tokens": self.config.max_output_tokens if self.config else 65536
    }

# %% ../nbs/plugin.ipynb #odr8y9xm0z
from typing import Generator

@patch
def supports_streaming(
    self:GeminiPlugin
) -> bool:  # True if streaming is supported
    """Check if this plugin supports streaming transcription."""
    return True

@patch  
def execute_stream(
    self:GeminiPlugin,
    audio: Union[AudioData, str, Path],  # Audio data object or path to audio file
    **kwargs  # Additional arguments to override config
) -> Generator[str, None, TranscriptionResult]:  # Yields text chunks, returns final result
    """Stream transcription results chunk by chunk."""
    if not self.client:
        raise RuntimeError("Plugin not initialized. Call initialize() first.")
    
    # Force streaming mode in config
    kwargs['use_streaming'] = True
    
    # Check if model is being overridden at execution time
    if "model" in kwargs and kwargs["model"] != self.config.model:
        self._update_max_tokens_for_model(kwargs["model"])
    
    # Prepare audio file
    audio_path, temp_created = self._prepare_audio(audio)
    uploaded_file = None
    
    try:
        # Get config values, allowing kwargs overrides
        model = kwargs.get("model", self.config.model)
        temperature = kwargs.get("temperature", self.config.temperature)
        top_p = kwargs.get("top_p", self.config.top_p)
        max_output_tokens = kwargs.get("max_output_tokens", self.config.max_output_tokens)
        seed = kwargs.get("seed", self.config.seed)
        response_mime_type = kwargs.get("response_mime_type", self.config.response_mime_type)
        safety_settings = kwargs.get("safety_settings", self.config.safety_settings)
        prompt = kwargs.get("prompt", self.config.prompt)
        use_file_upload = kwargs.get("use_file_upload", self.config.use_file_upload)
        delete_uploaded_files = kwargs.get("delete_uploaded_files", self.config.delete_uploaded_files)
        
        # Decide whether to upload file or embed in request
        if use_file_upload:
            # Upload audio file to Gemini API
            uploaded_file = self._upload_audio_file(audio_path)
            audio_content = uploaded_file
        else:
            # Read audio file and embed in request
            with open(audio_path, 'rb') as f:
                audio_bytes = f.read()
            
            # Determine MIME type
            suffix = audio_path.suffix.lower()
            mime_map = {
                '.wav': 'audio/wav',
                '.mp3': 'audio/mp3',
                '.aiff': 'audio/aiff',
                '.aac': 'audio/aac',
                '.ogg': 'audio/ogg',
                '.flac': 'audio/flac'
            }
            mime_type = mime_map.get(suffix, 'audio/wav')
            
            # Create audio content part
            audio_content = types.Part.from_bytes(
                data=audio_bytes,
                mime_type=mime_type
            )
        
        # Prepare generation config
        generate_config = types.GenerateContentConfig(
            response_mime_type=response_mime_type,
            temperature=temperature,
            top_p=top_p,
            max_output_tokens=max_output_tokens,
            seed=seed,
            safety_settings=[
                types.SafetySetting(
                    category="HARM_CATEGORY_HATE_SPEECH",
                    threshold=safety_settings
                ),
                types.SafetySetting(
                    category="HARM_CATEGORY_DANGEROUS_CONTENT",
                    threshold=safety_settings
                ),
                types.SafetySetting(
                    category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    threshold=safety_settings
                ),
                types.SafetySetting(
                    category="HARM_CATEGORY_HARASSMENT",
                    threshold=safety_settings
                )
            ]
        )
        
        # Prepare contents
        contents = [prompt, audio_content]
        
        # Generate transcription with streaming
        self.logger.info(f"Streaming transcription with Gemini model: {model} (max_tokens: {max_output_tokens})")
        
        transcribed_text = ""
        chunks_yielded = 0
        
        # Stream chunks as they arrive
        for chunk in self.client.models.generate_content_stream(
            model=model,
            contents=contents,
            config=generate_config
        ):
            if hasattr(chunk, 'text'):
                chunk_text = chunk.text
                transcribed_text += chunk_text
                chunks_yielded += 1
                yield chunk_text  # Yield each chunk in real-time
        
        self.logger.info(f"Streaming completed: {chunks_yielded} chunks, {len(transcribed_text.split())} words")
        
        # Return final result
        return TranscriptionResult(
            text=transcribed_text.strip(),
            confidence=None,  # Gemini doesn't provide confidence scores
            segments=None,  # Gemini doesn't provide segments by default
            metadata={
                "model": model,
                "temperature": temperature,
                "top_p": top_p,
                "max_output_tokens": max_output_tokens,
                "prompt": prompt[:100] + "..." if len(prompt) > 100 else prompt,
                "use_file_upload": use_file_upload,
                "use_streaming": True,
                "streaming_chunks": chunks_yielded
            }
        )
        
    finally:
        # Clean up uploaded file if configured to do so
        if uploaded_file and delete_uploaded_files:
            try:
                self._delete_uploaded_file(uploaded_file.name)
                # Remove from tracking list
                self.uploaded_files = [f for f in self.uploaded_files if f.name != uploaded_file.name]
            except Exception as e:
                self.logger.warning(f"Failed to cleanup uploaded file: {e}")
        
        # Clean up temporary file
        if temp_created:
            try:
                audio_path.unlink()
            except Exception:
                pass
