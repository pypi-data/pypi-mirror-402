{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Metrics and Losses\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nverchev/drytorch/blob/main/docs/tutorials/metrics_and_losses.ipynb)\n",
    "\n",
    "DRYTorch helps you **standardize and document** your model's metrics and loss.\n",
    "\n",
    "## Design\n",
    "The modular design extends to metrics and losses. DRYTorch provides a common interface for both, allowing you to easily switch between different libraries.\n",
    "\n",
    "### Terminology\n",
    "\n",
    "An **objective** is a criterion for model performance evaluation. We distinguish between two types:\n",
    "\n",
    "* **Metric:** Assesses model performance as a proxy for the overall goal.\n",
    "* **Loss:** Optimizes the model parameters to improve metric assessments.\n",
    "\n",
    "DRYTorch allows using losses as metrics, but not vice versa.\n",
    "\n",
    "### Protocols\n",
    "\n",
    "DRYTorch defines an `ObjectiveProtocol`, used by classes that implement the validation and testing of a model, and a `LossProtocol`, used for its training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "! uv pip install drytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Compatibility with Existing Libraries\n",
    "\n",
    "DRYTorch **does not re-implement** common metrics or losses. Instead, it defines **protocols** to ensure **full compatibility** with classes from popular existing libraries.\n",
    "\n",
    "\n",
    "### For Validation and Testing\n",
    "\n",
    "The `ObjectiveProtocol` is compatible with `Metric` classes from:\n",
    "* [**TorchMetrics**](https://lightning.ai/docs/torchmetrics/stable/)\n",
    "* [**TorchEval**](https://docs.pytorch.org/torcheval/stable/)\n",
    "\n",
    "You can use instances of these third-party metric classes **directly** when defining a DRYTorch validation or test step.\n",
    "\n",
    "### For Training\n",
    "\n",
    "The `LossProtocol` is designed to accept any class that meets its requirements, including some metrics. You can therefore use differentiable metrics from libraries like **TorchMetrics** directly when building a DRYTorch training class.\n",
    "\n",
    "\n",
    "**TorchMetrics** also offers a `CompositionalMetric`, with support for algebra operations, which inspired part of the DRYTorch own implementation. To make it compatible with the framework and better documentation, you can use\n",
    "`from_torchmetrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "from torcheval import metrics as eval_metrics\n",
    "\n",
    "from drytorch.core import protocols as p\n",
    "\n",
    "\n",
    "tensor_a = torch.ones(1, 1, dtype=torch.float)\n",
    "tensor_b = 3 * torch.ones(1, 1, dtype=torch.float)\n",
    "torch_metric = torchmetrics.MeanSquaredError()\n",
    "eval_metric = eval_metrics.MeanSquaredError()\n",
    "\n",
    "\n",
    "def is_valid_objective(\n",
    "    metric: p.ObjectiveProtocol[torch.Tensor, torch.Tensor],\n",
    ") -> bool:\n",
    "    \"\"\"Test metric follows the Objective protocol.\"\"\"\n",
    "    return isinstance(metric, p.ObjectiveProtocol)\n",
    "\n",
    "\n",
    "torch_metric.update(tensor_a, tensor_b)\n",
    "eval_metric.update(tensor_a, tensor_b)\n",
    "\n",
    "if not torch.isclose(torch_metric.compute(), eval_metric.compute()):\n",
    "    raise AssertionError('Metrics values should match.')\n",
    "\n",
    "if not (is_valid_objective(eval_metric) and is_valid_objective(torch_metric)):\n",
    "    raise AssertionError('These objects should follow the ObjectiveProtocol.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_loss(\n",
    "    metric: p.LossProtocol[torch.Tensor, torch.Tensor],\n",
    ") -> bool:\n",
    "    \"\"\"Test metric follows the Loss protocol.\"\"\"\n",
    "    return isinstance(metric, p.LossProtocol)\n",
    "\n",
    "\n",
    "if not is_valid_loss(torch_metric):\n",
    "    raise AssertionError('This object should also follow the LossProtocol.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drytorch.contrib.torchmetrics import from_torchmetrics\n",
    "\n",
    "\n",
    "new_metric = 1 + torch_metric\n",
    "imported_metric = from_torchmetrics(new_metric)\n",
    "imported_metric.update(tensor_a, tensor_b)\n",
    "expected_metrics_from_torchmetrics = {\n",
    "    'Combined Loss': torch.tensor(5.0),\n",
    "    'MeanSquaredError': torch.tensor(4.0),\n",
    "}\n",
    "if not imported_metric.compute() == expected_metrics_from_torchmetrics:\n",
    "    raise AssertionError('Metrics values should be as expected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## DRYTorch implementation\n",
    "DRYTorch objective classes act as wrappers around **user-defined** metric and loss callables.\n",
    "\n",
    "\n",
    "These callables must accept model outputs and targets as arguments and return a scalar PyTorch Tensor for an aggregated mini-batch value or a vector of batched values (recommended for more precise averaging across batches of varying sizes). The abstract `Objective` class handles **calling the logic, documenting, and correctly aggregating** the results across batches.\n",
    "\n",
    "\n",
    "### The Metric and MetricCollection classes\n",
    "The `Metric` class is to define a single metric. You can document it by\n",
    "giving it an explicit name and specifies whether it is better when higher or\n",
    "lower. You can also concatenate different Metric instances with compatible signatures into a `MetricCollection` instance, or creating one directly from a dictionary of named metric functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss as mse_loss_fn  # returns scalar value\n",
    "\n",
    "from drytorch.lib.objectives import Metric\n",
    "\n",
    "\n",
    "def mae_loss_fn(outputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Returns batched Meas Absolute Error (MAE) values.\"\"\"\n",
    "    return torch.abs(outputs - targets).flatten(1).mean(1)\n",
    "\n",
    "\n",
    "mse_metric = Metric(mse_loss_fn, name='MSE', higher_is_better=False)\n",
    "mae_metric = Metric(mae_loss_fn, 'MAE', higher_is_better=False)\n",
    "metric_collection = mse_metric | mae_metric\n",
    "metric_collection.update(tensor_a, tensor_b)\n",
    "metric_collection.compute()\n",
    "expected_metric_collection = {\n",
    "    'MSE': torch.tensor(4.0),\n",
    "    'MAE': torch.tensor(2.0),\n",
    "}\n",
    "if not metric_collection.compute() == expected_metric_collection:\n",
    "    raise AssertionError('Metrics values should be as expected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Define a Custom Metric class\n",
    "\n",
    "You can subclass the abstract `Objective` class by overriding the `calculate` method. In this example, we slightly reduce the calculation overhead to obtain the previous metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import override\n",
    "\n",
    "from drytorch.lib.objectives import Objective\n",
    "\n",
    "\n",
    "class MyMetrics(Objective[torch.Tensor, torch.Tensor]):\n",
    "    \"\"\"Class to calculate MSE and MAE more efficiently.\"\"\"\n",
    "\n",
    "    @override\n",
    "    def calculate(\n",
    "        self, outputs: torch.Tensor, targets: torch.Tensor\n",
    "    ) -> dict[str, torch.Tensor]:\n",
    "        diff = outputs - targets\n",
    "        return {\n",
    "            'MSE': torch.pow(diff, 2).flatten(1).mean(1),\n",
    "            'MAE': torch.abs(diff).flatten(1).mean(1),\n",
    "        }\n",
    "\n",
    "\n",
    "my_metrics = MyMetrics()\n",
    "my_metrics.update(tensor_a, tensor_b)\n",
    "my_metrics.compute()\n",
    "if not my_metrics.compute() == expected_metric_collection:\n",
    "    raise AssertionError('Metrics values should be as before.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## LossBase, Loss and CompositionalLoss\n",
    "\n",
    "`LossBase` is the abstract class for concrete loss classes, such as `Loss` and `CompositionalLoss`.\n",
    "\n",
    "`Loss` is equivalent to Metric and accepts a single callable that is used both as a criterion for backpropagation for the loss and as a metric.\n",
    "\n",
    "\n",
    "The `CompositionalLoss` class extends this idea by evaluating other metrics besides the main optimization criterion. This allows you to easily document and track the performance of the **single components** that make up a more complex, composed loss function.\n",
    "\n",
    "\n",
    "It is possible to create a compositional loss by using simple algebraic operations between a `LossBase` instance and an integer, float, or another `LossBase` instance. The resulting object's `formula` attribute documents the specific operations and component losses utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss as mse_loss_fn  # returns scalar value\n",
    "\n",
    "from drytorch.lib.objectives import Loss\n",
    "\n",
    "\n",
    "mse_loss = Loss(mse_loss_fn, name='MSE')\n",
    "mae_loss = Loss(mae_loss_fn, 'MAE')\n",
    "composed_loss = mse_loss**2 + 0.5 * mae_loss\n",
    "composed_loss.update(tensor_a, tensor_b)\n",
    "expected_metrics_from_loss = {\n",
    "    'Combined Loss': torch.tensor(17.0),\n",
    "    'MSE': torch.tensor(4.0),\n",
    "    'MAE': torch.tensor(2.0),\n",
    "}\n",
    "if not composed_loss.compute() == expected_metrics_from_loss:\n",
    "    raise AssertionError('Metrics values should be as expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if composed_loss.formula != '[MSE]^2 + 0.5 x [MAE]':\n",
    "    raise AssertionError('Formula mismatch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Data Distributed Parallelism\n",
    "DRYTorch `Objective` classes are compatible with PyTorch's Data Distributed Parallelism (DDP) module. Synchronization is handled by the library classes.\n",
    "\n",
    "To use `torchmetrics` and `torcheval` metrics with DDP, we recommend using the `from_torchmetrics` and `from_torcheval` utility functions.\n",
    "\n",
    "In particular, `from_torchmetrics` deactivates automatic synchronization and\n",
    "`from_torcheval` adds a `sync` method that calls `torcheval.metrics.toolkit.sync_and_compute` to synchronize the metrics across all processes.\n",
    "\n",
    "The following code snippet shows the latter call, which will raise a warning as the current process is not in a DDP scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drytorch.contrib.torcheval import from_torcheval\n",
    "\n",
    "\n",
    "eval_metric_with_sync = from_torcheval(eval_metric)\n",
    "\n",
    "eval_metric_with_sync.sync()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3",
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
