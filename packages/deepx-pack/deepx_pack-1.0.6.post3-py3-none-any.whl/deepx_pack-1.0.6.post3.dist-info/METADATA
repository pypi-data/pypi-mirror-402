Metadata-Version: 2.4
Name: deepx-pack
Version: 1.0.6.post3
Summary: DeepH-pack is a general-purpose neural network package for deep-learning electronic structure calculations. As the latest evolution of the DeepH framework, it integrates all prior methodologies into a unified, cohesive toolkit. This enhanced version has been fully rebuilt using JAX, delivering greater computational efficiency and expanded functionality.
Author-email: DeepH team <deeph-pack@outlook.com>
License-Expression: GPL-3.0-or-later
Project-URL: Repository, https://github.com/kYangLi/DeepH-pack-docs.git
Keywords: DeepH-pack,DeepH,Physics,Deep Learning,Graph Neural Network,JAX
Classifier: Development Status :: 5 - Production/Stable
Classifier: Programming Language :: Python :: 3.13
Requires-Python: <3.15,>=3.13
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pyarmor==9.1.9
Requires-Dist: numpy
Requires-Dist: toml
Requires-Dist: h5py
Requires-Dist: matplotlib
Requires-Dist: joblib
Requires-Dist: rocksdict
Provides-Extra: gpu
Requires-Dist: torch==2.7.1+cpu; extra == "gpu"
Requires-Dist: torch_geometric==2.6.1; extra == "gpu"
Requires-Dist: jax[cuda12]==0.6.2; extra == "gpu"
Requires-Dist: flax==0.10.6; extra == "gpu"
Requires-Dist: e3nn-jax==0.20.7; extra == "gpu"
Requires-Dist: optax==0.2.5; extra == "gpu"
Requires-Dist: orbax-checkpoint==0.11.16; extra == "gpu"
Provides-Extra: cpu
Requires-Dist: torch==2.7.1+cpu; extra == "cpu"
Requires-Dist: torch_geometric==2.6.1; extra == "cpu"
Requires-Dist: jax[cpu]==0.6.2; extra == "cpu"
Requires-Dist: flax==0.10.6; extra == "cpu"
Requires-Dist: e3nn-jax==0.20.7; extra == "cpu"
Requires-Dist: optax==0.2.5; extra == "cpu"
Requires-Dist: orbax-checkpoint==0.11.16; extra == "cpu"
Provides-Extra: julia
Requires-Dist: cython; extra == "julia"
Requires-Dist: juliacall; extra == "julia"
Provides-Extra: mpi
Requires-Dist: mpi4py; extra == "mpi"
Provides-Extra: mpi4jax
Requires-Dist: cython; extra == "mpi4jax"
Requires-Dist: mpi4jax==0.7.1; extra == "mpi4jax"
Provides-Extra: docs
Requires-Dist: sphinx; extra == "docs"
Requires-Dist: sphinx-book-theme; extra == "docs"
Requires-Dist: sphinx-autobuild; extra == "docs"
Requires-Dist: ipykernel; extra == "docs"
Requires-Dist: myst_nb; extra == "docs"
Requires-Dist: nbstripout; extra == "docs"
Requires-Dist: recommonmark; extra == "docs"
Requires-Dist: ipython_genutils; extra == "docs"
Requires-Dist: sphinx-design; extra == "docs"
Requires-Dist: jupytext; extra == "docs"
Requires-Dist: docutils; extra == "docs"
Dynamic: license-file

<!-- markdownlint-disable MD033 -->
<h1><p align="center">
  <img src="https://raw.githubusercontent.com/kYangLi/DeepH-pack-docs/main/docs/_image/logo-large.svg" alt="DeepH-pack Logo" width="500">
</p></h1>

<div align="center">

### *A General-purpose Neural Network Package for Deep-learning Electronic Structure Calculations*

[![GitHub Actions PyPI Release](https://github.com/kYangLi/DeepH-pack-docs/actions/workflows/publish.yaml/badge.svg)](https://github.com/kYangLi/DeepH-pack-docs/actions/workflows/publish.yaml)
[![PyPI Version](https://img.shields.io/pypi/v/deepx-pack.svg)](https://pypi.org/project/deepx-pack/)
[![Python 3.13](https://img.shields.io/badge/python-3.13-blue.svg)](https://www.python.org/)

[![License](https://img.shields.io/pypi/l/deepx-pack.svg)](https://pypi.org/project/deepx-pack/)
[![Documentation Status](https://readthedocs.org/projects/deeph-pack-docs/badge/?version=latest)](https://docs.deeph-pack.com/deeph-pack/en/latest/)
[![GitHub Issues](https://img.shields.io/github/issues/kYangLi/DeepH-pack-docs.svg)](https://github.com/kYangLi/DeepH-pack-docs/issues)
[![GitHub Stars](https://img.shields.io/github/stars/kYangLi/DeepH-pack-docs.svg?style=social)](https://github.com/kYangLi/DeepH-pack-docs/stargazers)

*Drive Accuracy and Efficiency with Intelligence.*
</div>

For the most comprehensive usage documentation, please visit [https://docs.deeph-pack.com/deeph-pack](https://docs.deeph-pack.com/deeph-pack/en/latest/).

---

- [Core Features](#core-features)
- [Quick Start](#quick-start)
  - [Get the Software](#get-the-software)
  - [Installation](#installation)
  - [Basic Usage](#basic-usage)
- [Citation](#citation)
- [Publications | DeepH Team](#publications--deeph-team)

## Core Features

The [modernized DeepH-pack](https://ticket.deeph-pack.com/?language=en) is built upon the [solid foundation of its predecessor](https://github.com/mzjb/DeepH-pack) and has been re-engineered with [JAX](https://github.com/jax-ml/jax) and [FLAX](https://github.com/google/flax) to unlock new levels of efficiency and flexibility.

## Quick Start

### Get the Software

Please visit the [DeepH-pack official website](https://ticket.deeph-pack.com/?language=en) to apply for and obtain the software.

### Installation

Before installing `DeepH-pack`, ensure that [uv](https://docs.astral.sh/uv/) — a fast and versatile Python package manager — is properly installed and configured, and that your `Python 3.13` environment is set up. If you plan to run DeepH in a GPU-accelerated environment, you must also pre-install `CUDA 12.8` or `12.9`.

```bash
pip install ./deepx-1.0.6+light-py3-none-any.whl[gpu] --extra-index-url https://download.pytorch.org/whl/cpu
```

For step-by-step detailed procedures, please refer to the [documentation](https://docs.deeph-pack.com/deeph-pack/en/latest/installation_and_setup.html).

**Parameter explanation:**

- `./deepx-1.0.6+light-py3-none-any.whl` is the Python wheel file available for download from the official [DeepH-pack website](https://ticket.deeph-pack.com/?language=en).

- The `[gpu]` extra dependency tag indicates the GPU-accelerated version of the package, which is **strongly recommended** for optimal performance. If your system only supports CPU computation, replace `[gpu]` with `[cpu]`.

- The `--extra-index-url` flag is used to specify an additional package index (in this case, PyTorch's official repository) for resolving certain dependencies.

### Basic Usage

```bash
deeph-train train.toml
deeph-infer infer.toml
```

For detailed instructions, see [DeepH-pack online documentation](https://docs.deeph-pack.com/deeph-pack/en/latest/).

## Citation

*Any and all use of this software, in whole or in part, should clearly acknowledge and link to this repository.*

If you use `DeepH-pack` in your work, please cite the following publications.

- **The original framework paper introducing the foundational methodology:**

    [He Li, Zun Wang, Nianlong Zou, *et al*. Deep-learning density functional theory Hamiltonian for efficient ab initio electronic-structure calculation. Nat. Comput. Sci. 2, 367 (2022)](https://doi.org/10.1038/s43588-022-00265-6)

- **Complete package featuring the latest implementation, methodology, and workflow:**

    [Yang Li, Yanzhen Wang, Boheng Zhao, *et al*. DeepH-pack: A general-purpose neural network package for deep-learning electronic structure calculations. arXiv:2601.02938 (2026)](https://arxiv.org/abs/2601.02938)

```bibtex
@article{li2022deep,
    title={Deep-learning density functional theory Hamiltonian for efficient ab initio electronic-structure calculation},
    author={Li, He and Wang, Zun and Zou, Nianlong and Ye, Meng and Xu, Runzhang and Gong, Xiaoxun and Duan, Wenhui and Xu, Yong},
    journal={Nat. Comput. Sci.},
    volume={2},
    number={6},
    pages={367},
    year={2022},
    publisher={Nature Publishing Group US New York}
}

@article{li2026deeph,
    title={DeepH-pack: A general-purpose neural network package for deep-learning electronic structure calculations},
    author={Li, Yang and Wang, Yanzhen and Zhao, Boheng and Gong, Xiaoxun and Wang, Yuxiang and Tang, Zechen and Wang, Zixu and Yuan, Zilong and Li, Jialin and Sun, Minghui and Chen, Zezhou and Tao, Honggeng and Wu, Baochun and Yu, Yuhang and Li, He and da Jornada, Felipe H. and Duan, Wenhui and Xu, Yong },
    journal={arXiv preprint arXiv:2601.02938},
    year={2026}
}
```

## Publications | DeepH Team

For a comprehensive overview of publications and research employing DeepH methods, please see the relevant section below. We also warmly welcome citations to our foundational papers if your work utilizes the DeepH framework or any of its modules (e.g., [DeepH-E3](https://github.com/Xiaoxun-Gong/DeepH-E3), [HPRO](https://github.com/Xiaoxun-Gong/HPRO)).

1. **Latest Software Implementation**

    - [Yang Li, Yanzhen Wang, Boheng Zhao, *et al*. DeepH-pack: A general-purpose neural network package for deep-learning electronic structure calculations. arXiv:2601.02938 (2026)](https://arxiv.org/abs/2601.02938)

2. **Architecture advancements**

    - **DeepH**: Original framework [Nat. Comput. Sci. 2, 367 (2022)](https://doi.org/10.1038/s43588-022-00265-6)
    - **DeepH-E3**: Integrating equivariant neural network [Nat. Commun. 14, 2848 (2023)](https://doi.org/10.1038/s41467-023-38468-8)
    - **DeepH-2**: Incorporating eSCN tensor product [arXiv:2401.17015 (2024)](https://arxiv.org/abs/2401.17015)
    - **DeepH-Zero**: Leveraging physics-informed unsupervised learning [Phys. Rev. Lett. 133, 076401 (2024)](https://doi.org/10.1103/PhysRevLett.133.076401)

3. **Improved compatibility with first-principles codes**

    - **HPRO**: Compatibility with plane-wave DFT [Nat. Comput. Sci. 4, 752 (2024)](https://doi.org/10.1038/s43588-024-00701-9)
    - **DeepH-hybrid**: Extension to hybrid DFT [Nat. Commun. 15, 8815 (2024)](https://doi.org/10.1038/s41467-024-53028-4)

4. **Exploration of application scenarios**

    - **xDeepH**: Dealing with magnetism with extended DeepH [Nat. Comput. Sci. 3, 321 (2023)](https://doi.org/10.1038/s43588-023-00424-3)
    - **DeepH-DFPT**: Investigating density functional perturbation theory [Phys. Rev. Lett. 132, 096401 (2024)](https://doi.org/10.1103/PhysRevLett.132.096401)
    - **DeepH-UMM**: Developing the universal model for electronic structures [Sci. Bull. 69, 2514 (2024)](https://doi.org/10.1016/j.scib.2024.06.011)

5. **Review of Recent Advancement**

    - From DeepH and ML-QMC to fast, accurate materials computation [Nat. Comput. Sci. 5, 1133 (2025)](https://doi.org/10.1038/s43588-025-00932-4)

---

*DeepH-pack is a general-purpose neural network package designed for deep-learning electronic structure calculations, empowering computational materials science with accelerated speed and enhanced efficiency through intelligent algorithms.*
