from __future__ import annotations

from typing import Any

from pydantic import BaseModel, Field, model_validator


class ModelConfig(BaseModel):
    """Configuration for an LLM model.

    Attributes:
        supported_formats: List of supported tool calling formats.
            - "native": Uses API's native function/tool calling
            - "xml": Uses XML-based tool calling in prompts
            Models default to supporting both formats.
        supports_thinking: Whether the model supports thinking/reasoning content.
    """

    name: str
    provider: str
    alias: str
    temperature: float = 0.2
    input_price: float = 0.0
    output_price: float = 0.0
    context: int = 128000
    max_output: int = 32000
    supported_formats: list[str] = Field(default_factory=lambda: ["native", "xml"])
    supports_thinking: bool = False

    @model_validator(mode="before")
    @classmethod
    def _default_alias_to_name(cls, data: Any) -> Any:
        if isinstance(data, dict):
            if "alias" not in data or data["alias"] is None:
                data["alias"] = data.get("name")
        return data


DEFAULT_MODELS = [
    # Mistral models
    ModelConfig(
        name="mistral-vibe-cli-latest",
        provider="mistral",
        alias="devstral-2",
        input_price=0.4,
        output_price=2.0,
        context=200000,
        max_output=32000,
    ),
    ModelConfig(
        name="devstral-small-latest",
        provider="mistral",
        alias="devstral-small",
        input_price=0.1,
        output_price=0.3,
        context=200000,
        max_output=32000,
    ),
    # OpenAI models
    ModelConfig(
        name="gpt-5.2",
        provider="openai",
        alias="gpt-5.2",
        input_price=1.75,
        output_price=14.0,
        context=400000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5.1",
        provider="openai",
        alias="gpt-5.1",
        input_price=1.25,
        output_price=10.0,
        context=400000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5",
        provider="openai",
        alias="gpt-5",
        input_price=1.25,
        output_price=10.0,
        context=400000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5-mini",
        provider="openai",
        alias="gpt-5-mini",
        input_price=0.25,
        output_price=2.0,
        context=400000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5.1-codex-max",
        provider="openai",
        alias="gpt-5.1-codex-max",
        input_price=1.25,
        output_price=10.0,
        context=400000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5.1-codex",
        provider="openai",
        alias="gpt-5.1-codex",
        input_price=1.25,
        output_price=10.0,
        context=1000000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5-codex",
        provider="openai",
        alias="gpt-5-codex",
        input_price=1.25,
        output_price=10.0,
        context=1000000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5.2-pro",
        provider="openai",
        alias="gpt-5.2-pro",
        input_price=21.0,
        output_price=168.0,
        context=400000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-5-pro",
        provider="openai",
        alias="gpt-5-pro",
        input_price=15.0,
        output_price=120.0,
        context=400000,
        max_output=128000,
    ),
    ModelConfig(
        name="gpt-4.1",
        provider="openai",
        alias="gpt-4.1",
        input_price=2.0,
        output_price=8.0,
        context=1000000,
        max_output=32768,
    ),
    # Groq models
    ModelConfig(
        name="moonshotai/kimi-k2-instruct-0905",
        provider="groq",
        alias="kimi-k2",
        input_price=1,
        output_price=3,
        context=262144,
        max_output=16384,
    ),
    ModelConfig(
        name="openai/gpt-oss-120b",
        provider="groq",
        alias="gpt-oss-120b-groq",
        input_price=0.15,
        output_price=0.60,
        context=131072,
        max_output=65536,
    ),
    ModelConfig(
        name="qwen/qwen3-32b",
        provider="groq",
        alias="qwen3-32b",
        input_price=0.29,
        output_price=0.59,
        context=131072,
        max_output=40960,
    ),
    ModelConfig(
        name="llama-3.3-70b-versatile",
        provider="groq",
        alias="llama-3.3-70b-groq",
        input_price=0.59,
        output_price=0.79,
        context=131072,
        max_output=32768,
    ),
    ModelConfig(
        name="zai-org/GLM-4.7",
        provider="huggingface",
        alias="glm-4.7",
        input_price=0.6,
        output_price=2.2,
        context=204800,
    ),
    ModelConfig(
        name="MiniMaxAI/MiniMax-M2.1",
        provider="huggingface",
        alias="minimax-m2.1",
        input_price=0.3,
        output_price=1.2,
        context=204800,
    ),
    ModelConfig(
        name="XiaomiMiMo/MiMo-V2-Flash",
        provider="huggingface",
        alias="mimo-v2-flash",
        input_price=0.098,
        output_price=0.293,
        context=262144,
    ),
    ModelConfig(
        name="deepseek-ai/DeepSeek-V3.2",
        provider="huggingface",
        alias="deepseek-v3.2",
        input_price=0.269,
        output_price=0.4,
        context=163840,
    ),
    ModelConfig(
        name="MiniMaxAI/MiniMax-M2",
        provider="huggingface",
        alias="minimax-m2",
        input_price=0.24,
        output_price=0.96,
        context=204800,
    ),
    ModelConfig(
        name="zai-org/GLM-4.6V-Flash",
        provider="huggingface",
        alias="glm-4.6v-flash",
        input_price=0.3,
        output_price=0.9,
        context=131072,
    ),
    ModelConfig(
        name="moonshotai/Kimi-K2-Thinking",
        provider="huggingface",
        alias="kimi-k2-thinking",
        input_price=0.48,
        output_price=2.0,
        context=262144,
    ),
    ModelConfig(
        name="moonshotai/Kimi-K2-Instruct-0905",
        provider="huggingface",
        alias="kimi-k2-instruct",
        input_price=0.48,
        output_price=2.0,
        context=262144,
    ),
    ModelConfig(
        name="Qwen/Qwen3-Coder-30B-A3B-Instruct",
        provider="huggingface",
        alias="qwen3-coder-30b",
        input_price=0.1,
        output_price=0.3,
        context=262144,
    ),
    ModelConfig(
        name="deepseek-ai/DeepSeek-V3.2-Exp",
        provider="huggingface",
        alias="deepseek-v3.2-exp",
        input_price=0.216,
        output_price=0.328,
        context=163840,
    ),
    ModelConfig(
        name="MiniMaxAI/MiniMax-M1-80k",
        provider="huggingface",
        alias="minimax-m1-80k",
        input_price=0.44,
        output_price=1.76,
        context=1000000,
    ),
    ModelConfig(
        name="Qwen/Qwen3-Coder-480B-A35B-Instruct",
        provider="huggingface",
        alias="qwen3-coder-480b",
        input_price=0.24,
        output_price=1.04,
        context=262144,
    ),
    # Cerebras models
    ModelConfig(
        name="zai-glm-4.6",
        provider="cerebras",
        alias="zai-glm-4.6",
        input_price=2.25,
        output_price=2.75,
        context=131072,
        max_output=40960,
    ),
    ModelConfig(
        name="qwen-3-235b-a22b-instruct-2507",
        provider="cerebras",
        alias="qwen-3-235b",
        input_price=0.60,
        output_price=1.20,
        context=131072,
        max_output=40960,
    ),
    ModelConfig(
        name="llama-3.3-70b",
        provider="cerebras",
        alias="llama-3.3-70b-cerebras",
        input_price=0.85,
        output_price=1.20,
        context=128000,
        max_output=65536,
    ),
    ModelConfig(
        name="qwen-3-32b",
        provider="cerebras",
        alias="qwen-3-32b",
        input_price=0.40,
        output_price=0.80,
        context=131072,
        max_output=8192,
    ),
    ModelConfig(
        name="gpt-oss-120b",
        provider="cerebras",
        alias="gpt-oss-120b-cerebras",
        input_price=0.35,
        output_price=0.75,
        context=131072,
        max_output=40960,
    ),
    # Qwen Code models
    ModelConfig(
        name="qwen3-coder-plus",
        provider="qwencode",
        alias="qwen-coder-plus",
        input_price=0.0,
        output_price=0.0,
        context=1000000,
        max_output=65536,
    ),
    ModelConfig(
        name="qwen3-coder-flash",
        provider="qwencode",
        alias="qwen-coder-flash",
        input_price=0.0,
        output_price=0.0,
        context=1000000,
        max_output=65536,
    ),
    # OpenRouter models
    ModelConfig(
        name="minimax/minimax-m2.1",
        provider="openrouter",
        alias="minimax-m2.1",
        input_price=0.30,
        output_price=1.20,
        context=205000,
    ),
    ModelConfig(
        name="z-ai/glm-4.7",
        provider="openrouter",
        alias="glm-4.7-openrouter",
        input_price=0.40,
        output_price=1.50,
        context=203000,
    ),
    ModelConfig(
        name="google/gemini-3-flash-preview",
        provider="openrouter",
        alias="gemini-3-flash-preview",
        input_price=0.50,
        output_price=3.0,
        context=1050000,
    ),
    ModelConfig(
        name="xiaomi/mimo-v2-flash:free",
        provider="openrouter",
        alias="mimo-v2-flash-free",
        input_price=0.0,
        output_price=0.0,
        context=262000,
    ),
    ModelConfig(
        name="allenai/olmo-3.1-32b-think:free",
        provider="openrouter",
        alias="olmo-3.1-32b-think-free",
        input_price=0.0,
        output_price=0.0,
        context=66000,
    ),
    ModelConfig(
        name="nvidia/nemotron-3-nano-30b-a3b:free",
        provider="openrouter",
        alias="nemotron-3-nano-free",
        input_price=0.0,
        output_price=0.0,
        context=262000,
    ),
    ModelConfig(
        name="nvidia/nemotron-3-nano-30b-a3b",
        provider="openrouter",
        alias="nemotron-3-nano-30b-a3b",
        input_price=0.06,
        output_price=0.24,
        context=262000,
    ),
    ModelConfig(
        name="mistralai/devstral-2512:free",
        provider="openrouter",
        alias="devstral-2512-free",
        input_price=0.0,
        output_price=0.0,
        context=262000,
    ),
    ModelConfig(
        name="mistralai/devstral-2512",
        provider="openrouter",
        alias="devstral-2512",
        input_price=0.05,
        output_price=0.22,
        context=262000,
    ),
    ModelConfig(
        name="deepseek/deepseek-v3.2-speciale",
        provider="openrouter",
        alias="deepseek-v3.2-speciale",
        input_price=0.27,
        output_price=0.41,
        context=164000,
    ),
    ModelConfig(
        name="anthropic/claude-opus-4.5",
        provider="openrouter",
        alias="claude-opus-4.5",
        input_price=5.0,
        output_price=25.0,
        context=200000,
    ),
    ModelConfig(
        name="x-ai/grok-4.1-fast",
        provider="openrouter",
        alias="grok-4.1-fast",
        input_price=0.20,
        output_price=0.50,
        context=2000000,
    ),
    ModelConfig(
        name="google/gemini-3-pro-preview",
        provider="openrouter",
        alias="gemini-3-pro-preview",
        input_price=2.0,
        output_price=12.0,
        context=1000000,
    ),
    ModelConfig(
        name="gemini-2.5-pro",
        provider="geminicli",
        alias="gemini-2.5-pro",
        input_price=0.0,
        output_price=0.0,
        context=1000000,
    ),
    ModelConfig(
        name="gemini-2.5-flash",
        provider="geminicli",
        alias="gemini-2.5-flash",
        input_price=0.0,
        output_price=0.0,
        context=1000000,
    ),
    ModelConfig(
        name="gemini-3-pro-preview",
        provider="geminicli",
        alias="gemini-3-pro-geminicli",
        input_price=0.0,
        output_price=0.0,
        context=1000000,
    ),
    ModelConfig(
        name="gemini-3-flash-preview",
        provider="geminicli",
        alias="gemini-3-flash-geminicli",
        input_price=0.0,
        output_price=0.0,
        context=1000000,
    ),
    ModelConfig(
        name="kwaipilot/kat-coder-pro:free",
        provider="openrouter",
        alias="kat-coder-pro-free",
        input_price=0.0,
        output_price=0.0,
        context=256000,
    ),
    ModelConfig(
        name="moonshotai/kimi-k2-thinking",
        provider="openrouter",
        alias="kimi-k2-thinking-openrouter",
        input_price=0.40,
        output_price=1.75,
        context=262000,
    ),
    ModelConfig(
        name="minimax/minimax-m2",
        provider="openrouter",
        alias="minimax-m2",
        input_price=0.20,
        output_price=1.0,
        context=197000,
    ),
    ModelConfig(
        name="anthropic/claude-haiku-4.5",
        provider="openrouter",
        alias="claude-haiku-4.5",
        input_price=1.0,
        output_price=5.0,
        context=200000,
    ),
    ModelConfig(
        name="z-ai/glm-4.6:exacto",
        provider="openrouter",
        alias="glm-4.6-exacto",
        input_price=0.44,
        output_price=1.76,
        context=205000,
    ),
    ModelConfig(
        name="anthropic/claude-sonnet-4.5",
        provider="openrouter",
        alias="claude-sonnet-4.5",
        input_price=3.0,
        output_price=15.0,
        context=1000000,
    ),
    ModelConfig(
        name="qwen/qwen3-coder-plus",
        provider="openrouter",
        alias="qwen3-coder-plus-openrouter",
        input_price=1.0,
        output_price=5.0,
        context=128000,
    ),
    ModelConfig(
        name="moonshotai/kimi-k2-0905",
        provider="openrouter",
        alias="kimi-k2-0905",
        input_price=0.39,
        output_price=1.90,
        context=262000,
    ),
    ModelConfig(
        name="x-ai/grok-code-fast-1",
        provider="openrouter",
        alias="grok-code-fast-1",
        input_price=0.20,
        output_price=1.50,
        context=256000,
    ),
    # OpenCode models
    ModelConfig(
        name="claude-opus-4-5",
        provider="opencode",
        alias="claude-opus-4-5",
        input_price=5.0,
        output_price=15.0,
        context=200000,
    ),
    ModelConfig(
        name="claude-opus-4-1",
        provider="opencode",
        alias="claude-opus-4-1",
        input_price=15.0,
        output_price=75.0,
        context=200000,
    ),
    ModelConfig(
        name="claude-sonnet-4",
        provider="opencode",
        alias="claude-sonnet-4",
        input_price=3.0,
        output_price=15.0,
        context=200000,
    ),
    ModelConfig(
        name="claude-sonnet-4-5",
        provider="opencode",
        alias="claude-sonnet-4-5",
        input_price=3.0,
        output_price=15.0,
        context=200000,
    ),
    ModelConfig(
        name="claude-3-5-haiku",
        provider="opencode",
        alias="claude-3-5-haiku",
        input_price=0.25,
        output_price=1.25,
        context=200000,
    ),
    ModelConfig(
        name="claude-haiku-4-5",
        provider="opencode",
        alias="claude-haiku-4-5",
        input_price=0.25,
        output_price=1.25,
        context=200000,
    ),
    ModelConfig(
        name="gemini-3-pro",
        provider="opencode",
        alias="gemini-3-pro",
        input_price=2.0,
        output_price=12.0,
        context=1000000,
    ),
    ModelConfig(
        name="gemini-3-flash",
        provider="opencode",
        alias="gemini-3-flash",
        input_price=0.075,
        output_price=0.30,
        context=1000000,
    ),
    ModelConfig(
        name="gpt-5.2",
        provider="opencode",
        alias="gpt-5.2",
        input_price=2.5,
        output_price=10.0,
        context=128000,
    ),
    ModelConfig(
        name="gpt-5.1",
        provider="opencode",
        alias="gpt-5.1",
        input_price=2.5,
        output_price=10.0,
        context=128000,
    ),
    ModelConfig(
        name="gpt-5",
        provider="opencode",
        alias="gpt-5",
        input_price=2.5,
        output_price=10.0,
        context=128000,
    ),
    ModelConfig(
        name="gpt-5.1-codex-max",
        provider="opencode",
        alias="gpt-5.1-codex-max",
        input_price=2.5,
        output_price=10.0,
        context=1000000,
    ),
    ModelConfig(
        name="gpt-5.1-codex",
        provider="opencode",
        alias="gpt-5.1-codex",
        input_price=2.5,
        output_price=10.0,
        context=1000000,
    ),
    ModelConfig(
        name="gpt-5-codex",
        provider="opencode",
        alias="gpt-5-codex",
        input_price=2.5,
        output_price=10.0,
        context=1000000,
    ),
    ModelConfig(
        name="gpt-5.1-codex-mini",
        provider="opencode",
        alias="gpt-5.1-codex-mini",
        input_price=0.25,
        output_price=2.0,
        context=128000,
    ),
    ModelConfig(
        name="gpt-5-nano",
        provider="opencode",
        alias="gpt-5-nano",
        input_price=0.15,
        output_price=1.2,
        context=128000,
    ),
    ModelConfig(
        name="qwen3-coder",
        provider="opencode",
        alias="qwen3-coder",
        input_price=1.0,
        output_price=5.0,
        context=128000,
    ),
    ModelConfig(
        name="glm-4.6",
        provider="opencode",
        alias="glm-4.6",
        input_price=0.44,
        output_price=1.76,
        context=128000,
    ),
    ModelConfig(
        name="kimi-k2",
        provider="opencode",
        alias="kimi-k2",
        input_price=0.39,
        output_price=1.90,
        context=262000,
    ),
    ModelConfig(
        name="kimi-k2-thinking",
        provider="opencode",
        alias="kimi-k2-thinking",
        input_price=0.40,
        output_price=1.75,
        context=262000,
    ),
    ModelConfig(
        name="minimax-m2.1-free",
        provider="opencode",
        alias="minimax-m2.1-free",
        input_price=0.0,
        output_price=0.0,
        context=197000,
    ),
    ModelConfig(
        name="glm-4.7-free",
        provider="opencode",
        alias="glm-4.7-free",
        input_price=0.0,
        output_price=0.0,
        context=128000,
    ),
    ModelConfig(
        name="grok-code",
        provider="opencode",
        alias="grok-code",
        input_price=0.0,
        output_price=0.0,
        context=200000,
    ),
    ModelConfig(
        name="alpha-glm-4.7",
        provider="opencode",
        alias="alpha-glm-4.7",
        input_price=0.44,
        output_price=1.76,
        context=128000,
    ),
    ModelConfig(
        name="alpha-gd4",
        provider="opencode",
        alias="alpha-gd4",
        input_price=0.44,
        output_price=1.76,
        context=128000,
    ),
    ModelConfig(
        name="big-pickle",
        provider="opencode",
        alias="big-pickle",
        input_price=0.0,
        output_price=0.0,
        context=128000,
    ),
    ModelConfig(
        name="x-ai/grok-code-fast-1",
        provider="kilocode",
        alias="x-ai/grok-code-fast-1",
        input_price=0.0,
        output_price=0.0,
        context=256000,
    ),
    ModelConfig(
        name="mistralai/devstral-2512:free",
        provider="kilocode",
        alias="mistralai/devstral-2512:free",
        input_price=0.0,
        output_price=0.0,
        context=262144,
    ),
    ModelConfig(
        name="kwaipilot/kat-coder-pro:free",
        provider="kilocode",
        alias="kwaipilot/kat-coder-pro:free",
        input_price=0.0,
        output_price=0.0,
        context=256000,
    ),
    ModelConfig(
        name="minimax/minimax-m2:free",
        provider="kilocode",
        alias="minimax/minimax-m2:free",
        input_price=0.0,
        output_price=0.0,
        context=204800,
    ),
    ModelConfig(
        name="mistralai/devstral-small-2512:free",
        provider="kilocode",
        alias="mistralai/devstral-small-2512:free",
        input_price=0.0,
        output_price=0.0,
        context=262144,
    ),
    # Antigravity models (Claude, Gemini via unified gateway) - XML only
    ModelConfig(
        name="claude-sonnet-4-5",
        provider="antigravity",
        alias="antigravity-claude-sonnet-4-5",
        input_price=0.0,
        output_price=0.0,
        context=200000,
        max_output=8192,
        supported_formats=["xml"],
        supports_thinking=False,
    ),
    ModelConfig(
        name="claude-sonnet-4-5-thinking",
        provider="antigravity",
        alias="antigravity-claude-sonnet-4-5-thinking",
        input_price=0.0,
        output_price=0.0,
        context=200000,
        max_output=64000,
        supported_formats=["xml"],
        supports_thinking=True,
    ),
    ModelConfig(
        name="claude-opus-4-5-thinking",
        provider="antigravity",
        alias="antigravity-claude-opus-4-5-thinking",
        input_price=0.0,
        output_price=0.0,
        context=200000,
        max_output=64000,
        supported_formats=["xml"],
        supports_thinking=True,
    ),
    ModelConfig(
        name="gemini-3-pro-high",
        provider="antigravity",
        alias="antigravity-gemini-3-pro-high",
        input_price=0.0,
        output_price=0.0,
        context=1048576,
        max_output=8192,
        supported_formats=["xml"],
        supports_thinking=True,
    ),
    ModelConfig(
        name="gemini-3-pro-low",
        provider="antigravity",
        alias="antigravity-gemini-3-pro-low",
        input_price=0.0,
        output_price=0.0,
        context=1048576,
        max_output=8192,
        supported_formats=["xml"],
        supports_thinking=True,
    ),
    ModelConfig(
        name="gpt-oss-120b-medium",
        provider="antigravity",
        alias="antigravity-gpt-oss-120b-medium",
        input_price=0.0,
        output_price=0.0,
        context=131072,
        max_output=8192,
        supported_formats=["xml"],
    ),
    # Chutes models
    ModelConfig(
        name="Qwen/Qwen3-235B-A22B-Instruct-2507-TEE",
        provider="chutes",
        alias="qwen3-235b",
        input_price=0.08,
        output_price=0.55,
        context=262144,
        max_output=65536,
    ),
    ModelConfig(
        name="zai-org/GLM-4.7-TEE",
        provider="chutes",
        alias="glm-4.7",
        input_price=0.4,
        output_price=1.5,
        context=202752,
        max_output=65535,
    ),
    ModelConfig(
        name="openai/gpt-oss-120b-TEE",
        provider="chutes",
        alias="gpt-oss-120b",
        input_price=0.04,
        output_price=0.18,
        context=131072,
        max_output=65536,
    ),
    ModelConfig(
        name="zai-org/GLM-4.6-TEE",
        provider="chutes",
        alias="glm-4.6",
        input_price=0.35,
        output_price=1.5,
        context=202752,
        max_output=65536,
    ),
    ModelConfig(
        name="deepseek-ai/DeepSeek-R1-0528-TEE",
        provider="chutes",
        alias="deepseek-r1",
        input_price=0.4,
        output_price=1.75,
        context=163840,
        max_output=65536,
    ),
    ModelConfig(
        name="tngtech/TNG-R1T-Chimera-TEE",
        provider="chutes",
        alias="tng-r1t-chimera",
        input_price=0.25,
        output_price=0.85,
        context=163840,
        max_output=65536,
    ),
    ModelConfig(
        name="deepseek-ai/DeepSeek-V3.1-TEE",
        provider="chutes",
        alias="deepseek-v3.1",
        input_price=0.2,
        output_price=0.8,
        context=163840,
        max_output=65536,
    ),
    ModelConfig(
        name="deepseek-ai/DeepSeek-V3.1-Terminus-TEE",
        provider="chutes",
        alias="deepseek-v3.1-terminus",
        input_price=0.23,
        output_price=0.9,
        context=163840,
        max_output=65536,
    ),
    ModelConfig(
        name="moonshotai/Kimi-K2-Thinking-TEE",
        provider="chutes",
        alias="kimi-k2-thinking",
        input_price=0.4,
        output_price=1.75,
        context=262144,
        max_output=65535,
    ),
    ModelConfig(
        name="deepseek-ai/DeepSeek-R1-TEE",
        provider="chutes",
        alias="deepseek-r1-full",
        input_price=0.3,
        output_price=1.2,
        context=163840,
        max_output=163840,
    ),
    ModelConfig(
        name="MiniMaxAI/MiniMax-M2.1-TEE",
        provider="chutes",
        alias="minimax-m2.1",
        input_price=0.3,
        output_price=1.2,
        context=196608,
        max_output=65536,
    ),
    ModelConfig(
        name="Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE",
        provider="chutes",
        alias="qwen3-coder-480b",
        input_price=0.22,
        output_price=0.95,
        context=262144,
        max_output=262144,
    ),
    ModelConfig(
        name="zai-org/GLM-4.5-TEE",
        provider="chutes",
        alias="glm-4.5",
        input_price=0.35,
        output_price=1.55,
        context=131072,
        max_output=65536,
    ),
    ModelConfig(
        name="deepseek-ai/DeepSeek-V3.2-Speciale-TEE",
        provider="chutes",
        alias="deepseek-v3.2-speciale",
        input_price=0.27,
        output_price=0.41,
        context=163840,
        max_output=65536,
    ),
]
