# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.context import Context
from ..types.continue_response_dto import ContinueResponseDto
from ..types.list_user_jobs_response_dto import ListUserJobsResponseDto
from ..types.pull_job_response_dto import PullJobResponseDto
from ..types.query import Query
from ..types.schema import Schema
from ..types.status_response_dto import StatusResponseDto
from ..types.submit_response_body import SubmitResponseBody
from .raw_client import AsyncRawJobsClient, RawJobsClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class JobsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawJobsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawJobsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawJobsClient
        """
        return self._raw_client

    def create_job(
        self,
        *,
        query: Query,
        schema: typing.Optional[Schema] = OMIT,
        context: typing.Optional[Context] = OMIT,
        limit: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SubmitResponseBody:
        """
        Submit a natural language query to create a new processing job.

        Parameters
        ----------
        query : Query

        schema : typing.Optional[Schema]

        context : typing.Optional[Context]

        limit : typing.Optional[int]
            Maximum number of records to return. If not specified, defaults to your plan limit.

            Use /catchAll/continue to extend the limit after job completion without reprocessing.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SubmitResponseBody
            Job created successfully

        Examples
        --------
        from newscatcher_catchall import CatchAllApi

        client = CatchAllApi(
            api_key="YOUR_API_KEY",
        )
        client.jobs.create_job(
            query="AI company acquisitions",
            context="Focus on deal size and acquiring company details",
        )
        """
        _response = self._raw_client.create_job(
            query=query, schema=schema, context=context, limit=limit, request_options=request_options
        )
        return _response.data

    def continue_job(
        self, *, job_id: str, new_limit: int, request_options: typing.Optional[RequestOptions] = None
    ) -> ContinueResponseDto:
        """
        Continue an existing job to process more records beyond the initial limit.

        Parameters
        ----------
        job_id : str
            Job identifier of the completed job to continue.

        new_limit : int
            New record limit for continued processing. Must be greater than the previous limit.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ContinueResponseDto
            Job continuation accepted

        Examples
        --------
        from newscatcher_catchall import CatchAllApi

        client = CatchAllApi(
            api_key="YOUR_API_KEY",
        )
        client.jobs.continue_job(
            job_id="af7a26d6-cf0b-458c-a6ed-4b6318c74da3",
            new_limit=100,
        )
        """
        _response = self._raw_client.continue_job(job_id=job_id, new_limit=new_limit, request_options=request_options)
        return _response.data

    def get_job_status(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> StatusResponseDto:
        """
        Retrieve the current processing status of a job.

        Parameters
        ----------
        job_id : str
            Unique job identifier returned from the `/catchAll/submit` endpoint.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        StatusResponseDto
            Status retrieved successfully.

        Examples
        --------
        from newscatcher_catchall import CatchAllApi

        client = CatchAllApi(
            api_key="YOUR_API_KEY",
        )
        client.jobs.get_job_status(
            job_id="af7a26d6-cf0b-458c-a6ed-4b6318c74da3",
        )
        """
        _response = self._raw_client.get_job_status(job_id, request_options=request_options)
        return _response.data

    def get_user_jobs(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[ListUserJobsResponseDto]:
        """
        Returns all jobs created by the authenticated user.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[ListUserJobsResponseDto]
            List of user jobs

        Examples
        --------
        from newscatcher_catchall import CatchAllApi

        client = CatchAllApi(
            api_key="YOUR_API_KEY",
        )
        client.jobs.get_user_jobs()
        """
        _response = self._raw_client.get_user_jobs(request_options=request_options)
        return _response.data

    def get_job_results(
        self,
        job_id: str,
        *,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PullJobResponseDto:
        """
        Retrieve the final results for a completed job.

        Parameters
        ----------
        job_id : str
            Unique job identifier returned from the `/catchAll/submit` endpoint.

        page : typing.Optional[int]
            Page number to retrieve.

        page_size : typing.Optional[int]
            Number of records per page.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PullJobResponseDto
            Results retrieved successfully

        Examples
        --------
        from newscatcher_catchall import CatchAllApi

        client = CatchAllApi(
            api_key="YOUR_API_KEY",
        )
        client.jobs.get_job_results(
            job_id="af7a26d6-cf0b-458c-a6ed-4b6318c74da3",
        )
        """
        _response = self._raw_client.get_job_results(
            job_id, page=page, page_size=page_size, request_options=request_options
        )
        return _response.data


class AsyncJobsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawJobsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawJobsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawJobsClient
        """
        return self._raw_client

    async def create_job(
        self,
        *,
        query: Query,
        schema: typing.Optional[Schema] = OMIT,
        context: typing.Optional[Context] = OMIT,
        limit: typing.Optional[int] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SubmitResponseBody:
        """
        Submit a natural language query to create a new processing job.

        Parameters
        ----------
        query : Query

        schema : typing.Optional[Schema]

        context : typing.Optional[Context]

        limit : typing.Optional[int]
            Maximum number of records to return. If not specified, defaults to your plan limit.

            Use /catchAll/continue to extend the limit after job completion without reprocessing.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SubmitResponseBody
            Job created successfully

        Examples
        --------
        import asyncio

        from newscatcher_catchall import AsyncCatchAllApi

        client = AsyncCatchAllApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.jobs.create_job(
                query="AI company acquisitions",
                context="Focus on deal size and acquiring company details",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create_job(
            query=query, schema=schema, context=context, limit=limit, request_options=request_options
        )
        return _response.data

    async def continue_job(
        self, *, job_id: str, new_limit: int, request_options: typing.Optional[RequestOptions] = None
    ) -> ContinueResponseDto:
        """
        Continue an existing job to process more records beyond the initial limit.

        Parameters
        ----------
        job_id : str
            Job identifier of the completed job to continue.

        new_limit : int
            New record limit for continued processing. Must be greater than the previous limit.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ContinueResponseDto
            Job continuation accepted

        Examples
        --------
        import asyncio

        from newscatcher_catchall import AsyncCatchAllApi

        client = AsyncCatchAllApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.jobs.continue_job(
                job_id="af7a26d6-cf0b-458c-a6ed-4b6318c74da3",
                new_limit=100,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.continue_job(
            job_id=job_id, new_limit=new_limit, request_options=request_options
        )
        return _response.data

    async def get_job_status(
        self, job_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> StatusResponseDto:
        """
        Retrieve the current processing status of a job.

        Parameters
        ----------
        job_id : str
            Unique job identifier returned from the `/catchAll/submit` endpoint.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        StatusResponseDto
            Status retrieved successfully.

        Examples
        --------
        import asyncio

        from newscatcher_catchall import AsyncCatchAllApi

        client = AsyncCatchAllApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.jobs.get_job_status(
                job_id="af7a26d6-cf0b-458c-a6ed-4b6318c74da3",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_job_status(job_id, request_options=request_options)
        return _response.data

    async def get_user_jobs(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[ListUserJobsResponseDto]:
        """
        Returns all jobs created by the authenticated user.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[ListUserJobsResponseDto]
            List of user jobs

        Examples
        --------
        import asyncio

        from newscatcher_catchall import AsyncCatchAllApi

        client = AsyncCatchAllApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.jobs.get_user_jobs()


        asyncio.run(main())
        """
        _response = await self._raw_client.get_user_jobs(request_options=request_options)
        return _response.data

    async def get_job_results(
        self,
        job_id: str,
        *,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PullJobResponseDto:
        """
        Retrieve the final results for a completed job.

        Parameters
        ----------
        job_id : str
            Unique job identifier returned from the `/catchAll/submit` endpoint.

        page : typing.Optional[int]
            Page number to retrieve.

        page_size : typing.Optional[int]
            Number of records per page.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PullJobResponseDto
            Results retrieved successfully

        Examples
        --------
        import asyncio

        from newscatcher_catchall import AsyncCatchAllApi

        client = AsyncCatchAllApi(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.jobs.get_job_results(
                job_id="af7a26d6-cf0b-458c-a6ed-4b6318c74da3",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get_job_results(
            job_id, page=page, page_size=page_size, request_options=request_options
        )
        return _response.data
