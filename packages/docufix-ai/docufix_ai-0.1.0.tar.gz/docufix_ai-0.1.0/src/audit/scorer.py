import tiktoken
from bs4 import BeautifulSoup
import re

class ContextAuditor:
    """
    æ£€æµ‹é•¿æ–‡æœ¬ç¼ºä¹ç»“æ„åŒ–æ ‡é¢˜çš„é£é™©ã€‚
    """
    def __init__(self):
        self.encoder = tiktoken.get_encoding("cl100k_base")
        self.chunk_size = 512

    def audit_chunking_risk(self, text: str) -> dict:
        tokens = self.encoder.encode(text)
        chunks = [tokens[i:i+self.chunk_size] for i in range(0, len(tokens), self.chunk_size)]
        
        high_risk_chunks = 0
        for chunk in chunks:
            chunk_text = self.encoder.decode(chunk)
            if not re.search(r'(#+ |<h[1-6]>)', chunk_text):
                high_risk_chunks += 1
        
        penalty = min(40, high_risk_chunks * 10)
        return {
            "score_impact": -penalty,
            "status": "ğŸš¨ é«˜é£é™©" if high_risk_chunks > 0 else "âœ… å·²ä¼˜åŒ–",
            "reason": f"å‘ç° {high_risk_chunks} ä¸ªé•¿æ–‡æœ¬å—ï¼ˆ>512 tokensï¼‰ç¼ºå°‘æ ‡é¢˜ç»“æ„ã€‚",
            "why": "AI RAG ç³»ç»Ÿé€šè¿‡åˆ‡ç‰‡ç´¢å¼•å†…å®¹ã€‚å¦‚æœæ²¡æœ‰æ ‡é¢˜ï¼ŒAI åœ¨æ£€ç´¢æ—¶ä¼šä¸¢å¤±ç« èŠ‚ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚ï¼šä¸çŸ¥é“è¿™æ®µè¯å¯¹åº”å“ªä¸ª APIï¼‰ã€‚",
            "fix": "æ¯éš” 300-500 ä¸ª tokens æ’å…¥ Markdown æ ‡é¢˜ï¼ˆ###ï¼‰ä»¥ç»´æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚"
        }

class CodeAuditor:
    """
    æ£€æµ‹ä»£ç å—çš„ AI å¯è¯»æ€§ï¼ˆæ³¨é‡Šã€Importï¼‰ã€‚
    """
    def audit_code_blocks(self, soup: BeautifulSoup) -> dict:
        code_blocks = soup.find_all(['code', 'pre'])
        if not code_blocks:
            return {
                "score_impact": 0, 
                "status": "âœ… æ— ä»£ç ", 
                "reason": "æœªæ£€æµ‹åˆ°ä»£ç å—ã€‚",
                "why": "ä¸é€‚ç”¨",
                "fix": "ä¸é€‚ç”¨"
            }
        
        penalty = 0
        total_blocks = len(code_blocks)
        bad_blocks = 0
        
        for block in code_blocks:
            text = block.get_text()
            lines = text.split('\n')
            if len(lines) > 5:
                has_comment = "#" in text or "//" in text or "/*" in text
                has_import = any(kw in text for kw in ["import ", "from ", "require(", "using "])
                
                if not has_comment or not has_import:
                    penalty += 5
                    bad_blocks += 1
        
        penalty = min(30, penalty)
        return {
            "score_impact": -penalty,
            "status": "âš ï¸ ç¼ºå°‘æ–‡æ¡£" if bad_blocks > 0 else "âœ… AI å‹å¥½",
            "reason": f"å‘ç° {bad_blocks}/{total_blocks} ä¸ªä»£ç ç‰‡æ®µç¼ºå°‘æ³¨é‡Šæˆ– import è¯­å¥ã€‚",
            "why": "å¦‚æœ AI çœ‹ä¸åˆ°å®Œæ•´çš„ä¾èµ–æˆ–é€»è¾‘æ³¨é‡Šï¼Œåœ¨ç”Ÿæˆä»£ç æ—¶ææ˜“äº§ç”Ÿâ€œå¹»è§‰â€ã€‚",
            "fix": "ç¡®ä¿æ¯ä¸ªä»£ç ç‰‡æ®µéƒ½æ˜¯è‡ªåŒ…å«çš„ï¼ŒåŒ…å«å¿…è¦çš„åº“å¼•ç”¨å’Œç®€è¦é€»è¾‘æ³¨é‡Šã€‚"
        }

class DocAuditor:
    """
    AI æ–‡æ¡£å®¡è®¡æ ¸å¿ƒç±»ã€‚
    """
    def __init__(self):
        self.context_auditor = ContextAuditor()
        self.code_auditor = CodeAuditor()

    def audit(self, html_content: str) -> dict:
        soup = BeautifulSoup(html_content, 'html.parser')
        text = soup.get_text()
        
        chunk_report = self.context_auditor.audit_chunking_risk(text)
        code_report = self.code_auditor.audit_code_blocks(soup)
        
        # æš‚æ—¶æ¨¡æ‹Ÿé“¾æ¥å’Œå…ƒæ•°æ®åˆ†æ•°
        link_report = {
            "score_impact": 0, 
            "status": "âœ… é“¾æ¥å¥åº·", 
            "reason": "æ‰€æœ‰å†…å¤–é“¾å‡æœ‰æ•ˆã€‚",
            "why": "å¤±æ•ˆé“¾æ¥ä¼šå¯¼è‡´ AI åœ¨é€’å½’çˆ¬å–æ—¶é™·å…¥æ­»èƒ¡åŒï¼Œä¸­æ–­æ¨ç†ã€‚",
            "fix": "ä¸é€‚ç”¨"
        }
        meta_report = {
            "score_impact": -5, 
            "status": "âš ï¸ ç¼ºå°‘å…ƒæ•°æ®", 
            "reason": "ç¼ºå°‘ Meta Description æˆ– Keywords æ ‡ç­¾ã€‚",
            "why": "ç¼ºå¤±å…ƒæ•°æ®ä¼šé™ä½æ¨¡å‹åœ¨é¢„å¤„ç†é˜¶æ®µå¯¹ç«™ç‚¹çš„åˆ†ç±»å‡†ç¡®åº¦ã€‚",
            "fix": "åœ¨ HTML æºç ä¸­æ·»åŠ  <meta name='description' content='...'>ã€‚"
        }
        
        total_score = 100 + chunk_report["score_impact"] + code_report["score_impact"] + link_report["score_impact"] + meta_report["score_impact"]
        total_score = max(0, min(100, total_score))
        
        return {
            "total_score": total_score,
            "metrics": {
                "Chunking Structure": chunk_report,
                "Code Snippets": code_report,
                "Link Health": link_report,
                "Metadata": meta_report
            }
        }
