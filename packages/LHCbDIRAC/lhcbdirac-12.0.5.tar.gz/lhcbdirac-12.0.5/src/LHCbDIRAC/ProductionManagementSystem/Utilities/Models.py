###############################################################################
# (c) Copyright 2022 CERN for the benefit of the LHCb Collaboration           #
#                                                                             #
# This software is distributed under the terms of the GNU General Public      #
# Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   #
#                                                                             #
# In applying this licence, CERN does not waive the privileges and immunities #
# granted to it by virtue of its status as an Intergovernmental Organization  #
# or submit itself to any jurisdiction.                                       #
###############################################################################
import re
from datetime import datetime
from enum import Enum
from typing import Annotated, Any, Literal, Self, Union

from pydantic import (
    ConfigDict,
    StringConstraints,
    BaseModel as _BaseModel,
    field_validator,
    model_validator,
    Field,
    PositiveInt,
    TypeAdapter,
)

from DIRAC.Core.Security.ProxyInfo import getProxyInfo
from DIRAC.Core.Utilities.ReturnValues import returnValueOrRaise


FILETYPE_PATTERN = r"[A-Z0-9\.]+"


class ProductionStates(str, Enum):
    NEW = "New"
    ACTIVE = "Active"
    SUBMITTED = "Submitted"
    PPG_OK = "PPG OK"
    TECH_OK = "Tech OK"
    ACCEPTED = "Accepted"
    DONE = "Done"
    COMPLETED = "Completed"
    CANCELLED = "Cancelled"
    REJECTED = "Rejected"


class BaseModel(_BaseModel):
    model_config = ConfigDict(extra="forbid")


class ProductionStep(BaseModel):
    id: PositiveInt | None = None
    name: str
    processing_pass: str

    class GaudirunOptions(BaseModel):
        command: Annotated[list[str], Field(min_length=1)] | None = None
        files: list[str]
        format: str | None = None
        gaudi_extra_options: str | None = None
        processing_pass: str | None = None

    class LbExecOptions(BaseModel):
        entrypoint: str
        extra_options: dict[str, Any]
        extra_args: list[str] = []

    options: list[str] | GaudirunOptions | LbExecOptions  # TODO the list of str is for legacy compatibility
    options_format: str | None = None  # TODO This should be merged into options
    visible: bool
    multicore: bool = False
    ready: bool = True
    obsolete: bool = False
    event_timeout: int | None = None  # in seconds, None means Gaudi default (3600 seconds)

    class Application(BaseModel):
        name: str
        version: str
        nightly: str | None = None
        binary_tag: str | None = None

        @field_validator("binary_tag", mode="before")
        @classmethod
        def binary_tag_to_string(cls, binary_tag, values):  # pylint: disable=no-self-argument
            if isinstance(binary_tag, str) or binary_tag is None:
                return binary_tag
            elif isinstance(binary_tag, list):
                return f"/({'|'.join(re.escape(tag) for tag in binary_tag)})/"
            else:
                raise ValueError(f"Invalid binary tag: {binary_tag}")

    application: Application

    class DataPackage(BaseModel):
        name: str
        version: str

    data_pkgs: list[DataPackage] = []

    class DBTags(BaseModel):
        DDDB: str | None = None
        CondDB: str | None = None
        DQTag: str | None = None

    dbtags: DBTags | None = None

    class FileType(BaseModel):
        type: Annotated[str, StringConstraints(pattern=FILETYPE_PATTERN)]
        visible: bool

    class InputFileType(FileType):
        step_idx: int | None = None

    input: list[InputFileType]
    output: Annotated[list[FileType], Field(min_length=1)]

    @field_validator("input", "output", mode="before")
    @classmethod
    def filetype_default(cls, filetypes, values):  # pylint: disable=no-self-argument
        """Expand a list of file types into the explicit form.

        This is to allow for a convenient list of input types to be specified.
        For example::

          input:
            - type: ["STREAM1.DST", "STREAM2.MDST"]
              visible: true
            - type: STREAM3.DST
              visible: false

        becomes::

          input:
            - type: STREAM1.DST
              visible: true
            - type: STREAM2.MDST
              visible: true
            - type: STREAM3.MDST
              visible: false
        """
        cleaned_filetypes = []
        for filetype in filetypes:
            if isinstance(filetype["type"], list):
                cleaned_filetypes.extend({"type": t, "visible": filetype["visible"]} for t in filetype["type"])
            else:
                cleaned_filetypes.append(filetype)
        return cleaned_filetypes

    @field_validator("input", mode="after")
    @classmethod
    def set_default_input_step_idx(cls, input):
        for idx, input_file in enumerate(input):
            if input_file.step_idx is None:
                input_file.step_idx = idx
        return input

    @field_validator("application", mode="before")
    @classmethod
    def application_default(cls, application, values):  # pylint: disable=no-self-argument
        if isinstance(application, str):
            name, version = application.rsplit("/", 2)
            application = {"name": name, "version": version}
        return application

    @field_validator("data_pkgs", mode="before")
    @classmethod
    def data_pkgs_default(cls, data_pkgs, values):  # pylint: disable=no-self-argument
        cleaned_data_pkgs = []
        for data_pkg in data_pkgs:
            if isinstance(data_pkg, str):
                name, version = data_pkg.rsplit(".", 2)
                cleaned_data_pkgs.append({"name": name, "version": version})
            else:
                cleaned_data_pkgs.append(data_pkg)
        return cleaned_data_pkgs


class InvalidStep(Exception):
    pass


class TransformationBase(BaseModel):
    type: str
    auto_activate: bool = True
    input_plugin: str
    group_size: int
    extra_sandboxes: list[str] = []


class ProcessingTransformation(TransformationBase):
    type: Literal[
        # Merging transformation types
        "Merge",
        "APMerge",
        "MCMerge",
        # Simulation transformation types
        "MCSimulation",
        "MCFastSimulation",
        "MCReconstruction",
        # Analysis production transformation types
        "WGProduction",
        "APPostProc",
        # Fluka simulation transformation types
        "FlukaSimulation",
        "FlukaMerge",
        # Other centralized transformation types
        "DataReconstruction",
        "DataStripping",
        "Sprucing",
    ]
    steps: list[int]
    output_se: str
    input_data_policy: Literal["protocol"] | Literal["download"]
    output_mode: Literal["Local"] | Literal["Run"] | Literal["Any"]

    output_file_mask: str = ""
    multicore: bool = True
    events: int = -1
    ancestor_depth: int = 0
    cpu: str = "1000000"
    priority: int = 2
    remove_inputs_flags: bool = False
    processors: tuple[int, int] = (0, 0)


class RemovalTransformation(TransformationBase):
    type: Literal["RemoveInput"]
    input_plugin: Literal["DestroyDataset", "RemoveReplicasWithAncestors", "RemoveReplicasWhenProcessed"]
    input_step_idx: int
    output_step_idx: int


class ReplicationTransformation(TransformationBase):
    type: Literal["ReplicateOutput"]
    # input_plugin: Literal["Replication"]
    step_idx: int
    filetypes: list[str] | None = None


TransformationDescription = Annotated[
    Union[ProcessingTransformation, RemovalTransformation, ReplicationTransformation], Field(discriminator="type")
]


class ProductionBase(BaseModel):
    type: str
    id: PositiveInt | None = None
    author: str = Field(default_factory=lambda: returnValueOrRaise(getProxyInfo())["username"])
    priority: Annotated[str, Field(pattern=r"^[12][ab]$")]
    name: Annotated[str, StringConstraints(strip_whitespace=True, min_length=3, max_length=128)]
    inform: list[Annotated[str, StringConstraints(strip_whitespace=True, min_length=3, max_length=50)]] = []
    # TODO: I'm inclined to hardcode the list of known working groups
    wg: str
    comment: str = ""
    state: ProductionStates = ProductionStates.NEW
    url: str | None = None

    steps: Annotated[list[ProductionStep], Field(min_length=1)]

    class SubmissionInfo(BaseModel):
        transforms: list[TransformationDescription]

        @property
        def processing_transforms(self) -> list[ProcessingTransformation]:
            """Get only the processing transformations."""
            return [t for t in self.transforms if isinstance(t, ProcessingTransformation)]

        @property
        def data_management_transforms(self) -> list[RemovalTransformation | ReplicationTransformation]:
            """Get only the data management transformations."""
            return [t for t in self.transforms if not isinstance(t, ProcessingTransformation)]

    # TODO: Once the submission_info is always present, remove the | None
    submission_info: SubmissionInfo | None = None

    @model_validator(mode="after")
    def validate_steps(self) -> Self:
        current_leaves = {ft.type for ft in self.steps[0].output}
        for step in self.steps[1:]:
            for input_filetype in step.input:
                if input_filetype.type not in current_leaves:
                    raise InvalidStep(f"Failed to find input {input_filetype.type!r} for {step!r}")
                current_leaves.remove(input_filetype.type)

            for output_filetype in step.output:
                if output_filetype.type in current_leaves:
                    raise InvalidStep(
                        f"Found producer for {output_filetype.type!r} despite previous instance having not been consumed"
                    )
                current_leaves.add(output_filetype.type)
        return self


class SimulationProduction(ProductionBase):
    type: Literal["Simulation"]
    mc_config_version: str
    sim_condition: str
    fast_simulation_type: Annotated[str, StringConstraints(strip_whitespace=True, min_length=4, max_length=32)] = "None"
    # TODO This should move to EventType
    retention_rate: Annotated[float, Field(gt=0, le=1)] = 1
    override_processing_pass: str | None = None

    class EventType(BaseModel):
        id: Annotated[str, Field(pattern=r"[0-9]{8}")]
        num_events: PositiveInt
        num_test_events: PositiveInt = 10

    event_types: Annotated[list[EventType], Field(min_length=1)]


class DataProduction(ProductionBase):
    type: Literal["Sprucing", "AnalysisProduction", "Stripping", "Reconstruction"]

    class InputDataset(BaseModel):
        class BookkeepingQuery(BaseModel):
            configName: str
            configVersion: str
            inFileType: str
            inProPass: str
            # TODO: Accept None and lists on these
            inDataQualityFlag: str = "OK"
            inExtendedDQOK: Annotated[list[str], Field(min_length=1)] | None = None
            inProductionID: str = "ALL"
            inTCKs: str = "ALL"
            inSMOG2State: Annotated[list[str], Field(min_length=1)] | None = None

        conditions_dict: BookkeepingQuery
        conditions_description: str
        event_type: Annotated[str, StringConstraints(pattern=r"[0-9]{8}")]

        class LaunchParameters(BaseModel):
            """Extra info which is currently needed when making transformations from a request"""

            run_numbers: list[str] | None = None
            sample_max_md5: Annotated[str, StringConstraints(pattern=r"[A-Z0-9]{32}")] | None = None
            sample_seed_md5: Annotated[str, StringConstraints(pattern=r"[A-Z0-9]{32}")] | None = None
            start_run: int | None = None
            end_run: int | None = None
            end_date: datetime | None = None

            @model_validator(mode="after")
            def sample_md5s_consistent(self) -> Self:
                if self.sample_max_md5 is None and self.sample_seed_md5 is not None:
                    raise ValueError("If sample_seed_md5 is set, sample_max_md5 must also be set")
                if self.sample_max_md5 is not None and self.sample_seed_md5 is None:
                    raise ValueError("If sample_max_md5 is set, sample_seed_md5 must also be set")
                return self

            @model_validator(mode="after")
            def validate_run_numbers(self) -> Self:
                if self.run_numbers and (self.start_run is not None or self.end_run is not None):
                    raise ValueError("Cannot specify both run_numbers and start_run/end_run")
                return self

        launch_parameters: Annotated[LaunchParameters, Field(default_factory=LaunchParameters)]

    input_dataset: InputDataset


Production = Annotated[Union[SimulationProduction, DataProduction], Field(discriminator="type")]


def parse_obj(obj: Any) -> Production:
    adapter = TypeAdapter(Production)
    return adapter.validate_python(obj)
