import json
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Union, overload

import pydantic
from pydantic.v1 import BaseModel, PrivateAttr
from typing_extensions import Self

from oold.backend.interface import (
    GetBackendParam,
    GetResolverParam,
    ResolveParam,
    StoreParam,
    get_backend,
    get_resolver,
)
from oold.static import GenericLinkedBaseModel, export_jsonld, import_jsonld

if TYPE_CHECKING:
    from pydantic.v1.typing import AbstractSetIntStr, MappingIntStrAny


# pydantic v1
_types: Dict[str, pydantic.v1.main.ModelMetaclass] = {}


# pydantic v1
class LinkedBaseModelMetaClass(pydantic.v1.main.ModelMetaclass):
    def __new__(mcs, name, bases, namespace):
        cls = super().__new__(mcs, name, bases, namespace)

        if hasattr(cls, "get_cls_iri"):
            iri = cls.get_cls_iri()
            if iri is not None:
                _types[iri] = cls
        return cls

    # override operators, see https://docs.python.org/3/library/operator.html

    @overload
    def __getitem__(cls: "LinkedBaseModel", item: str) -> Self:
        ...

    @overload
    def __getitem__(cls: "LinkedBaseModel", item: List[str]) -> List[Self]:
        ...

    def __getitem__(
        cls: "LinkedBaseModel", item: Union[str, List[str]]
    ) -> Union[Self, List[Self]]:
        """Allow access to the class by its IRI."""
        result = cls._resolve(item if isinstance(item, list) else [item])
        return result[item] if isinstance(item, str) else [result[i] for i in item]


# the following switch ensures that autocomplete works in IDEs like VSCode
if TYPE_CHECKING:

    class _LinkedBaseModel(BaseModel, GenericLinkedBaseModel):
        pass

else:

    class _LinkedBaseModel(
        BaseModel, GenericLinkedBaseModel, metaclass=LinkedBaseModelMetaClass
    ):
        pass


class LinkedBaseModel(_LinkedBaseModel):
    """LinkedBaseModel for pydantic v1"""

    __iris__: Optional[Dict[str, Union[str, List[str]]]] = PrivateAttr()

    @classmethod
    def get_cls_iri(cls) -> str:
        """Return the unique IRI of the class.
        Overwrite this method in the subclass."""
        schema = {}
        if hasattr(cls, "__config__"):
            if hasattr(cls.__config__, "schema_extra"):
                schema = cls.__config__.schema_extra

        if "iri" in schema:
            return schema["iri"]
        else:
            return None

    def get_iri(self) -> str:
        """Return the unique IRI of the object.
        Overwrite this method in the subclass."""
        return self.id

    @classmethod
    def parse_obj(cls, obj: Any) -> "LinkedBaseModel":
        """Parse the object and return a LinkedBaseModel instance.
        This method is called by pydantic when creating
        a new (default) instance of the model."""
        if isinstance(obj, str):
            # pydantic v1
            return cls._resolve([obj])[obj]
        if isinstance(obj, list):
            # pydantic v1
            # return cls._resolve(obj).nodes[obj[0]]
            node_dict = cls._resolve(obj)
            node_list = []
            for iri in obj:
                node = node_dict[iri]
                if node:
                    node_list.append(node)
            return node_list
        elif isinstance(obj, dict):
            return super().parse_obj(obj)

    def __init__(self, *a, **kw):
        if "__iris__" not in kw:
            kw["__iris__"] = {}

        for name in list(kw):  # force copy of keys for inline-delete
            # print(name)
            if name == "__iris__":
                continue
            # rewrite <attr> to <attr>_iri
            # pprint(self.__fields__)
            extra = None
            # pydantic v1
            if name in self.__fields__:
                if hasattr(self.__fields__[name].default, "json_schema_extra"):
                    extra = self.__fields__[name].default.json_schema_extra
                elif hasattr(self.__fields__[name].field_info, "extra"):
                    extra = self.__fields__[name].field_info.extra
            # pydantic v2
            # extra = self.model_fields[name].json_schema_extra

            if extra and "range" in extra:
                arg_is_list = isinstance(kw[name], list)

                # annotation_is_list = False
                # args = self.model_fields[name].annotation.__args__
                # if hasattr(args[0], "_name"):
                #    is_list = args[0]._name == "List"
                if arg_is_list:
                    kw["__iris__"][name] = []
                    for e in kw[name][:]:  # interate over copy of list
                        if isinstance(e, BaseModel):  # contructed with object ref
                            kw["__iris__"][name].append(e.get_iri())
                        elif isinstance(e, str):  # constructed from json
                            kw["__iris__"][name].append(e)
                            kw[name].remove(e)  # remove to construct valid instance
                    if len(kw[name]) == 0:
                        # pydantic v1
                        kw[name] = None  # else pydantic v1 will set a FieldInfo object
                        # pydantic v2
                        # del kw[name]
                else:
                    if isinstance(kw[name], BaseModel):  # contructed with object ref
                        # print(kw[name].id)
                        kw["__iris__"][name] = kw[name].get_iri()
                    elif isinstance(kw[name], str):  # constructed from json
                        kw["__iris__"][name] = kw[name]
                        # pydantic v1
                        kw[name] = None  # else pydantic v1 will set a FieldInfo object
                        # pydantic v2
                        # del kw[name]

        BaseModel.__init__(self, *a, **kw)
        # handle default values
        for name in list(self.__dict__.keys()):
            if self.__dict__[name] is None:
                continue
            extra = None
            # pydantic v1
            if name in self.__fields__:
                if hasattr(self.__fields__[name].default, "json_schema_extra"):
                    extra = self.__fields__[name].default.json_schema_extra
                elif hasattr(self.__fields__[name].field_info, "extra"):
                    extra = self.__fields__[name].field_info.extra
            if extra and "range" in extra and name not in kw["__iris__"]:
                arg_is_list = isinstance(self.__dict__[name], list)

                if arg_is_list:
                    kw["__iris__"][name] = []
                    for e in self.__dict__[name]:
                        if isinstance(e, BaseModel):  # contructed with object ref
                            kw["__iris__"][name].append(e.get_iri())
                else:
                    # contructed with object ref
                    if isinstance(self.__dict__[name], BaseModel):
                        kw["__iris__"][name] = self.__dict__[name].get_iri()

        self.__iris__ = kw["__iris__"]

        # iterate over all fields
        # if x-oold-required-iri occurs in extra and the field is not set in __iri__
        # throw an error
        for name in self.__fields__:
            extra = None
            # pydantic v1
            if name in self.__fields__:
                if hasattr(self.__fields__[name].default, "json_schema_extra"):
                    extra = self.__fields__[name].default.json_schema_extra
                elif hasattr(self.__fields__[name].field_info, "extra"):
                    extra = self.__fields__[name].field_info.extra
            # pydantic v2
            # extra = self.model_fields[name].json_schema_extra

            if extra and "x_oold_required_iri" in extra:
                if name not in self.__iris__:
                    raise ValueError(f"{name} is required but not set")

    def _handle_value(self, name, value):
        extra = None
        # pydantic v1
        if name in self.__fields__:
            if hasattr(self.__fields__[name].default, "json_schema_extra"):
                extra = self.__fields__[name].default.json_schema_extra
            elif hasattr(self.__fields__[name].field_info, "extra"):
                extra = self.__fields__[name].field_info.extra
        # pydantic v2
        # extra = self.model_fields[name].json_schema_extra

        if extra and "range" in extra:
            arg_is_list = isinstance(value, list)

            if arg_is_list:
                self.__iris__[name] = []
                for e in value[:]:  # interate over copy of list
                    if isinstance(e, BaseModel):  # contructed with object ref
                        self.__iris__[name].append(e.get_iri())
                    elif isinstance(e, str):  # constructed from json
                        self.__iris__[name].append(e)
                        value.remove(e)  # remove to construct valid instance
                if len(value) == 0:
                    # pydantic v1
                    value = None  # else pydantic v1 will set a FieldInfo object
                    # pydantic v2
                    # del kw[name]
            else:
                if isinstance(value, BaseModel):  # contructed with object ref
                    # print(value.id)
                    self.__iris__[name] = value.get_iri()
                elif isinstance(value, str):  # constructed from json
                    self.__iris__[name] = value
                    # pydantic v1
                    value = None  # else pydantic v1 will set a FieldInfo object
                    # pydantic v2
                    # del kw[name]
                elif value is None:
                    del self.__iris__[name]
        return value

    def __setattr__(self, name, value, internal=False):
        # print("__setattr__", name, value)
        if not internal and name not in [
            "__dict__",
            "__pydantic_private__",
            "__iris__",
        ]:
            value = self._handle_value(name, value)

        return super().__setattr__(name, value)

    def __getattribute__(self, name):
        # print("__getattribute__ ", name)
        # async? https://stackoverflow.com/questions/33128325/
        # how-to-set-class-attribute-with-await-in-init

        if name in ["__dict__", "__pydantic_private__", "__iris__"]:
            return BaseModel.__getattribute__(self, name)  # prevent loop

        else:
            if hasattr(self, "__iris__"):
                if name in self.__iris__ and len(self.__iris__[name]) > 0:
                    if self.__dict__[name] is None or (
                        isinstance(self.__dict__[name], list)
                        and len(self.__dict__[name]) == 0
                    ):
                        iris = self.__iris__[name]
                        is_list = isinstance(iris, list)
                        if not is_list:
                            iris = [iris]

                        node_dict = self._resolve(iris)
                        if is_list:
                            node_list = []
                            for iri in iris:
                                node = node_dict[iri]
                                node_list.append(node)
                            self.__setattr__(name, node_list, True)
                        else:
                            node = node_dict[iris[0]]
                            if node:
                                self.__setattr__(name, node, True)

        return BaseModel.__getattribute__(self, name)

    @staticmethod
    def _resolve(iris):
        resolver = get_resolver(GetResolverParam(iri=iris[0])).resolver
        node_dict = resolver.resolve(
            ResolveParam(iris=iris, model_cls=LinkedBaseModel)
        ).nodes
        return node_dict

    def _store(self):
        backend = get_backend(GetBackendParam(iri=self.get_iri())).backend
        backend.store(StoreParam(nodes={self.get_iri(): self}))

    def store_jsonld(self):
        """Store the model instance in a backend matching its IRI."""
        self._store()

    # pydantic v1
    def json(
        self,
        *,
        include: Optional[Union["AbstractSetIntStr", "MappingIntStrAny"]] = None,
        exclude: Optional[Union["AbstractSetIntStr", "MappingIntStrAny"]] = None,
        by_alias: bool = False,
        skip_defaults: Optional[bool] = None,
        exclude_unset: bool = False,
        exclude_defaults: bool = False,
        exclude_none: bool = False,
        encoder: Optional[Callable[[Any], Any]] = None,
        models_as_dict: bool = True,
        **dumps_kwargs: Any,
    ) -> str:
        """
        Generate a JSON representation of the model,
        `include` and `exclude` arguments as per `dict()`.

        `encoder` is an optional function to supply as `default` to json.dumps(),
        other arguments as per `json.dumps()`.
        """
        d = json.loads(
            BaseModel.json(
                self,
                include=include,
                exclude=exclude,
                by_alias=by_alias,
                skip_defaults=skip_defaults,
                exclude_unset=exclude_unset,
                exclude_defaults=exclude_defaults,
                exclude_none=False,  # handle None values separately
                encoder=encoder,
                models_as_dict=models_as_dict,
                **dumps_kwargs,
            )
        )  # ToDo directly use dict?
        # this may replace some None values with IRIs in case they were never resolved
        # thats why we handle exclude_none there
        self._object_to_iri(d)
        if exclude_none:
            d = self.remove_none(d)
        return json.dumps(d, **dumps_kwargs)

    def to_jsonld(self) -> Dict:
        """Return the RDF representation of the object as JSON-LD."""
        return export_jsonld(self, BaseModel)

    @classmethod
    def from_jsonld(self, jsonld: Dict) -> "LinkedBaseModel":
        """Constructs a model instance from a JSON-LD representation."""
        return import_jsonld(BaseModel, jsonld, _types)
