{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world example for hospital invoices\n",
    "\n",
    "This notebook will demonstrate how to use `dataframely` in a real-world example in the context of hospital invoices.\n",
    "The data model is a 1-N relationship between invoices and diagnoses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframely as dy\n",
    "import polars as pl\n",
    "from decimal import Decimal\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating individual data frames\n",
    "\n",
    "The base schema for the data frame containing the hospital invoices defines all columns with their respective column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceSchema(dy.Schema):\n",
    "    invoice_id = dy.String()\n",
    "    admission_date = dy.Date()\n",
    "    discharge_date = dy.Date()\n",
    "    received_at = dy.Datetime()\n",
    "    amount = dy.Decimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding column constraints to the schema\n",
    "\n",
    "`dataframely` enables users to define uniqueness constraints (e.g., primary key columns), nullability, regular expressions, limits, or other per-column validation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceSchema(dy.Schema):\n",
    "    invoice_id = dy.String(primary_key=True)\n",
    "    admission_date = dy.Date(nullable=False)\n",
    "    discharge_date = dy.Date(nullable=False)\n",
    "    received_at = dy.Datetime(nullable=False)\n",
    "    amount = dy.Decimal(nullable=False, min_exclusive=Decimal(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding cross-column validation rules\n",
    "\n",
    "Validation rules may span across multiple columns. By using the `@dy.rule` decorator, we can easily define cross-column validation rules using polars expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvoiceSchema(dy.Schema):\n",
    "    invoice_id = dy.String(primary_key=True)\n",
    "    admission_date = dy.Date(nullable=False)\n",
    "    discharge_date = dy.Date(nullable=False)\n",
    "    received_at = dy.Datetime(nullable=False)\n",
    "    amount = dy.Decimal(nullable=False, min_exclusive=Decimal(0))\n",
    "\n",
    "    @dy.rule()\n",
    "    def discharge_after_admission(cls) -> pl.Expr:\n",
    "        return pl.col(\"discharge_date\") >= pl.col(\"admission_date\")\n",
    "\n",
    "    @dy.rule()\n",
    "    def received_at_after_discharge(cls) -> pl.Expr:\n",
    "        return pl.col(\"received_at\").dt.date() >= pl.col(\"discharge_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating a data frame\n",
    "\n",
    "To validate a data frame, we can pass the `pl.DataFrame` or `pl.LazyFrame` into the `validate` method.\n",
    "If we want to coerce the column types to the types specified in the schema, we can pass `cast=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>invoice_id</th><th>admission_date</th><th>discharge_date</th><th>received_at</th><th>amount</th></tr><tr><td>str</td><td>date</td><td>date</td><td>datetime[μs]</td><td>decimal[*,0]</td></tr></thead><tbody><tr><td>&quot;001&quot;</td><td>2025-01-01</td><td>2025-01-04</td><td>2025-01-05 00:00:00</td><td>1000</td></tr><tr><td>&quot;002&quot;</td><td>2025-01-05</td><td>2025-01-07</td><td>2025-01-08 00:00:00</td><td>200</td></tr><tr><td>&quot;003&quot;</td><td>2025-01-01</td><td>2025-01-01</td><td>2025-01-02 00:00:00</td><td>400</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌────────────┬────────────────┬────────────────┬─────────────────────┬──────────────┐\n",
       "│ invoice_id ┆ admission_date ┆ discharge_date ┆ received_at         ┆ amount       │\n",
       "│ ---        ┆ ---            ┆ ---            ┆ ---                 ┆ ---          │\n",
       "│ str        ┆ date           ┆ date           ┆ datetime[μs]        ┆ decimal[*,0] │\n",
       "╞════════════╪════════════════╪════════════════╪═════════════════════╪══════════════╡\n",
       "│ 001        ┆ 2025-01-01     ┆ 2025-01-04     ┆ 2025-01-05 00:00:00 ┆ 1000         │\n",
       "│ 002        ┆ 2025-01-05     ┆ 2025-01-07     ┆ 2025-01-08 00:00:00 ┆ 200          │\n",
       "│ 003        ┆ 2025-01-01     ┆ 2025-01-01     ┆ 2025-01-02 00:00:00 ┆ 400          │\n",
       "└────────────┴────────────────┴────────────────┴─────────────────────┴──────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoices = pl.DataFrame(\n",
    "    {\n",
    "        \"invoice_id\": [\"001\", \"002\", \"003\"],\n",
    "        \"admission_date\": [date(2025, 1, 1), date(2025, 1, 5), date(2025, 1, 1)],\n",
    "        \"discharge_date\": [date(2025, 1, 4), date(2025, 1, 7), date(2025, 1, 1)],\n",
    "        \"received_at\": [\n",
    "            datetime(2025, 1, 5),\n",
    "            datetime(2025, 1, 8),\n",
    "            datetime(2025, 1, 2),\n",
    "        ],\n",
    "        \"amount\": [1000.0, 200.0, 400.0],\n",
    "    }\n",
    ")\n",
    "\n",
    "InvoiceSchema.validate(invoices, cast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data to validate contains invalid rows, `dataframely` will raise a `RuleValidationError` with a summary about the violated validation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuleValidationError",
     "evalue": "1 rules failed validation:\n * Column 'amount' failed validation for 1 rules:\n   - 'min_exclusive' failed for 1 rows",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuleValidationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Raise during validation if there are invalid rows\u001b[39;00m\n\u001b[32m      2\u001b[39m invoices = pl.DataFrame({\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minvoice_id\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m002\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m003\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33madmission_date\u001b[39m\u001b[33m\"\u001b[39m: [date(\u001b[32m2025\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m), date(\u001b[32m2025\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m), date(\u001b[32m2025\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)],\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mamount\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m0.0\u001b[39m, \u001b[32m200.0\u001b[39m, \u001b[32m400.0\u001b[39m], \u001b[38;5;66;03m# Invalid amount `0.0` here\u001b[39;00m\n\u001b[32m      8\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mInvoiceSchema\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvoices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dataframely/dataframely/schema.py:280\u001b[39m, in \u001b[36mSchema.validate\u001b[39m\u001b[34m(cls, df, cast)\u001b[39m\n\u001b[32m    278\u001b[39m df_valid, failures = \u001b[38;5;28mcls\u001b[39m.filter(df, cast=cast)\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failures) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RuleValidationError(failures.counts())\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df_valid\n",
      "\u001b[31mRuleValidationError\u001b[39m: 1 rules failed validation:\n * Column 'amount' failed validation for 1 rules:\n   - 'min_exclusive' failed for 1 rows"
     ]
    }
   ],
   "source": [
    "# Raise during validation if there are invalid rows\n",
    "invoices = pl.DataFrame(\n",
    "    {\n",
    "        \"invoice_id\": [\"001\", \"002\", \"003\"],\n",
    "        \"admission_date\": [date(2025, 1, 1), date(2025, 1, 5), date(2025, 1, 1)],\n",
    "        \"discharge_date\": [date(2025, 1, 4), date(2025, 1, 7), date(2025, 1, 1)],\n",
    "        \"received_at\": [\n",
    "            datetime(2025, 1, 5),\n",
    "            datetime(2025, 1, 8),\n",
    "            datetime(2025, 1, 2),\n",
    "        ],\n",
    "        \"amount\": [0.0, 200.0, 400.0],  # Invalid amount `0.0` here\n",
    "    }\n",
    ")\n",
    "\n",
    "InvoiceSchema.validate(invoices, cast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft-validation and validation failure introspection\n",
    "\n",
    "In a production pipeline, we typically do not want to raise an exception at run-time.\n",
    "`dataframely` provides the `filter` method to perform \"soft-validation\" which returns the rows that passed validation and an additional `FailureInfo` object to inspect invalid rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "good, failure = InvoiceSchema.filter(invoices, cast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount|min_exclusive': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the reasons for the failed rows\n",
    "failure.counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'amount|min_exclusive'}): 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the co-occurrences of validation failures\n",
    "failure.cooccurrence_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>invoice_id</th><th>admission_date</th><th>discharge_date</th><th>received_at</th><th>amount</th></tr><tr><td>str</td><td>date</td><td>date</td><td>datetime[μs]</td><td>decimal[*,0]</td></tr></thead><tbody><tr><td>&quot;001&quot;</td><td>2025-01-01</td><td>2025-01-04</td><td>2025-01-05 00:00:00</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌────────────┬────────────────┬────────────────┬─────────────────────┬──────────────┐\n",
       "│ invoice_id ┆ admission_date ┆ discharge_date ┆ received_at         ┆ amount       │\n",
       "│ ---        ┆ ---            ┆ ---            ┆ ---                 ┆ ---          │\n",
       "│ str        ┆ date           ┆ date           ┆ datetime[μs]        ┆ decimal[*,0] │\n",
       "╞════════════╪════════════════╪════════════════╪═════════════════════╪══════════════╡\n",
       "│ 001        ┆ 2025-01-01     ┆ 2025-01-04     ┆ 2025-01-05 00:00:00 ┆ 0            │\n",
       "└────────────┴────────────────┴────────────────┴─────────────────────┴──────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a data frame containing all failed rows\n",
    "failure.invalid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating groups of data frames\n",
    "\n",
    "Oftentimes, data frames (or rather tables) are interdependent and proper data validation requires consideration of multiple tables.\n",
    "`dataframely` enables users to define \"collections\" for groups of data frames with validation rules on the collection level.\n",
    "To create a collection, we first introduce a second schema for diagnosis data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(dy.Schema):\n",
    "    invoice_id = dy.String(primary_key=True)\n",
    "    diagnosis_code = dy.String(primary_key=True, regex=r\"[A-Z][0-9]{2,4}\")\n",
    "    is_main = dy.Bool(nullable=False)\n",
    "\n",
    "    @dy.rule(group_by=[\"invoice_id\"])\n",
    "    def exactly_one_main_diagnosis(cls) -> pl.Expr:\n",
    "        return pl.col(\"is_main\").sum() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we can also define validation rules on groups of rows using `@dy.rule(group_by=[...])`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema inheritance\n",
    "\n",
    "What is still a bit inconvenient about this schema definition is that we have duplicated the shared primary key between `InvoiceSchema` and `DiagnosisSchema`.\n",
    "To this end, we can leverage schema inheritance in `dataframely` by introducing a common base schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce redundancies in schemas by using schema inheritance.\n",
    "# Here, we introduce a base schema for the shared primary key.\n",
    "class InvoiceIdSchema(dy.Schema):\n",
    "    invoice_id = dy.String(primary_key=True)\n",
    "\n",
    "\n",
    "class InvoiceSchema(InvoiceIdSchema):\n",
    "    admission_date = dy.Date(nullable=False)\n",
    "    discharge_date = dy.Date(nullable=False)\n",
    "    received_at = dy.Datetime(nullable=False)\n",
    "    amount = dy.Decimal(nullable=False, min_exclusive=Decimal(0))\n",
    "\n",
    "    @dy.rule()\n",
    "    def discharge_after_admission(cls) -> pl.Expr:\n",
    "        return pl.col(\"discharge_date\") >= pl.col(\"admission_date\")\n",
    "\n",
    "    @dy.rule()\n",
    "    def received_at_after_discharge(cls) -> pl.Expr:\n",
    "        return pl.col(\"received_at\").dt.date() >= pl.col(\"discharge_date\")\n",
    "\n",
    "\n",
    "class DiagnosisSchema(InvoiceIdSchema):\n",
    "    diagnosis_code = dy.String(primary_key=True, regex=r\"[A-Z][0-9]{2,4}\")\n",
    "    is_main = dy.Bool(nullable=False)\n",
    "\n",
    "    @dy.rule(group_by=[\"invoice_id\"])\n",
    "    def exactly_one_main_diagnosis(cls) -> pl.Expr:\n",
    "        return pl.col(\"is_main\").sum() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `dy.Collection`\n",
    "\n",
    "To add the two schemas to a collection, we can create a new collection by subclassing `dy.Collection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a collection for groups of schema-validated data frames\n",
    "class HospitalClaims(dy.Collection):\n",
    "    invoices: dy.LazyFrame[InvoiceSchema]\n",
    "    diagnoses: dy.LazyFrame[DiagnosisSchema]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding cross-dataframe validation rules to a collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further enhance the collection, we can now add validation rules to the collection using the `@dy.filter` decorator.\n",
    "A filter receives a collection as input and must return a data frame like the following:\n",
    "\n",
    "- The columns must be a superset of the common primary keys across all members.\n",
    "- The rows must provide the primary keys which ought to be *kept* across the members. The filter results in the removal of rows which are lost as the result of inner-joining members onto the return value of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalClaims(dy.Collection):\n",
    "    invoices: dy.LazyFrame[InvoiceSchema]\n",
    "    diagnoses: dy.LazyFrame[DiagnosisSchema]\n",
    "\n",
    "    @dy.filter()\n",
    "    def at_least_one_diagnosis_per_invoice(self) -> pl.LazyFrame:\n",
    "        return self.invoices.join(\n",
    "            self.diagnoses.select(pl.col(\"invoice_id\").unique()),\n",
    "            on=\"invoice_id\",\n",
    "            how=\"inner\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating a collection\n",
    "\n",
    "If we call `validate` on the collection, it will raise a validation exception if any of the input data frames does not satisfy its schema definition or the filters on this collection result in the removal of at least one row across any of the input data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemberValidationError",
     "evalue": "2 members failed validation:\n > Member 'invoices' failed validation:\n   1 rules failed validation:\n    - 'at_least_one_diagnosis_per_invoice' failed validation for 1 rows\n > Member 'diagnoses' failed validation:\n   0 rules failed validation:",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemberValidationError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m      1\u001b[39m invoices = pl.DataFrame(\n\u001b[32m      2\u001b[39m     {\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minvoice_id\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m002\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m003\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     }\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m diagnoses = pl.DataFrame(\n\u001b[32m     16\u001b[39m     {\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minvoice_id\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m001\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m002\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     }\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m claims = \u001b[43mHospitalClaims\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minvoices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minvoices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdiagnoses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiagnoses\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Aggregate diagnoses per invoice\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     29\u001b[39m     claims.invoices.join(claims.diagnoses, on=\u001b[33m\"\u001b[39m\u001b[33minvoice_id\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m     .group_by(\u001b[33m\"\u001b[39m\u001b[33minvoice_id\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     .collect()\n\u001b[32m     39\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dataframely/dataframely/collection.py:82\u001b[39m, in \u001b[36mCollection.validate\u001b[39m\u001b[34m(cls, data, cast)\u001b[39m\n\u001b[32m     80\u001b[39m out, failure = \u001b[38;5;28mcls\u001b[39m.filter(data, cast=cast)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mlen\u001b[39m(fail) > \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fail \u001b[38;5;129;01min\u001b[39;00m failure.values()):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MemberValidationError(\n\u001b[32m     83\u001b[39m         {\n\u001b[32m     84\u001b[39m             name: RuleValidationError(fail.counts())\n\u001b[32m     85\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m name, fail \u001b[38;5;129;01min\u001b[39;00m failure.items()\n\u001b[32m     86\u001b[39m         }\n\u001b[32m     87\u001b[39m     )\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[31mMemberValidationError\u001b[39m: 2 members failed validation:\n > Member 'invoices' failed validation:\n   1 rules failed validation:\n    - 'at_least_one_diagnosis_per_invoice' failed validation for 1 rows\n > Member 'diagnoses' failed validation:\n   0 rules failed validation:"
     ]
    }
   ],
   "source": [
    "invoices = pl.DataFrame(\n",
    "    {\n",
    "        \"invoice_id\": [\"001\", \"002\", \"003\"],\n",
    "        \"admission_date\": [date(2025, 1, 1), date(2025, 1, 5), date(2025, 1, 1)],\n",
    "        \"discharge_date\": [date(2025, 1, 4), date(2025, 1, 7), date(2025, 1, 1)],\n",
    "        \"received_at\": [\n",
    "            datetime(2025, 1, 5),\n",
    "            datetime(2025, 1, 8),\n",
    "            datetime(2025, 1, 2),\n",
    "        ],\n",
    "        \"amount\": [1000.0, 200.0, 400.0],\n",
    "    }\n",
    ")\n",
    "\n",
    "diagnoses = pl.DataFrame(\n",
    "    {\n",
    "        \"invoice_id\": [\"001\", \"001\", \"002\"],\n",
    "        \"diagnosis_code\": [\"A123\", \"B456\", \"C789\"],\n",
    "        \"is_main\": [True, False, True],\n",
    "    }\n",
    ")\n",
    "\n",
    "claims = HospitalClaims.validate(\n",
    "    {\"invoices\": invoices, \"diagnoses\": diagnoses}, cast=True\n",
    ")\n",
    "\n",
    "# Aggregate diagnoses per invoice\n",
    "print(\n",
    "    claims.invoices.join(claims.diagnoses, on=\"invoice_id\", how=\"inner\")\n",
    "    .group_by(\"invoice_id\")\n",
    "    .agg(\n",
    "        pl.col(\"admission_date\").first(),\n",
    "        pl.col(\"discharge_date\").first(),\n",
    "        pl.col(\"received_at\").first(),\n",
    "        pl.col(\"amount\").first(),\n",
    "        pl.col(\"diagnosis_code\"),\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that collections can also be soft-validated using `filter`. The failure introspection is similar to schemas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
