import digitalarzengine.proj_bootstrap
import math
import os

import pandas as pd
import rasterio
from osgeo import gdal
import geopandas as gpd

import numpy as np
import rasterio as rio
from typing import Union, List, Optional, Tuple, Literal

import shapely
from affine import Affine
from rasterio import CRS, windows

from rasterio.mask import mask
from rasterio.transform import from_bounds, rowcol

from shapely import box

from digitalarzengine.io.file_io import FileIO
from digitalarzengine.processing.raster.band_process import BandProcess
from digitalarzengine.utils.singletons import da_loggerC

ResampleMethod = Literal[
    "nearest", "bilinear", "cubic", "average", "mode",
    "max", "min", "med", "q1", "q3", "lanczos"
]

class RioRaster:
    dataset: rio.DatasetReader = None

    def __init__(self, src: Union[str, rio.DatasetReader, None], prj_path: str = None):
        if src is not None:
            self.set_dataset(src)
            if prj_path is not None and os.path.exists(prj_path):
                self.add_crs_from_prj(prj_path)

    def __repr__(self):
        if self.empty:
            return "<RioRaster: Empty>"
        return f"<RioRaster: {self.dataset.name}, {self.get_image_resolution()}, {self.get_crs()}>"

    def set_dataset(self, src: Union[str, rio.DatasetReader]):
        """
        Set the raster dataset from a source.

        :param src: The source path or DatasetReader object.
        """
        try:
            if isinstance(src, rio.DatasetReader):
                if '/vsipythonfilelike/' in src.name:
                    self.dataset = self.rio_dataset_from_array(src.read(), src.meta)
                else:
                    self.dataset = src
            elif isinstance(src, str):
                if "/vsimem/" in src:
                    with rio.MemoryFile(src) as memfile:
                        self.dataset = memfile.open()
                else:
                    if os.path.exists(src):
                        self.dataset = rio.open(src, mode='r', ignore_cog_layout_break='YES')
                    else:
                        raise FileNotFoundError(f"Raster file not available at {src}")

            if self.dataset is None:
                raise ValueError("Dataset could not be set. It is None.")
        except Exception as e:
            da_logger.exception(f"Error setting dataset: {e}")

    def get_dataset(self) -> rio.DatasetReader:
        """Get the current dataset."""
        return self.dataset

    @staticmethod
    def rio_dataset_from_array(data: np.ndarray, meta, descriptions: list = None) -> rio.DatasetReader:
        """
        Create a RioDataset from an array.

        :param data: The data array.
        :param meta: The metadata.
        :param descriptions: The band descriptions.
        :return: The resulting DatasetReader object.
        """
        bands = 1 if len(data.shape) == 2 else data.shape[0]
        memfile = rio.MemoryFile()
        dst = memfile.open(**meta,
                           compress='lzw',
                           BIGTIFF='YES')
        for i in range(bands):
            d = data if len(data.shape) == 2 else data[i, :, :]
            dst.write(d, i + 1)
        if descriptions is not None:
            for i, desc in enumerate(descriptions):
                if desc:
                    dst.set_band_description(i + 1, desc)
        dst.close()
        return memfile.open()

    def add_crs_from_prj(self, prj_file: str):
        name, ext = os.path.splitext(prj_file)
        if ext.lower() != ".prj":
            return
        with open(prj_file) as f:
            wkt = f.read()
        crs = CRS.from_wkt(wkt)
        meta = self.dataset.meta.copy()
        meta.update(crs=crs)
        # rewrite into MemoryFile preserving data
        data = self.dataset.read()
        self.dataset = self.rio_dataset_from_array(data, meta, list(self.dataset.descriptions or ()))

    def get_meta(self)->dict:
        """Get the metadata of the current dataset."""
        return self.dataset.meta

    def get_profile(self):
        """Get the profile of the dataset."""
        return self.dataset.profile

    def get_spectral_resolution(self) -> int:
        """
        Get the number of bands (spectral resolution) in the raster.

        :return: Number of bands.
        """
        if self.dataset is not None:
            return self.dataset.count
        else:
            raise ValueError("Dataset is not set.")

    def get_spatial_resolution(self, in_meter=True) -> tuple:
        """
        Return the spatial resolution (pixel size) as (x_resolution, y_resolution).

        If `in_meter` is True and the CRS is geographic (degrees),
        it will approximate the resolution in meters using a degree-to-meter conversion
        at the dataset's center latitude.
        """
        if self.dataset is None:
            raise ValueError("Dataset is not set.")

        a, _, _, _, e, _ = self.dataset.transform[:6]
        x_res, y_res = abs(a), abs(e)

        if in_meter:
            crs = CRS.from_user_input(self.dataset.crs)
            if crs.is_geographic:
                # Get dataset center latitude for conversion
                bounds = self.dataset.bounds
                center_lat = (bounds.top + bounds.bottom) / 2

                # Convert degrees to meters at center latitude
                meters_per_degree_lon = 111320 * math.cos(math.radians(center_lat))
                meters_per_degree_lat = 110540  # average

                x_res *= meters_per_degree_lon
                y_res *= meters_per_degree_lat

        return x_res, y_res

    def get_radiometric_resolution(self) -> str:
        """
        Return the radiometric resolution (bit depth) based on the data type.

        :return: String representing the data type (e.g., 'uint8', 'int16')
        """
        if self.dataset is not None:
            return self.dataset.dtypes[0]  # Assume all bands have the same dtype
        else:
            raise ValueError("Dataset is not set.")

    def get_image_resolution(self) -> tuple:
        """
        Return the image resolution in pixels as (width, height).

        :return: Tuple (width, height)
        """
        if self.dataset is not None:
            return self.dataset.width, self.dataset.height
        else:
            raise ValueError("Dataset is not set.")

    @property
    def empty(self):
        return self.dataset is None

    @staticmethod
    def write_to_file(img_des: str, data: np.ndarray, crs: CRS, affine_transform: Affine, nodata_value,
                      band_names: List[str] = ()):
        """Write raster data to a file (GeoTIFF or COG) with optional S3 support.

        Args:
            img_des (str): The destination file path (local or S3 URI).
            data (np.ndarray): The raster data array.
            crs (CRS): The Coordinate Reference System.
            affine_transform (Affine): The affine transformation.
            nodata_value: The no-data value.
            band_names: list of band names to write with file as description
        """
        try:

            dir_name = FileIO.mkdirs(img_des)
            da_logger.debug(f"directory name {dir_name}")
            # Determine driver and BigTIFF
            driver = 'COG' if img_des.lower().endswith('.cog') else 'GTiff'
            bigtiff = 'YES' if data.nbytes > 4 * 1024 * 1024 * 1024 else 'NO'

            # Get dimensions and bands
            if len(data.shape) == 2:
                # bands, rows, cols = 1, *data.shape
                bands = 1
                rows, cols = data.shape
            else:
                bands, rows, cols = data.shape

            # Write raster data with optional S3 environment
            dtype = np.dtype(data.dtype)
            predictor = 3 if np.issubdtype(dtype, np.floating) else 2
            with rio.open(img_des, 'w', driver=driver, height=rows, width=cols,
                          count=bands, dtype=str(data.dtype), crs=crs,
                          transform=affine_transform, compress='deflate',
                          predictor=predictor, zlevel=7,  # Predictor and compression level for Deflate
                          nodata=nodata_value, BIGTIFF=bigtiff) as dst:

                for i in range(bands):
                    d = data if bands == 1 else data[i, :, :]
                    dst.write(d, indexes=i + 1) if bands > 1 else dst.write(d)
                    # Assign band names (Check if band names list is correct)
                    if i < len(band_names):
                        dst.set_band_description(i + 1, band_names[i])

                # Add overviews for COGs (if applicable)
                # if driver == 'COG':
                #     dst.build_overviews([2, 4, 8, 16, 32])
                if driver == 'GTiff':
                    dst.build_overviews([2, 4, 8, 16, 32])


        except rio.RasterioIOError as e:
            da_logger.exception(f"Error writing raster to file {img_des}: {e}")

    def save_to_file(self, img_des: str, data: np.ndarray = None, crs: CRS = None,
                     affine_transform: Affine = None, nodata_value=None, band_names: List[str] = ()):
        """
        Save the dataset to a file.

        :param img_des: The destination file path.
        :param data: The data array to save.
        :param crs: The CRS to use.
        :param affine_transform: The affine transform to use.
        :param nodata_value: The no-data value to use.
        :param band_names: The list of band name to write in the file as description
        """
        data = self.get_data_array() if data is None else data
        crs = crs if crs else self.dataset.crs
        affine_transform = affine_transform if affine_transform else self.dataset.transform
        # nodata_value = nodata_value if nodata_value else self.get_nodata_value()
        nodata_value = nodata_value if nodata_value is not None else self.get_nodata_value()
        self.write_to_file(img_des, data, crs, affine_transform, nodata_value, band_names=band_names)

    def get_data_array_by_band_name(self, target_band_names: List, convert_no_data_2_nan=False) -> np.ndarray:
        band_names = self.dataset.descriptions
        data = []
        for target_band_name in target_band_names:
            if target_band_name in band_names:
                band_index = band_names.index(target_band_name) + 1
                band_data = self.get_data_array(band_index, convert_no_data_2_nan=convert_no_data_2_nan)
                data.append(band_data)
        return np.array(data if len(data) > 1 else data[0])

    def get_data_array(self, band: int = None, convert_no_data_2_nan: bool = False, envelop_gdf=None) -> np.ndarray:
        """
        Get the data array from the dataset, optionally within an envelope.

        :param band: The band number to read (1-based index). Reads all bands if None.
        :param convert_no_data_2_nan: Whether to convert no-data values to NaN.
        :param envelop_gdf: Optional GeoDataFrame containing the envelope geometry to crop data.
        :return: NumPy array of raster values.
        """
        if self.dataset is None:
            raise ValueError("Raster dataset is empty.")

        dataset = self.dataset

        if envelop_gdf is not None:
            # Ensure CRS match
            if envelop_gdf.crs != dataset.crs:
                envelop_gdf = envelop_gdf.to_crs(dataset.crs)

            # Mask raster with given envelope geometry
            geom = [envelop_gdf.unary_union]
            data_arr, _ = mask(dataset, geom, crop=True, indexes=band)
        else:
            data_arr = dataset.read(band) if band else dataset.read()

        if convert_no_data_2_nan:
            nodata_val = dataset.nodata
            if nodata_val is not None:
                if not np.issubdtype(data_arr.dtype, np.floating):
                    data_arr = data_arr.astype(np.float32)
                data_arr[data_arr == nodata_val] = np.nan

        return data_arr

    def calculate_pixel_wise_stats(
            self,
            method: Literal["min", "max", "mean", "sum", "std"] = "mean"
    ) -> 'RioRaster':
        """
        stack raster before this operation
        Performs pixel-wise statistics across all bands of the current RioRaster.
        Returns a new single-band RioRaster.
        """
        if self.dataset is None:
            raise ValueError("Raster dataset is empty.")

        # 1. Get data array (Bands, Height, Width)
        # We use convert_no_data_2_nan=True to ensure NoData doesn't bias the stats
        data = self.get_data_array(convert_no_data_2_nan=True)

        if data.ndim < 3:
            da_logger.warning("Raster has only one band. Stats will return original values.")
            return self if not hasattr(self, 'copy') else RioRaster(self.dataset)

        # 2. Perform calculation along the Band axis (axis 0)
        if method == "min":
            stat_arr = np.nanmin(data, axis=0)
        elif method == "max":
            stat_arr = np.nanmax(data, axis=0)
        elif method == "mean" or method == "avg":
            stat_arr = np.nanmean(data, axis=0)
        elif method == "sum":
            stat_arr = np.nansum(data, axis=0)
        elif method == "std":
            stat_arr = np.nanstd(data, axis=0)
        else:
            raise ValueError(f"Unsupported method: {method}")

        # 3. Handle pixels where ALL bands were NaN (NumPy often turns these into
        # Infinity or 0 depending on the function). We ensure they stay NaN.
        all_nan_mask = np.all(np.isnan(data), axis=0)
        stat_arr[all_nan_mask] = np.nan

        # 4. Create new single-band metadata
        new_meta = self.get_meta().copy()
        new_meta.update({
            "count": 1,
            "dtype": "float32",
            "nodata": np.nan
        })

        # 5. Return as a new RioRaster
        # Wrap in 3D array for rio_dataset_from_array (1, H, W)
        stat_arr_3d = stat_arr[np.newaxis, ...]

        new_ds = RioRaster.rio_dataset_from_array(
            stat_arr_3d,
            new_meta,
            descriptions=[f"Pixelwise {method}"]
        )

        return RioRaster(new_ds)

    def get_data_shape(self):
        """
        Get the shape of the data array.

        :return: Tuple of (band, row, column).
        """
        data = self.get_data_array()
        bands, rows, cols = 0, 0, 0
        if len(data.shape) == 2:
            bands = 1
            rows, cols = data.shape
        elif len(data.shape) == 3:
            bands, rows, cols = data.shape
        return bands, rows, cols

    def get_crs(self) -> CRS:
        """Get the CRS of the dataset."""
        return self.dataset.crs

    def get_extent_after_skip_rows_cols(self, n_rows_skip, n_cols_skip):
        """
        Get the extent of the dataset after skipping rows and columns.

        :param n_rows_skip: Number of rows to skip.
        :param n_cols_skip: Number of columns to skip.
        :return: The new extent.
        """
        # y_size, x_size = self.get_image_resolution()
        x_size, y_size = self.get_image_resolution()
        geo_t = self.get_geo_transform()
        min_x = geo_t[2] + n_cols_skip * geo_t[0]
        max_y = geo_t[5] + n_rows_skip * geo_t[4]
        max_x = geo_t[2] + geo_t[0] * (x_size - n_cols_skip)
        min_y = geo_t[5] + geo_t[4] * (y_size - n_rows_skip)
        return min_x, min_y, max_x, max_y

    def get_envelop(self, n_rows_skip: int = 0, n_cols_skip: int = 0, srid: int = 0) -> gpd.GeoDataFrame:
        """
        Build the raster envelope as a single-row GeoDataFrame.

        :param n_rows_skip: Number of rows to skip (top/bottom handling should be in your extent fn).
        :param n_cols_skip: Number of columns to skip (left/right handling should be in your extent fn).
        :param srid: Optional EPSG code to reproject the envelope to.
        :return: GeoDataFrame with one polygon row representing the envelope.
        """
        if self.dataset is None:
            raise ValueError("Dataset is not set.")

        # Get extent with or without skipping
        if n_rows_skip or n_cols_skip:
            minx, miny, maxx, maxy = self.get_extent_after_skip_rows_cols(n_rows_skip, n_cols_skip)
        else:
            minx, miny, maxx, maxy = self.get_raster_extent()

        # Build polygon in the dataset's native CRS
        gdf = gpd.GeoDataFrame(
            {"id": [1]},
            geometry=[box(minx, miny, maxx, maxy)],
            crs=self.get_crs()  # should return a pyproj CRS or EPSG int
        )

        # Reproject if requested (to_crs returns a new GeoDataFrame)
        if srid:
            gdf = gdf.to_crs(epsg=srid)

        return gdf

    def get_raster_extent(self) -> list:
        """Get the extent of the raster."""
        bounds = self.dataset.bounds
        return [bounds.left, bounds.bottom, bounds.right, bounds.top]

    def get_raster_srid(self) -> int:
        """
        Get the spatial reference ID (SRID) of the raster.

        :return: The SRID or 0 if unavailable.
        """
        if self.dataset is None:
            raise ValueError("Dataset is not set.")

        try:
            crs = self.dataset.crs
            if crs is None:
                return 0

            # Try EPSG directly
            epsg_code = crs.to_epsg()
            if epsg_code:
                return epsg_code

            # If not EPSG, try parsing from WKT
            crs_obj = CRS.from_wkt(str(crs))
            return crs_obj.to_epsg() or 0

        except Exception as e:
            da_logger.exception(f"Error getting SRID: {e}")
            return 0

    def get_geo_transform(self) -> Affine:
        """
        Get the affine transform of the dataset.

        :return: The affine transform.
            the sequence is [a,b,c,d,e,f]
        """
        return self.dataset.transform

    def get_nodata_value(self):
        """Get the no-data value of the dataset."""
        return self.dataset.nodata

    def set_nodata(self, nodata_value=None):
        """Set NoData value for the raster (requires writable dataset, e.g. mode='r+')."""
        if self.dataset is None:
            raise ValueError("Raster dataset is empty.")

        # Must be writable
        if self.dataset.mode not in ("r+", "w", "w+"):
            raise RuntimeError(
                f"Dataset is read-only (mode='{self.dataset.mode}'). "
                "Reopen with mode='r+' (or write to a new file) to set NoData."
            )

        # Choose a sensible default if not provided
        dtype = np.dtype(self.dataset.dtypes[0])
        if nodata_value is None:
            if dtype.kind in ("f",):  # float
                nodata_value = np.finfo(dtype).max  # or use np.nan if your workflow/driver supports it
            else:  # int/uint
                nodata_value = np.iinfo(dtype).min

        # Set NoData (no update_tags on DatasetReader; writable dataset will persist on close)
        self.dataset.nodata = nodata_value
        return nodata_value

    def rio_raster_from_array(self, img_arr: np.ndarray) -> 'RioRaster':
        """
        Create a RioRaster object from an array.

        :param img_arr: The image array.
        :return: A new RioRaster object.
        """
        # meta_data = self.get_meta().copy()
        raster = self.raster_from_array(img_arr, crs=self.get_crs(),
                                        g_transform=self.get_geo_transform(),
                                        nodata_value=self.get_nodata_value())
        return raster

    @staticmethod
    def raster_from_array(img_arr: np.ndarray, crs: Union[str, CRS],
                          g_transform: Affine, nodata_value=None) -> 'RioRaster':
        """
        Create a RioRaster object from an array.

        :param img_arr: The image array.
        :param crs: The CRS to use.
        :param g_transform: The affine transform to use.
        :param nodata_value: The no-data value to use.
        :return: A new RioRaster object.
        """
        try:
            memfile = rio.MemoryFile()
            if len(img_arr.shape) == 2:
                bands = 1
                rows, cols = img_arr.shape
            else:
                bands, rows, cols = img_arr.shape

            with memfile.open(driver='GTiff',
                              height=rows,
                              width=cols,
                              count=bands,
                              dtype=str(img_arr.dtype),
                              crs=crs,
                              transform=g_transform,
                              nodata=nodata_value,
                              compress='lzw',
                              BIGTIFF='YES') as dataset:
                for i in range(bands):
                    d = img_arr if len(img_arr.shape) == 2 else img_arr[i, :, :]
                    dataset.write(d, i + 1)
                dataset.close()

            dataset = memfile.open()  # Reopen as DatasetReader
            new_raster = RioRaster(dataset)
            return new_raster

        except Exception as e:
            da_logger.exception(f"Error creating raster from array: {e}")
            return None

    def get_bounds(self) -> tuple:
        """
        Get the bounding box of the raster in the format (minx, miny, maxx, maxy).

        :return: Tuple of (minx, miny, maxx, maxy).
        """
        if self.dataset is not None:
            # return self.dataset.bounds  # returns BoundingBox(minx, miny, maxx, maxy)
            return tuple(self.dataset.bounds)
        else:
            raise ValueError("Dataset is not set.")

    def clip_raster(
            self,
            aoi: Union[gpd.GeoDataFrame, shapely.geometry.Polygon, shapely.geometry.MultiPolygon],
            in_place: bool = True,
            crs: Union[int, str, CRS] = None,
            clip_within_aoi: bool = True,  # Default to True to see the effect
            nodata_value: Optional[Union[int, float]] = None
    ) -> Optional['RioRaster']:

        if self.dataset is None:
            raise RuntimeError("Dataset is not set.")

        # 1. Standardize AOI
        if isinstance(aoi, (shapely.geometry.Polygon, shapely.geometry.MultiPolygon)):
            aoi = gpd.GeoDataFrame(geometry=[aoi], crs=crs)
        if aoi.crs is None:
            aoi.set_crs(crs or self.get_crs(), inplace=True)

        # 2. Align CRS
        if not aoi.crs.equals(self.get_crs()):
            aoi = aoi.to_crs(self.get_crs())

        # 3. Intersection Check
        raster_box = box(*self.get_bounds())
        intersecting_aoi = aoi[aoi.intersects(raster_box)]

        if intersecting_aoi.empty:
            da_logger.warning("âŒ No intersection found.")
            return None

        # 4. Define Geometries
        if clip_within_aoi:
            geometries = [geom for geom in intersecting_aoi.geometry if geom.is_valid]
        else:
            geometries = [box(*intersecting_aoi.total_bounds)]

        # 5. Determine NoData
        if nodata_value is None:
            nodata_value = self.get_nodata_value()
            if nodata_value is None:
                dtype = np.dtype(self.dataset.dtypes[0])
                nodata_value = 0 if np.issubdtype(dtype, np.integer) else np.nan

        # 6. MASK OPERATION
        # We use all_touched=True to ensure we don't lose thin pixels
        out_img, out_transform = mask(
            self.dataset,
            geometries,
            crop=True,
            nodata=nodata_value,
            filled=True,
            all_touched=True
        )

        # --- THE "FORCE" FIX ---
        # Sometimes rasterio's internal mask doesn't fill perfectly if the geometries
        # are complex. We can force a secondary mask if necessary, but 'filled=True'
        # with a valid 'nodata' usually does the trick.
        # -----------------------

        # 7. Metadata update
        out_meta = self.dataset.meta.copy()
        out_meta.update({
            "height": out_img.shape[1],
            "width": out_img.shape[2],
            "transform": out_transform,
            "nodata": nodata_value,  # CRITICAL: This must be in metadata
            "count": self.dataset.count
        })

        # 8. Create new Dataset
        new_ds = self.rio_dataset_from_array(out_img, out_meta, list(self.dataset.descriptions or []))

        if in_place:
            self.dataset.close()
            self.dataset = new_ds
            return self
        return RioRaster(new_ds)

    def reproject_to(self, target_crs: Union[str, CRS], in_place=False, resampling:ResampleMethod="nearest") -> 'RioRaster':
        """
        Reproject the current raster to the specified CRS.

        :param target_crs: CRS to reproject to (e.g., 'EPSG:4326' or rasterio.CRS object)
        :param in_place: If True, modifies self. Otherwise returns a new RioRaster.
        :return: Reprojected RioRaster object or self (if in_place=True)
        """
        from rasterio.warp import calculate_default_transform, reproject, Resampling
        if not hasattr(Resampling, resampling):
            raise ValueError(f"Unsupported resampling '{resampling}'.")
        resampling_enum = getattr(Resampling, resampling)

        target_crs = CRS.from_user_input(target_crs)
        transform, width, height = calculate_default_transform(
            self.dataset.crs, target_crs,
            self.dataset.width, self.dataset.height,
            *self.dataset.bounds
        )
        kwargs = self.dataset.meta.copy()
        kwargs.update({'crs': target_crs, 'transform': transform, 'width': width, 'height': height})
        if self.dataset.nodata is not None:
            kwargs['nodata'] = self.dataset.nodata

        memfile = rio.MemoryFile()
        with memfile.open(**kwargs) as dst:
            for i in range(1, self.dataset.count + 1):
                reproject(
                    source=rio.band(self.dataset, i),
                    destination=rio.band(dst, i),
                    src_transform=self.dataset.transform,
                    src_crs=self.dataset.crs,
                    dst_transform=transform,
                    dst_crs=target_crs,
                    resampling=resampling_enum
                )
            # descriptionsâ€¦

            # Set band descriptions if available
            descriptions = self.dataset.descriptions
            if descriptions:
                for i, desc in enumerate(descriptions):
                    if desc:
                        dst.set_band_description(i + 1, desc)

        new_raster = RioRaster(memfile.open())
        if in_place:
            self.dataset = new_raster.dataset
            return self
        else:
            return new_raster

    # def pad_raster(self, des_raster: 'RioRaster', in_place: bool = True) -> Union[None, 'RioRaster']:
    #     src_crs = self.get_crs()
    #     des_crs = des_raster.get_crs()
    #
    #     # Check CRS compatibility
    #     if src_crs != des_crs:
    #         da_logger.debug("ðŸ”„ CRS mismatch. Reprojecting source raster to match destination raster CRS...")
    #         self.reproject_to(des_crs, in_place=True)
    #
    #     aff: Affine = self.get_geo_transform()
    #     des_bounds = des_raster.get_bounds()
    #
    #     rows, cols = rio.transform.rowcol(
    #         aff,
    #         xs=[des_bounds[0], des_bounds[2]],
    #         ys=[des_bounds[3], des_bounds[1]],
    #     )
    #
    #     height = rows[1] - rows[0]
    #     width = cols[1] - cols[0]
    #
    #     window = windows.Window(col_off=cols[0], row_off=rows[0], width=width, height=height)
    #     window_transform = windows.transform(window, aff)
    #
    #     kwargs = self.dataset.meta.copy()
    #     kwargs.update({
    #         'crs': self.get_crs(),
    #         'transform': window_transform,
    #         'width': width,
    #         'height': height
    #     })
    #
    #     memfile = rio.MemoryFile()
    #     dst = memfile.open(**kwargs)
    #
    #     fill = self.dataset.nodata
    #     if fill is None:
    #         fill = np.nan if np.issubdtype(np.dtype(self.dataset.dtypes[0]), np.floating) else 0
    #
    #     data = self.dataset.read(window=window, boundless=True, fill_value=fill)
    #     dst.write(data)
    #     dst.close()
    #     result = RioRaster(memfile.open())
    #
    #     if in_place:
    #         self.dataset = result.dataset
    #         return None
    #     else:
    #         return result

    def pad_raster(self, des_raster: 'RioRaster', in_place: bool = True) -> Union[None, 'RioRaster']:
        src_crs = self.get_crs()
        des_crs = des_raster.get_crs()

        # 1) CRS compatibility
        if src_crs != des_crs:
            da_logger.debug("ðŸ”„ CRS mismatch. Reprojecting source raster to match destination raster CRS...")
            self.reproject_to(des_crs, in_place=True)

        aff: Affine = self.get_geo_transform()
        des_bounds = des_raster.get_bounds()

        # 2) Compute window in source pixel coords
        rows, cols = rio.transform.rowcol(
            aff,
            xs=[des_bounds[0], des_bounds[2]],
            ys=[des_bounds[3], des_bounds[1]],
        )

        height = rows[1] - rows[0]
        width = cols[1] - cols[0]

        window = windows.Window(col_off=cols[0], row_off=rows[0], width=width, height=height)
        window_transform = windows.transform(window, aff)

        # 3) Build new meta, but FORCE float32 + NaN nodata
        src_meta = self.dataset.meta.copy()
        src_nodata = self.dataset.nodata
        src_dtype = np.dtype(self.dataset.dtypes[0])

        kwargs = src_meta.copy()
        kwargs.update({
            "crs": self.get_crs(),
            "transform": window_transform,
            "width": width,
            "height": height,
            "dtype": "float32",  # <- force float
            "nodata": np.nan,  # <- nodata is NaN
        })

        memfile = rio.MemoryFile()
        dst = memfile.open(**kwargs)

        # 4) Read from source, then convert to float32 / NaN
        #    Use src_nodata as fill, then map it to NaN after cast.
        fill = src_nodata
        if fill is None:
            # If original is float, NaN is ok; if int, use some fill (will be turned to NaN anyway)
            if np.issubdtype(src_dtype, np.floating):
                fill = np.nan
            else:
                # choose a fill that is likely nodata; will be converted to NaN anyway
                fill = 0

        data = self.dataset.read(window=window, boundless=True, fill_value=fill)
        data = data.astype("float32", copy=False)

        # Map original nodata to NaN (for float stack)
        if src_nodata is not None and not (isinstance(src_nodata, float) and np.isnan(src_nodata)):
            mask = (data == src_nodata)
            data[mask] = np.nan
        # If we chose fill manually above and we know it's a fake nodata, you can also map that to NaN:
        # else: if we used some special fill, you could map that here.

        dst.write(data)
        dst.close()
        result = RioRaster(memfile.open())

        if in_place:
            self.dataset = result.dataset
            return None
        else:
            return result

    def reclassify_raster(
            self,
            thresholds: Union[dict, List[tuple]],
            band: int = None,
            nodata: int = 0
    ) -> 'RioRaster':
        """
        Reclassify a single-band raster using defined threshold rules.

        :param thresholds: Reclassification rules in dict or list format.
            Dict example:
                {
                    "water": (('lt', 0.015), 4),
                    "built-up": ((0.015, 0.02), 1),
                    "barren": ((0.07, 0.27), 2),
                    "vegetation": (('gt', 0.27), 3)
                }
            List example:
                [
                    (('lt', 0.015), 4),
                    ((0.015, 0.02), 1),
                    ((0.07, 0.27), 2),
                    (('gt', 0.27), 3)
                ]

        :param band: 1-based band number. If not specified and multiple bands exist, raises error.
        :param nodata: Optional fallback NoData value.
        :return: A new reclassified single-band RioRaster.
        """
        if self.dataset is None:
            raise ValueError("Raster dataset is empty.")

        band_count = self.get_spectral_resolution()
        if band_count > 1 and band is None:
            raise ValueError("Multiple bands detected. Specify 'band' explicitly for reclassification.")

        band = band or 1
        img_arr = self.get_data_array(band)
        img_arr = np.squeeze(img_arr)

        # Support both dict and list threshold formats
        if isinstance(thresholds, dict):
            threshold_rules = list(thresholds.values())
        elif isinstance(thresholds, list):
            threshold_rules = thresholds
        else:
            raise TypeError("Thresholds must be a dict or a list of tuples.")

        nodata_val = self.get_nodata_value()
        if nodata_val is None or nodata_val == nodata:
            nodata_val = nodata

        classified = BandProcess.reclassify_band(img_arr, threshold_rules, nodata_val)
        result_array = np.expand_dims(classified.astype(np.uint8), axis=0)

        return self.rio_raster_from_array(result_array)

    def get_masked_array(self, band=1) -> np.ma.MaskedArray:
        data = self.get_data_array(band)
        nodata = self.get_nodata_value()
        if nodata is None:
            return np.ma.masked_array(data, mask=False)
        if np.issubdtype(data.dtype, np.floating) and np.isnan(nodata):
            mask = np.isnan(data)
        else:
            mask = (data == nodata)
        return np.ma.masked_array(data, mask=mask)

    # def to_xarray(self):
    #     """
    #     Convert the raster to xarray.DataArray for advanced analysis.
    #
    #     :return: xarray.DataArray object.
    #     """
    #     import rioxarray  # extends xarray with rasterio support
    #
    #     if self.dataset is None:
    #         raise ValueError("Raster dataset is empty.")
    #
    #     # rioxarray.open_rasterio returns an xarray.DataArray
    #     return rioxarray.open_rasterio(self.dataset.name, masked=True)

    @staticmethod
    def create_dummy_geotiff(
            output_path: str = "tests/data/sample_geotiff.tif",
            width: Optional[int] = None,
            height: Optional[int] = None,
            spatial_resolution: Optional[float] = None,
            count: int = 3,
            crs: str = "EPSG:4326",
            extent: Optional[Tuple[float, float, float, float]] = None,
            dtype: Union[np.dtype, str] = np.uint8,
            value_range: Optional[Tuple[float, float]] = None
    ) -> str:
        """
        Create a dummy GeoTIFF with optional extent, spatial resolution, data type, and value range.
            create_dummy_geotiff(
                output_path="tests/data/ndvi_dummy.tif",
                spatial_resolution=0.001,
                count=1,
                dtype=np.float16,
                value_range=(0.0, 1.0)
            )
        :param output_path: Output file path.
        :param width: Width in pixels (optional if spatial_resolution is set).
        :param height: Height in pixels (optional if spatial_resolution is set).
        :param spatial_resolution: Pixel resolution in CRS units (assumes square pixels).
        :param count: Number of bands.
        :param crs: Coordinate Reference System.
        :param extent: (minx, miny, maxx, maxy) bounding box.
        :param dtype: Numpy dtype or string (e.g., np.float16, "uint8").
        :param value_range: Tuple (min, max) to define data range.
        :return: Output path.
        """
        if os.path.exists(output_path):
            return output_path

        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        if extent is None:
            minx, miny = 74.3, 31.45
            maxx, maxy = 74.35, 31.50
            extent = (minx, miny, maxx, maxy)

        minx, miny, maxx, maxy = extent
        x_res = maxx - minx
        y_res = maxy - miny

        if spatial_resolution is not None:
            width = int(np.ceil(x_res / spatial_resolution))
            height = int(np.ceil(y_res / spatial_resolution))
        elif width is None or height is None:
            raise ValueError("Either spatial_resolution or both width and height must be provided.")

        transform = from_bounds(minx, miny, maxx, maxy, width, height)

        # Handle value range for float or int types
        if value_range is not None:
            low, high = value_range
            if np.issubdtype(np.dtype(dtype), np.integer):
                data = np.random.randint(low, high + 1, (count, height, width), dtype=dtype)
            else:
                data = np.random.uniform(low, high, (count, height, width)).astype(dtype)
        else:
            if np.issubdtype(np.dtype(dtype), np.integer):
                data = np.random.randint(0, 255, (count, height, width), dtype=dtype)
            else:
                data = np.random.uniform(0.0, 1.0, (count, height, width)).astype(dtype)
        import rasterio
        with rasterio.open(
                output_path,
                'w',
                driver='GTiff',
                height=height,
                width=width,
                count=count,
                dtype=data.dtype,
                crs=crs,
                transform=transform,
        ) as dst:
            dst.write(data)

        return output_path

    def get_band_colormap(self, band_no: int = 1) -> dict:
        """
        Reads the colormap from the specified band of the raster dataset.

        Parameters:
            band_no (int): The band number to read the colormap from. Defaults to 1.

        Returns:
            dict: A dictionary mapping pixel values to RGB(A) tuples.
                  - Keys are integer pixel values (e.g., 0, 1, 2, ...)
                  - Values are tuples of (R, G, B) or (R, G, B, A) where each is in the range 0â€“255
        """
        src = self.get_dataset()  # no context manager here
        try:
            colormap = src.colormap(band_no)
            return colormap if colormap else {}
        except ValueError as e:
            if "NULL color table" in str(e):
                return {}
            else:
                raise

    @staticmethod
    def build_lookup_table(
            pixel_values: list,
            colors: list,
            class_names: list,
            *,
            nodata_value: int | None = None,
            nodata_color: str = "#000000",
            nodata_label: str = "NoData",
    ) -> pd.DataFrame:
        """
        Build a lookup table DataFrame for classified rasters.

        Parameters
        ----------
        pixel_values : list[int]
            List of pixel/class values.
        colors : list[str | tuple]
            List of colors (hex strings like '#ffbb22' or RGB/RGBA tuples).
        class_names : list[str]
            List of class labels.
        nodata_value : int | None, optional
            If provided, prepends a NoData row to the LUT.
        nodata_color : str, optional
            Color for NoData (default black).
        nodata_label : str, optional
            Label for NoData.

        Returns
        -------
        pd.DataFrame
            DataFrame with columns: ['pixel_value', 'color', 'class_name']
        """

        if not (len(pixel_values) == len(colors) == len(class_names)):
            raise ValueError(
                "pixel_values, colors, and class_names must have the same length"
            )

        df = pd.DataFrame({
            "pixel_value": [int(v) for v in pixel_values],
            "color": colors,
            "class_name": class_names,
        })

        # Ensure correct dtypes
        df["pixel_value"] = df["pixel_value"].astype(int)
        df["class_name"] = df["class_name"].astype(str)

        # Optional NoData row (inserted at top)
        if nodata_value is not None:
            nodata_row = pd.DataFrame([{
                "pixel_value": int(nodata_value),
                "color": nodata_color,
                "class_name": nodata_label,
            }])
            df = pd.concat([nodata_row, df], ignore_index=True)

        return df

    from typing import List
    import numpy as np
    import pandas as pd
    import rasterio
    from osgeo import gdal

    def save_with_colormap_and_lookup_table(
            self,
            output_fp: str,
            lookup_df: pd.DataFrame,
            band_no: int = 1,
            class_column: str = "class_name",
            value_column: str = "pixel_value",
            color_column: str = "color",
            nodata_value: int = 0,
            is_hex: bool = True,
            band_names: List[str] = (),
    ):
        """
        Create a new raster (single-band) with a colormap and a Raster Attribute Table (RAT),
        writing entries only for pixel values actually present in the raster data.

        Parameters:
            output_fp (str): Output raster path.
            lookup_df (pd.DataFrame): DataFrame with pixel value, color, and class name.
            band_no (int): Band number to process (default: 1).
            class_column (str): Column with class descriptions.
            value_column (str): Column with pixel values.
            color_column (str): Column with color values (hex or RGB string/tuple).
            nodata_value (int): Value used as NoData in the raster.
            is_hex (bool): Whether the color is given in hex format (e.g. "#ffbb22"). If False, assumes RGB strings or tuples.

        Also writes a band description (band name) if provided.
        """

        gdal.UseExceptions()

        def parse_color(c):
            """Parses a color from hex or RGB string/tuple into an (R, G, B) tuple"""
            if is_hex and isinstance(c, str) and c.startswith("#"):
                c = c.lstrip("#")
                return tuple(int(c[idx:idx + 2], 16) for idx in (0, 2, 4))
            if isinstance(c, str):
                return tuple(map(int, c.strip("() ").split(",")))
            return tuple(int(x) for x in c)

        # ---- Read & prepare raster data and metadata ----
        raster_data = self.get_data_array(band_no).astype("uint8")
        meta = self.get_meta().copy()
        meta.update(dtype="uint8", count=1, nodata=nodata_value)

        # Allowed pixel values from LUT
        allowed_values = set(lookup_df[value_column].astype(int).unique())

        # Replace invalids with NoData
        mask_invalid = ~np.isin(raster_data, list(allowed_values))
        raster_data[mask_invalid] = nodata_value

        present_values = set(np.unique(raster_data)) - {nodata_value}
        lut = lookup_df[lookup_df[value_column].isin(present_values)].copy()

        # Colormap
        colormap = {int(r[value_column]): parse_color(r[color_column]) for _, r in lut.iterrows()}
        if nodata_value not in colormap:
            colormap[nodata_value] = (0, 0, 0)

        # ---- Write raster + colormap using rasterio ----
        band_desc = None
        if band_names and len(band_names) > 0:
            band_desc = str(band_names[0])

        with rasterio.open(output_fp, "w", **meta) as dst:
            dst.write(raster_data, 1)
            dst.write_colormap(1, colormap)

            # Write band description (band name)
            if band_desc:
                dst.set_band_description(1, band_desc)

        # ---- Write RAT with GDAL ----
        ds = gdal.Open(output_fp, gdal.GA_Update)
        if ds is None:
            raise RuntimeError(f"Failed to open {output_fp} with GDAL for RAT writing.")
        band = ds.GetRasterBand(1)

        # Also set description via GDAL (helps some GIS)
        if band_desc:
            try:
                band.SetDescription(band_desc)
            except Exception:
                pass

        # Prepare LUT sorted
        lut_sorted = lut.copy()
        lut_sorted[value_column] = lut_sorted[value_column].astype(int)
        lut_sorted = lut_sorted.sort_values(by=value_column).reset_index(drop=True)

        rat = gdal.RasterAttributeTable()
        rat.CreateColumn("Value", gdal.GFT_Integer, gdal.GFU_Generic)
        rat.CreateColumn("Label", gdal.GFT_String, gdal.GFU_Name)
        rat.CreateColumn("Red", gdal.GFT_Integer, gdal.GFU_Red)
        rat.CreateColumn("Green", gdal.GFT_Integer, gdal.GFU_Green)
        rat.CreateColumn("Blue", gdal.GFT_Integer, gdal.GFU_Blue)
        rat.SetRowCount(len(lut_sorted))

        for i, (_, row) in enumerate(lut_sorted.iterrows()):
            val = int(row[value_column])
            r, g, b = parse_color(row[color_column])
            label = str(row[class_column]) if pd.notnull(row[class_column]) else f"Class {val}"
            rat.SetValueAsInt(i, 0, val)
            rat.SetValueAsString(i, 1, label)
            rat.SetValueAsInt(i, 2, r)
            rat.SetValueAsInt(i, 3, g)
            rat.SetValueAsInt(i, 4, b)

        band.SetDefaultRAT(rat)

        # ---- Category names ----
        max_val = max([nodata_value] + list(present_values)) if present_values else nodata_value
        size = max(max_val + 1, 256)
        cat_names = [""] * size
        if nodata_value < size:
            cat_names[nodata_value] = "NoData"

        for _, row in lut_sorted.iterrows():
            v = int(row[value_column])
            if v < size:
                cat_names[v] = str(row[class_column]) if pd.notnull(row[class_column]) else f"Class {v}"

        try:
            band.SetCategoryNames(cat_names)
        except Exception:
            pass

        ds.FlushCache()
        ds = None  # IMPORTANT: close dataset to persist RAT reliably

    # def save_with_colormap_and_lookup_table(
    #         self,
    #         output_fp: str,
    #         lookup_df: pd.DataFrame,
    #         band_no: int = 1,
    #         class_column: str = "class_name",
    #         value_column: str = "pixel_value",
    #         color_column: str = "color",
    #         nodata_value: int = 0,
    #         is_hex=True
    # ):
    #     """
    #     Create a new raster (single-band) with a colormap and a Raster Attribute Table (RAT),
    #     writing entries only for pixel values actually present in the raster data.
    #
    #     Parameters:
    #         output_fp (str): Output raster path.
    #         lookup_df (pd.DataFrame): DataFrame with pixel value, color, and class name.
    #         band_no (int): Band number to process (default: 1).
    #         class_column (str): Column with class descriptions.
    #         value_column (str): Column with pixel values.
    #         color_column (str): Column with color values (hex or RGB string/tuple).
    #         nodata_value (int): Value used as NoData in the raster.
    #         is_hex (bool): Whether the color is given in hex format (e.g. "#ffbb22"). If False, assumes RGB strings or tuples.
    #     """
    #
    #     # Enable explicit error handling in GDAL
    #     gdal.UseExceptions()
    #
    #     def parse_color(c):
    #         """Parses a color from hex or RGB string/tuple into an (R, G, B) tuple"""
    #         if is_hex and isinstance(c, str) and c.startswith("#"):
    #             c = c.lstrip("#")
    #             return tuple(int(c[idx:idx + 2], 16) for idx in (0, 2, 4))
    #         if isinstance(c, str):
    #             return tuple(map(int, c.strip("() ").split(",")))
    #         return tuple(int(x) for x in c)
    #
    #     # ---- Read & prepare raster data and metadata ----
    #     raster_data = self.get_data_array(band_no).astype("uint8")
    #     meta = self.get_meta().copy()
    #     meta.update(dtype="uint8", count=1, nodata=nodata_value)
    #
    #     # Get the set of allowed pixel values from the lookup table
    #     allowed_values = set(lookup_df[value_column].astype(int).unique())
    #
    #     #
    #     # Replace all values not in lookup with nodata_value
    #     mask_invalid = ~np.isin(raster_data, list(allowed_values))
    #     raster_data[mask_invalid] = nodata_value
    #
    #     # Determine which pixel values are actually present (excluding NoData)
    #     present_values = set(np.unique(raster_data)) - {nodata_value}
    #
    #     # Filter lookup table to only include present values
    #     lut = lookup_df[lookup_df[value_column].isin(present_values)].copy()
    #
    #     # Build colormap dictionary: pixel value â†’ (R, G, B)
    #     colormap = {int(r[value_column]): parse_color(r[color_column]) for _, r in lut.iterrows()}
    #     if nodata_value not in colormap:
    #         colormap[nodata_value] = (0, 0, 0)  # Black for NoData
    #
    #     # ---- Write new raster and colormap using rasterio ----
    #     with rasterio.open(output_fp, "w", **meta) as dst:
    #         dst.write(raster_data, 1)
    #         dst.write_colormap(1, colormap)
    #
    #     # ---- Write Raster Attribute Table (RAT) with GDAL ----
    #     ds = gdal.Open(output_fp, gdal.GA_Update)
    #     if ds is None:
    #         raise RuntimeError(f"Failed to open {output_fp} with GDAL for RAT writing.")
    #     band = ds.GetRasterBand(1)
    #
    #     # Prepare sorted lookup for consistent row ordering
    #     lut_sorted = lut.copy()
    #     lut_sorted[value_column] = lut_sorted[value_column].astype(int)
    #     lut_sorted = lut_sorted.sort_values(by=value_column).reset_index(drop=True)
    #
    #     # Create and populate the Raster Attribute Table (RAT)
    #     rat = gdal.RasterAttributeTable()
    #     rat.CreateColumn("Value", gdal.GFT_Integer, gdal.GFU_Generic)
    #     rat.CreateColumn("Label", gdal.GFT_String, gdal.GFU_Name)
    #     rat.CreateColumn("Red", gdal.GFT_Integer, gdal.GFU_Red)
    #     rat.CreateColumn("Green", gdal.GFT_Integer, gdal.GFU_Green)
    #     rat.CreateColumn("Blue", gdal.GFT_Integer, gdal.GFU_Blue)
    #     rat.SetRowCount(len(lut_sorted))
    #
    #     for i, (_, row) in enumerate(lut_sorted.iterrows()):
    #         val = int(row[value_column])
    #         r, g, b = parse_color(row[color_column])
    #         label = str(row[class_column]) if pd.notnull(row[class_column]) else f"Class {val}"
    #         rat.SetValueAsInt(i, 0, val)
    #         rat.SetValueAsString(i, 1, label)
    #         rat.SetValueAsInt(i, 2, r)
    #         rat.SetValueAsInt(i, 3, g)
    #         rat.SetValueAsInt(i, 4, b)
    #
    #     band.SetDefaultRAT(rat)
    #
    #     # ---- Set category names (for QGIS and similar viewers) ----
    #     max_val = max([nodata_value] + list(present_values)) if present_values else nodata_value
    #     size = max(max_val + 1, 256)
    #     cat_names = [""] * size
    #     if nodata_value < size:
    #         cat_names[nodata_value] = "NoData"
    #
    #     for _, row in lut_sorted.iterrows():
    #         v = int(row[value_column])
    #         if v < size:
    #             cat_names[v] = str(row[class_column]) if pd.notnull(row[class_column]) else f"Class {v}"
    #
    #     try:
    #         band.SetCategoryNames(cat_names)
    #     except Exception:
    #         # Some formats may not support category names; ignore safely
    #         pass
    #
    #     ds.FlushCache()
    #     # ds = None

    def get_band_name(self, band_no: int):
        """
        Get the name of a band. Falls back to 'Band {band_no}' if no name is available.

        :param band_no: The band number (1-based index).
        :return: The band name as a string.
        """
        if self.dataset is None:
            raise ValueError("Dataset is not set.")

        if self.dataset.descriptions and len(self.dataset.descriptions) >= band_no:
            name = self.dataset.descriptions[
                band_no - 1]  # Rasterio is 1-based indexing for bands, but descriptions list is 0-based
            if name and name.strip():
                return name

        return f"Band {band_no}"

    def get_band_summaries(self) -> pd.DataFrame:
        """
        Get summaries of all bands in the dataset.

        :return: A DataFrame containing the summaries.
        """
        summaries = {}
        for i in range(1, self.get_spectral_resolution() + 1):
            band_name = self.get_band_name(i)
            data = self.get_data_array(i)
            no_data = self.get_nodata_value()
            summary = BandProcess.get_summary_data(data, nodata=no_data)
            summaries[band_name] = summary
        return pd.DataFrame(summaries).T

    def resample(
            self,
            target_resolution_m: float,
            resampling: ResampleMethod = "nearest",
            in_place: bool = False
    ) -> 'RioRaster':
        """
        Resample the raster to a new spatial resolution specified in meters.

        This keeps the current CRS and geographic extent, but changes the pixel size
        (and thus the raster width/height). If the CRS is geographic (degrees), the
        target meter resolution is converted to degrees using an approximation at the
        raster's center latitude.

        Args:
            target_resolution_m (float): Desired pixel size in meters (square pixels).
            resampling (str): Resampling method name. Options include:
                "nearest", "bilinear", "cubic", "average", "mode", "max", "min",
                "med", "q1", "q3", "lanczos"
            in_place (bool): If True, replace this object's dataset; otherwise return a new RioRaster.

        Returns:
            RioRaster: The resampled raster (or self if in_place=True).
        """
        src = self.dataset
        if src is None:
            raise ValueError("Raster dataset is empty.")

        from rasterio.warp import reproject, Resampling
        if not hasattr(Resampling, resampling):
            raise ValueError(f"Unsupported resampling '{resampling}'.")
        resampling_enum = getattr(Resampling, resampling)

        src = self.dataset
        crs = CRS.from_user_input(src.crs)
        bounds = src.bounds

        # Current extent in CRS units
        width_crs = bounds.right - bounds.left
        height_crs = bounds.top - bounds.bottom

        # Determine target pixel size in *CRS units*
        if crs.is_geographic:
            # Convert meters -> degrees at center latitude
            center_lat = (bounds.top + bounds.bottom) / 2.0
            meters_per_degree_lon = 111320.0 * math.cos(math.radians(center_lat))
            meters_per_degree_lat = 110540.0  # average
            # Avoid division by zero near the poles
            meters_per_degree_lon = max(meters_per_degree_lon, 1e-6)

            xres_units = target_resolution_m / meters_per_degree_lon
            yres_units = target_resolution_m / meters_per_degree_lat
        else:
            # Projected CRS assumed metric
            xres_units = float(target_resolution_m)
            yres_units = float(target_resolution_m)

        # Compute new raster size
        new_width = max(1, int(math.ceil(width_crs / xres_units)))
        new_height = max(1, int(math.ceil(height_crs / yres_units)))

        # Build new transform from existing bounds
        new_transform = from_bounds(bounds.left, bounds.bottom, bounds.right, bounds.top,
                                    new_width, new_height)

        # Prepare output profile
        out_meta = src.meta.copy()
        out_meta.update({
            "width": new_width,
            "height": new_height,
            "transform": new_transform,
            "crs": src.crs,
        })
        # Keep nodata if present
        if src.nodata is not None:
            out_meta["nodata"] = src.nodata

        memfile = rio.MemoryFile()
        with memfile.open(**out_meta) as dst:
            for i in range(1, src.count + 1):
                reproject(
                    source=rio.band(src, i),
                    destination=rio.band(dst, i),
                    src_transform=src.transform,
                    src_crs=src.crs,
                    dst_transform=new_transform,
                    dst_crs=src.crs,
                    resampling=resampling_enum
                )

            # Preserve band descriptions if available
            descriptions = src.descriptions
            if descriptions:
                for i, desc in enumerate(descriptions):
                    if desc:
                        dst.set_band_description(i + 1, desc)

        new_ds = memfile.open()
        if in_place:
            self.dataset = new_ds
            return self
        else:
            return RioRaster(new_ds)

    from rasterio.transform import rowcol

    def get_pixel_value(
            self,
            x: float,
            y: float,
            band: int = 1,
            default=None
    ):
        """
        Get the pixel value at a given map coordinate (x, y).

        Parameters
        ----------
        x : float
            X coordinate (same CRS as the raster)
        y : float
            Y coordinate (same CRS as the raster)
        band : int, optional
            Raster band to read from (default=1)
        default : any, optional
            Value to return if point is outside raster bounds or nodata.
            If None, nodata value from raster is returned.

        Returns
        -------
        value : number or None
            Pixel value at that location.
        """
        if self.dataset is None:
            raise RuntimeError("Dataset not loaded. Use set_dataset() first.")

        # Convert coordinate â†’ pixel row/col
        try:
            row, col = rowcol(self.dataset.transform, x, y)
        except Exception:
            return default

        # Check bounds
        if row < 0 or col < 0 or row >= self.dataset.height or col >= self.dataset.width:
            return default

        # Read value
        value = self.dataset.read(band)[row, col]

        # Handle nodata
        nodata = self.dataset.nodata
        if nodata is not None and value == nodata:
            return default if default is not None else nodata

        return value

    def make_coincident(
            self, template: "RioRaster", resampling: ResampleMethod = "nearest", in_place: bool = False
    ) -> "RioRaster":
        """
        Reproject/resample this raster so that it matches the grid of a template raster:
        - same CRS
        - same transform
        - same width/height

        Typically used to align rasters for pixel-wise operations.
        """

        from rasterio.warp import reproject, Resampling

        if not hasattr(Resampling, resampling):
            raise ValueError(f"Unsupported resampling '{resampling}'.")
        resampling_enum = getattr(Resampling, resampling)

        src = self.dataset
        if src is None:
            raise ValueError("Raster dataset is empty.")

        tmpl_ds = template.get_dataset()
        dst_crs = tmpl_ds.crs
        dst_transform = tmpl_ds.transform
        dst_width = tmpl_ds.width
        dst_height = tmpl_ds.height

        # Start from source meta, but force grid to match template
        out_meta = src.meta.copy()
        out_meta.update({
            "crs": dst_crs,
            "transform": dst_transform,
            "width": dst_width,
            "height": dst_height,
        })
        if src.nodata is not None:
            out_meta["nodata"] = src.nodata

        memfile = rio.MemoryFile()
        with memfile.open(**out_meta) as dst:
            for i in range(1, src.count + 1):
                reproject(
                    source=rio.band(src, i),
                    destination=rio.band(dst, i),
                    src_transform=src.transform,
                    src_crs=src.crs,
                    dst_transform=dst_transform,
                    dst_crs=dst_crs,
                    resampling=resampling_enum,
                )

            # Preserve band descriptions if available
            descriptions = src.descriptions
            if descriptions:
                for i, desc in enumerate(descriptions):
                    if desc:
                        dst.set_band_description(i + 1, desc)

        new_ds = memfile.open()
        if in_place:
            self.dataset = new_ds
            return self
        else:
            return RioRaster(new_ds)

    def ignore_values(
            self, values: Union[int, float, List[Union[int, float]]],
            band: Optional[int] = None, in_place: bool = False
    ) -> "RioRaster":
        """
        Replace given pixel value(s) with NaN.

        - Converts data to float32 if not already floating.
        - Sets the raster nodata to NaN.
        - Can operate on a single band or all bands.

        Parameters
        ----------
        values : int | float | list
            Single value or list of values to turn into NaN.
        band : int, optional
            1-based band index. If None, apply to all bands.
        in_place : bool
            If True, modifies this RioRaster and returns self.
            Otherwise returns a new RioRaster.

        Returns
        -------
        RioRaster
            Raster with specified values set to NaN.
        """
        if self.dataset is None:
            raise ValueError("Raster dataset is empty.")

        # Normalize values to a 1D numpy array
        if np.isscalar(values):
            values = [values]
        values = np.array(values)

        # Read data
        if band is None:
            data = self.get_data_array()  # shape: (bands, rows, cols) or (rows, cols)
        else:
            data = self.get_data_array(band)  # shape: (rows, cols)

        # Ensure we always have a 3D array for uniform handling
        squeeze_back = False
        if data.ndim == 2:
            data = data[np.newaxis, ...]  # (1, rows, cols)
            squeeze_back = True

        # Cast to float32 so we can safely assign np.nan
        if not np.issubdtype(data.dtype, np.floating):
            data = data.astype("float32", copy=False)

        # Build mask for any of the given values
        # (np.isin works elementwise on the array)
        mask = np.isin(data, values)
        data[mask] = np.nan

        # If we originally had a single band, drop back to 2D
        if squeeze_back:
            data = data[0, :, :]

        # Create a new raster with nodata = np.nan
        new_raster = self.raster_from_array(
            img_arr=data,
            crs=self.get_crs(),
            g_transform=self.get_geo_transform(),
            nodata_value=np.nan,
        )

        # Preserve band descriptions if possible
        if new_raster is not None and self.dataset is not None:
            desc = self.dataset.descriptions
            if desc and any(desc):
                ds = new_raster.get_dataset()
                for i, d in enumerate(desc):
                    if d:
                        ds.set_band_description(i + 1, d)

        if in_place and new_raster is not None:
            # Optionally close old dataset if you want to free resources
            # self.close()
            self.dataset = new_raster.dataset
            return self

        return new_raster

    def get_unique_colors(
            self,
            ignore_transparent: bool = True,
            alpha_band_index: int = 3
    ) -> pd.DataFrame:
        """
        Return all unique RGB colors in the raster (across all pixels),
        with their occurrence counts.

        - Works for 3-band (RGB) or 4-band (RGBA) rasters.
        - For 4-band rasters, alpha is used only optionally to filter
          fully transparent pixels, then dropped before uniqueness.

        Parameters
        ----------
        ignore_transparent : bool
            If True and 4-band raster, drop pixels where alpha == 0.
        alpha_band_index : int
            Zero-based index of alpha band in the array (default: 3 -> RGBA).

        Returns
        -------
        pandas.DataFrame
            Columns:
                - R, G, B
                - count
        """
        if self.dataset is None:
            raise ValueError("Raster dataset is empty.")

        data = self.get_data_array()  # (bands, rows, cols)
        if data.ndim != 3:
            raise ValueError(f"Expected 3D array (bands, rows, cols), got shape {data.shape}")

        bands, rows, cols = data.shape
        if bands not in (3, 4):
            raise ValueError(f"Expected 3 or 4 bands (RGB/RGBA), got {bands}")

        # (rows, cols, bands)
        pixels = np.moveaxis(data, 0, -1).reshape(-1, bands)

        if bands == 4:
            # Optionally drop fully transparent pixels
            if ignore_transparent:
                alpha = pixels[:, alpha_band_index]
                pixels = pixels[alpha != 0]

            # Now drop alpha completely: only keep RGB
            rgb_pixels = np.delete(pixels, alpha_band_index, axis=1)  # shape: (N, 3)
        else:
            rgb_pixels = pixels  # already RGB

        unique_colors, counts = np.unique(rgb_pixels, axis=0, return_counts=True)

        df = pd.DataFrame(unique_colors, columns=["R", "G", "B"])
        df["count"] = counts
        return df

    def close(self):
        if self.dataset:
            self.dataset.close()
