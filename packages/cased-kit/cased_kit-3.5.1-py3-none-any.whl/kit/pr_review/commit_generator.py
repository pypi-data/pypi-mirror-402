"""Commit message generator implementation with repository intelligence and LLM analysis."""

import asyncio
import subprocess
from typing import Any, Dict, List

from kit import Repository
from kit.llm_client_factory import create_client_from_review_config

from .config import LLMProvider, ReviewConfig
from .cost_tracker import CostTracker


class CommitMessageGenerator:
    """Generate intelligent commit messages using repository context and LLM analysis."""

    def __init__(self, config: ReviewConfig):
        self.config = config
        self.cost_tracker = CostTracker(config.custom_pricing)
        self._llm_client: Any = None

    def get_staged_diff(self) -> str:
        """Get the diff of staged changes."""
        try:
            result = subprocess.run(
                ["git", "diff", "--cached"], capture_output=True, text=True, encoding="utf-8", check=True
            )
            return result.stdout
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Failed to get staged diff: {e}")

    def get_staged_files(self) -> List[str]:
        """Get list of staged files."""
        try:
            result = subprocess.run(
                ["git", "diff", "--cached", "--name-only"], capture_output=True, text=True, encoding="utf-8", check=True
            )
            return [f.strip() for f in result.stdout.splitlines() if f.strip()]
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Failed to get staged files: {e}")

    def check_staged_changes(self) -> bool:
        """Check if there are any staged changes."""
        staged_files = self.get_staged_files()
        return len(staged_files) > 0

    async def analyze_changes_for_commit(self, repo_path: str) -> str:
        """Analyze staged changes using repository intelligence to generate commit message."""
        repo = Repository(repo_path)

        # Get staged changes
        diff = self.get_staged_diff()
        staged_files = self.get_staged_files()

        if not diff.strip():
            return "No staged changes to commit"

        # Analyze changed files with repository context
        file_analysis: Dict[str, Dict[str, Any]] = {}
        change_types = set()

        for file_path in staged_files:
            try:
                # Get symbols from the file
                file_symbols = repo.extract_symbols(file_path)

                # Determine change type based on file extension and content
                if file_path.endswith((".py", ".js", ".ts", ".java", ".cpp", ".c", ".go", ".rs")):
                    change_types.add("code")
                elif file_path.endswith((".md", ".txt", ".rst")):
                    change_types.add("docs")
                elif file_path.endswith((".yaml", ".yml", ".json", ".toml", ".ini")):
                    change_types.add("config")
                elif file_path.endswith((".test.py", ".spec.js", ".test.ts")):
                    change_types.add("test")

                file_analysis[file_path] = {
                    "symbols": file_symbols[:3],  # Top 3 symbols
                    "symbol_count": len(file_symbols),
                }

            except Exception:
                file_analysis[file_path] = {"symbols": [], "symbol_count": 0}

        # Create commit message generation prompt
        commit_prompt = f"""You are an expert developer writing a concise, clear commit message.

**Changes Overview:**
- Files changed: {len(staged_files)}
- Change types: {", ".join(change_types) if change_types else "general"}

**File Analysis:**"""

        # Limit to 5 files and ensure proper typing
        file_items = list(file_analysis.items())[:5]
        for file_path, analysis in file_items:
            commit_prompt += f"""
- {file_path}: {analysis["symbol_count"]} symbols"""
            if analysis["symbols"]:
                symbol_names = [s["name"] for s in analysis["symbols"]]
                commit_prompt += f" ({', '.join(symbol_names)})"

        commit_prompt += f"""

**Diff (first 2000 chars):**
```diff
{diff[:2000]}{"..." if len(diff) > 2000 else ""}
```

**Generate a commit message following these guidelines:**
1. First line: concise summary (50 chars max, no period)
2. If needed, add a blank line then detailed explanation
3. Use imperative mood ("Add feature" not "Added feature")
4. Focus on WHY and WHAT, not HOW
5. Use conventional commit prefixes when appropriate (feat:, fix:, docs:, refactor:, test:)

**Examples of good commit messages:**
- feat: add user authentication with JWT tokens
- fix: resolve memory leak in data processing pipeline
- docs: update API documentation for v2 endpoints
- refactor: extract validation logic into separate module
- test: add integration tests for payment flow

Generate only the commit message, nothing else."""

        # Use LLM to generate commit message
        if self.config.llm.provider == LLMProvider.ANTHROPIC:
            message = await self._generate_with_anthropic(commit_prompt)
        elif self.config.llm.provider == LLMProvider.GOOGLE:
            message = await self._generate_with_google(commit_prompt)
        elif self.config.llm.provider == LLMProvider.OLLAMA:
            message = await self._generate_with_ollama(commit_prompt)
        else:
            message = await self._generate_with_openai(commit_prompt)

        return message.strip()

    async def _generate_with_anthropic(self, prompt: str) -> str:
        """Generate commit message using Anthropic Claude."""
        if not self._llm_client:
            self._llm_client = create_client_from_review_config(self.config.llm)

        try:
            response = self._llm_client.messages.create(
                model=self.config.llm.model,
                max_tokens=200,  # Short for commit messages
                # Temperature removed for better model compatibility
                messages=[{"role": "user", "content": prompt}],
            )

            # Track cost
            input_tokens, output_tokens = self.cost_tracker.extract_anthropic_usage(response)
            self.cost_tracker.track_llm_usage(
                self.config.llm.provider, self.config.llm.model, input_tokens, output_tokens
            )

            # Extract text from the response content
            text_content = ""
            for content_block in response.content:
                if hasattr(content_block, "text"):
                    text_content += content_block.text

            return text_content if text_content else "Update files"

        except Exception as e:
            return f"Update files (error: {e})"

    async def _generate_with_google(self, prompt: str) -> str:
        """Generate commit message using Google Gemini."""
        try:
            from google.genai import types
        except ImportError:
            raise RuntimeError("google-genai package not installed. Run: pip install google-genai")

        if not self._llm_client:
            self._llm_client = create_client_from_review_config(self.config.llm)

        try:
            response = self._llm_client.models.generate_content(
                model=self.config.llm.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    max_output_tokens=200,
                ),
            )

            # Track cost
            if hasattr(response, "usage_metadata") and response.usage_metadata:
                input_tokens = getattr(response.usage_metadata, "prompt_token_count", 0)
                output_tokens = getattr(response.usage_metadata, "candidates_token_count", 0)
                self.cost_tracker.track_llm_usage(
                    self.config.llm.provider, self.config.llm.model, input_tokens, output_tokens
                )

            result_text = response.text
            return result_text if result_text is not None else "Update files"

        except Exception as e:
            return f"Update files (error: {e})"

    async def _generate_with_openai(self, prompt: str) -> str:
        """Generate commit message using OpenAI GPT."""
        if not self._llm_client:
            self._llm_client = create_client_from_review_config(self.config.llm)

        try:
            # GPT-5 models use max_completion_tokens instead of max_tokens
            completion_params: Dict[str, Any] = {
                "model": self.config.llm.model,
                "messages": [{"role": "user", "content": prompt}],
            }
            if "gpt-5" in self.config.llm.model.lower():
                completion_params["max_completion_tokens"] = 200
            else:
                completion_params["max_tokens"] = 200

            response = self._llm_client.chat.completions.create(**completion_params)

            # Track cost
            input_tokens, output_tokens = self.cost_tracker.extract_openai_usage(response)
            self.cost_tracker.track_llm_usage(
                self.config.llm.provider, self.config.llm.model, input_tokens, output_tokens
            )

            content = response.choices[0].message.content
            return content if content is not None else "Update files"

        except Exception as e:
            return f"Update files (error: {e})"

    async def _generate_with_ollama(self, prompt: str) -> str:
        """Generate commit message using Ollama."""
        if not self._llm_client:
            self._llm_client = create_client_from_review_config(self.config.llm)

        try:
            response = await asyncio.to_thread(
                self._llm_client.generate,
                prompt,
                num_predict=200,
            )

            # Track usage (free but good for statistics)
            estimated_input_tokens = len(prompt) // 4
            estimated_output_tokens = len(response) // 4
            self.cost_tracker.track_llm_usage(
                self.config.llm.provider, self.config.llm.model, estimated_input_tokens, estimated_output_tokens
            )

            return response if response else "Update files"

        except Exception as e:
            return f"Update files (error: {e})"

    def commit_with_message(self, message: str) -> None:
        """Execute git commit with the generated message."""
        try:
            subprocess.run(
                ["git", "commit", "-m", message], check=True, capture_output=True, text=True, encoding="utf-8"
            )
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Failed to commit: {e.stderr}")

    def generate_and_commit(self, repo_path: str = ".") -> str:
        """Generate commit message and commit changes in one step."""
        try:
            # Check for staged changes
            if not self.check_staged_changes():
                return "âŒ No staged changes to commit. Use 'git add <files>' to stage changes."

            quiet = getattr(self.config, "quiet", False)

            if not quiet:
                print("ğŸ” Analyzing staged changes...")

            # Generate commit message
            message = asyncio.run(self.analyze_changes_for_commit(repo_path))

            if not quiet:
                print(f"ğŸ’­ Generated message: {message}")
                print("ğŸ“ Committing changes...")

            # Commit with generated message
            self.commit_with_message(message)

            # Show cost if not quiet
            if not quiet:
                total_cost = self.cost_tracker.get_total_cost()
                if total_cost > 0:
                    print(f"ğŸ’° Cost: ${total_cost:.4f}")

            return f"âœ… Committed with message: {message}"

        except Exception as e:
            return f"âŒ Commit failed: {e}"
