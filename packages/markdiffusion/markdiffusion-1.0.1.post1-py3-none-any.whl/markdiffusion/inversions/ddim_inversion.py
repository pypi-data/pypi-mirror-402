from functools import partial
import torch
from typing import Optional, Callable
from tqdm import tqdm
from .base_inversion import BaseInversion
import warnings

class DDIMInversion(BaseInversion):
    def __init__(self,
                 scheduler,
                 unet,
                 device,
                 ):
        super(DDIMInversion, self).__init__(scheduler, unet, device)
        self.forward_diffusion = partial(self.backward_diffusion, reverse_process=True)
    
    def _backward_ddim(self, x_t, alpha_t, alpha_tm1, eps_xt):
        """ from noise to image"""
        return (
            alpha_tm1**0.5
            * (
                (alpha_t**-0.5 - alpha_tm1**-0.5) * x_t
                + ((1 / alpha_tm1 - 1) ** 0.5 - (1 / alpha_t - 1) ** 0.5) * eps_xt
            )
            + x_t
        )    
    
    @torch.inference_mode()
    def backward_diffusion(
        self,
        use_old_emb_i=25,
        text_embeddings=None,
        old_text_embeddings=None,
        new_text_embeddings=None,
        latents: Optional[torch.FloatTensor] = None,
        num_inference_steps: int = 50,
        guidance_scale: float = 7.5,
        callback: Optional[Callable[[int, int, torch.FloatTensor], None]] = None,
        callback_steps: Optional[int] = 1,
        reverse_process: True = False,
        **kwargs,
    ):
        """ Generate image from text prompt and latents
        """
        ## If kwargs has inv_order, warn that it is ignored for DDIM Inversion
        if "inv_order" in kwargs:
            warnings.warn("inv_order is ignored for DDIM Inversion")
        if "inverse_opt" in kwargs:
            warnings.warn("inverse_opt is ignored for DDIM Inversion")
        
        # Keep a list of inverted latents as the process goes on
        intermediate_latents = []
        # here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)
        # of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`
        # corresponds to doing no classifier free guidance.
        do_classifier_free_guidance = guidance_scale > 1.0
        # set timesteps
        self.scheduler.set_timesteps(num_inference_steps)
        # Some schedulers like PNDM have timesteps as arrays
        # It's more optimized to move all timesteps to correct device beforehand
        timesteps_tensor = self.scheduler.timesteps.to(self.device)
        # scale the initial noise by the standard deviation required by the scheduler
        latents = latents * self.scheduler.init_noise_sigma

        if old_text_embeddings is not None and new_text_embeddings is not None:
            prompt_to_prompt = True
        else:
            prompt_to_prompt = False


        for i, t in enumerate(tqdm(timesteps_tensor if not reverse_process else reversed(timesteps_tensor))):
            if prompt_to_prompt:
                if i < use_old_emb_i:
                    text_embeddings = old_text_embeddings
                else:
                    text_embeddings = new_text_embeddings

            # expand the latents if we are doing classifier free guidance
            # latent_model_input = (
            #     torch.cat([latents] * 2) if do_classifier_free_guidance else latents
            # )
            latent_model_input, info = self._prepare_latent_for_unet(latents, do_classifier_free_guidance, self.unet)
            latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)
            
            # predict the noise residual
            noise_pred_raw = self.unet(
                latent_model_input, t, encoder_hidden_states=text_embeddings
            ).sample
            
            # reshape back if needed
            noise_pred = self._restore_latent_from_unet(noise_pred_raw, info, guidance_scale)

            # # perform guidance
            # noise_pred = self._apply_guidance_scale(noise_pred, guidance_scale)

            prev_timestep = (
                t
                - self.scheduler.config.num_train_timesteps
                // self.scheduler.num_inference_steps
            )
            # call the callback, if provided
            if callback is not None and i % callback_steps == 0:
                callback(i, t, latents)
            
            # ddim 
            alpha_prod_t = self.scheduler.alphas_cumprod[t]
            alpha_prod_t_prev = (
                self.scheduler.alphas_cumprod[prev_timestep]
                if prev_timestep >= 0
                else self.scheduler.final_alpha_cumprod
            )
            if reverse_process:
                alpha_prod_t, alpha_prod_t_prev = alpha_prod_t_prev, alpha_prod_t
            latents = self._backward_ddim(
                x_t=latents,
                alpha_t=alpha_prod_t,
                alpha_tm1=alpha_prod_t_prev,
                eps_xt=noise_pred,
            )
            # Save intermediate latents
            intermediate_latents.append(latents.clone())
        return intermediate_latents