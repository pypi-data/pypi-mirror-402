# coding: utf-8

"""
    Antimatter Security Lakehouse Public API

    Interact with the Antimatter ASL API.

    The version of the OpenAPI document: 0.0.1
    Contact: support@antimatter.io
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class DbuiV1DataSourceInferenceResult(BaseModel):
    """
    DbuiV1DataSourceInferenceResult
    """ # noqa: E501
    format: Optional[StrictStr] = Field(default=None, description="The inferred format of the data in the external location (e.g., parquet, json, jsonl, csv, etc.)")
    source: Optional[StrictStr] = Field(default=None, description="The detected data provider or origin vendor (e.g., \"aws\", \"onelogin\", \"akamai\")")
    source_type: Optional[StrictStr] = Field(default=None, description="The detected product, service, or log type from the vendor (e.g., \"route53\", \"cloudtrail\", \"waf\")", alias="sourceType")
    bronze_table_name: Optional[StrictStr] = Field(default=None, description="The inferred bronze table name. Typically this is equal to source_sourceType", alias="bronzeTableName")
    time_column_path: Optional[List[StrictStr]] = Field(default=None, description="The path segments to the time column in normalized form. Structure: [columnName, ...variantPath] - First element: Column name (always present) - Remaining elements: Variant/nested path segments (if any) Examples: - JSON format with nested time: [\"data\", \"metadata\", \"timestamp\"] - Text/wholetext format: [\"value\", \"timestamp\"] (value is the column name for text files) ", alias="timeColumnPath")
    time_column_expression: Optional[StrictStr] = Field(default=None, description="SQL expression to extract and convert the time column. Only returned if conversion/transformation is needed (e.g., \"timestamp_seconds(data:time_field :: INT)\" for unix timestamps). The timeColumnExpression can be used directly as a bronze pre-transform on a DataSource spec. If this field is null and timeColumnPath is provided, the time column can be accessed directly using the path. ", alias="timeColumnExpression")
    primary_key_paths: Optional[List[List[StrictStr]]] = Field(default=None, description="Array of path segments for each primary key field that together uniquely identify each record. Structure: [columnName, ...variantPath] - First element: Column name (always present) - Remaining elements: Variant/nested path segments (if any) Examples: - JSON with multiple nested keys: [[\"data\", \"user\", \"id\"], [\"data\", \"event\", \"id\"]] - Parquet with nested struct: [[\"id\"], [\"metadata\", \"account_id\"]] ", alias="primaryKeyPaths")
    primary_key_expressions: Optional[List[StrictStr]] = Field(default=None, description="SQL expressions to extract each primary key field, corresponding to primaryKeyPaths. These are deterministically generated based on column types (e.g., \"`id`\" for top-level, \"data:account:id\" for nested VARIANT fields). ", alias="primaryKeyExpressions")
    presets: Optional[List[StrictStr]] = Field(default=None, description="Array of potential preset names ordered by relevance / confidence in descending order. ")
    pre_transforms: Optional[List[List[StrictStr]]] = Field(default=None, description="List of potential pretransforms (SQL expressions) that will be used as bronze.preTransforms. For specific details refer to the bronze.preTransforms description of Datasource resource. ", alias="preTransforms")
    format_options: Optional[Dict[str, StrictStr]] = Field(default=None, description="Optional format-specific options that were inferred during analysis. For XML format, includes the inferred 'rowtag' that specifies which XML element maps to a row. For other formats, this field will be null. ", alias="formatOptions")
    single_variant: Optional[StrictBool] = Field(default=None, description="If true, indicates that the data should be loaded as a single variant column. ", alias="singleVariant")
    schema_hints: Optional[StrictStr] = Field(default=None, description="Inferred schema hints for the analyzed data. This will only be populated when the data is not marked as single variant. ", alias="schemaHints")
    error: Optional[StrictStr] = Field(default=None, description="An error encountered during DataSource inference. ")
    __properties: ClassVar[List[str]] = ["format", "source", "sourceType", "bronzeTableName", "timeColumnPath", "timeColumnExpression", "primaryKeyPaths", "primaryKeyExpressions", "presets", "preTransforms", "formatOptions", "singleVariant", "schemaHints", "error"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DbuiV1DataSourceInferenceResult from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # set to None if format (nullable) is None
        # and model_fields_set contains the field
        if self.format is None and "format" in self.model_fields_set:
            _dict['format'] = None

        # set to None if source (nullable) is None
        # and model_fields_set contains the field
        if self.source is None and "source" in self.model_fields_set:
            _dict['source'] = None

        # set to None if source_type (nullable) is None
        # and model_fields_set contains the field
        if self.source_type is None and "source_type" in self.model_fields_set:
            _dict['sourceType'] = None

        # set to None if bronze_table_name (nullable) is None
        # and model_fields_set contains the field
        if self.bronze_table_name is None and "bronze_table_name" in self.model_fields_set:
            _dict['bronzeTableName'] = None

        # set to None if time_column_path (nullable) is None
        # and model_fields_set contains the field
        if self.time_column_path is None and "time_column_path" in self.model_fields_set:
            _dict['timeColumnPath'] = None

        # set to None if time_column_expression (nullable) is None
        # and model_fields_set contains the field
        if self.time_column_expression is None and "time_column_expression" in self.model_fields_set:
            _dict['timeColumnExpression'] = None

        # set to None if primary_key_paths (nullable) is None
        # and model_fields_set contains the field
        if self.primary_key_paths is None and "primary_key_paths" in self.model_fields_set:
            _dict['primaryKeyPaths'] = None

        # set to None if primary_key_expressions (nullable) is None
        # and model_fields_set contains the field
        if self.primary_key_expressions is None and "primary_key_expressions" in self.model_fields_set:
            _dict['primaryKeyExpressions'] = None

        # set to None if presets (nullable) is None
        # and model_fields_set contains the field
        if self.presets is None and "presets" in self.model_fields_set:
            _dict['presets'] = None

        # set to None if pre_transforms (nullable) is None
        # and model_fields_set contains the field
        if self.pre_transforms is None and "pre_transforms" in self.model_fields_set:
            _dict['preTransforms'] = None

        # set to None if format_options (nullable) is None
        # and model_fields_set contains the field
        if self.format_options is None and "format_options" in self.model_fields_set:
            _dict['formatOptions'] = None

        # set to None if single_variant (nullable) is None
        # and model_fields_set contains the field
        if self.single_variant is None and "single_variant" in self.model_fields_set:
            _dict['singleVariant'] = None

        # set to None if schema_hints (nullable) is None
        # and model_fields_set contains the field
        if self.schema_hints is None and "schema_hints" in self.model_fields_set:
            _dict['schemaHints'] = None

        # set to None if error (nullable) is None
        # and model_fields_set contains the field
        if self.error is None and "error" in self.model_fields_set:
            _dict['error'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DbuiV1DataSourceInferenceResult from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "format": obj.get("format"),
            "source": obj.get("source"),
            "sourceType": obj.get("sourceType"),
            "bronzeTableName": obj.get("bronzeTableName"),
            "timeColumnPath": obj.get("timeColumnPath"),
            "timeColumnExpression": obj.get("timeColumnExpression"),
            "primaryKeyPaths": obj.get("primaryKeyPaths"),
            "primaryKeyExpressions": obj.get("primaryKeyExpressions"),
            "presets": obj.get("presets"),
            "preTransforms": obj.get("preTransforms"),
            "formatOptions": obj.get("formatOptions"),
            "singleVariant": obj.get("singleVariant"),
            "schemaHints": obj.get("schemaHints"),
            "error": obj.get("error")
        })
        return _obj


