import tiktoken
from typing import Dict, List, Optional, Any
from langfuse import Langfuse, LangfuseSpan, propagate_attributes
from sycommon.llm.llm_logger import LLMLogger
from langchain_core.runnables import Runnable, RunnableConfig
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage
from sycommon.llm.llm_tokens import TokensCallbackHandler
from sycommon.logging.kafka_log import SYLogger
from sycommon.config.LLMConfig import LLMConfig
from sycommon.tools.env import get_env_var
from sycommon.tools.merge_headers import get_header_value


class StructuredRunnableWithToken(Runnable):
    """
    ç»Ÿä¸€åŠŸèƒ½ Runnableï¼šTraceè¿½è¸ª + Tokenç»Ÿè®¡ + è‡ªåŠ¨ä¸Šä¸‹æ–‡å‹ç¼©
    """

    def __init__(
        self,
        retry_chain: Runnable,
        langfuse: Optional[Langfuse] = None,
        llmConfig: Optional[LLMConfig] = None,
        summary_prompt: Optional[str] = None,
        model_name: str = "Qwen2.5-72B",
        enable_compression: bool = True,
        threshold_ratio: float = 0.8
    ):
        super().__init__()
        self.retry_chain = retry_chain
        self.langfuse = langfuse
        self.llmConfig = llmConfig
        self.summary_prompt = summary_prompt
        self.model_name = model_name
        self.enable_compression = enable_compression
        self.threshold_ratio = threshold_ratio

        # åˆå§‹åŒ– Tokenizer
        try:
            self.encoding = tiktoken.encoding_for_model(model_name)
        except KeyError:
            self.encoding = tiktoken.get_encoding("cl100k_base")

    def _count_tokens(self, messages: List[BaseMessage]) -> int:
        """å¿«é€Ÿä¼°ç®— Token æ•°é‡"""
        num_tokens = 0
        for message in messages:
            num_tokens += 4  # æ¯æ¡æ¶ˆæ¯çš„å›ºå®šå¼€é”€
            # å…¼å®¹ content æ˜¯å­—ç¬¦ä¸²æˆ–è€… dict çš„æƒ…å†µ
            content = message.content
            if isinstance(content, str):
                num_tokens += len(self.encoding.encode(content))
            elif isinstance(content, list):  # å¤šæ¨¡æ€æˆ–å¤æ‚ç»“æ„
                for item in content:
                    if isinstance(item, dict) and "text" in item:
                        num_tokens += len(self.encoding.encode(item["text"]))
            elif isinstance(content, dict):
                num_tokens += len(self.encoding.encode(str(content)))
        return num_tokens

    async def _acompress_context(self, messages: List[BaseMessage]) -> List[BaseMessage]:
        """æ‰§è¡Œå¼‚æ­¥ä¸Šä¸‹æ–‡å‹ç¼©"""
        # ç­–ç•¥ï¼šä¿ç•™ System Prompt + æœ€è¿‘ N æ¡ï¼Œä¸­é—´çš„æ‘˜è¦
        keep_last_n = 1

        # åˆ†ç¦»ç³»ç»Ÿæ¶ˆæ¯å’Œå¯¹è¯æ¶ˆæ¯
        system_msgs = [m for m in messages if isinstance(m, SystemMessage)]
        conversation = [
            m for m in messages if not isinstance(m, SystemMessage)]

        if len(conversation) <= keep_last_n:
            return messages

        to_summarize = conversation[:-keep_last_n]
        keep_recent = conversation[-keep_last_n:]

        # æ„é€ æ‘˜è¦ Prompt
        # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥ä½¿ç”¨ retry_chain è¿›è¡Œæ‘˜è¦ï¼Œé˜²æ­¢æ­»å¾ªç¯
        summary_content = self.summary_prompt or "è¯·å°†ä¸Šä¸‹æ–‡å†…å®¹è¿›è¡Œæ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ï¼Œå°†å†…å®¹å‹ç¼©åˆ°åŸæ¥é•¿åº¦çš„50%å·¦å³ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€‚"
        summary_prompt = [
            SystemMessage(content=summary_content),
            HumanMessage(content=f"å†å²è®°å½•:\n{to_summarize}\n\næ‘˜è¦:")
        ]

        try:
            SYLogger.info(
                f"ğŸš€ Triggering compression: {len(to_summarize)} messages -> summary")

            # è°ƒç”¨å­é“¾ç”Ÿæˆæ‘˜è¦
            # ã€å…³é”®ã€‘å¿…é¡»æ¸…ç©º callbacksï¼Œå¦åˆ™ Langfuse ä¼šé€’å½’è¿½è¸ªï¼Œå¯¼è‡´æ­»å¾ªç¯æˆ–å™ªéŸ³
            summary_result = await self.retry_chain.ainvoke(
                {"messages": summary_prompt},
                config=RunnableConfig(callbacks=[])
            )

            summary_text = summary_result.content if hasattr(
                summary_result, 'content') else str(summary_result)

            # é‡ç»„æ¶ˆæ¯ï¼šSystem + Summary + Recent
            new_messages = system_msgs + \
                [SystemMessage(
                    content=f"[History Summary]: {summary_text}")] + keep_recent
            return new_messages

        except Exception as e:
            SYLogger.error(
                f"âŒ Compression failed: {e}, using original context.")
            return messages

    def _adapt_input(self, input: Any) -> List[BaseMessage]:
        """é€‚é…è¾“å…¥æ ¼å¼"""
        if isinstance(input, list) and all(isinstance(x, BaseMessage) for x in input):
            return input
        elif isinstance(input, BaseMessage):
            return [input]
        elif isinstance(input, str):
            return [HumanMessage(content=input)]
        elif isinstance(input, dict) and "messages" in input:
            # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼å­—å…¸ï¼Œç›´æ¥æå–
            msgs = input["messages"]
            return msgs if isinstance(msgs, list) else [msgs]
        elif isinstance(input, dict) and "input" in input:
            return [HumanMessage(content=str(input["input"]))]
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥æ ¼å¼ï¼š{type(input)}")

    def _get_callback_config(
        self,
        config: Optional[RunnableConfig] = None,
        trace_id: Optional[str] = None,
        user_id: Optional[str] = None
    ) -> tuple[RunnableConfig, TokensCallbackHandler]:
        """æ„å»ºåŒ…å«Tokenç»Ÿè®¡å’Œmetadataçš„å›è°ƒé…ç½®"""
        token_handler = TokensCallbackHandler()

        if config is None:
            processed_config = RunnableConfig(callbacks=[], metadata={})
        else:
            processed_config = config.copy()
            if "callbacks" not in processed_config:
                processed_config["callbacks"] = []
            if "metadata" not in processed_config:
                processed_config["metadata"] = {}

        # æ·»åŠ  Langfuse metadata
        if trace_id:
            processed_config["metadata"]["langfuse_session_id"] = trace_id
        if user_id:
            processed_config["metadata"]["langfuse_user_id"] = user_id

        callbacks = processed_config["callbacks"]
        if not any(isinstance(cb, LLMLogger) for cb in callbacks):
            callbacks.append(LLMLogger())
        callbacks.append(token_handler)

        # å»é‡
        callback_types = {}
        unique_callbacks = []
        for cb in callbacks:
            cb_type = type(cb)
            if cb_type not in callback_types:
                callback_types[cb_type] = cb
                unique_callbacks.append(cb)

        processed_config["callbacks"] = unique_callbacks

        return processed_config, token_handler

    def invoke(self, input: Any, config: Optional[RunnableConfig] = None, **kwargs) -> Dict[str, Any]:
        # è·å– trace_id å’Œ user_id
        trace_id = SYLogger.get_trace_id()
        userid = get_header_value(SYLogger.get_headers(), "x-userid-header")
        syVersion = get_header_value(SYLogger.get_headers(), "s-y-version")
        user_id = userid or syVersion or get_env_var('VERSION')

        # åˆ¤æ–­æ˜¯å¦å¯ç”¨ Langfuse
        if self.langfuse:
            try:
                with self.langfuse.start_as_current_observation(as_type="span", name="invoke") as span:
                    with propagate_attributes(session_id=trace_id, user_id=user_id):
                        span.update_trace(user_id=user_id, session_id=trace_id)
                        return self._execute_chain(input, config, trace_id, user_id, span)
            except Exception as e:
                # Langfuse è·Ÿè¸ªå¤±è´¥ä¸åº”é˜»æ–­ä¸šåŠ¡ï¼Œé™çº§æ‰§è¡Œ
                SYLogger.error(f"Langfuse åŒæ­¥è·Ÿè¸ªå¤±è´¥: {str(e)}", exc_info=True)
                return self._execute_chain(input, config, trace_id, user_id, None)
        else:
            # æœªå¯ç”¨ Langfuseï¼Œç›´æ¥æ‰§è¡Œä¸šåŠ¡é€»è¾‘
            return self._execute_chain(input, config, trace_id, user_id, None)

    async def ainvoke(self, input: Any, config: Optional[RunnableConfig] = None, **kwargs) -> Dict[str, Any]:
        # è·å– trace_id å’Œ user_id
        trace_id = SYLogger.get_trace_id()
        userid = get_header_value(SYLogger.get_headers(), "x-userid-header")
        syVersion = get_header_value(SYLogger.get_headers(), "s-y-version")
        user_id = userid or syVersion or get_env_var('VERSION')

        # åˆ¤æ–­æ˜¯å¦å¯ç”¨ Langfuse
        if self.langfuse:
            try:
                with self.langfuse.start_as_current_observation(as_type="span", name="ainvoke") as span:
                    with propagate_attributes(session_id=trace_id, user_id=user_id):
                        span.update_trace(user_id=user_id, session_id=trace_id)
                        return await self._aexecute_chain(input, config, trace_id, user_id, span)
            except Exception as e:
                # Langfuse è·Ÿè¸ªå¤±è´¥ä¸åº”é˜»æ–­ä¸šåŠ¡ï¼Œé™çº§æ‰§è¡Œ
                SYLogger.error(f"Langfuse å¼‚æ­¥è·Ÿè¸ªå¤±è´¥: {str(e)}", exc_info=True)
                return await self._aexecute_chain(input, config, trace_id, user_id, None)
        else:
            # æœªå¯ç”¨ Langfuseï¼Œç›´æ¥æ‰§è¡Œä¸šåŠ¡é€»è¾‘
            return await self._aexecute_chain(input, config, trace_id, user_id, None)

    def _execute_chain(
        self,
        input: Any,
        config: Optional[RunnableConfig],
        trace_id: str,
        user_id: str,
        span: LangfuseSpan
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®é™…çš„è°ƒç”¨é€»è¾‘ (åŒæ­¥)"""
        try:
            processed_config, token_handler = self._get_callback_config(
                config,
                trace_id=trace_id,
                user_id=user_id
            )

            # ã€åŒæ­¥æ¨¡å¼ä¸‹ä¸å»ºè®®è§¦å‘å‹ç¼©ï¼Œå› ä¸ºå‹ç¼©æœ¬èº«æ˜¯å¼‚æ­¥è°ƒç”¨ LLMã€‘
            # å¦‚æœåŒæ­¥ä¹Ÿè¦å‹ç¼©ï¼Œéœ€è¦ç”¨ asyncio.run(...)ï¼Œè¿™é‡Œæš‚æ—¶ä¿æŒåŸé€»è¾‘ç›´æ¥é€ä¼ 
            adapted_input = self._adapt_input(input)
            input_data = {"messages": adapted_input}

            if span:
                span.update_trace(input=input_data)

            structured_result = self.retry_chain.invoke(
                input_data,
                config=processed_config
            )

            if span:
                span.update_trace(output=structured_result)

            token_usage = token_handler.usage_metadata
            structured_result._token_usage_ = token_usage

            return structured_result
        except Exception as e:
            SYLogger.error(f"åŒæ­¥LLMè°ƒç”¨å¤±è´¥: {str(e)}", exc_info=True)
            return None

    async def _aexecute_chain(
        self,
        input: Any,
        config: Optional[RunnableConfig],
        trace_id: str,
        user_id: str,
        span: LangfuseSpan
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®é™…çš„è°ƒç”¨é€»è¾‘ (å¼‚æ­¥)"""
        try:
            processed_config, token_handler = self._get_callback_config(
                config,
                trace_id=trace_id,
                user_id=user_id
            )

            # 1. é€‚é…è¾“å…¥
            adapted_input = self._adapt_input(input)

            # 2. æ£€æŸ¥å¹¶æ‰§è¡Œä¸Šä¸‹æ–‡å‹ç¼© (ä»…åœ¨å¼‚æ­¥æ¨¡å¼ä¸”å¼€å¯æ—¶)
            if self.enable_compression:
                max_tokens = self.llmConfig.maxTokens
                current_tokens = self._count_tokens(adapted_input)

                if current_tokens > max_tokens * self.threshold_ratio:
                    SYLogger.warning(
                        f"âš ï¸ Context limit reached: {current_tokens}/{max_tokens}")
                    # æ‰§è¡Œå‹ç¼©ï¼Œæ›¿æ¢ adapted_input
                    adapted_input = await self._acompress_context(adapted_input)

            input_data = {"messages": adapted_input}

            if span:
                span.update_trace(input=input_data)

            # 3. è°ƒç”¨å­é“¾
            structured_result = await self.retry_chain.ainvoke(
                input_data,
                config=processed_config
            )

            if span:
                span.update_trace(output=structured_result)

            token_usage = token_handler.usage_metadata
            structured_result._token_usage_ = token_usage

            return structured_result
        except Exception as e:
            SYLogger.error(f"å¼‚æ­¥LLMè°ƒç”¨å¤±è´¥: {str(e)}", exc_info=True)
            return None
