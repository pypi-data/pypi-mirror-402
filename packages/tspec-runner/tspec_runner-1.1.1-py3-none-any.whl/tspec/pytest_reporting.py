from __future__ import annotations

import json
import os
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Optional

from .errors import ExecutionError


def _build_test_module(report_json: Path) -> str:
    # Read at build time to create deterministic parametrization ids
    data = json.loads(report_json.read_text(encoding="utf-8"))
    cases = data.get("cases", []) or []
    ids: List[str] = []
    # Create a lightweight structure passed into test
    payload_cases: List[Dict[str, Any]] = []
    for c in cases:
        cid = c.get("id") or c.get("case_id") or "CASE"
        title = c.get("title") or ""
        ids.append(f"{cid} {title}".strip())
        payload_cases.append(
            {
                "id": cid,
                "title": title,
                "status": c.get("status"),
                "duration_ms": c.get("duration_ms"),
                "steps": c.get("steps") or [],
            }
        )

    # embed payload to avoid file I/O per test
    cases_json = json.dumps(payload_cases, ensure_ascii=False)
    ids_json = json.dumps(ids, ensure_ascii=False)
    return f"""# auto-generated by tspec-runner
import json
import pytest

CASES = json.loads({cases_json!r})
IDS = json.loads({ids_json!r})

def _format_failure(case):
    lines = []
    lines.append(f"case: {{case.get('id')}} {{case.get('title')}}")
    lines.append(f"status: {{case.get('status')}}")
    for i, s in enumerate(case.get('steps') or [], start=1):
        st = s.get('status')
        do = s.get('do')
        name = s.get('name') or ''
        err = s.get('error') or ''
        msg = s.get('message') or ''
        dur = s.get('duration_ms')
        if st != 'passed':
            lines.append(f"  step #{{i}}: {{st}} {{do}} {{name}} ({{dur}}ms)")
            if msg:
                lines.append(f"    msg: {{msg}}")
            if err:
                lines.append(f"    err: {{err}}")
    return "\\n".join(lines)

@pytest.mark.parametrize("case", CASES, ids=IDS)
def test_tspec_case(case):
    # Treat 'passed' as success; everything else fails
    if case.get('status') == 'passed':
        return
    pytest.fail(_format_failure(case), pytrace=False)
"""


def generate_pytest_reports(
    report_json: Path,
    *,
    html: Optional[Path] = None,
    junitxml: Optional[Path] = None,
    title: str = "tspec-report",
    extra_args: Optional[List[str]] = None,
) -> Dict[str, str]:
    """Generate pytest-based reports from a tspec JSON report.

    - Does NOT rerun UI actions. It converts existing JSON report -> pytest test module -> pytest run.
    - Requires `pytest` and optional `pytest-html` when `html` is set.
    """
    try:
        import pytest  # type: ignore
    except Exception as e:  # pragma: no cover
        raise ExecutionError("pytest is not installed. Install with: pip install -e '.[report]'") from e

    if html is not None:
        try:
            import pytest_html  # noqa: F401  # type: ignore
        except Exception as e:  # pragma: no cover
            raise ExecutionError("pytest-html is not installed. Install with: pip install -e '.[report]'") from e

    extra_args = extra_args or []
    out: Dict[str, str] = {}

    with tempfile.TemporaryDirectory(prefix="tspec_pytest_") as td:
        tdir = Path(td)
        test_file = tdir / "test_tspec_report.py"
        test_file.write_text(_build_test_module(report_json), encoding="utf-8")

        args: List[str] = [str(test_file), "-q"]
        # Ensure consistent junit schema if requested
        if junitxml is not None:
            junitxml.parent.mkdir(parents=True, exist_ok=True)
            args += ["--junitxml", str(junitxml)]
            out["junitxml"] = str(junitxml)

        if html is not None:
            html.parent.mkdir(parents=True, exist_ok=True)
            args += ["--html", str(html), "--self-contained-html"]
            out["html"] = str(html)

        # Allow user tuning (e.g., -o junit_family=xunit2)
        args += list(extra_args)

        # Run pytest; do not raise SystemExit here. We only care about artifact generation.
        rc = pytest.main(args)
        out["pytest_exit_code"] = str(rc)

    return out
