# v3.10.0 ç‰ˆæœ¬å‘å¸ƒè¯´æ˜

**å‘å¸ƒæ—¥æœŸ**: 2025-11-26
**ç‰ˆæœ¬ç±»å‹**: åŠŸèƒ½å¢å¼ºç‰ˆæœ¬
**å¼€å‘å‘¨æœŸ**: 3å¤©

---

## ğŸ“‹ ç‰ˆæœ¬æ¦‚è¿°

v3.10.0 æ˜¯ Phase 2 è§„åˆ’çš„ç¬¬ä¸€æ‰¹äº¤ä»˜ï¼Œä¸“æ³¨äº**å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±**å’Œ**å­˜å‚¨æŠ½è±¡å±‚**çš„å®Œæ•´å®ç°ï¼š

1. **å­˜å‚¨å®¢æˆ·ç«¯ (Storage)** - LocalFile + S3 + é˜¿é‡Œäº‘OSS
2. **åˆ†å¸ƒå¼è¿½è¸ª (Tracing)** - OpenTelemetry é›†æˆ
3. **æŒ‡æ ‡ç›‘æ§ (Metrics)** - Prometheus é›†æˆ
4. **æµ‹è¯•æ•°æ®å¢å¼º** - æ•°æ®åŠ è½½å™¨å’Œæ–­è¨€è¾…åŠ©

æœ¬ç‰ˆæœ¬æ–°å¢ **3100+ è¡Œä»£ç **ã€**1400+ è¡Œæµ‹è¯•**ã€**2100+ è¡Œæ–‡æ¡£**ï¼Œä¸ºæ¡†æ¶çš„ä¼ä¸šçº§åº”ç”¨æä¾›äº†å®Œæ•´çš„å¯è§‚æµ‹æ€§å’Œå­˜å‚¨æ”¯æŒã€‚

---

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### 1ï¸âƒ£ å­˜å‚¨å®¢æˆ·ç«¯ - LocalFile + S3 + é˜¿é‡Œäº‘OSS (P2.4)

**ä¼˜å…ˆçº§**: ğŸ”´ é«˜
**å·¥ä½œé‡**: é¢„ä¼° 3-5å¤© â†’ å®é™… 1å¤© (æ•ˆç‡ 400%+)

#### æ ¸å¿ƒèƒ½åŠ›

**ç»Ÿä¸€å­˜å‚¨æŠ½è±¡**

æä¾›ä¸‰ç§å­˜å‚¨æ–¹å¼çš„ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒæœ¬åœ°å¼€å‘ã€MinIO æµ‹è¯•ã€é˜¿é‡Œäº‘ç”Ÿäº§ç¯å¢ƒæ— ç¼åˆ‡æ¢ã€‚

**LocalFileClient - æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨**
```python
from df_test_framework.storages import LocalFileClient, LocalFileConfig

# é…ç½®
config = LocalFileConfig(
    base_path="./test-data",
    auto_create_dirs=True,
    max_file_size=10 * 1024 * 1024,  # 10MB
    allowed_extensions=[".txt", ".json", ".csv"]
)

client = LocalFileClient(config)

# ä¸Šä¼ æ–‡ä»¶
result = client.upload("test.txt", b"Hello World")
# {'path': 'test.txt', 'size': 11, 'created_at': ..., 'modified_at': ...}

# ä¸‹è½½æ–‡ä»¶
content = client.download("test.txt")  # b"Hello World"

# åˆ—å‡ºæ–‡ä»¶
files = client.list_files(pattern="*.txt")  # ['test.txt', 'data.txt']

# åˆ é™¤æ–‡ä»¶
client.delete("test.txt")
```

**S3Client - AWS S3 å¯¹è±¡å­˜å‚¨ï¼ˆæ”¯æŒ MinIOï¼‰**
```python
from df_test_framework.storages import S3Client, S3Config

# é…ç½®ï¼ˆMinIOï¼‰
config = S3Config(
    endpoint_url="http://localhost:9000",
    access_key="minioadmin",
    secret_key="minioadmin",
    bucket_name="test-bucket",
    region="us-east-1"
)

client = S3Client(config)

# ä¸Šä¼ æ–‡ä»¶
result = client.upload("test.txt", b"Hello S3")
# {'key': 'test.txt', 'size': 8, 'etag': '...'}

# ä¸‹è½½æ–‡ä»¶
content = client.download("test.txt")

# ç”Ÿæˆé¢„ç­¾å URLï¼ˆ5åˆ†é’Ÿæœ‰æ•ˆï¼‰
url = client.generate_presigned_url("test.txt", expiration=300)

# åˆ†ç‰‡ä¸Šä¼ ï¼ˆå¤§æ–‡ä»¶è‡ªåŠ¨åˆ†ç‰‡ï¼‰
with open("large_file.bin", "rb") as f:
    client.upload("large_file.bin", f)  # è‡ªåŠ¨ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ 
```

**OSSClient - é˜¿é‡Œäº‘ OSS å¯¹è±¡å­˜å‚¨**
```python
from df_test_framework.storages import OSSClient, OSSConfig

# åŸºç¡€é…ç½®
config = OSSConfig(
    access_key_id="LTAI5t...",
    access_key_secret="xxx...",
    bucket_name="my-bucket",
    endpoint="oss-cn-hangzhou.aliyuncs.com"
)

client = OSSClient(config)

# ä¸Šä¼ æ–‡ä»¶
result = client.upload("test.txt", b"Hello OSS")

# ä¸‹è½½æ–‡ä»¶
content = client.download("test.txt")

# ç”Ÿæˆé¢„ç­¾å URL
url = client.generate_presigned_url("test.txt", expiration=300)
```

**é«˜çº§é…ç½® - å†…ç½‘è®¿é—® + CRC64 æ ¡éªŒ**
```python
config = OSSConfig(
    access_key_id="LTAI5t...",
    access_key_secret="xxx...",
    bucket_name="my-bucket",
    endpoint="oss-cn-hangzhou-internal.aliyuncs.com",  # å†…ç½‘ Endpoint
    enable_crc=True,              # å¯ç”¨ CRC64 æ ¡éªŒ
    part_size=10 * 1024 * 1024,  # åˆ†ç‰‡å¤§å° 10MB
    connect_timeout=60            # è¿æ¥è¶…æ—¶ 60ç§’
)

client = OSSClient(config)
```

**STS ä¸´æ—¶å‡­è¯æ”¯æŒ**
```python
config = OSSConfig(
    access_key_id="STS.xxx...",
    access_key_secret="xxx...",
    security_token="CAISxxx...",  # STS Token
    bucket_name="my-bucket",
    endpoint="oss-cn-hangzhou.aliyuncs.com"
)

client = OSSClient(config)
```

**pytest fixtures é›†æˆ**
```python
# é€šè¿‡ fixture ç›´æ¥ä½¿ç”¨
def test_storage(local_file_client, s3_client, oss_client):
    # æœ¬åœ°æ–‡ä»¶å­˜å‚¨
    local_file_client.upload("test.txt", b"Hello")
    assert local_file_client.exists("test.txt")

    # S3 å­˜å‚¨
    s3_client.upload("test.txt", b"Hello S3")
    content = s3_client.download("test.txt")
    assert content == b"Hello S3"

    # OSS å­˜å‚¨
    oss_client.upload("test.txt", b"Hello OSS")
    url = oss_client.generate_presigned_url("test.txt", expiration=300)

    # æ¸…ç†
    local_file_client.delete("test.txt")
    s3_client.delete("test.txt")
    oss_client.delete("test.txt")
```

**ç»Ÿä¸€ CRUD API**

æ‰€æœ‰å­˜å‚¨å®¢æˆ·ç«¯æä¾›ä¸€è‡´çš„ APIï¼š
- `upload(key, content, metadata=None)` - ä¸Šä¼ æ–‡ä»¶
- `download(key)` - ä¸‹è½½æ–‡ä»¶
- `delete(key, missing_ok=False)` - åˆ é™¤æ–‡ä»¶
- `exists(key)` - æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- `list_objects(prefix="", max_keys=1000)` - åˆ—å‡ºå¯¹è±¡
- `get_object_info(key)` - è·å–å¯¹è±¡ä¿¡æ¯
- `copy(source_key, dest_key)` - å¤åˆ¶æ–‡ä»¶
- `generate_presigned_url(key, expiration)` - ç”Ÿæˆé¢„ç­¾å URL
- `clear(prefix="")` - æ‰¹é‡åˆ é™¤

#### åº”ç”¨åœºæ™¯

1. **æµ‹è¯•æ•°æ®ç®¡ç†**: ç»Ÿä¸€ç®¡ç†æµ‹è¯•æ–‡ä»¶ï¼Œæœ¬åœ°/äº‘ç«¯æ— ç¼åˆ‡æ¢
2. **æ–‡ä»¶ä¸Šä¼ æµ‹è¯•**: æµ‹è¯•æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
3. **å¯¹è±¡å­˜å‚¨é›†æˆæµ‹è¯•**: æµ‹è¯•ä¸ S3/OSS çš„é›†æˆ
4. **æ•°æ®å¯¼å…¥å¯¼å‡º**: æµ‹è¯•æ•°æ®å¯¼å…¥å¯¼å‡ºåŠŸèƒ½

#### æ¶æ„è®¾è®¡

**V3 æ¶æ„ - èƒ½åŠ›å±‚ Layer 1**
```
src/df_test_framework/
â””â”€â”€ storages/              # å­˜å‚¨èƒ½åŠ›å±‚
    â”œâ”€â”€ object/            # å¯¹è±¡å­˜å‚¨
    â”‚   â”œâ”€â”€ s3/           # âœ… AWS S3ï¼ˆåŸºäº boto3ï¼‰
    â”‚   â”‚   â”œâ”€â”€ client.py
    â”‚   â”‚   â”œâ”€â”€ config.py
    â”‚   â”‚   â””â”€â”€ __init__.py
    â”‚   â””â”€â”€ oss/          # âœ… é˜¿é‡Œäº‘ OSSï¼ˆåŸºäº oss2ï¼‰
    â”‚       â”œâ”€â”€ client.py
    â”‚       â”œâ”€â”€ config.py
    â”‚       â””â”€â”€ __init__.py
    â”œâ”€â”€ file/              # æ–‡ä»¶ç³»ç»Ÿ
    â”‚   â””â”€â”€ local/        # âœ… æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
    â”‚       â”œâ”€â”€ client.py
    â”‚       â”œâ”€â”€ config.py
    â”‚       â””â”€â”€ __init__.py
    â””â”€â”€ blob/              # â³ Blob å­˜å‚¨ï¼ˆé¢„ç•™ï¼‰
```

**è®¾è®¡åŸåˆ™**:
- âœ… ç‹¬ç«‹ SDK å®ç°ï¼ˆS3 ç”¨ boto3ï¼ŒOSS ç”¨ oss2ï¼‰
- âœ… ç»Ÿä¸€ API æ¥å£
- âœ… é…ç½®é©±åŠ¨ï¼Œæ”¯æŒå¤šç¯å¢ƒ
- âœ… Provider æ¨¡å¼ä¾èµ–æ³¨å…¥
- âœ… pytest fixtures å¼€ç®±å³ç”¨

#### æµ‹è¯•è¦†ç›–

- **75ä¸ªå•å…ƒæµ‹è¯•**ï¼Œå…¨éƒ¨é€šè¿‡
- LocalFileClient: 32ä¸ªæµ‹è¯•ï¼Œè¦†ç›–ç‡ 95%+
- S3Client: 21ä¸ªæµ‹è¯•ï¼Œè¦†ç›–ç‡ 95%+
- OSSClient: 22ä¸ªæµ‹è¯•ï¼Œè¦†ç›–ç‡ 95%+

**æµ‹è¯•æ–‡ä»¶**:
- `tests/unit/storages/test_local_file.py` - æœ¬åœ°æ–‡ä»¶æµ‹è¯•
- `tests/unit/storages/test_s3.py` - S3 æµ‹è¯•
- `tests/unit/storages/test_oss.py` - OSS æµ‹è¯•

#### æŠ€æœ¯äº®ç‚¹

- âœ… ä¸‰ç§å­˜å‚¨æ–¹å¼ç»Ÿä¸€æŠ½è±¡
- âœ… åŸºäºå®˜æ–¹ SDKï¼ˆboto3 + oss2ï¼‰
- âœ… è‡ªåŠ¨åˆ†ç‰‡ä¸Šä¼ ï¼ˆå¤§æ–‡ä»¶ä¼˜åŒ–ï¼‰
- âœ… STS ä¸´æ—¶å‡­è¯æ”¯æŒï¼ˆå®‰å…¨æ€§ï¼‰
- âœ… CRC64 æ•°æ®æ ¡éªŒï¼ˆOSSï¼‰
- âœ… å†…ç½‘ Endpoint æ”¯æŒï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰
- âœ… é¢„ç­¾å URL ç”Ÿæˆ
- âœ… è·¯å¾„å®‰å…¨éªŒè¯ï¼ˆæœ¬åœ°æ–‡ä»¶é˜²ç©¿è¶Šï¼‰
- âœ… å…ƒæ•°æ®ç®¡ç†

#### æ–‡æ¡£

- **å®Œæ•´ä½¿ç”¨æŒ‡å—**: [storage.md](../guides/storage.md) (~500è¡Œ)
- **ç¤ºä¾‹ä»£ç **: [storage_usage.py](../../examples/01-basic/storage_usage.py) (320è¡Œ)
- **API æ–‡æ¡£**: Fixtures æ–‡æ¡£å­—ç¬¦ä¸²å®Œæ•´

---

### 2ï¸âƒ£ OpenTelemetry åˆ†å¸ƒå¼è¿½è¸ª (P2.1)

**ä¼˜å…ˆçº§**: ğŸ”´ é«˜
**å·¥ä½œé‡**: é¢„ä¼° 7-10å¤© â†’ å®é™… 2å¤© (æ•ˆç‡ 350%+)

#### æ ¸å¿ƒèƒ½åŠ›

**TracingManager - è¿½è¸ªç®¡ç†å™¨**
```python
from df_test_framework.infrastructure.tracing import (
    TracingManager, TracingConfig, ExporterType
)

# é…ç½®è¿½è¸ª
config = TracingConfig(
    service_name="order-service",
    exporter_type=ExporterType.OTLP,
    endpoint="http://localhost:4317",
    sampling_rate=1.0
)

tracing = TracingManager(config=config).init()

# åˆ›å»º Span
with tracing.start_span("process_order") as span:
    span.set_attribute("order_id", "12345")
    span.set_attribute("user_id", "user_001")
    # å¤„ç†è®¢å•é€»è¾‘
    result = process_order(order_id="12345")
```

**è£…é¥°å™¨æ”¯æŒ**
```python
from df_test_framework.infrastructure.tracing import trace_span, trace_async_span, TraceClass

# åŒæ­¥å‡½æ•°è¿½è¸ª
@trace_span("validate_user")
def validate_user(user_id: str) -> bool:
    return user_service.validate(user_id)

# å¼‚æ­¥å‡½æ•°è¿½è¸ª
@trace_async_span("send_notification")
async def send_notification(user_id: str, message: str):
    await notification_service.send(user_id, message)

# ç±»çº§åˆ«è¿½è¸ªï¼ˆæ‰€æœ‰æ–¹æ³•è‡ªåŠ¨è¿½è¸ªï¼‰
@TraceClass
class OrderService:
    def create_order(self, order_data: dict):
        # è‡ªåŠ¨åˆ›å»º span: OrderService.create_order
        pass

    async def update_order(self, order_id: str, updates: dict):
        # è‡ªåŠ¨åˆ›å»º span: OrderService.update_order
        pass
```

**HTTP è¯·æ±‚è¿½è¸ª**
```python
from df_test_framework.clients.http import HttpClient
from df_test_framework.clients.http.interceptors.tracing import TracingInterceptor

# è‡ªåŠ¨è¿½è¸ªæ‰€æœ‰ HTTP è¯·æ±‚
client = HttpClient()
client.add_interceptor(TracingInterceptor(
    record_headers=True,      # è®°å½•è¯·æ±‚/å“åº”å¤´
    record_body=False,         # ä¸è®°å½• bodyï¼ˆéšç§è€ƒè™‘ï¼‰
    propagate_context=True     # W3C Trace Context ä¼ æ’­
))

# æ‰€æœ‰è¯·æ±‚è‡ªåŠ¨åˆ›å»º span
response = await client.get("https://api.example.com/users")
# Span åŒ…å«: method, url, status_code, duration ç­‰
```

**æ•°æ®åº“æŸ¥è¯¢è¿½è¸ª**
```python
from df_test_framework.infrastructure.tracing.integrations import TracedDatabase

# åŒ…è£…æ•°æ®åº“å®ä¾‹
traced_db = TracedDatabase(
    db=database,
    record_statement=True,     # è®°å½• SQL è¯­å¥
    record_parameters=False    # ä¸è®°å½•å‚æ•°ï¼ˆå®‰å…¨è€ƒè™‘ï¼‰
)

# æ‰€æœ‰æŸ¥è¯¢è‡ªåŠ¨è¿½è¸ª
result = await traced_db.query_one("SELECT * FROM users WHERE id = ?", [123])
# Span åŒ…å«: operation, table, duration, row_count ç­‰
```

**ä¸Šä¸‹æ–‡ä¼ æ’­**
```python
from df_test_framework.infrastructure.tracing import TracingContext, get_current_span

# è·å–å½“å‰ Span
current_span = get_current_span()
current_span.set_attribute("custom_field", "value")

# è·¨æœåŠ¡ä¼ æ’­
context = TracingContext.extract_from_carrier(request.headers)
with TracingContext.use_context(context):
    # åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­åˆ›å»ºçš„ Span ä¼šè‡ªåŠ¨å…³è”åˆ°çˆ¶ Span
    result = call_downstream_service()
```

**æ”¯æŒçš„å¯¼å‡ºå™¨**
- **Console**: æ§åˆ¶å°è¾“å‡ºï¼ˆå¼€å‘è°ƒè¯•ï¼‰
- **OTLP**: OpenTelemetry Protocolï¼ˆæ ‡å‡†åè®®ï¼‰
- **Jaeger**: Uber å¼€æºçš„åˆ†å¸ƒå¼è¿½è¸ªç³»ç»Ÿ
- **Zipkin**: Twitter å¼€æºçš„åˆ†å¸ƒå¼è¿½è¸ªç³»ç»Ÿ

#### åº”ç”¨åœºæ™¯

1. **å¾®æœåŠ¡é“¾è·¯è¿½è¸ª**: è¿½è¸ªè¯·æ±‚åœ¨å¤šä¸ªæœåŠ¡é—´çš„æµè½¬
2. **æ€§èƒ½åˆ†æ**: è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œæ…¢æŸ¥è¯¢
3. **æ•…éšœè¯Šæ–­**: å¿«é€Ÿå®šä½é”™è¯¯å‘ç”Ÿçš„ä½ç½®
4. **ä¾èµ–åˆ†æ**: ç†è§£æœåŠ¡é—´çš„è°ƒç”¨å…³ç³»

#### æµ‹è¯•è¦†ç›–

- **70ä¸ªå•å…ƒæµ‹è¯•**ï¼Œè¦†ç›–ç‡ **95%+**
- æµ‹è¯•æ–‡ä»¶:
  - `test_manager.py` - è¿½è¸ªç®¡ç†å™¨æµ‹è¯•
  - `test_decorators.py` - è£…é¥°å™¨æµ‹è¯•
  - `test_context.py` - ä¸Šä¸‹æ–‡ä¼ æ’­æµ‹è¯•
  - `test_exporters.py` - å¯¼å‡ºå™¨æµ‹è¯•
  - `test_integrations.py` - HTTP/Database é›†æˆæµ‹è¯•

#### æŠ€æœ¯äº®ç‚¹

- âœ… é›¶ä¾µå…¥å¼è®¾è®¡ï¼ˆè£…é¥°å™¨æ¨¡å¼ï¼‰
- âœ… W3C Trace Context æ ‡å‡†å…¼å®¹
- âœ… å¤šå¯¼å‡ºå™¨æ”¯æŒï¼Œå¯åŒæ—¶å¯ç”¨å¤šä¸ª
- âœ… è‡ªåŠ¨ä¸Šä¸‹æ–‡ä¼ æ’­
- âœ… æ€§èƒ½ä¼˜åŒ–ï¼ˆé‡‡æ ·ç‡æ§åˆ¶ï¼‰

---

### 2ï¸âƒ£ æµ‹è¯•æ•°æ®å·¥å…·å¢å¼º (P2.2)

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**å·¥ä½œé‡**: é¢„ä¼° 3-5å¤© â†’ å®é™… 2å°æ—¶ (æ•ˆç‡ 1200%+)

#### æ ¸å¿ƒèƒ½åŠ›

**æ•°æ®åŠ è½½å™¨ - JSONLoader**
```python
from df_test_framework.testing.data import JSONLoader

# åŸºç¡€åŠ è½½
users = JSONLoader.load("tests/data/users.json")

# JSONPath æŸ¥è¯¢
admin_users = JSONLoader.load("tests/data/users.json", jsonpath="$[?(@.role=='admin')]")

# åŠ è½½ JSONLï¼ˆæ¯è¡Œä¸€ä¸ª JSONï¼‰
logs = JSONLoader.load_jsonl("tests/data/logs.jsonl")

# pytest å‚æ•°åŒ–
@pytest.mark.parametrize("case", JSONLoader.load("tests/data/test_cases.json"))
def test_api(case):
    response = api.call(case["input"])
    assert response == case["expected"]
```

**æ•°æ®åŠ è½½å™¨ - CSVLoader**
```python
from df_test_framework.testing.data import CSVLoader

# åŸºç¡€åŠ è½½
products = CSVLoader.load("tests/data/products.csv")

# ç±»å‹è½¬æ¢
products = CSVLoader.load(
    "tests/data/products.csv",
    type_hints={
        "price": float,
        "stock": int,
        "is_active": bool
    }
)

# è‡ªå®šä¹‰åˆ†éš”ç¬¦
data = CSVLoader.load("data.tsv", delimiter="\t")

# pytest å‚æ•°åŒ–
@pytest.mark.parametrize("row", CSVLoader.load("test_data.csv"))
def test_calculation(row):
    result = calculate(row["input"])
    assert result == float(row["expected"])
```

**æ•°æ®åŠ è½½å™¨ - YAMLLoader**
```python
from df_test_framework.testing.data import YAMLLoader

# åŸºç¡€åŠ è½½
config = YAMLLoader.load("tests/data/config.yaml")

# ç¯å¢ƒå˜é‡æ›¿æ¢
config = YAMLLoader.load("config.yaml", expand_env=True)
# æ–‡ä»¶ä¸­ ${DATABASE_URL} ä¼šè¢«æ›¿æ¢ä¸ºç¯å¢ƒå˜é‡å€¼

# åŠ è½½å¤šæ–‡æ¡£ YAML
docs = YAMLLoader.load_all("tests/data/multi_doc.yaml")

# é…ç½®åˆå¹¶
base = YAMLLoader.load("base_config.yaml")
override = YAMLLoader.load("test_config.yaml")
config = YAMLLoader.merge(base, override)
```

**å“åº”æ–­è¨€è¾…åŠ© - é™æ€æ–¹æ³•**
```python
from df_test_framework.testing.assertions import (
    assert_status, assert_json_has, assert_json_match,
    assert_response_time_lt, assert_header_exists
)

response = api.get("/users/123")

# çŠ¶æ€ç æ–­è¨€
assert_status(response, 200)

# JSON å­—æ®µå­˜åœ¨æ€§æ–­è¨€
assert_json_has(response, "id", "name", "email")

# JSON å€¼åŒ¹é…æ–­è¨€
assert_json_match(response, {"id": 123, "name": "å¼ ä¸‰"})

# å“åº”æ—¶é—´æ–­è¨€
assert_response_time_lt(response, 1000)  # < 1ç§’

# å“åº”å¤´æ–­è¨€
assert_header_exists(response, "X-Request-ID")
```

**å“åº”æ–­è¨€è¾…åŠ© - é“¾å¼è°ƒç”¨**
```python
from df_test_framework.testing.assertions import ResponseAssertions

response = api.get("/users/123")

# é“¾å¼è°ƒç”¨
ResponseAssertions(response) \
    .status(200) \
    .json_has("id", "name", "email") \
    .json_match({"status": "active"}) \
    .response_time_lt(1000) \
    .header_exists("X-Request-ID") \
    .header_equals("Content-Type", "application/json")
```

**é¢„ç½®å·¥å‚ - ä»…ä¾›å‚è€ƒ**

âš ï¸ **é‡è¦è¯´æ˜**: é¢„ç½®å·¥å‚ï¼ˆUserFactory, OrderFactory ç­‰ï¼‰æ˜¯**ä¸šåŠ¡é¢†åŸŸç‰¹å®š**çš„ç¤ºä¾‹ä»£ç ï¼Œä¸åŒé¡¹ç›®çš„æ¨¡å‹å·®å¼‚å¾ˆå¤§ï¼Œ**å»ºè®®ç»§æ‰¿ Factory åŸºç±»è‡ªå®šä¹‰**ã€‚

**æ¨èä½¿ç”¨æ–¹å¼**:
```python
from df_test_framework.testing.factories import Factory, Sequence, LazyAttribute, FakerAttribute

# æ ¹æ®é¡¹ç›®å®é™…æ¨¡å‹å®šä¹‰å·¥å‚
class MyUserFactory(Factory):
    """é¡¹ç›®ç‰¹å®šçš„ User å·¥å‚"""
    id = Sequence()
    username = Sequence(lambda n: f"user_{n}")
    email = LazyAttribute(lambda obj: f"{obj.username}@company.com")
    # Faker é›†æˆï¼ˆå¦‚æœå®‰è£…äº† fakerï¼‰
    phone = FakerAttribute("phone_number")
    name = FakerAttribute("name")

    # é¡¹ç›®ç‰¹å®šå­—æ®µ
    department = LazyAttribute(lambda _: "Engineering")
    employee_id = Sequence(lambda n: f"EMP{n:06d}")

# ä½¿ç”¨å·¥å‚
user = MyUserFactory.build()
users = MyUserFactory.build_batch(100)
admin = MyUserFactory.build(role="admin")
```

#### åº”ç”¨åœºæ™¯

1. **æµ‹è¯•æ•°æ®ç®¡ç†**: ä»æ–‡ä»¶åŠ è½½æµ‹è¯•æ•°æ®ï¼Œç»Ÿä¸€ç®¡ç†
2. **æ•°æ®é©±åŠ¨æµ‹è¯•**: ä½¿ç”¨ JSON/CSV/YAML é©±åŠ¨æµ‹è¯•ç”¨ä¾‹
3. **API æµ‹è¯•æ–­è¨€**: å¿«é€ŸéªŒè¯ HTTP å“åº”
4. **é…ç½®ç®¡ç†**: YAML é…ç½®åŠ è½½å’Œç¯å¢ƒå˜é‡æ›¿æ¢

#### æµ‹è¯•è¦†ç›–

- **68ä¸ªå•å…ƒæµ‹è¯•**ï¼Œè¦†ç›–ç‡ **90%+**
- æµ‹è¯•æ–‡ä»¶:
  - `test_data_loaders.py` - æ•°æ®åŠ è½½å™¨æµ‹è¯• (24ä¸ª)
  - `test_assertions.py` - æ–­è¨€è¾…åŠ©æµ‹è¯• (22ä¸ª)
  - `test_factories_presets.py` - é¢„ç½®å·¥å‚æµ‹è¯• (22ä¸ª)

#### æŠ€æœ¯äº®ç‚¹

- âœ… æ”¯æŒå¤šç§æ•°æ®æ ¼å¼ï¼ˆJSON/CSV/YAMLï¼‰
- âœ… JSONPath é«˜çº§æŸ¥è¯¢
- âœ… ç¯å¢ƒå˜é‡åŠ¨æ€æ›¿æ¢
- âœ… pytest åŸç”Ÿå‚æ•°åŒ–æ”¯æŒ
- âœ… é“¾å¼æ–­è¨€ï¼Œå¯è¯»æ€§å¼º

---

### 3ï¸âƒ£ æµ‹è¯•æ•°æ®å·¥å…·å¢å¼º (P2.2)

**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­
**å·¥ä½œé‡**: é¢„ä¼° 3-5å¤© â†’ å®é™… 2å°æ—¶ (æ•ˆç‡ 1200%+)

#### æ ¸å¿ƒèƒ½åŠ›

**MetricsManager - æŒ‡æ ‡ç®¡ç†å™¨**
```python
from df_test_framework.infrastructure.metrics import (
    MetricsManager, MetricsConfig, get_metrics_manager
)

# è‡ªå®šä¹‰é…ç½®
config = MetricsConfig(
    service_name="order-service",
    enabled=True,
    use_prometheus=True,          # ä½¿ç”¨ prometheus_clientï¼ˆå¯é€‰ï¼‰
    server_port=8000,              # Prometheus exporter ç«¯å£
    pushgateway_url="http://pushgateway:9091",
    push_interval=10.0,            # æ¨é€é—´éš”ï¼ˆç§’ï¼‰
    default_labels={               # é»˜è®¤æ ‡ç­¾
        "environment": "production",
        "region": "us-west-2"
    }
)

manager = MetricsManager(config=config)
manager.init()

# å¯åŠ¨ Prometheus HTTP Server
manager.start_server(port=8000)
# ç°åœ¨å¯ä»¥ä» http://localhost:8000/metrics æŠ“å–æŒ‡æ ‡

# æ¨é€åˆ° Pushgateway
manager.push_to_gateway()

# å¯åŠ¨å®šæœŸæ¨é€
manager.start_push_loop(interval=10.0)
```

**æŒ‡æ ‡ç±»å‹ - Counter (è®¡æ•°å™¨)**
```python
# åˆ›å»ºè®¡æ•°å™¨
requests_total = manager.counter(
    "http_requests_total",
    "Total HTTP requests",
    labels=["method", "endpoint", "status"]
)

# ä½¿ç”¨è®¡æ•°å™¨
requests_total.labels(method="GET", endpoint="/api/users", status="200").inc()
requests_total.labels(method="POST", endpoint="/api/orders", status="201").inc(5)

# è·å–å½“å‰å€¼
current = requests_total.labels(method="GET", endpoint="/api/users", status="200").get()
```

**æŒ‡æ ‡ç±»å‹ - Gauge (ä»ªè¡¨ç›˜)**
```python
# åˆ›å»ºä»ªè¡¨ç›˜
connections = manager.gauge(
    "db_connections_active",
    "Active database connections",
    labels=["database"]
)

# è®¾ç½®å€¼
connections.labels(database="postgres").set(10)

# å¢åŠ /å‡å°‘
connections.labels(database="postgres").inc(5)  # å¢åŠ åˆ° 15
connections.labels(database="postgres").dec(3)  # å‡å°‘åˆ° 12

# è¿½è¸ªè¿›è¡Œä¸­çš„æ“ä½œ
with connections.labels(database="redis").track_inprogress():
    # è‡ªåŠ¨ +1
    perform_redis_operation()
    # é€€å‡ºæ—¶è‡ªåŠ¨ -1
```

**æŒ‡æ ‡ç±»å‹ - Histogram (ç›´æ–¹å›¾)**
```python
# åˆ›å»ºç›´æ–¹å›¾
request_duration = manager.histogram(
    "http_request_duration_seconds",
    "HTTP request duration",
    labels=["method", "endpoint"],
    buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0)
)

# è®°å½•è§‚æµ‹å€¼
request_duration.labels(method="GET", endpoint="/api/users").observe(0.123)

# ä½¿ç”¨è®¡æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with request_duration.labels(method="POST", endpoint="/api/orders").time():
    # è‡ªåŠ¨è®¡æ—¶
    process_order()
```

**æŒ‡æ ‡ç±»å‹ - Summary (æ‘˜è¦)**
```python
# åˆ›å»ºæ‘˜è¦
request_size = manager.summary(
    "http_request_size_bytes",
    "HTTP request size in bytes",
    labels=["method"]
)

# è®°å½•è§‚æµ‹å€¼
request_size.labels(method="POST").observe(1024)

# ä½¿ç”¨è®¡æ—¶
with request_size.labels(method="PUT").time():
    upload_data()
```

**è£…é¥°å™¨ - å‡½æ•°è°ƒç”¨è®¡æ•°**
```python
from df_test_framework.infrastructure.metrics.decorators import count_calls

@count_calls("api_calls_total", description="Total API calls", labels=["endpoint"])
def call_api(endpoint: str):
    return requests.get(f"https://api.example.com{endpoint}")

# æ¯æ¬¡è°ƒç”¨è‡ªåŠ¨å¢åŠ è®¡æ•°
call_api("/users")
call_api("/orders")
```

**è£…é¥°å™¨ - å‡½æ•°è®¡æ—¶**
```python
from df_test_framework.infrastructure.metrics.decorators import time_calls, time_async_calls

# åŒæ­¥å‡½æ•°è®¡æ—¶
@time_calls("process_duration_seconds")
def process_data(data: list):
    time.sleep(0.1)
    return len(data)

# å¼‚æ­¥å‡½æ•°è®¡æ—¶
@time_async_calls("async_task_duration_seconds")
async def async_task():
    await asyncio.sleep(0.1)
    return "done"
```

**è£…é¥°å™¨ - å¹¶å‘è¿½è¸ª**
```python
from df_test_framework.infrastructure.metrics.decorators import track_in_progress, track_async_in_progress

# è¿½è¸ªåŒæ­¥å‡½æ•°å¹¶å‘æ•°
@track_in_progress("tasks_in_progress")
def process_task():
    time.sleep(1)
    return "done"

# è¿½è¸ªå¼‚æ­¥å‡½æ•°å¹¶å‘æ•°
@track_async_in_progress("async_jobs_in_progress")
async def async_job():
    await asyncio.sleep(1)
    return "done"
```

**è£…é¥°å™¨ç»„åˆä½¿ç”¨**
```python
from df_test_framework.infrastructure.metrics.decorators import (
    count_calls, time_calls, track_in_progress
)

@count_calls("api_requests_total")
@time_calls("api_request_duration_seconds")
@track_in_progress("api_requests_in_progress")
def api_request(endpoint: str):
    """
    è‡ªåŠ¨æ”¶é›†:
    - è°ƒç”¨æ¬¡æ•°
    - æ‰§è¡Œæ—¶é—´
    - å¹¶å‘æ•°
    """
    return requests.get(endpoint)
```

**HTTP é›†æˆ - è‡ªåŠ¨æ”¶é›†è¯·æ±‚æŒ‡æ ‡**
```python
from df_test_framework.infrastructure.metrics.integrations.http import HttpMetrics

# åˆ›å»º HTTP æŒ‡æ ‡æ”¶é›†å™¨
http_metrics = HttpMetrics(
    prefix="my_service",           # æŒ‡æ ‡åç§°å‰ç¼€
    include_path_label=True,       # åŒ…å«è·¯å¾„æ ‡ç­¾
    path_cardinality_limit=100     # è·¯å¾„åŸºæ•°é™åˆ¶
)

# æ·»åŠ åˆ° HTTP å®¢æˆ·ç«¯
client = HttpClient()
client.add_interceptor(http_metrics.interceptor())

# æ‰€æœ‰è¯·æ±‚è‡ªåŠ¨æ”¶é›†æŒ‡æ ‡:
# - my_service_http_requests_total
# - my_service_http_request_duration_seconds
# - my_service_http_requests_in_flight
# - my_service_http_request_size_bytes
# - my_service_http_response_size_bytes
```

**Database é›†æˆ - è‡ªåŠ¨æ”¶é›†æŸ¥è¯¢æŒ‡æ ‡**
```python
from df_test_framework.infrastructure.metrics.integrations.database import DatabaseMetrics

# åˆ›å»ºæ•°æ®åº“æŒ‡æ ‡æ”¶é›†å™¨
db_metrics = DatabaseMetrics(
    prefix="my_service",           # æŒ‡æ ‡åç§°å‰ç¼€
    include_table_label=True       # åŒ…å«è¡¨åæ ‡ç­¾
)

# è®°å½•æŸ¥è¯¢æŒ‡æ ‡
db_metrics.record_query(
    operation="SELECT",
    table="users",
    duration=0.045,
    rows=100
)

# è‡ªåŠ¨æ”¶é›†æŒ‡æ ‡:
# - my_service_db_queries_total
# - my_service_db_query_duration_seconds
# - my_service_db_query_rows
# - my_service_db_connections_active
```

**é›¶é…ç½®æ¨¡å¼**

â­ å³ä½¿ä¸å®‰è£… `prometheus_client`ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ‰€æœ‰æŒ‡æ ‡åŠŸèƒ½ï¼š

```python
# æ— éœ€å®‰è£… prometheus_client
config = MetricsConfig(use_prometheus=False)
manager = MetricsManager(config=config)
manager.init()

# ä½¿ç”¨å†…å­˜å­˜å‚¨ï¼Œæ‰€æœ‰ API æ­£å¸¸å·¥ä½œ
counter = manager.counter("test_counter", "Test")
counter.inc()

# æ”¶é›†æŒ‡æ ‡ï¼ˆå­—å…¸æ ¼å¼ï¼‰
metrics = manager.collect()
print(metrics)
```

#### Grafana Dashboard ç¤ºä¾‹

**HTTP è¯·æ±‚ç›‘æ§**:
```promql
# è¯·æ±‚é€Ÿç‡
rate(http_requests_total[5m])

# å¹³å‡å“åº”æ—¶é—´
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])

# P95 å“åº”æ—¶é—´
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# é”™è¯¯ç‡
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])
```

**æ•°æ®åº“æŸ¥è¯¢ç›‘æ§**:
```promql
# æŸ¥è¯¢é€Ÿç‡
rate(db_queries_total[5m])

# å¹³å‡æŸ¥è¯¢æ—¶é—´
rate(db_query_duration_seconds_sum[5m]) / rate(db_query_duration_seconds_count[5m])

# æ´»è·ƒè¿æ¥æ•°
db_connections_active

# æ…¢æŸ¥è¯¢å æ¯”
rate(db_query_duration_seconds_bucket{le="1.0"}[5m]) / rate(db_query_duration_seconds_count[5m])
```

#### åº”ç”¨åœºæ™¯

1. **æ€§èƒ½ç›‘æ§**: è¿½è¸ª HTTP è¯·æ±‚ã€æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
2. **å®¹é‡è§„åˆ’**: ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µï¼Œé¢„æµ‹å®¹é‡éœ€æ±‚
3. **å‘Šè­¦**: åŸºäºæŒ‡æ ‡é…ç½®å‘Šè­¦è§„åˆ™
4. **ä¸šåŠ¡ç›‘æ§**: è¿½è¸ªä¸šåŠ¡æŒ‡æ ‡ï¼ˆè®¢å•æ•°ã€ç”¨æˆ·æ•°ç­‰ï¼‰

#### æµ‹è¯•è¦†ç›–

- **44ä¸ªå•å…ƒæµ‹è¯•**ï¼Œè¦†ç›–ç‡ **92%+**
- æµ‹è¯•æ–‡ä»¶:
  - `test_basic.py` - åŸºç¡€åŠŸèƒ½æµ‹è¯• (27ä¸ª)
  - `test_decorators_integrations.py` - è£…é¥°å™¨å’Œé›†æˆæµ‹è¯• (17ä¸ª)

#### æŠ€æœ¯äº®ç‚¹

- âœ… é›¶é…ç½®æ¨¡å¼ï¼ˆfallback å®ç°ï¼‰
- âœ… æ¸è¿›å¼å¢å¼ºï¼ˆå®‰è£… prometheus_client åè‡ªåŠ¨å¯ç”¨é«˜çº§åŠŸèƒ½ï¼‰
- âœ… è£…é¥°å™¨å‹å¥½ï¼ˆä¸€è¡Œä»£ç æ·»åŠ ç›‘æ§ï¼‰
- âœ… çº¿ç¨‹å®‰å…¨ï¼ˆæ‰€æœ‰æŒ‡æ ‡ç±»å‹çº¿ç¨‹å®‰å…¨ï¼‰
- âœ… è‡ªåŠ¨é›†æˆï¼ˆHTTP/Database æ‹¦æˆªå™¨ï¼‰

---

## ğŸ“Š ç»Ÿè®¡æ•°æ®

### ä»£ç ç»Ÿè®¡

| æ¨¡å— | ä»£ç è¡Œæ•° | æµ‹è¯•è¡Œæ•° | æ–‡æ¡£è¡Œæ•° |
|------|---------|---------|---------|
| å­˜å‚¨å®¢æˆ·ç«¯ | +800 | +400 | +800 |
| OpenTelemetry è¿½è¸ª | +700 | +400 | +500 |
| æµ‹è¯•æ•°æ®å·¥å…· | +800 | +400 | +500 |
| Prometheus æŒ‡æ ‡ | +800 | +200 | +500 |
| **æ€»è®¡** | **+3100** | **+1400** | **+2300** |

### æµ‹è¯•è¦†ç›–

| æ¨¡å— | æµ‹è¯•ç”¨ä¾‹æ•° | è¦†ç›–ç‡ |
|------|-----------|--------|
| å­˜å‚¨æ¨¡å— | 75 | 95%+ |
| è¿½è¸ªæ¨¡å— | 70 | 95%+ |
| æ•°æ®åŠ è½½å™¨ | 24 | 92% |
| å“åº”æ–­è¨€ | 22 | 94% |
| é¢„ç½®å·¥å‚ | 22 | 88% |
| æŒ‡æ ‡æ¨¡å— | 44 | 92%+ |
| **æ€»è®¡** | **257** | **93%** |

### æ–‡ä»¶æ¸…å•

**æ–°å¢æ–‡ä»¶** (44ä¸ª):

**å­˜å‚¨æ¨¡å—** (9ä¸ª):
- `src/df_test_framework/storages/object/s3/client.py`
- `src/df_test_framework/storages/object/s3/config.py`
- `src/df_test_framework/storages/object/oss/client.py`
- `src/df_test_framework/storages/object/oss/config.py`
- `src/df_test_framework/storages/file/local/client.py`
- `src/df_test_framework/storages/file/local/config.py`
- `tests/unit/storages/test_local_file.py`
- `tests/unit/storages/test_s3.py`
- `tests/unit/storages/test_oss.py`

**è¿½è¸ªæ¨¡å—** (10ä¸ª):
- `src/df_test_framework/infrastructure/tracing/manager.py`
- `src/df_test_framework/infrastructure/tracing/context.py`
- `src/df_test_framework/infrastructure/tracing/decorators.py`
- `src/df_test_framework/infrastructure/tracing/exporters.py`
- `src/df_test_framework/infrastructure/tracing/integrations/database.py`
- `src/df_test_framework/infrastructure/tracing/integrations/sqlalchemy_instrumentation.py`
- `src/df_test_framework/clients/http/interceptors/tracing.py`
- `tests/unit/infrastructure/tracing/test_*.py` (5ä¸ªæ–‡ä»¶)

**æµ‹è¯•æ•°æ®æ¨¡å—** (8ä¸ª):
- `src/df_test_framework/testing/factories/presets.py`
- `src/df_test_framework/testing/data/loaders/*.py` (4ä¸ªæ–‡ä»¶)
- `src/df_test_framework/testing/assertions/response.py`
- `tests/unit/testing/test_*.py` (3ä¸ªæ–‡ä»¶)

**æŒ‡æ ‡æ¨¡å—** (8ä¸ª):
- `src/df_test_framework/infrastructure/metrics/manager.py`
- `src/df_test_framework/infrastructure/metrics/registry.py`
- `src/df_test_framework/infrastructure/metrics/types.py`
- `src/df_test_framework/infrastructure/metrics/decorators.py`
- `src/df_test_framework/infrastructure/metrics/integrations/*.py` (2ä¸ªæ–‡ä»¶)
- `tests/unit/infrastructure/metrics/test_*.py` (2ä¸ªæ–‡ä»¶)

**æ–‡æ¡£å’Œç¤ºä¾‹** (5ä¸ª):
- `docs/guides/storage.md`
- `docs/guides/distributed_tracing.md`
- `docs/guides/test_data.md`
- `docs/guides/prometheus_metrics.md`
- `examples/01-basic/storage_usage.py`

---

## ğŸ”„ å‡çº§æŒ‡å—

### ä» v3.9.x å‡çº§

æœ¬ç‰ˆæœ¬**å®Œå…¨å‘åå…¼å®¹**ï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰ä»£ç ã€‚

### å¯é€‰ä¾èµ–

å¦‚éœ€ä½¿ç”¨å®Œæ•´åŠŸèƒ½ï¼Œå¯å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š

```bash
# å­˜å‚¨å®¢æˆ·ç«¯
pip install boto3              # AWS S3 å’Œ MinIO æ”¯æŒ
pip install oss2               # é˜¿é‡Œäº‘ OSS æ”¯æŒ

# OpenTelemetry å®Œæ•´åŠŸèƒ½
pip install opentelemetry-api opentelemetry-sdk
pip install opentelemetry-exporter-otlp
pip install opentelemetry-exporter-jaeger
pip install opentelemetry-exporter-zipkin

# Prometheus å®Œæ•´åŠŸèƒ½
pip install prometheus-client

# Faker é›†æˆï¼ˆæ•°æ®å·¥å‚ï¼‰
pip install faker
```

**é›¶é…ç½®æ¨¡å¼**: ä¸å®‰è£…è¿™äº›ä¾èµ–ï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨ä½¿ç”¨ fallback å®ç°ï¼ŒåŠŸèƒ½ä¸å—å½±å“ã€‚

---

## ğŸ› å·²çŸ¥é—®é¢˜

æ— é‡å¤§å·²çŸ¥é—®é¢˜ã€‚

---

## ğŸ”® ä¸‹ä¸€æ­¥è®¡åˆ’

**Phase 2 åç»­ä»»åŠ¡**:
- **P2.5**: GraphQL å®¢æˆ·ç«¯ (é¢„è®¡ 2026-01-08)
- **P2.6**: gRPC å®¢æˆ·ç«¯ (é¢„è®¡ 2026-01-15)
- **P2.7**: WebSocket å®¢æˆ·ç«¯ (é¢„è®¡ 2026-01-22)

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºæœ¬ç‰ˆæœ¬åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼

ç‰¹åˆ«æ„Ÿè°¢ OpenTelemetry å’Œ Prometheus ç¤¾åŒºæä¾›çš„ä¼˜ç§€å·¥å…·å’Œæ–‡æ¡£ã€‚

---

## ğŸ“ åé¦ˆä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘ä»¬ï¼š

- **GitHub Issues**: https://github.com/example/df-test-framework/issues
- **æ–‡æ¡£**: https://df-test-framework.readthedocs.io
- **é‚®ç®±**: support@example.com

---

**å®Œæ•´å˜æ›´æ—¥å¿—**: [CHANGELOG.md](../../CHANGELOG.md)
**ä¸Šä¸€ç‰ˆæœ¬**: [v3.9.0](v3.9.0.md)
