"""ä» OpenAPI/Swagger è§„èŒƒç”Ÿæˆæµ‹è¯•ä»£ç 

åŸºäº OpenAPI è§„èŒƒè‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€API å®¢æˆ·ç«¯å’Œ Pydantic æ¨¡å‹ã€‚

v3.38.0 é‡å¤§æ”¹è¿›:
- Model åˆ†ç±»ç”Ÿæˆï¼ˆrequests/responses/commonï¼‰
- API æ–¹æ³•ç±»å‹åŒ–ï¼ˆå¼ºç±»å‹å‚æ•°å’Œè¿”å›å€¼ï¼‰
- é€šç”¨å“åº”åŒ…è£…å¤„ç†ï¼ˆResult[T]ï¼‰
- ç¬¦åˆæ¡†æ¶æœ€ä½³å®è·µå’Œè„šæ‰‹æ¶ç»“æ„

v3.39.1 æ”¹è¿›ï¼ˆæ™ºèƒ½ç±»å‹æ¨æ–­ï¼‰:
- åŸºäºå­—æ®µåçš„æ™ºèƒ½ç±»å‹æ¨æ–­ï¼ˆdata/pagination â†’ dictï¼Œlist/items â†’ listï¼‰
- æŸ¥è¯¢æ“ä½œè¯†åˆ«å’Œæ›´ç²¾ç¡®çš„æ–­è¨€æ¨¡æ¿
- å…¼å®¹ ok/success ä¸¤ç§å“åº”çŠ¶æ€æ ¼å¼
- é€‚é… Java åç«¯ç¼ºå°‘ Swagger æ³¨è§£çš„åœºæ™¯
"""

from __future__ import annotations

import re
from collections import defaultdict
from pathlib import Path

from ..utils import (
    AUTO_GENERATED_END,
    AUTO_GENERATED_START,
    AUTO_GENERATED_WARNING,
    USER_EXTENSIONS_HINT,
    USER_EXTENSIONS_START,
    create_file_with_merge,
    detect_project_name,
    generate_init_from_directory,
    merge_with_markers,
    to_ascii_identifier,
    to_pascal_case,
    to_snake_case,
)
from .openapi_parser import OPENAPI_AVAILABLE, APIEndpoint, OpenAPIParser


def _simplify_operation_id(operation_id: str) -> str:
    """ç®€åŒ– FastAPI è‡ªåŠ¨ç”Ÿæˆçš„ operationId

    FastAPI è‡ªåŠ¨ç”Ÿæˆçš„ operationId æ ¼å¼ä¸º: {summary}_{path}_{method}
    ä¾‹å¦‚: create_association_group_api_jym_product_associations_groups_post

    æœ¬å‡½æ•°æå–æœ‰æ„ä¹‰çš„éƒ¨åˆ†ï¼Œç§»é™¤å†—ä½™çš„è·¯å¾„å’Œæ–¹æ³•åç¼€ã€‚

    Args:
        operation_id: åŸå§‹çš„ operationId

    Returns:
        ç®€åŒ–åçš„åç§°

    Example:
        >>> _simplify_operation_id("create_association_group_api_jym_product_associations_groups_post")
        "create_association_group"
        >>> _simplify_operation_id("get_user_by_id_api_users_id_get")
        "get_user_by_id"
        >>> _simplify_operation_id("simple_action")
        "simple_action"
    """
    if not operation_id:
        return "unknown"

    name = operation_id

    # ç­–ç•¥1: æŸ¥æ‰¾ _api_ æ¨¡å¼ï¼ˆFastAPI å¸¸è§æ ¼å¼ï¼‰
    # ä¾‹å¦‚: create_group_api_xxx_yyy_post -> create_group
    api_match = re.search(r"^(.+?)_api_", name)
    if api_match:
        name = api_match.group(1)
    else:
        # ç­–ç•¥2: ç§»é™¤ _using_xxx åç¼€ï¼ˆSpring é£æ ¼ï¼Œä¼˜å…ˆæ£€æŸ¥ï¼‰
        # ä¾‹å¦‚: delete_item_using_delete -> delete_item
        for suffix in ["_using_get", "_using_post", "_using_put", "_using_delete", "_using_patch"]:
            if name.endswith(suffix):
                name = name[: -len(suffix)]
                break
        else:
            # ç­–ç•¥3: ç§»é™¤ç®€å•çš„ HTTP æ–¹æ³•åç¼€
            # ä¾‹å¦‚: get_users_get -> get_users
            for suffix in ["_get", "_post", "_put", "_delete", "_patch", "_head", "_options"]:
                if name.endswith(suffix):
                    name = name[: -len(suffix)]
                    break

    return name


def generate_from_openapi(
    spec_path: str | Path,
    *,
    output_dir: Path | None = None,
    generate_tests: bool = True,
    generate_clients: bool = True,
    generate_models: bool = True,
    tags: list[str] | None = None,
    force: bool = False,
    merge: bool = False,
) -> None:
    """ä» OpenAPI è§„èŒƒç”Ÿæˆæµ‹è¯•ä»£ç 

    Args:
        spec_path: OpenAPI è§„èŒƒæ–‡ä»¶è·¯å¾„æˆ– URL
        output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: å½“å‰ç›®å½•ï¼‰
        generate_tests: æ˜¯å¦ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        generate_clients: æ˜¯å¦ç”Ÿæˆ API å®¢æˆ·ç«¯
        generate_models: æ˜¯å¦ç”Ÿæˆ Pydantic æ¨¡å‹
        tags: è¿‡æ»¤çš„æ ‡ç­¾åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºç”Ÿæˆæ‰€æœ‰ï¼‰
        force: æ˜¯å¦å¼ºåˆ¶è¦†ç›–ï¼ˆä¸ merge äº’æ–¥ï¼‰
        merge: æ˜¯å¦ä½¿ç”¨å¢é‡åˆå¹¶æ¨¡å¼ï¼ˆv3.39.0+ï¼‰

    v3.39.0 æ–°å¢å¢é‡åˆå¹¶æ¨¡å¼:
        ä½¿ç”¨ merge=True æ—¶ï¼Œä¼šä¿ç•™ç”¨æˆ·åœ¨ USER EXTENSIONS åŒºåŸŸçš„ä¿®æ”¹ï¼Œ
        åªæ›´æ–° AUTO-GENERATED åŒºåŸŸçš„å†…å®¹ã€‚é€‚ç”¨äºåˆ†é˜¶æ®µç”Ÿæˆæˆ– API æ–°å¢æ¥å£çš„åœºæ™¯ã€‚

    Example:
        >>> # é¦–æ¬¡ç”Ÿæˆ
        >>> generate_from_openapi("swagger.json", tags=["ç”¨æˆ·ç®¡ç†"])
        >>>
        >>> # æ–°å¢æ¥å£åå¢é‡åˆå¹¶
        >>> generate_from_openapi("swagger.json", tags=["ç”¨æˆ·ç®¡ç†"], merge=True)
    """
    if not OPENAPI_AVAILABLE:
        print("âŒ é”™è¯¯: OpenAPI åŠŸèƒ½éœ€è¦å®‰è£… pyyaml åº“")
        print("   è¯·è¿è¡Œ: pip install pyyaml")
        return

    # æ£€æµ‹é¡¹ç›®åç§°å¹¶è½¬æ¢ä¸ºæœ‰æ•ˆçš„ Python åŒ…å
    raw_project_name = detect_project_name()
    if not raw_project_name:
        print("âš ï¸  é”™è¯¯: æ— æ³•æ£€æµ‹é¡¹ç›®åç§°ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œ")
        return
    # è½¬æ¢ä¸º snake_caseï¼ˆPython åŒ…åä¸èƒ½åŒ…å«è¿å­—ç¬¦ï¼‰
    project_name = to_snake_case(raw_project_name)

    if output_dir is None:
        output_dir = Path.cwd()

    # è§£æ OpenAPI è§„èŒƒ
    print(f"\nğŸ“ è§£æ OpenAPI è§„èŒƒ: {spec_path}")
    try:
        parser = OpenAPIParser(spec_path)
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        return

    # è·å– API ä¿¡æ¯
    info = parser.get_info()
    print(f"ğŸ“‹ API: {info.get('title', 'Unknown')} v{info.get('version', '1.0.0')}")

    # è·å–ç«¯ç‚¹åˆ—è¡¨
    endpoints = parser.get_endpoints(tags=tags)
    print(f"ğŸ“Š æ‰¾åˆ° {len(endpoints)} ä¸ª API ç«¯ç‚¹")

    if not endpoints:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ API ç«¯ç‚¹")
        return

    # ç”Ÿæˆç»Ÿè®¡
    generated_files = []

    # æ˜¾ç¤ºæ¨¡å¼
    if merge:
        print("ğŸ”€ ä½¿ç”¨å¢é‡åˆå¹¶æ¨¡å¼ï¼ˆä¿ç•™ç”¨æˆ·ä¿®æ”¹ï¼‰")
    elif force:
        print("âš ï¸  ä½¿ç”¨å¼ºåˆ¶è¦†ç›–æ¨¡å¼")

    # Phase 1: ç”Ÿæˆæ¨¡å‹ï¼ˆåˆ†ç±»åˆ° requests/responses/commonï¼‰
    if generate_models:
        print("\nğŸ“ ç”Ÿæˆ Pydantic æ¨¡å‹...")
        model_files = _generate_models_v2(
            parser, endpoints, project_name, output_dir, force=force, merge=merge
        )
        generated_files.extend(model_files)

    # Phase 2: ç”Ÿæˆ API å®¢æˆ·ç«¯ï¼ˆç±»å‹åŒ–æ–¹æ³•ï¼‰
    if generate_clients:
        print("\nğŸ“ ç”Ÿæˆ API å®¢æˆ·ç«¯...")
        client_files = _generate_api_clients_v2(
            endpoints, parser, project_name, output_dir, force=force, merge=merge
        )
        generated_files.extend(client_files)

    # Phase 3: ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
    if generate_tests:
        print("\nğŸ“ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
        # v3.41.1: ä¼ é€’ parser ç”¨äºè§£æ $ref å¼•ç”¨
        test_files = _generate_tests_v2(
            endpoints, project_name, output_dir, parser=parser, force=force, merge=merge
        )
        generated_files.extend(test_files)

    # è¾“å‡ºç»“æœ
    print("\nâœ… ç”Ÿæˆå®Œæˆï¼")
    print(f"\nğŸ“ å…±ç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡ä»¶:")
    for file_type, file_path in generated_files:
        print(f"  âœ“ {file_type:<20} {file_path}")

    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. åœ¨ tests/conftest.py ä¸­æ·»åŠ ä»¥ä¸‹ä»£ç ï¼ˆè‡ªåŠ¨å‘ç°æ‰€æœ‰ API ç±»ï¼‰:")
    print("     ```python")
    print("     from df_test_framework.testing.decorators import load_api_fixtures")
    print("")
    print(f'     load_api_fixtures(globals(), apis_package="{project_name}.apis")')
    print("     ```")
    print("  2. æ ¹æ®éœ€è¦å®Œå–„è¯·æ±‚/å“åº”æ¨¡å‹")
    print("  3. è¿è¡Œæµ‹è¯•: pytest tests/ -v")


# ========== Phase 1: Model åˆ†ç±»ç”Ÿæˆ ==========


def _generate_models_v2(
    parser: OpenAPIParser,
    endpoints: list[APIEndpoint],
    project_name: str,
    output_dir: Path,
    *,
    force: bool = False,
    merge: bool = False,
) -> list[tuple[str, Path]]:
    """ç”Ÿæˆåˆ†ç±»çš„ Pydantic æ¨¡å‹

    v3.38.0 æ”¹è¿›:
    - åŒºåˆ† requests/responses/common
    - æŒ‰ tag ç»„ç»‡æ–‡ä»¶
    - ç”Ÿæˆé€šç”¨å“åº”åŒ…è£…ç±»

    v3.39.0 æ”¹è¿›:
    - æ”¯æŒå¢é‡åˆå¹¶æ¨¡å¼ï¼ˆmerge=Trueï¼‰
    - åŠ¨æ€ç”Ÿæˆ __init__.py å¯¼å‡º
    """
    generated: list[tuple[str, Path]] = []

    # åˆ›å»ºç›®å½•
    models_dir = output_dir / "src" / project_name / "models"
    requests_dir = models_dir / "requests"
    responses_dir = models_dir / "responses"
    requests_dir.mkdir(parents=True, exist_ok=True)
    responses_dir.mkdir(parents=True, exist_ok=True)

    # Phase 1.1: ç”Ÿæˆ models/base.pyï¼ˆé€šç”¨å“åº”åŒ…è£…ï¼‰
    base_model_files = _generate_base_models(models_dir, force=force, merge=merge)
    generated.extend(base_model_files)

    # Phase 1.2: æŒ‰ tag åˆ†ç»„ endpoints
    endpoints_by_tag: dict[str, list[APIEndpoint]] = defaultdict(list)
    for endpoint in endpoints:
        tag = endpoint.tags[0] if endpoint.tags else "default"
        endpoints_by_tag[tag].append(endpoint)

    # Phase 1.3: ä¸ºæ¯ä¸ª tag ç”Ÿæˆ request/response æ¨¡å‹
    parser.get_schemas()

    for tag, tag_endpoints in endpoints_by_tag.items():
        # ç”Ÿæˆ requests/{tag}.py
        request_files = _generate_request_models(
            tag, tag_endpoints, parser, requests_dir, force=force, merge=merge
        )
        generated.extend(request_files)

        # ç”Ÿæˆ responses/{tag}.py
        response_files = _generate_response_models(
            tag, tag_endpoints, parser, responses_dir, force=force, merge=merge
        )
        generated.extend(response_files)

    # Phase 1.4: ç”Ÿæˆ __init__.pyï¼ˆåŠ¨æ€æ‰«æç›®å½•ï¼‰
    init_files = _generate_model_init_files(models_dir, requests_dir, responses_dir)
    generated.extend(init_files)

    return generated


def _generate_base_models(
    models_dir: Path, *, force: bool = False, merge: bool = False
) -> list[tuple[str, Path]]:
    """ç”Ÿæˆ models/base.pyï¼ˆé€šç”¨å“åº”åŒ…è£…ç±»ï¼‰

    v3.39.0: æ·»åŠ åˆ†åŒºæ ‡è®°æ”¯æŒå¢é‡åˆå¹¶
    """
    generated = []

    base_model_code = f'''"""é€šç”¨å“åº”æ¨¡å‹

æä¾›å¸¸è§çš„å“åº”åŒ…è£…ç±»ï¼Œå¦‚ Result[T]ã€PageInfo ç­‰ã€‚
"""

from typing import Generic, TypeVar

from pydantic import BaseModel, Field

T = TypeVar("T")


{AUTO_GENERATED_START}
{AUTO_GENERATED_WARNING}


class Result(BaseModel, Generic[T]):
    """é€šç”¨å“åº”åŒ…è£…

    å¸¸è§æ ¼å¼:
        {{
          "code": 200,
          "message": "success",
          "data": {{ ... }}
        }}

    ä½¿ç”¨ç¤ºä¾‹:
        >>> class UserResponse(BaseModel):
        ...     id: int
        ...     name: str
        >>>
        >>> response_data = {{"code": 200, "message": "success", "data": {{"id": 1, "name": "Alice"}}}}
        >>> result = Result[UserResponse](**response_data)
        >>> print(result.data.name)  # Alice
    """

    code: int = Field(..., description="ä¸šåŠ¡çŠ¶æ€ç ")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")
    data: T | None = Field(None, description="å“åº”æ•°æ®")


class PageInfo(BaseModel, Generic[T]):
    """åˆ†é¡µå“åº”

    å¸¸è§æ ¼å¼:
        {{
          "total": 100,
          "current": 1,
          "size": 20,
          "records": [...]
        }}
    """

    total: int = Field(..., description="æ€»è®°å½•æ•°")
    current: int = Field(default=1, description="å½“å‰é¡µç ")
    size: int = Field(default=20, description="æ¯é¡µå¤§å°")
    records: list[T] = Field(default_factory=list, description="è®°å½•åˆ—è¡¨")


{AUTO_GENERATED_END}


{USER_EXTENSIONS_START}
{USER_EXTENSIONS_HINT}


__all__ = ["Result", "PageInfo"]
'''

    file_path = models_dir / "base.py"
    success, action = create_file_with_merge(file_path, base_model_code, force=force, merge=merge)

    if success:
        generated.append(
            ("Model (Base)", Path("src") / file_path.relative_to(models_dir.parent.parent))
        )
        if action == "merged":
            print(f"  ğŸ”€ åˆå¹¶: {file_path.name}")
    elif "skipped" not in action:
        print(f"  âš ï¸  {action}: {file_path.name}")

    return generated


def _generate_request_models(
    tag: str,
    endpoints: list[APIEndpoint],
    parser: OpenAPIParser,
    requests_dir: Path,
    *,
    force: bool = False,
    merge: bool = False,
) -> list[tuple[str, Path]]:
    """ç”Ÿæˆè¯·æ±‚æ¨¡å‹æ–‡ä»¶

    v3.39.0: æ·»åŠ åˆ†åŒºæ ‡è®°æ”¯æŒå¢é‡åˆå¹¶
    """
    generated = []

    # æ”¶é›†è¯¥ tag ä¸‹æ‰€æœ‰çš„ request models
    request_models = []
    for endpoint in endpoints:
        if endpoint.request_body:
            model_info = _extract_request_model_info(endpoint, parser)
            if model_info:
                request_models.append(model_info)

    if not request_models:
        return generated

    # ç”Ÿæˆæ–‡ä»¶å†…å®¹ï¼ˆä½¿ç”¨ ASCII æ ‡è¯†ç¬¦å¤„ç†ä¸­æ–‡ tagï¼‰
    tag_id = to_ascii_identifier(tag)
    file_name = f"{tag_id}.py"
    file_path = requests_dir / file_name

    code = _build_request_models_file(tag, tag_id, request_models)

    success, action = create_file_with_merge(file_path, code, force=force, merge=merge)

    if success:
        generated.append(
            (
                "Model (Request)",
                Path("src") / file_path.relative_to(requests_dir.parent.parent.parent),
            )
        )
        if action == "merged":
            print(f"  ğŸ”€ åˆå¹¶: {file_path.name}")
    elif "skipped" not in action:
        print(f"  âš ï¸  {action}: {file_path.name}")

    return generated


def _generate_response_models(
    tag: str,
    endpoints: list[APIEndpoint],
    parser: OpenAPIParser,
    responses_dir: Path,
    *,
    force: bool = False,
    merge: bool = False,
) -> list[tuple[str, Path]]:
    """ç”Ÿæˆå“åº”æ¨¡å‹æ–‡ä»¶

    v3.39.0: æ·»åŠ åˆ†åŒºæ ‡è®°æ”¯æŒå¢é‡åˆå¹¶
    """
    generated = []

    # æ”¶é›†è¯¥ tag ä¸‹æ‰€æœ‰çš„ response models
    response_models = []
    for endpoint in endpoints:
        model_info = _extract_response_model_info(endpoint, parser)
        if model_info:
            response_models.append(model_info)

    if not response_models:
        return generated

    # ç”Ÿæˆæ–‡ä»¶å†…å®¹ï¼ˆä½¿ç”¨ ASCII æ ‡è¯†ç¬¦å¤„ç†ä¸­æ–‡ tagï¼‰
    tag_id = to_ascii_identifier(tag)
    file_name = f"{tag_id}.py"
    file_path = responses_dir / file_name

    code = _build_response_models_file(tag, tag_id, response_models)

    success, action = create_file_with_merge(file_path, code, force=force, merge=merge)

    if success:
        generated.append(
            (
                "Model (Response)",
                Path("src") / file_path.relative_to(responses_dir.parent.parent.parent),
            )
        )
        if action == "merged":
            print(f"  ğŸ”€ åˆå¹¶: {file_path.name}")
    elif "skipped" not in action:
        print(f"  âš ï¸  {action}: {file_path.name}")

    return generated


def _extract_request_model_info(endpoint: APIEndpoint, parser: OpenAPIParser) -> dict | None:
    """ä» endpoint æå–è¯·æ±‚æ¨¡å‹ä¿¡æ¯"""
    if not endpoint.request_body:
        return None

    # ç”Ÿæˆæ¨¡å‹åç§°ï¼ˆç®€åŒ–åçš„ operationIdï¼‰
    simplified_name = _simplify_operation_id(endpoint.operation_id)
    model_name = to_pascal_case(simplified_name) + "Request"

    # è·å– schema å¹¶è§£æ $ref å¼•ç”¨
    schema = endpoint.request_body.get("schema", {})
    if "$ref" in schema:
        schema = parser._resolve_ref(schema["$ref"])

    return {
        "name": model_name,
        "schema": schema,
        "description": endpoint.summary or f"{model_name} è¯·æ±‚æ¨¡å‹",
    }


def _extract_response_model_info(endpoint: APIEndpoint, parser: OpenAPIParser) -> dict | None:
    """ä» endpoint æå–å“åº”æ¨¡å‹ä¿¡æ¯

    å³ä½¿ Swagger æ–‡æ¡£ä¸­æ²¡æœ‰è¯¦ç»†çš„å“åº” schemaï¼Œä¹Ÿä¼šç”ŸæˆåŸºäº Result[dict] çš„å ä½ç¬¦æ¨¡å‹ã€‚
    """
    # å°è¯•è·å– 200/201 å“åº”
    success_response = endpoint.get_success_response()
    if not success_response:
        return None

    # ç”Ÿæˆæ¨¡å‹åç§°ï¼ˆç®€åŒ–åçš„ operationIdï¼‰
    simplified_name = _simplify_operation_id(endpoint.operation_id)
    model_name = to_pascal_case(simplified_name) + "Response"

    # è·å– schema å¹¶è§£æ $ref å¼•ç”¨
    schema = success_response.get("schema", {})
    if "$ref" in schema:
        schema = parser._resolve_ref(schema["$ref"])

    # æ ‡è®°æ˜¯å¦æœ‰è¯¦ç»†çš„ schemaï¼ˆç”¨äºå†³å®šç”Ÿæˆå®Œæ•´æ¨¡å‹è¿˜æ˜¯å ä½ç¬¦ï¼‰
    has_detailed_schema = bool(schema and schema.get("properties"))

    return {
        "name": model_name,
        "schema": schema,
        "description": success_response.get("description", f"{model_name} å“åº”æ¨¡å‹"),
        "has_detailed_schema": has_detailed_schema,
    }


def _build_request_models_file(tag: str, tag_id: str, models: list[dict]) -> str:
    """æ„å»ºè¯·æ±‚æ¨¡å‹æ–‡ä»¶å†…å®¹

    Args:
        tag: åŸå§‹ tag åç§°ï¼ˆç”¨äºæ³¨é‡Šï¼‰
        tag_id: ASCII æ ‡è¯†ç¬¦ï¼ˆç”¨äºå¯¼å…¥è·¯å¾„ï¼‰
        models: æ¨¡å‹ä¿¡æ¯åˆ—è¡¨

    v3.39.0: æ·»åŠ åˆ†åŒºæ ‡è®°æ”¯æŒå¢é‡åˆå¹¶
    v3.41.1: ä½¿ç”¨ BaseRequest åŸºç±»ï¼ˆä½äº core.modelsï¼Œé»˜è®¤æ’é™¤ None å€¼ï¼‰
    """
    # å»é‡
    unique_models = {m["name"]: m for m in models}

    model_classes = []
    for model_info in unique_models.values():
        # v3.41.1: è¯·æ±‚æ¨¡å‹ä½¿ç”¨ BaseRequest åŸºç±»
        model_code = _build_model_class(
            model_info["name"],
            model_info["schema"],
            model_info["description"],
            base_class="BaseRequest",
        )
        model_classes.append(model_code)

    all_names = list(unique_models.keys())

    code = f'''"""è‡ªåŠ¨ç”Ÿæˆçš„è¯·æ±‚æ¨¡å‹ - {tag}

ä» OpenAPI è§„èŒƒç”Ÿæˆã€‚
æ¨¡å—æ ‡è¯†: {tag_id}

v3.41.1 æ”¹è¿›ï¼š
- ä½¿ç”¨ BaseRequest åŸºç±»ï¼ˆä½äº core.modelsï¼‰ï¼Œåºåˆ—åŒ–æ—¶è‡ªåŠ¨æ’é™¤ None å€¼
- å­—æ®µåä½¿ç”¨ Python æƒ¯ä¾‹çš„ snake_caseï¼Œåºåˆ—åŒ–æ—¶ä½¿ç”¨åŸå§‹çš„ camelCase
"""

from typing import Any

from pydantic import Field
from df_test_framework import BaseRequest


{AUTO_GENERATED_START}
{AUTO_GENERATED_WARNING}

{chr(10).join(model_classes)}

{AUTO_GENERATED_END}


{USER_EXTENSIONS_START}
{USER_EXTENSIONS_HINT}


__all__ = {all_names}
'''

    return code


def _build_response_models_file(tag: str, tag_id: str, models: list[dict]) -> str:
    """æ„å»ºå“åº”æ¨¡å‹æ–‡ä»¶å†…å®¹

    Args:
        tag: åŸå§‹ tag åç§°ï¼ˆç”¨äºæ³¨é‡Šï¼‰
        tag_id: ASCII æ ‡è¯†ç¬¦ï¼ˆç”¨äºå¯¼å…¥è·¯å¾„ï¼‰
        models: æ¨¡å‹ä¿¡æ¯åˆ—è¡¨

    v3.38.1 æ”¹è¿›ï¼š
    - ä¸ºæ²¡æœ‰è¯¦ç»† schema çš„å“åº”ç”ŸæˆåŸºäº Result[dict] çš„å ä½ç¬¦æ¨¡å‹
    - æ·»åŠ  TODO æ³¨é‡Šæç¤ºç”¨æˆ·å®Œå–„æ¨¡å‹

    v3.39.0: æ·»åŠ åˆ†åŒºæ ‡è®°æ”¯æŒå¢é‡åˆå¹¶
    """
    # å»é‡
    unique_models = {m["name"]: m for m in models}

    model_classes = []
    for model_info in unique_models.values():
        has_detailed_schema = model_info.get("has_detailed_schema", False)
        if has_detailed_schema:
            # æœ‰è¯¦ç»† schemaï¼Œç”Ÿæˆå®Œæ•´æ¨¡å‹
            model_code = _build_model_class(
                model_info["name"], model_info["schema"], model_info["description"]
            )
        else:
            # æ²¡æœ‰è¯¦ç»† schemaï¼Œç”Ÿæˆå ä½ç¬¦æ¨¡å‹
            model_code = _build_placeholder_response_model(
                model_info["name"], model_info["description"]
            )
        model_classes.append(model_code)

    all_names = list(unique_models.keys())

    code = f'''"""è‡ªåŠ¨ç”Ÿæˆçš„å“åº”æ¨¡å‹ - {tag}

ä» OpenAPI è§„èŒƒç”Ÿæˆã€‚
æ¨¡å—æ ‡è¯†: {tag_id}

æ³¨æ„ï¼š
- å­—æ®µåä½¿ç”¨ Python æƒ¯ä¾‹çš„ snake_caseï¼Œä½†åºåˆ—åŒ–æ—¶ä½¿ç”¨åŸå§‹çš„ camelCase
- å¦‚æœ Swagger æ–‡æ¡£æœªå®šä¹‰å“åº”ç»“æ„ï¼Œä¼šç”ŸæˆåŸºäº Result[dict] çš„å ä½ç¬¦æ¨¡å‹
- è¯·æ ¹æ®å®é™… API å“åº”ç»“æ„å®Œå–„è¿™äº›æ¨¡å‹
"""

from typing import Any

from pydantic import BaseModel, ConfigDict, Field
from ..base import Result


{AUTO_GENERATED_START}
{AUTO_GENERATED_WARNING}

{chr(10).join(model_classes)}

{AUTO_GENERATED_END}


{USER_EXTENSIONS_START}
{USER_EXTENSIONS_HINT}


__all__ = {all_names}
'''

    return code


def _build_placeholder_response_model(model_name: str, description: str) -> str:
    """æ„å»ºå ä½ç¬¦å“åº”æ¨¡å‹ï¼ˆå½“ Swagger æœªå®šä¹‰å“åº” schema æ—¶ä½¿ç”¨ï¼‰

    ç”ŸæˆåŸºäº Result[dict] çš„ç®€å•æ¨¡å‹ï¼Œç”¨æˆ·å¯ä»¥åç»­æ ¹æ®å®é™…å“åº”ç»“æ„å®Œå–„ã€‚
    """
    return f'''class {model_name}(Result[dict[str, Any]]):
    """{description}

    æ³¨æ„ï¼šSwagger æ–‡æ¡£æœªå®šä¹‰æ­¤å“åº”çš„è¯¦ç»†ç»“æ„ã€‚
    æ­¤æ¨¡å‹åŸºäºé€šç”¨ Result[dict] ç”Ÿæˆï¼Œè¯·æ ¹æ®å®é™… API å“åº”å®Œå–„ã€‚

    å¸¸è§å“åº”æ ¼å¼:
        {{"code": 200, "message": "success", "data": {{...}}}}

    ä½¿ç”¨ç¤ºä¾‹:
        >>> response = api.some_method(request)
        >>> if response.code == 200:
        ...     print(response.data)  # dict[str, Any]

    TODO: æ ¹æ®å®é™…å“åº”ç»“æ„å®šä¹‰å…·ä½“å­—æ®µ
    """
    pass
'''


def _build_model_class(
    model_name: str,
    schema: dict,
    description: str,
    base_class: str = "BaseModel",
) -> str:
    """æ„å»º Pydantic æ¨¡å‹ç±»ä»£ç 

    è‡ªåŠ¨å¤„ç† Java/Python å‘½åè½¬æ¢ï¼š
    - Java camelCase -> Python snake_case
    - ä¿ç•™åŸå§‹åç§°ä½œä¸º alias

    Args:
        model_name: æ¨¡å‹ç±»å
        schema: OpenAPI schema å®šä¹‰
        description: æ¨¡å‹æè¿°
        base_class: åŸºç±»åç§°ï¼Œé»˜è®¤ "BaseModel"ï¼Œè¯·æ±‚æ¨¡å‹ä½¿ç”¨ "BaseRequest"

    v3.41.1 æ”¹è¿›ï¼š
    - æ”¯æŒæŒ‡å®šåŸºç±»
    - è¯·æ±‚æ¨¡å‹ä½¿ç”¨ BaseRequestï¼ˆä½äº core.modelsï¼Œé»˜è®¤æ’é™¤ None å€¼ï¼‰
    """
    properties = schema.get("properties", {})
    required = schema.get("required", [])

    # BaseRequest å·²ç»åŒ…å« model_configï¼Œä¸éœ€è¦é‡å¤å®šä¹‰
    need_model_config = base_class != "BaseRequest"
    model_config_line = (
        "\n    model_config = ConfigDict(populate_by_name=True)\n" if need_model_config else ""
    )

    if not properties:
        # ç©ºæ¨¡å‹
        if need_model_config:
            return f'''class {model_name}({base_class}):
    """{description}"""

    model_config = ConfigDict(populate_by_name=True)
    pass
'''
        else:
            return f'''class {model_name}({base_class}):
    """{description}"""
    pass
'''

    # ç”Ÿæˆå­—æ®µ
    fields = []
    for original_name, field_schema in properties.items():
        # è½¬æ¢å­—æ®µåï¼šcamelCase -> snake_case
        python_name = to_snake_case(original_name)
        # v3.39.1: ä¼ é€’å­—æ®µåè¿›è¡Œæ™ºèƒ½ç±»å‹æ¨æ–­
        field_type = _get_python_type(field_schema, field_name=original_name)
        is_required = original_name in required
        field_desc = field_schema.get("description", f"{original_name} å­—æ®µ")

        # å¦‚æœè½¬æ¢ååç§°ä¸åŒï¼Œæ·»åŠ  alias
        if python_name != original_name:
            alias_param = f', alias="{original_name}"'
        else:
            alias_param = ""

        if is_required:
            fields.append(
                f'    {python_name}: {field_type} = Field(..., description="{field_desc}"{alias_param})'
            )
        else:
            fields.append(
                f'    {python_name}: {field_type} | None = Field(None, description="{field_desc}"{alias_param})'
            )

    fields_code = "\n".join(fields)

    return f'''class {model_name}({base_class}):
    """{description}"""
{model_config_line}
{fields_code}
'''


def _get_python_type(schema: dict, field_name: str | None = None) -> str:
    """å°† OpenAPI ç±»å‹è½¬æ¢ä¸º Python ç±»å‹

    v3.39.1 æ”¹è¿›:
    - æ”¯æŒåŸºäºå­—æ®µåçš„æ™ºèƒ½ç±»å‹æ¨æ–­
    - å½“ Swagger æ³¨è§£ä¸å®Œæ•´æ—¶ï¼Œæ ¹æ®å¸¸è§å‘½åæƒ¯ä¾‹æ¨æ–­æ­£ç¡®ç±»å‹
    - å¤„ç† $ref å¼•ç”¨ç±»å‹ï¼Œè½¬æ¢ä¸º dict[str, Any]

    v3.41.1 æ”¹è¿›:
    - ä¼˜å…ˆä½¿ç”¨åç«¯æ˜ç¡®å®šä¹‰çš„ç±»å‹
    - åªæœ‰å½“ç±»å‹ä¸º object/$ref æ—¶æ‰ä½¿ç”¨æ™ºèƒ½æ¨æ–­

    Args:
        schema: OpenAPI schema å®šä¹‰
        field_name: å­—æ®µåç§°ï¼Œç”¨äºæ™ºèƒ½ç±»å‹æ¨æ–­

    Returns:
        Python ç±»å‹å­—ç¬¦ä¸²
    """
    schema_type = schema.get("type")

    # åŸºç¡€ç±»å‹æ˜ å°„ï¼ˆå½“åç«¯æ˜ç¡®å®šä¹‰æ—¶ç›´æ¥ä½¿ç”¨ï¼‰
    type_mapping = {
        "string": "str",
        "integer": "int",
        "number": "float",
        "boolean": "bool",
    }

    # 1. ä¼˜å…ˆä½¿ç”¨åç«¯æ˜ç¡®å®šä¹‰çš„åŸºç¡€ç±»å‹
    if schema_type in type_mapping:
        return type_mapping[schema_type]

    # 2. å¤„ç†æ•°ç»„ç±»å‹
    if schema_type == "array" and "items" in schema:
        item_type = _get_python_type(schema["items"])
        return f"list[{item_type}]"

    # 3. å½“ç±»å‹ä¸º object/$ref æˆ–æœªå®šä¹‰æ—¶ï¼Œä½¿ç”¨æ™ºèƒ½å­—æ®µåæ¨æ–­
    # è¿™æ˜¯ Java åç«¯ Swagger æ³¨è§£ä¸å®Œå–„çš„å¸¸è§æƒ…å†µ
    is_ambiguous_type = schema_type == "object" or schema_type is None or "$ref" in schema

    if is_ambiguous_type and field_name:
        field_lower = field_name.lower()

        # v3.41.1: å¸¸è§çš„åº”è¯¥æ˜¯ str ç±»å‹çš„å­—æ®µå
        # è¿™äº›å­—æ®µé€šå¸¸è¢« Java åç«¯é”™è¯¯åœ°æ ‡æ³¨ä¸º object æˆ–æ²¡æœ‰æ˜ç¡®ç±»å‹
        string_patterns = [
            "msg",  # æ¶ˆæ¯
            "message",  # æ¶ˆæ¯
            "error",  # é”™è¯¯ä¿¡æ¯
            "error_msg",  # é”™è¯¯æ¶ˆæ¯
            "error_message",  # é”™è¯¯æ¶ˆæ¯
            "status",  # çŠ¶æ€ï¼ˆé€šå¸¸æ˜¯ "ok"/"fail" ç­‰å­—ç¬¦ä¸²ï¼‰
            "reason",  # åŸå› 
            "description",  # æè¿°
            "title",  # æ ‡é¢˜
            "remark",  # å¤‡æ³¨
            "remarks",  # å¤‡æ³¨
            "note",  # æ³¨é‡Š
            "notes",  # æ³¨é‡Š
        ]

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§å­—ç¬¦ä¸²å­—æ®µ
        for pattern in string_patterns:
            if field_lower == pattern or field_lower.endswith(f"_{pattern}"):
                return "str"

        # å¸¸è§çš„åº”è¯¥æ˜¯ dict ç±»å‹çš„å­—æ®µå
        dict_patterns = [
            "data",  # å“åº”æ•°æ®å®¹å™¨
            "pagination",  # åˆ†é¡µä¿¡æ¯
            "params",  # å‚æ•°å¯¹è±¡
            "result",  # ç»“æœå¯¹è±¡
            "info",  # ä¿¡æ¯å¯¹è±¡
            "config",  # é…ç½®å¯¹è±¡
            "settings",  # è®¾ç½®å¯¹è±¡
            "options",  # é€‰é¡¹å¯¹è±¡
            "metadata",  # å…ƒæ•°æ®
            "extra",  # é¢å¤–ä¿¡æ¯
            "attributes",  # å±æ€§å¯¹è±¡
            "properties",  # å±æ€§å¯¹è±¡
        ]

        # å¸¸è§çš„åº”è¯¥æ˜¯ list ç±»å‹çš„å­—æ®µå
        list_patterns = [
            "list",  # åˆ—è¡¨æ•°æ®
            "items",  # é¡¹ç›®åˆ—è¡¨
            "records",  # è®°å½•åˆ—è¡¨
            "rows",  # è¡Œæ•°æ®
            "results",  # ç»“æœåˆ—è¡¨
            "ids",  # ID åˆ—è¡¨
            "names",  # åç§°åˆ—è¡¨
            "codes",  # ç¼–ç åˆ—è¡¨
            "values",  # å€¼åˆ—è¡¨
            "tags",  # æ ‡ç­¾åˆ—è¡¨
            "permissions",  # æƒé™åˆ—è¡¨
            "roles",  # è§’è‰²åˆ—è¡¨
        ]

        # æ£€æŸ¥ dict æ¨¡å¼
        for pattern in dict_patterns:
            if field_lower == pattern or field_lower.endswith(f"_{pattern}"):
                return "dict[str, Any]"

        # æ£€æŸ¥ list æ¨¡å¼
        for pattern in list_patterns:
            if field_lower == pattern or field_lower.endswith(f"_{pattern}"):
                return "list[Any]"

    return type_mapping.get(schema_type, "Any")


def _generate_model_init_files(
    models_dir: Path, requests_dir: Path, responses_dir: Path
) -> list[tuple[str, Path]]:
    """ç”Ÿæˆ models/__init__.py å’Œå­ç›®å½•çš„ __init__.py

    v3.39.0 æ”¹è¿›ï¼š
    - åŠ¨æ€æ‰«æç›®å½•ç”Ÿæˆå¯¼å‡ºåˆ—è¡¨
    - è§£å†³åˆ†é˜¶æ®µç”Ÿæˆæ—¶å¯¼å‡ºä¸ç´¯ç§¯çš„é—®é¢˜
    - __init__.py æ€»æ˜¯æ ¹æ®å®é™…æ–‡ä»¶é‡æ–°ç”Ÿæˆ
    """
    generated = []

    # models/__init__.pyï¼ˆå¯¼å‡º base æ¨¡å— + å­åŒ…å†…å®¹ï¼‰
    models_init_code = f'''"""æ•°æ®æ¨¡å‹æ¨¡å—

ç»„ç»‡ç»“æ„:
- base.py: é€šç”¨å“åº”åŒ…è£…ç±»ï¼ˆResult[T]ã€PageInfoç­‰ï¼‰
- requests/: è¯·æ±‚æ¨¡å‹
- responses/: å“åº”æ¨¡å‹
"""

{AUTO_GENERATED_START}
{AUTO_GENERATED_WARNING}

from .base import PageInfo, Result
from .requests import *  # noqa: F401, F403
from .responses import *  # noqa: F401, F403

__all__ = ["PageInfo", "Result", "requests", "responses"]

{AUTO_GENERATED_END}


{USER_EXTENSIONS_START}
{USER_EXTENSIONS_HINT}

'''

    models_init_path = models_dir / "__init__.py"
    # ä½¿ç”¨å¢é‡åˆå¹¶ï¼šä¿ç•™ç”¨æˆ·æ‰©å±•åŒºåŸŸ
    if models_init_path.exists():
        existing = models_init_path.read_text(encoding="utf-8")
        if USER_EXTENSIONS_START in existing and AUTO_GENERATED_START in existing:
            models_init_code = merge_with_markers(existing, models_init_code)

    models_init_path.write_text(models_init_code, encoding="utf-8")
    generated.append(
        (
            "Model (Init)",
            Path("src") / models_init_path.relative_to(models_dir.parent.parent),
        )
    )

    # requests/__init__.pyï¼ˆåŠ¨æ€æ‰«æç”Ÿæˆï¼‰
    requests_init_code = generate_init_from_directory(requests_dir, docstring="è¯·æ±‚æ¨¡å‹æ¨¡å—")
    requests_init_path = requests_dir / "__init__.py"
    # ä½¿ç”¨å¢é‡åˆå¹¶ï¼šä¿ç•™ç”¨æˆ·æ‰©å±•åŒºåŸŸ
    if requests_init_path.exists():
        existing = requests_init_path.read_text(encoding="utf-8")
        if USER_EXTENSIONS_START in existing and AUTO_GENERATED_START in existing:
            requests_init_code = merge_with_markers(existing, requests_init_code)

    requests_init_path.write_text(requests_init_code, encoding="utf-8")

    # responses/__init__.pyï¼ˆåŠ¨æ€æ‰«æç”Ÿæˆï¼‰
    responses_init_code = generate_init_from_directory(responses_dir, docstring="å“åº”æ¨¡å‹æ¨¡å—")
    responses_init_path = responses_dir / "__init__.py"
    # ä½¿ç”¨å¢é‡åˆå¹¶ï¼šä¿ç•™ç”¨æˆ·æ‰©å±•åŒºåŸŸ
    if responses_init_path.exists():
        existing = responses_init_path.read_text(encoding="utf-8")
        if USER_EXTENSIONS_START in existing and AUTO_GENERATED_START in existing:
            responses_init_code = merge_with_markers(existing, responses_init_code)

    responses_init_path.write_text(responses_init_code, encoding="utf-8")

    return generated


# ========== Phase 2: API å®¢æˆ·ç«¯ç±»å‹åŒ– ==========


def _generate_api_clients_v2(
    endpoints: list[APIEndpoint],
    parser: OpenAPIParser,
    project_name: str,
    output_dir: Path,
    *,
    force: bool = False,
    merge: bool = False,
) -> list[tuple[str, Path]]:
    """ç”Ÿæˆç±»å‹åŒ–çš„ API å®¢æˆ·ç«¯

    v3.38.0 æ”¹è¿›:
    - æ–¹æ³•å‚æ•°å’Œè¿”å›å€¼ä½¿ç”¨ Pydantic æ¨¡å‹
    - è‡ªåŠ¨å¯¼å…¥å¯¹åº”çš„ request/response æ¨¡å‹
    - åˆ©ç”¨ BaseAPI çš„è‡ªåŠ¨åºåˆ—åŒ–èƒ½åŠ›

    v3.39.0 æ”¹è¿›:
    - æ”¯æŒå¢é‡åˆå¹¶æ¨¡å¼ï¼ˆmerge=Trueï¼‰
    """
    generated: list[tuple[str, Path]] = []

    # æŒ‰æ ‡ç­¾åˆ†ç»„
    endpoints_by_tag: dict[str, list[APIEndpoint]] = defaultdict(list)
    for endpoint in endpoints:
        tag = endpoint.tags[0] if endpoint.tags else "default"
        endpoints_by_tag[tag].append(endpoint)

    apis_dir = output_dir / "src" / project_name / "apis"
    apis_dir.mkdir(parents=True, exist_ok=True)

    # ä¸ºæ¯ä¸ªæ ‡ç­¾ç”Ÿæˆä¸€ä¸ªå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ ASCII æ ‡è¯†ç¬¦å¤„ç†ä¸­æ–‡ tagï¼‰
    for tag, tag_endpoints in endpoints_by_tag.items():
        tag_id = to_ascii_identifier(tag)
        file_name = f"{tag_id}_api.py"
        file_path = apis_dir / file_name

        # ç”Ÿæˆå®¢æˆ·ç«¯ä»£ç 
        content = _build_typed_client_code(tag, tag_id, tag_endpoints, project_name)

        success, action = create_file_with_merge(file_path, content, force=force, merge=merge)

        if success:
            generated.append(("API Client", file_path.relative_to(output_dir)))
            if action == "merged":
                print(f"  ğŸ”€ åˆå¹¶: {file_path.name}")
        elif "skipped" in action:
            print(f"  â­ï¸  è·³è¿‡: {file_path.name}ï¼ˆå·²å­˜åœ¨ï¼‰")
        else:
            print(f"  âš ï¸  {action}: {file_path.name}")

    # ç”Ÿæˆ apis/__init__.pyï¼ˆåŠ¨æ€æ‰«æç”Ÿæˆï¼‰
    apis_init_code = generate_init_from_directory(apis_dir, docstring="API å®¢æˆ·ç«¯æ¨¡å—")
    apis_init_path = apis_dir / "__init__.py"
    # ä½¿ç”¨å¢é‡åˆå¹¶ï¼šä¿ç•™ç”¨æˆ·æ‰©å±•åŒºåŸŸ
    if apis_init_path.exists():
        existing = apis_init_path.read_text(encoding="utf-8")
        if USER_EXTENSIONS_START in existing and AUTO_GENERATED_START in existing:
            apis_init_code = merge_with_markers(existing, apis_init_code)

    apis_init_path.write_text(apis_init_code, encoding="utf-8")
    generated.append(("API (Init)", apis_init_path.relative_to(output_dir)))

    return generated


def _build_typed_client_code(
    tag: str, tag_id: str, endpoints: list[APIEndpoint], project_name: str
) -> str:
    """æ„å»ºç±»å‹åŒ–çš„ API å®¢æˆ·ç«¯ä»£ç 

    Args:
        tag: åŸå§‹ tag åç§°ï¼ˆç”¨äºæ³¨é‡Šï¼‰
        tag_id: ASCII æ ‡è¯†ç¬¦ï¼ˆç”¨äºç±»åã€fixtureåã€å¯¼å…¥è·¯å¾„ï¼‰
        endpoints: API ç«¯ç‚¹åˆ—è¡¨
        project_name: é¡¹ç›®åç§°

    v3.38.0 æ”¹è¿›:
    - å¯¼å…¥ request/response æ¨¡å‹
    - æ–¹æ³•ç­¾åä½¿ç”¨å¼ºç±»å‹
    - åˆ©ç”¨ BaseAPI è‡ªåŠ¨åºåˆ—åŒ–/è§£æ
    """
    class_name = to_pascal_case(tag_id) + "API"
    fixture_name = tag_id + "_api"
    tag_snake = tag_id

    # è·å–å…¬å…±è·¯å¾„å‰ç¼€
    paths = [e.path for e in endpoints]
    base_path = _get_common_path_prefix(paths)

    # æ”¶é›†éœ€è¦å¯¼å…¥çš„æ¨¡å‹ï¼ˆä½¿ç”¨ç®€åŒ–åçš„åç§°ï¼‰
    request_models = set()
    response_models = set()

    for endpoint in endpoints:
        if endpoint.request_body:
            simplified_name = _simplify_operation_id(endpoint.operation_id)
            request_models.add(to_pascal_case(simplified_name) + "Request")

        if endpoint.get_success_response():
            simplified_name = _simplify_operation_id(endpoint.operation_id)
            response_models.add(to_pascal_case(simplified_name) + "Response")

    # ç”Ÿæˆå¯¼å…¥è¯­å¥
    imports = []
    if request_models:
        imports.append(
            f"from ..models.requests.{tag_snake} import (\n    "
            + ",\n    ".join(sorted(request_models))
            + ",\n)"
        )
    if response_models:
        imports.append(
            f"from ..models.responses.{tag_snake} import (\n    "
            + ",\n    ".join(sorted(response_models))
            + ",\n)"
        )

    imports_code = "\n".join(imports) if imports else ""

    # ç”Ÿæˆæ–¹æ³•
    methods = []
    for endpoint in endpoints:
        method_code = _build_typed_method_code(endpoint, base_path)
        methods.append(method_code)

    code = f'''"""è‡ªåŠ¨ç”Ÿæˆçš„ API å®¢æˆ·ç«¯ - {tag}

ä» OpenAPI è§„èŒƒç”Ÿæˆï¼ŒåŸºäº df-test-framework v3.38.0 æœ€ä½³å®è·µã€‚
ç±»å: {class_name}
æ¨¡å—æ ‡è¯†: {tag_id}

v3.38.0 ç‰¹æ€§:
- âœ… å¼ºç±»å‹æ–¹æ³•ç­¾åï¼ˆPydantic è¯·æ±‚/å“åº”æ¨¡å‹ï¼‰
- âœ… BaseAPI è‡ªåŠ¨åºåˆ—åŒ–è¯·æ±‚æ¨¡å‹
- âœ… BaseAPI è‡ªåŠ¨è§£æå“åº”æ¨¡å‹
- âœ… @api_class è£…é¥°å™¨è‡ªåŠ¨æ³¨å†Œ fixture
- âœ… IDE æ™ºèƒ½æç¤ºå’Œç±»å‹æ£€æŸ¥

v3.39.0 æ–°å¢:
- âœ… æ”¯æŒå¢é‡åˆå¹¶ï¼ˆ--force é€‰é¡¹ä¿ç•™ç”¨æˆ·æ‰©å±•ï¼‰
- âœ… ç”¨æˆ·æ‰©å±•åŒºåŸŸä¿ç•™è‡ªå®šä¹‰ä»£ç 

ä½¿ç”¨ç¤ºä¾‹:
    # æ–¹å¼1: ç›´æ¥å®ä¾‹åŒ–
    from {project_name}.models.requests.{tag_snake} import XxxRequest
    from {project_name}.models.responses.{tag_snake} import XxxResponse

    api = {class_name}(http_client)
    request = XxxRequest(field="value")
    response: XxxResponse = api.xxx_method(request)

    # æ–¹å¼2: ä½¿ç”¨ fixtureï¼ˆæ¨èï¼‰
    def test_example({fixture_name}):
        request = XxxRequest(field="value")
        response = {fixture_name}.xxx_method(request)
        assert response.code == 200
"""

from typing import Any

from df_test_framework import BaseAPI, HttpClient
from df_test_framework.testing.decorators import api_class

{imports_code}


{AUTO_GENERATED_START}
{AUTO_GENERATED_WARNING}


@api_class("{fixture_name}")
class {class_name}(BaseAPI):
    """{tag} API å®¢æˆ·ç«¯

    è‡ªåŠ¨ä» OpenAPI è§„èŒƒç”Ÿæˆã€‚

    æ¥å£å‰ç¼€: {base_path or "/"}
    Fixture åç§°: {fixture_name}
    """

    def __init__(self, http_client: HttpClient):
        super().__init__(http_client)
        self.base_path = "{base_path}"

{chr(10).join(methods)}


{AUTO_GENERATED_END}


{USER_EXTENSIONS_START}
{USER_EXTENSIONS_HINT}


__all__ = ["{class_name}"]
'''

    return code


def _build_typed_method_code(endpoint: APIEndpoint, base_path: str = "") -> str:
    """æ„å»ºç±»å‹åŒ–çš„æ–¹æ³•ä»£ç 

    v3.38.0 æ”¹è¿›:
    - request: XXXRequest å‚æ•°
    - -> XXXResponse è¿”å›å€¼
    - ä½¿ç”¨ BaseAPI çš„ model å‚æ•°
    """
    # ç”Ÿæˆæ–¹æ³•åï¼ˆä½¿ç”¨ç®€åŒ–åçš„åç§°ï¼‰
    simplified_name = _simplify_operation_id(endpoint.operation_id)
    method_name = to_snake_case(simplified_name)

    # è·¯å¾„å‚æ•°
    path_params = endpoint.get_path_params()
    query_params = endpoint.get_query_params()

    # è¯·æ±‚æ¨¡å‹ï¼ˆä½¿ç”¨ç®€åŒ–åçš„åç§°ï¼‰
    request_model_name = None
    if endpoint.request_body:
        request_model_name = to_pascal_case(simplified_name) + "Request"

    # å“åº”æ¨¡å‹ï¼ˆä½¿ç”¨ç®€åŒ–åçš„åç§°ï¼‰
    response_model_name = None
    if endpoint.get_success_response():
        response_model_name = to_pascal_case(simplified_name) + "Response"

    # æ„å»ºæ–¹æ³•å‚æ•°ï¼ˆå¿…å¡«å‚æ•°åœ¨å‰ï¼Œå¯é€‰å‚æ•°åœ¨åï¼‰
    # åˆ†ç¦»å¿…å¡«å’Œå¯é€‰çš„ query å‚æ•°
    required_query_params = [qp for qp in query_params if qp.required]
    optional_query_params = [qp for qp in query_params if not qp.required]

    params = []
    # 1. å¿…å¡«å‚æ•°ï¼ˆæ— é»˜è®¤å€¼ï¼‰
    if path_params:
        params.extend([f"{p.name}: {_get_python_type(p.schema)}" for p in path_params])
    if required_query_params:
        params.extend([f"{qp.name}: {_get_python_type(qp.schema)}" for qp in required_query_params])
    if request_model_name:
        params.append(f"request: {request_model_name}")

    # 2. å¯é€‰å‚æ•°ï¼ˆæœ‰é»˜è®¤å€¼ï¼‰
    if optional_query_params:
        params.extend(
            [
                f"{qp.name}: {_get_python_type(qp.schema)} | None = None"
                for qp in optional_query_params
            ]
        )
    if not request_model_name and endpoint.method.upper() in ["POST", "PUT", "PATCH"]:
        params.append("data: dict[str, Any] | None = None")

    params_str = ", ".join(params)

    # è¿”å›ç±»å‹
    return_type = response_model_name if response_model_name else "dict[str, Any]"

    # æ„å»ºç›¸å¯¹è·¯å¾„
    path = endpoint.path
    if base_path and path.startswith(base_path):
        path = path[len(base_path) :]
    if not path:
        path = "/"

    # HTTP æ–¹æ³•
    http_method = endpoint.method.lower()

    # ç”Ÿæˆæ–‡æ¡£å­—ç¬¦ä¸²
    summary = endpoint.summary or method_name.replace("_", " ").title()
    doc_lines = [f'"""{summary}']

    if endpoint.description:
        doc_lines.append("")
        doc_lines.append(f"        {endpoint.description}")

    if params:
        doc_lines.append("")
        doc_lines.append("        Args:")
        # æŒ‰ç…§å‚æ•°é¡ºåºç”Ÿæˆæ–‡æ¡£ï¼šå¿…å¡«å‚æ•°åœ¨å‰ï¼Œå¯é€‰å‚æ•°åœ¨å
        for p in path_params:
            doc_lines.append(f"            {p.name}: {p.description or p.name}")
        for qp in required_query_params:
            doc_lines.append(f"            {qp.name}: {qp.description or qp.name}")
        if request_model_name:
            doc_lines.append(f"            request: {request_model_name} è¯·æ±‚æ¨¡å‹")
        for qp in optional_query_params:
            doc_lines.append(f"            {qp.name}: {qp.description or qp.name}ï¼ˆå¯é€‰ï¼‰")
        if not request_model_name and endpoint.method.upper() in ["POST", "PUT", "PATCH"]:
            doc_lines.append("            data: è¯·æ±‚æ•°æ®ï¼ˆå¯é€‰ï¼‰")

    doc_lines.append("")
    doc_lines.append("        Returns:")
    doc_lines.append(f"            {return_type}: å“åº”æ•°æ®")
    doc_lines.append('        """')

    doc = "\n".join(doc_lines)

    # æ„å»ºè·¯å¾„è¡¨è¾¾å¼
    if path_params:
        path_expr = f'f"{{self.base_path}}{path}"'
    else:
        path_expr = f'self.base_path + "{path}"'

    # æ„å»ºæ–¹æ³•è°ƒç”¨
    call_args = [path_expr]
    if request_model_name:
        call_args.append("json=request")
    elif endpoint.method.upper() in ["POST", "PUT", "PATCH"] and "data" in params_str:
        call_args.append("json=data")

    # æ·»åŠ  query å‚æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
    if query_params:
        # æ„å»º params å­—å…¸
        query_param_names = [qp.name for qp in query_params]
        if len(query_param_names) == 1:
            # å•ä¸ªå‚æ•°ï¼Œç®€åŒ–å†™æ³•
            qp_name = query_param_names[0]
            call_args.append(f'params={{"{qp_name}": {qp_name}}}')
        else:
            # å¤šä¸ªå‚æ•°ï¼Œä½¿ç”¨å­—å…¸
            params_dict = ", ".join([f'"{qp.name}": {qp.name}' for qp in query_params])
            call_args.append(f"params={{{params_dict}}}")

    # æ·»åŠ  model å‚æ•°ï¼ˆå¦‚æœæœ‰å“åº”æ¨¡å‹ï¼‰
    if response_model_name:
        call_args.append(f"model={response_model_name}")

    call_str = ", ".join(call_args)

    # ç”Ÿæˆæ–¹æ³•ä½“
    if response_model_name:
        return_stmt = f"return self.{http_method}({call_str})"
    else:
        return_stmt = (
            f"response = self.http_client.{http_method}({call_str})\n        return response.json()"
        )

    code = f"""    def {method_name}(self{", " + params_str if params_str else ""}) -> {return_type}:
        {doc}
        {return_stmt}
"""

    return code


def _get_common_path_prefix(paths: list[str]) -> str:
    """è·å–è·¯å¾„åˆ—è¡¨çš„å…¬å…±å‰ç¼€"""
    if not paths:
        return ""

    # å°†è·¯å¾„åˆ†å‰²ä¸ºéƒ¨åˆ†
    split_paths = [p.split("/") for p in paths]
    if not split_paths:
        return ""

    # æ‰¾åˆ°å…¬å…±å‰ç¼€
    common = []
    for parts in zip(*split_paths):
        # è·³è¿‡è·¯å¾„å‚æ•° {id}
        if all(p == parts[0] and not p.startswith("{") for p in parts):
            common.append(parts[0])
        else:
            break

    return "/".join(common) if common else ""


# ========== Phase 3: æµ‹è¯•ä»£ç ç”Ÿæˆ ==========


def _generate_tests_v2(
    endpoints: list[APIEndpoint],
    project_name: str,
    output_dir: Path,
    *,
    parser: OpenAPIParser | None = None,
    force: bool = False,
    merge: bool = False,
) -> list[tuple[str, Path]]:
    """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹

    v3.38.0 æ”¹è¿›:
    - ä½¿ç”¨ç±»å‹åŒ–çš„ API å®¢æˆ·ç«¯
    - æ›´æ¸…æ™°çš„æµ‹è¯•ç»“æ„

    v3.39.0 æ”¹è¿›:
    - æ”¯æŒå¢é‡åˆå¹¶æ¨¡å¼ï¼ˆmerge=Trueï¼‰

    v3.41.1 æ”¹è¿›:
    - æ¥å— parser å‚æ•°ç”¨äºè§£æ $ref å¼•ç”¨
    """
    generated: list[tuple[str, Path]] = []

    # æŒ‰æ ‡ç­¾åˆ†ç»„
    endpoints_by_tag: dict[str, list[APIEndpoint]] = defaultdict(list)
    for endpoint in endpoints:
        tag = endpoint.tags[0] if endpoint.tags else "default"
        endpoints_by_tag[tag].append(endpoint)

    tests_dir = output_dir / "tests" / "api"
    tests_dir.mkdir(parents=True, exist_ok=True)

    # ä¸ºæ¯ä¸ªæ ‡ç­¾ç”Ÿæˆä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ï¼ˆä½¿ç”¨ ASCII æ ‡è¯†ç¬¦å¤„ç†ä¸­æ–‡ tagï¼‰
    for tag, tag_endpoints in endpoints_by_tag.items():
        tag_id = to_ascii_identifier(tag)
        file_name = f"test_{tag_id}_api.py"
        file_path = tests_dir / file_name

        # ç”Ÿæˆæµ‹è¯•ä»£ç 
        # v3.41.1: ä¼ é€’ parser ç”¨äºè§£æ $ref å¼•ç”¨
        content = _build_typed_test_code(tag, tag_id, tag_endpoints, project_name, parser=parser)

        success, action = create_file_with_merge(file_path, content, force=force, merge=merge)

        if success:
            generated.append(("Test", file_path.relative_to(output_dir)))
            if action == "merged":
                print(f"  ğŸ”€ åˆå¹¶: {file_path.name}")
        elif "skipped" in action:
            print(f"  â­ï¸  è·³è¿‡: {file_path.name}ï¼ˆå·²å­˜åœ¨ï¼‰")
        else:
            print(f"  âš ï¸  {action}: {file_path.name}")

    return generated


def _build_typed_test_code(
    tag: str,
    tag_id: str,
    endpoints: list[APIEndpoint],
    project_name: str,
    *,
    parser: OpenAPIParser | None = None,
) -> str:
    """æ„å»ºç±»å‹åŒ–çš„æµ‹è¯•ä»£ç ï¼ˆv3.41.0 å¢å¼ºç‰ˆï¼‰

    Args:
        tag: åŸå§‹ tag åç§°ï¼ˆç”¨äºæ³¨é‡Šå’Œ allure featureï¼‰
        tag_id: ASCII æ ‡è¯†ç¬¦ï¼ˆç”¨äºç±»åã€fixtureåã€å¯¼å…¥è·¯å¾„ï¼‰
        endpoints: API ç«¯ç‚¹åˆ—è¡¨
        project_name: é¡¹ç›®åç§°
        parser: OpenAPI è§£æå™¨ï¼ˆç”¨äºè§£æ $ref å¼•ç”¨ï¼‰

    v3.41.0 å¢å¼º:
    - æ™ºèƒ½ç”Ÿæˆåˆ†é¡µæŸ¥è¯¢è¯·æ±‚ç¤ºä¾‹
    - å‰ç½®æŸ¥è¯¢ç”Ÿæˆ
    - ä¸­æ–‡æµ‹è¯•æ ‡é¢˜
    - æ™ºèƒ½åŒºåˆ† smoke/regression æµ‹è¯•
    - å¢å¼ºæ–­è¨€
    - è‡ªåŠ¨ç”Ÿæˆ E2E å’Œè´Ÿå‘æµ‹è¯•
    - è‡ªåŠ¨ç”Ÿæˆ import è¯­å¥

    v3.41.1 å¢å¼º:
    - æ¥å— parser å‚æ•°ç”¨äºè§£æ $ref å¼•ç”¨
    """
    class_name = "Test" + to_pascal_case(tag_id) + "API"
    api_fixture_name = tag_id + "_api"
    tag_snake = tag_id

    # v3.41.0: æ”¶é›†éœ€è¦å¯¼å…¥çš„è¯·æ±‚æ¨¡å‹
    request_models_to_import = set()
    for endpoint in endpoints:
        simplified_name = _simplify_operation_id(endpoint.operation_id)
        request_model = to_pascal_case(simplified_name) + "Request"
        if endpoint.request_body:
            request_models_to_import.add(request_model)
        # å‰ç½®æŸ¥è¯¢ä¹Ÿéœ€è¦å¯¼å…¥åˆ—è¡¨æŸ¥è¯¢çš„è¯·æ±‚æ¨¡å‹
        if _needs_precondition_query(endpoint.operation_id, endpoint.summary):
            list_info = _find_list_endpoint(endpoints, endpoint)
            # v3.41.1: åªæœ‰å½“åˆ—è¡¨æ¥å£æœ‰è¯·æ±‚ä½“æ—¶æ‰æ·»åŠ åˆ°å¯¼å…¥
            if list_info and list_info[1]:
                request_models_to_import.add(list_info[1])

    # ç”Ÿæˆæµ‹è¯•æ–¹æ³•ï¼ˆä½¿ç”¨ç®€åŒ–åçš„åç§°ï¼‰
    test_methods = []
    for endpoint in endpoints:
        simplified_name = _simplify_operation_id(endpoint.operation_id)
        api_method = to_snake_case(simplified_name)

        # v3.41.0: ä¼ é€’ endpoints åˆ—è¡¨ç”¨äºå‰ç½®æŸ¥è¯¢
        # v3.41.1: ä¼ é€’ parser ç”¨äºè§£æ $ref å¼•ç”¨
        method_code = _build_typed_test_method_code(
            endpoint,
            api_fixture_name,
            api_method,
            project_name,
            tag_id,
            endpoints=endpoints,
            parser=parser,
        )
        test_methods.append(method_code)

    # v3.41.0: ç”Ÿæˆ E2E æµ‹è¯•ç±»
    e2e_test_class = _build_e2e_test_class(tag, tag_id, endpoints, api_fixture_name, project_name)

    # v3.41.0: ç”Ÿæˆè´Ÿå‘æµ‹è¯•ç±»
    negative_test_class = _build_negative_test_class(
        tag, tag_id, endpoints, api_fixture_name, project_name
    )

    # v3.41.0: ç”Ÿæˆè¯·æ±‚æ¨¡å‹å¯¼å…¥è¯­å¥
    if request_models_to_import:
        imports_code = (
            f"from {project_name}.models.requests.{tag_snake} import (\n    "
            + ",\n    ".join(sorted(request_models_to_import))
            + ",\n)"
        )
    else:
        imports_code = ""

    code = f'''"""è‡ªåŠ¨ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶ - {tag}

ä» OpenAPI è§„èŒƒç”Ÿæˆï¼ŒåŸºäº df-test-framework v3.41.0 æœ€ä½³å®è·µã€‚
æµ‹è¯•ç±»: {class_name}
æ¨¡å—æ ‡è¯†: {tag_id}

v3.41.0 æ–°å¢:
- âœ… æ™ºèƒ½ç”Ÿæˆåˆ†é¡µæŸ¥è¯¢è¯·æ±‚ç¤ºä¾‹ï¼ˆä¸å†æ˜¯ç©ºå ä½ç¬¦ï¼‰
- âœ… å‰ç½®æŸ¥è¯¢ç”Ÿæˆï¼ˆè¯¦æƒ…/æ›´æ–°/åˆ é™¤æ“ä½œè‡ªåŠ¨æŸ¥è¯¢è·å–IDï¼‰
- âœ… ä¸­æ–‡æµ‹è¯•æ ‡é¢˜
- âœ… æ™ºèƒ½åŒºåˆ† smoke/regression æµ‹è¯•
- âœ… å¢å¼ºçš„åˆ—è¡¨æŸ¥è¯¢æ–­è¨€
- âœ… è‡ªåŠ¨ç”Ÿæˆ E2E æµç¨‹æµ‹è¯•
- âœ… è‡ªåŠ¨ç”Ÿæˆè´Ÿå‘æµ‹è¯•

v3.39.0 ç‰¹æ€§:
- âœ… æ”¯æŒå¢é‡åˆå¹¶ï¼ˆ--force é€‰é¡¹ä¿ç•™ç”¨æˆ·æ‰©å±•ï¼‰
- âœ… ç”¨æˆ·æ‰©å±•åŒºåŸŸä¿ç•™è‡ªå®šä¹‰æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
    pytest tests/api/test_{tag_snake}_api.py -v
    pytest tests/api/test_{tag_snake}_api.py -v -k "smoke"  # ä»…è¿è¡Œ smoke æµ‹è¯•
    pytest tests/api/test_{tag_snake}_api.py -v -k "e2e"    # ä»…è¿è¡Œ E2E æµ‹è¯•

å‰ç½®æ¡ä»¶:
    åœ¨ tests/conftest.py ä¸­æ·»åŠ :
        from df_test_framework.testing.decorators import load_api_fixtures

        load_api_fixtures(globals(), apis_package="{project_name}.apis")
"""

import pytest
import allure
from assertpy import assert_that

from df_test_framework import attach_json, step, DataGenerator

{imports_code}


{AUTO_GENERATED_START}
{AUTO_GENERATED_WARNING}


@allure.feature("{tag}")
class {class_name}:
    """{tag} API æµ‹è¯•ç±»

    è‡ªåŠ¨ä» OpenAPI è§„èŒƒç”Ÿæˆã€‚

    Fixture ä¾èµ– (v3.41.0+):
        - {api_fixture_name}: API å®¢æˆ·ç«¯ï¼ˆç”± @api_class è‡ªåŠ¨æ³¨å†Œï¼‰
        - cleanup: æ•°æ®æ¸…ç†ç®¡ç†å™¨ï¼ˆæŒ‰éœ€ä½¿ç”¨ï¼‰

    Note:
        allure_observer æ˜¯ autouse fixtureï¼Œæ— éœ€å£°æ˜å³å¯è‡ªåŠ¨è®°å½•è¯·æ±‚/å“åº”åˆ° Allure
    """

{chr(10).join(test_methods)}

{e2e_test_class}
{negative_test_class}

{AUTO_GENERATED_END}


{USER_EXTENSIONS_START}
{USER_EXTENSIONS_HINT}
'''

    return code


def _build_e2e_test_class(
    tag: str, tag_id: str, endpoints: list[APIEndpoint], api_fixture: str, project_name: str
) -> str:
    """ç”Ÿæˆ E2E æµ‹è¯•ç±»

    v3.40.0: è‡ªåŠ¨ç”Ÿæˆ CRUD æµç¨‹æµ‹è¯•
    """
    # æŸ¥æ‰¾ CRUD æ“ä½œ
    create_endpoint = None
    list_endpoint = None
    detail_endpoint = None
    update_endpoint = None
    delete_endpoint = None

    for ep in endpoints:
        op_id = ep.operation_id or ""
        if _is_create_operation(op_id, ep.summary) and not create_endpoint:
            create_endpoint = ep
        elif _is_list_query_operation(op_id, ep.summary) and not list_endpoint:
            list_endpoint = ep
        elif _is_detail_operation(op_id, ep.summary) and not detail_endpoint:
            detail_endpoint = ep
        elif _is_update_operation(op_id, ep.summary) and not update_endpoint:
            update_endpoint = ep
        elif _is_delete_operation(op_id, ep.summary) and not delete_endpoint:
            delete_endpoint = ep

    # å¦‚æœæ²¡æœ‰å®Œæ•´çš„ CRUD æ“ä½œï¼Œä¸ç”Ÿæˆ E2E æµ‹è¯•
    if not (create_endpoint and list_endpoint):
        return ""

    class_name = "Test" + to_pascal_case(tag_id) + "E2E"

    # ç”Ÿæˆæ–¹æ³•å
    def get_method_name(ep):
        simplified = _simplify_operation_id(ep.operation_id)
        return to_snake_case(simplified)

    create_method = get_method_name(create_endpoint) if create_endpoint else None
    list_method = get_method_name(list_endpoint) if list_endpoint else None
    detail_method = get_method_name(detail_endpoint) if detail_endpoint else None
    update_method = get_method_name(update_endpoint) if update_endpoint else None
    delete_method = get_method_name(delete_endpoint) if delete_endpoint else None

    # ç”Ÿæˆè¯·æ±‚æ¨¡å‹åç§°
    def get_request_model(ep):
        simplified = _simplify_operation_id(ep.operation_id)
        return to_pascal_case(simplified) + "Request"

    create_request = get_request_model(create_endpoint) if create_endpoint else None
    list_request = get_request_model(list_endpoint) if list_endpoint else None

    # æ„å»º E2E æµ‹è¯•ä»£ç 
    e2e_steps = []

    # åˆ›å»ºæ­¥éª¤
    if create_endpoint:
        e2e_steps.append(f"""
        # 1. åˆ›å»ºæ•°æ®
        with step("åˆ›å»ºæµ‹è¯•æ•°æ®"):
            test_id = DataGenerator.test_id("E2E")
            create_request = {create_request}(
                # TODO: æ ¹æ®å®é™…éœ€æ±‚å¡«å……åˆ›å»ºå‚æ•°
            )
            create_response = {api_fixture}.{create_method}(create_request)
            assert_that(create_response.status).is_in("ok", "success")""")

    # æŸ¥è¯¢åˆ—è¡¨éªŒè¯
    if list_endpoint:
        e2e_steps.append(f"""
        # 2. æŸ¥è¯¢åˆ—è¡¨éªŒè¯
        with step("æŸ¥è¯¢åˆ—è¡¨éªŒè¯åˆ›å»ºæˆåŠŸ"):
            list_request = {list_request}(pagination={{"pageSize": 10, "current": 1}})
            list_response = {api_fixture}.{list_method}(list_request)
            assert_that(list_response.status).is_in("ok", "success")
            # è·å–åˆ›å»ºçš„æ•°æ® ID
            if list_response.data and list_response.data.get("list"):
                created_id = list_response.data["list"][0].get("id")
            else:
                pytest.skip("æœªæ‰¾åˆ°åˆ›å»ºçš„æ•°æ®")""")

    # æŸ¥è¯¢è¯¦æƒ…éªŒè¯
    if detail_endpoint:
        detail_request = get_request_model(detail_endpoint)
        e2e_steps.append(f"""
        # 3. æŸ¥è¯¢è¯¦æƒ…éªŒè¯
        with step("æŸ¥è¯¢è¯¦æƒ…éªŒè¯"):
            detail_request = {detail_request}(id=created_id)
            detail_response = {api_fixture}.{detail_method}(detail_request)
            assert_that(detail_response.status).is_in("ok", "success")""")

    # æ›´æ–°éªŒè¯
    if update_endpoint:
        update_request = get_request_model(update_endpoint)
        e2e_steps.append(f"""
        # 4. æ›´æ–°æ•°æ®
        with step("æ›´æ–°æ•°æ®"):
            update_request = {update_request}(
                id=created_id,
                # TODO: æ ¹æ®å®é™…éœ€æ±‚å¡«å……æ›´æ–°å‚æ•°
            )
            update_response = {api_fixture}.{update_method}(update_request)
            assert_that(update_response.status).is_in("ok", "success")""")

    # åˆ é™¤éªŒè¯
    if delete_endpoint:
        delete_request = get_request_model(delete_endpoint)
        e2e_steps.append(f"""
        # 5. åˆ é™¤æ•°æ®
        with step("åˆ é™¤æ•°æ®"):
            delete_request = {delete_request}(id=created_id)
            delete_response = {api_fixture}.{delete_method}(delete_request)
            assert_that(delete_response.status).is_in("ok", "success")""")

    e2e_code = "\n".join(e2e_steps)

    return f'''
@allure.feature("{tag}")
@allure.story("E2E æµç¨‹æµ‹è¯•")
class {class_name}:
    """{tag} E2E æµç¨‹æµ‹è¯•

    v3.41.0 è‡ªåŠ¨ç”Ÿæˆï¼šå®Œæ•´çš„ CRUD æµç¨‹æµ‹è¯•
    """

    @allure.title("å®Œæ•´ CRUD æµç¨‹æµ‹è¯•")
    @allure.severity(allure.severity_level.CRITICAL)
    @pytest.mark.e2e
    def test_crud_flow(self, {api_fixture}, cleanup):
        """å®Œæ•´çš„åˆ›å»º-æŸ¥è¯¢-æ›´æ–°-åˆ é™¤æµç¨‹æµ‹è¯•

        æµ‹è¯•æ­¥éª¤:
        1. åˆ›å»ºæ•°æ®
        2. æŸ¥è¯¢åˆ—è¡¨éªŒè¯
        3. æŸ¥è¯¢è¯¦æƒ…éªŒè¯
        4. æ›´æ–°æ•°æ®
        5. åˆ é™¤æ•°æ®
        """{e2e_code}
'''


def _build_negative_test_class(
    tag: str, tag_id: str, endpoints: list[APIEndpoint], api_fixture: str, project_name: str
) -> str:
    """ç”Ÿæˆè´Ÿå‘æµ‹è¯•ç±»

    v3.40.0: è‡ªåŠ¨ç”Ÿæˆè¾¹ç•Œæ¡ä»¶å’Œé”™è¯¯åœºæ™¯æµ‹è¯•
    """
    # æŸ¥æ‰¾è¯¦æƒ…å’Œåˆ é™¤æ“ä½œ
    detail_endpoint = None
    delete_endpoint = None

    for ep in endpoints:
        op_id = ep.operation_id or ""
        if _is_detail_operation(op_id, ep.summary) and not detail_endpoint:
            detail_endpoint = ep
        elif _is_delete_operation(op_id, ep.summary) and not delete_endpoint:
            delete_endpoint = ep

    # å¦‚æœæ²¡æœ‰è¯¦æƒ…æˆ–åˆ é™¤æ“ä½œï¼Œä¸ç”Ÿæˆè´Ÿå‘æµ‹è¯•
    if not detail_endpoint and not delete_endpoint:
        return ""

    class_name = "Test" + to_pascal_case(tag_id) + "Negative"

    def get_method_name(ep):
        simplified = _simplify_operation_id(ep.operation_id)
        return to_snake_case(simplified)

    def get_request_model(ep):
        simplified = _simplify_operation_id(ep.operation_id)
        return to_pascal_case(simplified) + "Request"

    negative_tests = []

    # æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®
    if detail_endpoint:
        detail_method = get_method_name(detail_endpoint)
        detail_request = get_request_model(detail_endpoint)
        negative_tests.append(f'''
    @allure.title("æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®")
    @allure.severity(allure.severity_level.NORMAL)
    @pytest.mark.regression
    def test_find_non_existent(self, {api_fixture}):
        """æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®åº”è¿”å›ç©ºæˆ–é”™è¯¯"""
        with step("æŸ¥è¯¢ä¸å­˜åœ¨çš„ID"):
            request = {detail_request}(id=999999999)
            response = {api_fixture}.{detail_method}(request)

        with step("éªŒè¯å“åº”"):
            # åº”è¯¥è¿”å›ç©ºæ•°æ®æˆ–é”™è¯¯ç 
            # å…·ä½“è¡Œä¸ºå–å†³äºåç«¯å®ç°
            assert_that(response).is_not_none()''')

    # åˆ é™¤ä¸å­˜åœ¨çš„æ•°æ®
    if delete_endpoint:
        delete_method = get_method_name(delete_endpoint)
        delete_request = get_request_model(delete_endpoint)
        negative_tests.append(f'''
    @allure.title("åˆ é™¤ä¸å­˜åœ¨çš„æ•°æ®")
    @allure.severity(allure.severity_level.NORMAL)
    @pytest.mark.regression
    def test_delete_non_existent(self, {api_fixture}):
        """åˆ é™¤ä¸å­˜åœ¨çš„æ•°æ®åº”è¿”å›é”™è¯¯"""
        with step("åˆ é™¤ä¸å­˜åœ¨çš„ID"):
            request = {delete_request}(id=999999999)
            response = {api_fixture}.{delete_method}(request)

        with step("éªŒè¯å“åº”"):
            # åº”è¯¥è¿”å›é”™è¯¯æˆ–ç‰¹å®šçŠ¶æ€
            assert_that(response).is_not_none()''')

    negative_code = "\n".join(negative_tests)

    return f'''
@allure.feature("{tag}")
@allure.story("è´Ÿå‘æµ‹è¯•")
class {class_name}:
    """{tag} è´Ÿå‘æµ‹è¯•

    v3.41.0 è‡ªåŠ¨ç”Ÿæˆï¼šè¾¹ç•Œæ¡ä»¶å’Œé”™è¯¯åœºæ™¯æµ‹è¯•
    """
{negative_code}
'''


# ========== v3.40.0 ä¼˜åŒ–ï¼šæ“ä½œç±»å‹è¯†åˆ«å’Œæ™ºèƒ½ä»£ç ç”Ÿæˆ ==========

# æ“ä½œç±»å‹ä¸­æ–‡æ˜ å°„
OPERATION_TYPE_CN = {
    "find": "æŸ¥è¯¢",
    "get": "è·å–",
    "list": "åˆ—è¡¨",
    "query": "æŸ¥è¯¢",
    "search": "æœç´¢",
    "add": "æ–°å¢",
    "create": "åˆ›å»º",
    "insert": "æ’å…¥",
    "save": "ä¿å­˜",
    "update": "æ›´æ–°",
    "modify": "ä¿®æ”¹",
    "edit": "ç¼–è¾‘",
    "delete": "åˆ é™¤",
    "del": "åˆ é™¤",
    "remove": "ç§»é™¤",
    "export": "å¯¼å‡º",
    "import": "å¯¼å…¥",
    "refresh": "åˆ·æ–°",
    "sync": "åŒæ­¥",
    # v3.41.0: æ·»åŠ å®¡æ‰¹æµç¨‹ç›¸å…³æ“ä½œ
    "confirm": "ç¡®è®¤",
    "cancel": "å–æ¶ˆ",
    "approve": "å®¡æ‰¹",
    "reject": "æ‹’ç»",
    "submit": "æäº¤",
    "revoke": "æ’¤é”€",
    "enable": "å¯ç”¨",
    "disable": "ç¦ç”¨",
}


def _is_detail_operation(operation_id: str | None, summary: str | None) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯è¯¦æƒ…æŸ¥è¯¢æ“ä½œï¼ˆéœ€è¦æœ‰æ•ˆIDï¼‰

    è¯¦æƒ…æŸ¥è¯¢æ“ä½œç‰¹å¾:
        - findById, getById, findDetail, getDetail
        - åŒ…å« "byId", "ById", "detail" ç­‰å…³é”®è¯

    Args:
        operation_id: OpenAPI çš„ operationId
        summary: æ¥å£æ‘˜è¦

    Returns:
        True å¦‚æœæ˜¯è¯¦æƒ…æŸ¥è¯¢æ“ä½œ
    """
    detail_patterns = ("byid", "detail", "info", "getone", "findone")

    if operation_id:
        op_lower = operation_id.lower()
        for pattern in detail_patterns:
            if pattern in op_lower:
                return True

    if summary:
        summary_lower = summary.lower()
        cn_detail_keywords = ("è¯¦æƒ…", "è¯¦ç»†", "å•ä¸ª", "æ ¹æ®id", "æ ¹æ®ID")
        for keyword in cn_detail_keywords:
            if keyword in summary_lower:
                return True

    return False


def _is_update_operation(operation_id: str | None, summary: str | None) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯æ›´æ–°æ“ä½œï¼ˆéœ€è¦æœ‰æ•ˆIDï¼‰"""
    update_prefixes = ("update", "modify", "edit", "change", "set")

    if operation_id:
        op_lower = operation_id.lower()
        for prefix in update_prefixes:
            if op_lower.startswith(prefix):
                return True
            if f"_{prefix}" in op_lower:
                return True

    if summary:
        summary_lower = summary.lower()
        cn_keywords = ("æ›´æ–°", "ä¿®æ”¹", "ç¼–è¾‘")
        for keyword in cn_keywords:
            if keyword in summary_lower:
                return True

    return False


def _is_delete_operation(operation_id: str | None, summary: str | None) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯åˆ é™¤æ“ä½œï¼ˆéœ€è¦æœ‰æ•ˆIDï¼‰"""
    delete_prefixes = ("delete", "del", "remove")

    if operation_id:
        op_lower = operation_id.lower()
        for prefix in delete_prefixes:
            if op_lower.startswith(prefix):
                return True
            if f"_{prefix}" in op_lower:
                return True

    if summary:
        summary_lower = summary.lower()
        cn_keywords = ("åˆ é™¤", "ç§»é™¤")
        for keyword in cn_keywords:
            if keyword in summary_lower:
                return True

    return False


def _is_list_query_operation(operation_id: str | None, summary: str | None) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯åˆ—è¡¨æŸ¥è¯¢æ“ä½œï¼ˆé€šå¸¸æœ‰åˆ†é¡µï¼‰

    åˆ—è¡¨æŸ¥è¯¢æ“ä½œç‰¹å¾:
        - findList, getList, queryList, searchList
        - find + å¤æ•°åè¯ï¼ˆå¦‚ findSuppliersï¼‰
        - ä¸åŒ…å« ById, Detail ç­‰è¯¦æƒ…å…³é”®è¯
    """
    if _is_detail_operation(operation_id, summary):
        return False

    list_patterns = ("list", "all", "page", "search", "query")

    if operation_id:
        op_lower = operation_id.lower()
        # ä»¥ find/get å¼€å¤´ä¸”åŒ…å« list æˆ–å¤æ•°å½¢å¼
        if op_lower.startswith(("find", "get", "query", "search")):
            for pattern in list_patterns:
                if pattern in op_lower:
                    return True
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¤æ•°å½¢å¼ï¼ˆç®€å•åˆ¤æ–­ï¼šä»¥ s ç»“å°¾ä½†ä¸æ˜¯ ssï¼‰
            if op_lower.endswith("s") and not op_lower.endswith("ss"):
                return True

    if summary:
        summary_lower = summary.lower()
        cn_keywords = ("åˆ—è¡¨", "åˆ†é¡µ", "æŸ¥è¯¢åˆ—è¡¨")
        for keyword in cn_keywords:
            if keyword in summary_lower:
                return True

    return False


def _needs_precondition_query(operation_id: str | None, summary: str | None) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦å‰ç½®æŸ¥è¯¢è·å–æœ‰æ•ˆID

    ä»¥ä¸‹æ“ä½œéœ€è¦å‰ç½®æŸ¥è¯¢:
    - è¯¦æƒ…æŸ¥è¯¢ï¼ˆfindById, getDetailï¼‰
    - æ›´æ–°æ“ä½œï¼ˆupdate, modifyï¼‰
    - åˆ é™¤æ“ä½œï¼ˆdelete, removeï¼‰
    """
    return (
        _is_detail_operation(operation_id, summary)
        or _is_update_operation(operation_id, summary)
        or _is_delete_operation(operation_id, summary)
    )


def _find_list_endpoint(endpoints: list, current_endpoint) -> tuple[str, str | None] | None:
    """æŸ¥æ‰¾å¯¹åº”çš„åˆ—è¡¨æŸ¥è¯¢æ¥å£

    v3.41.0: æ™ºèƒ½åŒ¹é…åŒç±»å®ä½“çš„åˆ—è¡¨æ¥å£
    v3.41.1: åªè¿”å›æœ‰è¯·æ±‚ä½“çš„ç«¯ç‚¹çš„ request_modelï¼Œæ²¡æœ‰è¯·æ±‚ä½“çš„è¿”å› None

    Args:
        endpoints: åŒä¸€ tag ä¸‹çš„æ‰€æœ‰ç«¯ç‚¹
        current_endpoint: å½“å‰ç«¯ç‚¹

    Returns:
        (api_method_name, request_model_name | None) æˆ– None
        - request_model_name ä¸º None æ—¶è¡¨ç¤ºè¯¥åˆ—è¡¨æ¥å£æ²¡æœ‰è¯·æ±‚ä½“

    Example:
        updateSupplier -> findSupplierList
        updateSupplierAccount -> findSupplierAccountList
    """
    # æå–å½“å‰æ“ä½œçš„å®ä½“åç§°
    current_simplified = _simplify_operation_id(current_endpoint.operation_id)
    current_lower = current_simplified.lower()

    # ç§»é™¤æ“ä½œå‰ç¼€ï¼Œè·å–å®ä½“å
    current_entity = current_lower
    for prefix in ["update", "modify", "edit", "delete", "del", "remove", "find", "get"]:
        if current_lower.startswith(prefix + "_"):
            current_entity = current_lower[len(prefix) + 1 :]
            break
        elif current_lower.startswith(prefix):
            current_entity = current_lower[len(prefix) :]
            break

    # æ”¶é›†æ‰€æœ‰åˆ—è¡¨æŸ¥è¯¢æ¥å£
    # v3.41.1: ä¼˜å…ˆæ”¶é›†æœ‰è¯·æ±‚ä½“çš„åˆ—è¡¨æ¥å£
    list_endpoints_with_body = []
    list_endpoints_without_body = []
    for ep in endpoints:
        if _is_list_query_operation(ep.operation_id, ep.summary):
            simplified_name = _simplify_operation_id(ep.operation_id)
            api_method = to_snake_case(simplified_name)
            has_request_body = ep.request_body is not None
            request_model = (
                to_pascal_case(simplified_name) + "Request" if has_request_body else None
            )
            ep_data = (ep, api_method, request_model, simplified_name.lower())
            if has_request_body:
                list_endpoints_with_body.append(ep_data)
            else:
                list_endpoints_without_body.append(ep_data)

    # åˆå¹¶ï¼šä¼˜å…ˆè€ƒè™‘æœ‰è¯·æ±‚ä½“çš„ç«¯ç‚¹
    list_endpoints = list_endpoints_with_body + list_endpoints_without_body

    if not list_endpoints:
        return None

    # ä¼˜å…ˆåŒ¹é…åŒç±»å®ä½“çš„åˆ—è¡¨æ¥å£
    for ep, api_method, request_model, ep_lower in list_endpoints:
        # æå–åˆ—è¡¨æ¥å£çš„å®ä½“å
        list_entity = ep_lower
        for prefix in ["find", "get", "list", "query", "search"]:
            if ep_lower.startswith(prefix + "_"):
                list_entity = ep_lower[len(prefix) + 1 :]
                break
            elif ep_lower.startswith(prefix):
                list_entity = ep_lower[len(prefix) :]
                break

        # ç§»é™¤ _list åç¼€
        list_entity = list_entity.rstrip("_list").rstrip("list")

        # ç²¾ç¡®åŒ¹é…æˆ–åŒ…å«åŒ¹é…
        if current_entity == list_entity:
            return (api_method, request_model)
        # å½“å‰å®ä½“ä»¥åˆ—è¡¨å®ä½“å¼€å¤´ï¼ˆå¦‚ supplier_account åŒ…å« supplier_accountï¼‰
        if current_entity.startswith(list_entity) and list_entity:
            return (api_method, request_model)

    # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ªåˆ—è¡¨æ¥å£ä½œä¸ºå¤‡é€‰
    return (list_endpoints[0][1], list_endpoints[0][2])


def _generate_request_example(
    request_schema: dict, request_model_name: str, is_create: bool = False
) -> str:
    """æ ¹æ® schema ç”Ÿæˆæ™ºèƒ½è¯·æ±‚ç¤ºä¾‹

    v3.40.0: æ™ºèƒ½è¯†åˆ«åˆ†é¡µã€æ’åºç­‰å¸¸è§å­—æ®µï¼Œç”Ÿæˆå¯è¿è¡Œçš„ç¤ºä¾‹ä»£ç 

    Args:
        request_schema: è¯·æ±‚ä½“çš„ schema
        request_model_name: è¯·æ±‚æ¨¡å‹åç§°
        is_create: æ˜¯å¦æ˜¯åˆ›å»ºæ“ä½œ

    Returns:
        ç”Ÿæˆçš„è¯·æ±‚ç¤ºä¾‹ä»£ç 
    """
    props = request_schema.get("properties", {})
    if not props:
        return f"{request_model_name}()"

    example_fields = []

    # 1. åˆ†é¡µå­—æ®µ
    if "pagination" in props:
        example_fields.append('pagination={"pageSize": 10, "current": 1}')

    # 2. æ’åºå­—æ®µ
    if "sortName" in props or "sort_name" in props:
        example_fields.append('sort_name="id"')
    if "sortType" in props or "sort_type" in props:
        example_fields.append('sort_type="desc"')

    # 3. åˆ›å»ºæ“ä½œçš„å¸¸è§å­—æ®µ
    if is_create:
        # åç§°å­—æ®µ
        for name_field in ["name", "supplierName", "supplier_name", "ruleName", "rule_name"]:
            if name_field in props:
                snake_name = to_snake_case(name_field)
                example_fields.append(f'{snake_name}=f"è‡ªåŠ¨åŒ–æµ‹è¯•_{{test_id}}"')
                break

        # å¤‡æ³¨å­—æ®µ
        if "remarks" in props:
            example_fields.append('remarks=f"è‡ªåŠ¨åŒ–æµ‹è¯•åˆ›å»º - {test_id}"')

        # çŠ¶æ€å­—æ®µ
        if "status" in props:
            example_fields.append("status=1")

        # æœ‰æ•ˆæ ‡å¿—
        for eff_field in ["isEffective", "is_effective"]:
            if eff_field in props:
                example_fields.append("is_effective=1")
                break

    if example_fields:
        fields_str = ",\n                ".join(example_fields)
        return f"{request_model_name}(\n                {fields_str}\n            )"
    else:
        return f"{request_model_name}()"


def _split_camel_case(name: str) -> str:
    """å°†é©¼å³°å‘½åæ‹†åˆ†ä¸ºç©ºæ ¼åˆ†éš”çš„å•è¯

    v3.41.0: æ”¹è¿›æ ‡é¢˜å¯è¯»æ€§

    Example:
        >>> _split_camel_case("SupplierAccountList")
        "Supplier Account List"
        >>> _split_camel_case("findById")
        "find By Id"
    """
    # åœ¨å¤§å†™å­—æ¯å‰æ’å…¥ç©ºæ ¼
    result = re.sub(r"([a-z])([A-Z])", r"\1 \2", name)
    # å¤„ç†è¿ç»­å¤§å†™å­—æ¯
    result = re.sub(r"([A-Z]+)([A-Z][a-z])", r"\1 \2", result)
    return result


def _generate_chinese_title(operation_id: str | None, summary: str | None) -> str:
    """ç”Ÿæˆä¸­æ–‡æµ‹è¯•æ ‡é¢˜

    v3.41.0: ä¼˜å…ˆä½¿ç”¨ Swagger summaryï¼Œå¦åˆ™æ™ºèƒ½ç¿»è¯‘ï¼Œå¹¶æ‹†åˆ†é©¼å³°å‘½å

    Args:
        operation_id: OpenAPI çš„ operationId
        summary: æ¥å£æ‘˜è¦

    Returns:
        ä¸­æ–‡æµ‹è¯•æ ‡é¢˜
    """
    # ä¼˜å…ˆä½¿ç”¨ summaryï¼ˆå¦‚æœæ˜¯ä¸­æ–‡ï¼‰
    if summary:
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        if any("\u4e00" <= c <= "\u9fff" for c in summary):
            return summary

    # æ ¹æ®æ“ä½œç±»å‹ç”Ÿæˆä¸­æ–‡æ ‡é¢˜
    if not operation_id:
        return summary or "æœªçŸ¥æ“ä½œ"

    op_lower = operation_id.lower()
    simplified = _simplify_operation_id(operation_id)

    # å°è¯•è¯†åˆ«æ“ä½œç±»å‹
    for en_prefix, cn_prefix in OPERATION_TYPE_CN.items():
        if op_lower.startswith(en_prefix):
            # æå–å®ä½“åï¼ˆå»æ‰æ“ä½œå‰ç¼€ï¼‰
            entity_part = simplified[len(en_prefix) :].strip("_")
            if entity_part:
                # v3.41.0: å°† snake_case è½¬ä¸º PascalCase å†æ‹†åˆ†
                pascal_name = to_pascal_case(entity_part)
                entity_name = _split_camel_case(pascal_name)
                # ç‰¹æ®Šå¤„ç† ById
                if "by_id" in entity_part.lower() or "byid" in entity_part.lower():
                    return f"æ ¹æ®ID{cn_prefix}"
                return f"{cn_prefix} {entity_name}"
            return cn_prefix

    # é»˜è®¤ä½¿ç”¨ summary æˆ–æ ¼å¼åŒ–çš„ operation_id
    if summary:
        return summary
    # v3.41.0: æ‹†åˆ†é©¼å³°å‘½å
    pascal_name = to_pascal_case(simplified)
    return _split_camel_case(pascal_name)


def _get_pytest_mark(operation_id: str | None, summary: str | None) -> str:
    """æ ¹æ®æ“ä½œç±»å‹è·å– pytest mark

    v3.40.0: æ™ºèƒ½åŒºåˆ† smoke å’Œ regression æµ‹è¯•

    è§„åˆ™:
    - smoke: æ ¸å¿ƒæŸ¥è¯¢ï¼ˆåˆ—è¡¨ã€è¯¦æƒ…ï¼‰ã€åˆ›å»ºæ“ä½œ
    - regression: æ›´æ–°ã€åˆ é™¤ã€å¯¼å‡ºã€åˆ·æ–°ç­‰

    Returns:
        "smoke" æˆ– "regression"
    """
    if not operation_id:
        return "smoke"

    op_lower = operation_id.lower()

    # smoke æµ‹è¯•ï¼šæ ¸å¿ƒåŠŸèƒ½
    smoke_patterns = ("findlist", "getlist", "findbyid", "getbyid", "add", "create", "insert")
    for pattern in smoke_patterns:
        if pattern in op_lower:
            return "smoke"

    # ç®€å•çš„åˆ—è¡¨æŸ¥è¯¢ä¹Ÿæ˜¯ smoke
    if _is_list_query_operation(operation_id, summary):
        return "smoke"

    # å…¶ä»–éƒ½æ˜¯ regression
    return "regression"


def _is_create_operation(operation_id: str | None, summary: str | None) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯åˆ›å»ºæ“ä½œï¼ˆéœ€è¦æ•°æ®æ¸…ç†ï¼‰

    æ ¹æ® operation_id å’Œ summary çš„è¯­ä¹‰åˆ¤æ–­æ“ä½œç±»å‹ã€‚

    åˆ›å»ºç±»æ“ä½œï¼ˆéœ€è¦æ¸…ç†ï¼‰:
        - add*, create*, insert*, save*, new*, register*

    éåˆ›å»ºç±»æ“ä½œï¼ˆä¸éœ€è¦æ¸…ç†ï¼‰:
        - find*, get*, list*, query*, search*, export* (æŸ¥è¯¢)
        - delete*, remove*, del* (åˆ é™¤)
        - update*, modify*, edit*, change* (æ›´æ–°)
        - refresh*, sync*, init* (åˆ·æ–°/åŒæ­¥)

    Args:
        operation_id: OpenAPI çš„ operationId
        summary: æ¥å£æ‘˜è¦

    Returns:
        True å¦‚æœæ˜¯åˆ›å»ºæ“ä½œï¼Œéœ€è¦æ¸…ç†
    """
    # åˆ›å»ºç±»æ“ä½œçš„å‰ç¼€
    create_prefixes = ("add", "create", "insert", "save", "new", "register")

    # æ£€æŸ¥ operation_id
    if operation_id:
        op_lower = operation_id.lower()
        # æ£€æŸ¥æ˜¯å¦ä»¥åˆ›å»ºç±»å‰ç¼€å¼€å¤´
        for prefix in create_prefixes:
            if op_lower.startswith(prefix):
                return True
            # ä¹Ÿæ£€æŸ¥ä¸‹åˆ’çº¿åˆ†éš”çš„æƒ…å†µï¼Œå¦‚ "supplier_add"
            if f"_{prefix}" in op_lower or f"{prefix}_" in op_lower:
                return True

    # æ£€æŸ¥ summary
    if summary:
        summary_lower = summary.lower()
        for prefix in create_prefixes:
            if prefix in summary_lower:
                return True

    return False


def _is_query_operation(operation_id: str | None, summary: str | None) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯æŸ¥è¯¢æ“ä½œ

    v3.39.1 æ–°å¢ï¼šç”¨äºç”Ÿæˆæ›´ç²¾ç¡®çš„æ–­è¨€æ¨¡æ¿ã€‚

    æŸ¥è¯¢ç±»æ“ä½œç‰¹å¾:
        - find*, get*, list*, query*, search*, select*, fetch*

    Args:
        operation_id: OpenAPI çš„ operationId
        summary: æ¥å£æ‘˜è¦

    Returns:
        True å¦‚æœæ˜¯æŸ¥è¯¢æ“ä½œ
    """
    # æŸ¥è¯¢ç±»æ“ä½œçš„å‰ç¼€
    query_prefixes = ("find", "get", "list", "query", "search", "select", "fetch", "load")

    # æ£€æŸ¥ operation_id
    if operation_id:
        op_lower = operation_id.lower()
        for prefix in query_prefixes:
            if op_lower.startswith(prefix):
                return True
            # ä¹Ÿæ£€æŸ¥ä¸‹åˆ’çº¿åˆ†éš”çš„æƒ…å†µ
            if f"_{prefix}" in op_lower or f"{prefix}_" in op_lower:
                return True

    # æ£€æŸ¥ summary
    if summary:
        summary_lower = summary.lower()
        # ä¸­æ–‡å…³é”®è¯
        cn_query_keywords = ("æŸ¥è¯¢", "è·å–", "åˆ—è¡¨", "æœç´¢", "æŸ¥æ‰¾")
        for keyword in cn_query_keywords:
            if keyword in summary_lower:
                return True
        # è‹±æ–‡å…³é”®è¯
        for prefix in query_prefixes:
            if prefix in summary_lower:
                return True

    return False


def _build_typed_test_method_code(
    endpoint: APIEndpoint,
    api_fixture: str,
    api_method: str,
    project_name: str,
    tag_id: str,
    endpoints: list | None = None,
    parser: OpenAPIParser | None = None,
) -> str:
    """æ„å»ºç±»å‹åŒ–çš„æµ‹è¯•æ–¹æ³•ä»£ç ï¼ˆv3.40.0 å¢å¼ºç‰ˆï¼‰

    ä½¿ç”¨ AAAï¼ˆArrange-Act-Assertï¼‰æ¨¡å¼ï¼š
    - Arrange: å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆåŒ…æ‹¬è·¯å¾„å‚æ•°å’Œè¯·æ±‚ä½“ï¼‰
    - Act: è°ƒç”¨æ¥å£
    - Assert: éªŒè¯å“åº”

    v3.40.0 å¢å¼º:
    - æ™ºèƒ½ç”Ÿæˆåˆ†é¡µæŸ¥è¯¢è¯·æ±‚ç¤ºä¾‹ï¼ˆä¸å†æ˜¯ç©ºå ä½ç¬¦ï¼‰
    - å‰ç½®æŸ¥è¯¢ç”Ÿæˆï¼ˆè¯¦æƒ…/æ›´æ–°/åˆ é™¤æ“ä½œè‡ªåŠ¨æŸ¥è¯¢è·å–IDï¼‰
    - ä¸­æ–‡æµ‹è¯•æ ‡é¢˜
    - æ™ºèƒ½åŒºåˆ† smoke/regression æµ‹è¯•
    - å¢å¼ºçš„åˆ—è¡¨æŸ¥è¯¢æ–­è¨€
    """
    test_name = f"test_{api_method}"

    # v3.40.0: ç”Ÿæˆä¸­æ–‡æµ‹è¯•æ ‡é¢˜
    title = _generate_chinese_title(endpoint.operation_id, endpoint.summary)

    # v3.40.0: æ™ºèƒ½è·å– pytest mark
    pytest_mark = _get_pytest_mark(endpoint.operation_id, endpoint.summary)

    # æ£€æŸ¥æ˜¯å¦æœ‰è¯·æ±‚ä½“
    has_request_model = endpoint.request_body is not None

    # è·å–è·¯å¾„å‚æ•°å’Œ query å‚æ•°ï¼ˆåˆ†ç¦»å¿…å¡«å’Œå¯é€‰ï¼‰
    path_params = endpoint.get_path_params()
    query_params = endpoint.get_query_params()
    required_query_params = [qp for qp in query_params if qp.required]
    optional_query_params = [qp for qp in query_params if not qp.required]
    has_path_params = bool(path_params)
    has_query_params = bool(query_params)

    # åˆ¤æ–­æ“ä½œç±»å‹
    needs_cleanup = _is_create_operation(endpoint.operation_id, endpoint.summary)
    is_list_query = _is_list_query_operation(endpoint.operation_id, endpoint.summary)
    needs_precondition = _needs_precondition_query(endpoint.operation_id, endpoint.summary)

    # è·å–è¯·æ±‚æ¨¡å‹åç§°ï¼ˆä½¿ç”¨ç®€åŒ–åçš„åç§°ï¼‰
    simplified_name = _simplify_operation_id(endpoint.operation_id)
    request_model = to_pascal_case(simplified_name) + "Request"

    # è·å–è¯·æ±‚ schemaï¼ˆç”¨äºæ™ºèƒ½ç”Ÿæˆç¤ºä¾‹ï¼‰
    request_schema = {}
    if endpoint.request_body:
        request_schema = endpoint.request_body.get("schema", {})
        if "$ref" in request_schema and parser:
            request_schema = parser._resolve_ref(request_schema["$ref"])

    # v3.40.0: æŸ¥æ‰¾åˆ—è¡¨æŸ¥è¯¢æ¥å£ï¼ˆç”¨äºå‰ç½®æŸ¥è¯¢ï¼‰
    list_api_info = None
    if needs_precondition and endpoints:
        list_api_info = _find_list_endpoint(endpoints, endpoint)

    # ========== Arrange é˜¶æ®µ ==========
    arrange_parts = []
    imports_needed = []

    # v3.40.0: å¦‚æœéœ€è¦å‰ç½®æŸ¥è¯¢ï¼Œç”Ÿæˆå‰ç½®æŸ¥è¯¢ä»£ç 
    if needs_precondition and list_api_info:
        list_method, list_request_model = list_api_info
        # v3.41.1: åªæœ‰å½“åˆ—è¡¨æ¥å£æœ‰è¯·æ±‚ä½“æ—¶æ‰æ·»åŠ åˆ°å¯¼å…¥
        if list_request_model:
            imports_needed.append(list_request_model)
        if has_request_model:
            imports_needed.append(request_model)

        # ç¡®å®šè¦è·å–çš„ ID å­—æ®µå
        id_field = "id"
        for param in path_params:
            if "id" in param.name.lower():
                id_field = param.name
                break

        # v3.41.1: æ ¹æ®åˆ—è¡¨æ¥å£æ˜¯å¦æœ‰è¯·æ±‚ä½“ç”Ÿæˆä¸åŒçš„ä»£ç 
        if list_request_model:
            arrange_parts.append(f"""# å‰ç½®æŸ¥è¯¢ï¼šè·å–æœ‰æ•ˆçš„ {id_field}
            list_request = {list_request_model}(pagination={{"pageSize": 1, "current": 1}})
            list_response = {api_fixture}.{list_method}(list_request)
            assert_that(list_response.status).is_in("ok", "success")
            if not list_response.data or not list_response.data.get("list"):
                pytest.skip("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•æ•°æ®")
            {id_field} = list_response.data["list"][0].get("id")""")
        else:
            # åˆ—è¡¨æ¥å£æ²¡æœ‰è¯·æ±‚ä½“ï¼Œç›´æ¥è°ƒç”¨æ— å‚æ–¹æ³•
            arrange_parts.append(f"""# å‰ç½®æŸ¥è¯¢ï¼šè·å–æœ‰æ•ˆçš„ {id_field}
            list_response = {api_fixture}.{list_method}()
            assert_that(list_response.status).is_in("ok", "success")
            if not list_response.data or not list_response.data.get("list"):
                pytest.skip("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•æ•°æ®")
            {id_field} = list_response.data["list"][0].get("id")""")

        # æ›´æ–°/è¯¦æƒ…æ“ä½œçš„è¯·æ±‚ä½“
        if has_request_model and not needs_cleanup:
            if _is_update_operation(endpoint.operation_id, endpoint.summary):
                arrange_parts.append(f"""
            # æ„é€ æ›´æ–°è¯·æ±‚
            existing_data = list_response.data["list"][0]
            request = {request_model}(
                id={id_field},
                # ä¿ç•™åŸæœ‰æ•°æ®ï¼Œåªä¿®æ”¹éœ€è¦æ›´æ–°çš„å­—æ®µ
            )""")
            else:
                # è¯¦æƒ…æŸ¥è¯¢
                arrange_parts.append(f"""
            # æ„é€ è¯¦æƒ…æŸ¥è¯¢è¯·æ±‚
            request = {request_model}(id={id_field})""")

    # 1. è·¯å¾„å‚æ•°å‡†å¤‡ï¼ˆå¦‚æœæ²¡æœ‰å‰ç½®æŸ¥è¯¢ï¼‰
    elif has_path_params:
        path_param_lines = []
        for param in path_params:
            param_type = _get_python_type(param.schema)
            if param_type == "int":
                path_param_lines.append(f"{param.name} = 1  # TODO: æ›¿æ¢ä¸ºå®é™…çš„ {param.name}")
            elif param_type == "str":
                path_param_lines.append(f'{param.name} = "test"  # TODO: æ›¿æ¢ä¸ºå®é™…çš„ {param.name}')
            else:
                path_param_lines.append(f"{param.name} = None  # TODO: æ›¿æ¢ä¸ºå®é™…çš„ {param.name}")
        arrange_parts.append("\n            ".join(path_param_lines))

    # 2. Query å‚æ•°å‡†å¤‡
    if has_query_params and not needs_precondition:
        query_param_lines = []
        for param in query_params:
            param_type = _get_python_type(param.schema)
            if param_type == "int":
                query_param_lines.append(f"{param.name} = 1  # TODO: æ›¿æ¢ä¸ºå®é™…çš„ {param.name}")
            elif param_type == "str":
                query_param_lines.append(
                    f'{param.name} = "test"  # TODO: æ›¿æ¢ä¸ºå®é™…çš„ {param.name}'
                )
            else:
                query_param_lines.append(f"{param.name} = None  # TODO: æ›¿æ¢ä¸ºå®é™…çš„ {param.name}")
        arrange_parts.append("\n            ".join(query_param_lines))

    # 3. è¯·æ±‚ä½“å‡†å¤‡ï¼ˆå¦‚æœæ²¡æœ‰åœ¨å‰ç½®æŸ¥è¯¢ä¸­å¤„ç†ï¼‰
    if not needs_precondition or not list_api_info:
        if needs_cleanup:
            # åˆ›å»ºæ“ä½œï¼šéœ€è¦ DataGenerator ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
            imports_needed.append(request_model)
            # v3.40.0: ä½¿ç”¨æ™ºèƒ½è¯·æ±‚ç¤ºä¾‹ç”Ÿæˆ
            request_example = _generate_request_example(
                request_schema, request_model, is_create=True
            )
            arrange_parts.append(f"""test_id = DataGenerator.test_id("TEST")  # ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦
            request = {request_example}""")
        elif has_request_model:
            # æœ‰è¯·æ±‚ä½“ä½†éåˆ›å»ºæ“ä½œï¼ˆæŸ¥è¯¢ç­‰ï¼‰
            imports_needed.append(request_model)
            # v3.40.0: ä½¿ç”¨æ™ºèƒ½è¯·æ±‚ç¤ºä¾‹ç”Ÿæˆ
            request_example = _generate_request_example(
                request_schema, request_model, is_create=False
            )
            arrange_parts.append(f"request = {request_example}")

    # ç»„åˆ Arrange ä»£ç 
    if arrange_parts:
        arrange_code = "\n            ".join(arrange_parts)
    else:
        arrange_code = "# æ— éœ€å‡†å¤‡è¯·æ±‚æ•°æ®\n            pass"

    # ========== Act é˜¶æ®µ ==========
    # æ„å»ºè°ƒç”¨å‚æ•°ï¼ˆä¸ API å®¢æˆ·ç«¯æ–¹æ³•ç­¾åé¡ºåºä¸€è‡´ï¼‰
    call_args = []
    # 1. è·¯å¾„å‚æ•°ï¼ˆä½ç½®å‚æ•°ï¼‰
    if has_path_params:
        call_args.extend([p.name for p in path_params])
    # 2. å¿…å¡« query å‚æ•°ï¼ˆä½ç½®å‚æ•°ï¼‰
    if required_query_params:
        call_args.extend([qp.name for qp in required_query_params])
    # 3. è¯·æ±‚ä½“ï¼ˆä½ç½®å‚æ•°ï¼‰
    if has_request_model or needs_cleanup:
        call_args.append("request")
    # 4. å¯é€‰ query å‚æ•°ï¼ˆå…³é”®å­—å‚æ•°ï¼‰
    if optional_query_params:
        call_args.extend([f"{qp.name}={qp.name}" for qp in optional_query_params])

    if call_args:
        act_code = f"response = {api_fixture}.{api_method}({', '.join(call_args)})"
    else:
        act_code = f"response = {api_fixture}.{api_method}()"

    # æ¸…ç†æ³¨å†Œï¼ˆåœ¨ Act ä¹‹åï¼‰
    cleanup_code = ""
    if needs_cleanup:
        cleanup_code = """

            # æ³¨å†Œæ•°æ®æ¸…ç†ï¼ˆåˆ›å»ºæˆåŠŸåæ¸…ç†ï¼‰
            # cleanup.add("resource_type", test_id)"""

    # ========== Assert é˜¶æ®µ ==========
    # v3.40.0: å¢å¼ºçš„æ–­è¨€æ¨¡æ¿
    if is_list_query:
        # åˆ—è¡¨æŸ¥è¯¢æ“ä½œï¼šéªŒè¯åˆ—è¡¨ç»“æ„å’Œåˆ†é¡µ
        assert_code = """# éªŒè¯å“åº”çŠ¶æ€
            assert_that(response.status).is_in("ok", "success")
            # éªŒè¯åˆ—è¡¨æ•°æ®ç»“æ„
            assert_that(response.data).is_not_none()
            if "list" in response.data:
                assert_that(response.data["list"]).is_instance_of(list)
            # éªŒè¯åˆ†é¡µä¿¡æ¯
            if "pagination" in response.data:
                assert_that(response.data["pagination"]).contains_key("total")
                assert_that(response.data["pagination"]["total"]).is_greater_than_or_equal_to(0)"""
    elif _is_detail_operation(endpoint.operation_id, endpoint.summary):
        # è¯¦æƒ…æŸ¥è¯¢ï¼šéªŒè¯è¿”å›çš„æ•°æ®
        assert_code = """# éªŒè¯å“åº”çŠ¶æ€
            assert_that(response.status).is_in("ok", "success")
            # éªŒè¯è¯¦æƒ…æ•°æ®
            assert_that(response.data).is_not_none()"""
    elif needs_cleanup:
        # åˆ›å»ºæ“ä½œï¼šéªŒè¯åˆ›å»ºæˆåŠŸ
        assert_code = """# éªŒè¯åˆ›å»ºæˆåŠŸ
            assert_that(response.status).is_in("ok", "success")
            # éªŒè¯è¿”å›æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            # assert_that(response.data).is_not_none()"""
    elif _is_update_operation(endpoint.operation_id, endpoint.summary):
        # æ›´æ–°æ“ä½œ
        assert_code = """# éªŒè¯æ›´æ–°æˆåŠŸ
            assert_that(response.status).is_in("ok", "success")"""
    elif _is_delete_operation(endpoint.operation_id, endpoint.summary):
        # åˆ é™¤æ“ä½œ
        assert_code = """# éªŒè¯åˆ é™¤æˆåŠŸ
            assert_that(response.status).is_in("ok", "success")"""
    elif _is_query_operation(endpoint.operation_id, endpoint.summary):
        # å…¶ä»–æŸ¥è¯¢æ“ä½œ
        assert_code = """# éªŒè¯å“åº”çŠ¶æ€
            assert_that(response.status).is_in("ok", "success")
            assert_that(response.data).is_not_none()"""
    else:
        # å…¶ä»–æ“ä½œï¼šé€šç”¨æ–­è¨€
        assert_code = """# éªŒè¯å“åº”çŠ¶æ€
            assert_that(response.status).is_in("ok", "success")"""

    # æ„å»º fixture å‚æ•°å’Œæ–‡æ¡£
    if needs_cleanup:
        fixture_params = f"{api_fixture}, cleanup"
        fixture_docs = f"""{api_fixture}: API å®¢æˆ·ç«¯ï¼ˆè‡ªåŠ¨æ³¨å†Œï¼‰
            cleanup: æ•°æ®æ¸…ç†ç®¡ç†å™¨ï¼ˆåˆ›å»ºæ“ä½œéœ€è¦ï¼‰"""
    else:
        fixture_params = api_fixture
        fixture_docs = f"{api_fixture}: API å®¢æˆ·ç«¯ï¼ˆè‡ªåŠ¨æ³¨å†Œï¼‰"

    # æ„å»ºå®Œæ•´çš„æµ‹è¯•æ–¹æ³•ï¼ˆAAA æ¨¡å¼ï¼‰
    code = f'''    @allure.title("{title}")
    @allure.severity(allure.severity_level.NORMAL)
    @pytest.mark.{pytest_mark}
    def {test_name}(self, {fixture_params}):
        """{title}

        Args:
            {fixture_docs}

        Note:
            allure_observer æ˜¯ autouse fixtureï¼Œè‡ªåŠ¨è®°å½•è¯·æ±‚/å“åº”åˆ° Allure æŠ¥å‘Š
        """
        # Arrange - å‡†å¤‡æµ‹è¯•æ•°æ®
        with step("å‡†å¤‡æµ‹è¯•æ•°æ®"):
            {arrange_code}

        # Act - æ‰§è¡Œæ“ä½œ
        with step("è°ƒç”¨æ¥å£"):
            {act_code}{cleanup_code}

        # Assert - éªŒè¯ç»“æœ
        with step("éªŒè¯å“åº”"):
            {assert_code}
'''

    return code


__all__ = ["generate_from_openapi"]
