"""RabbitMQæ¶ˆæ¯é˜Ÿåˆ—å®¢æˆ·ç«¯

æä¾›RabbitMQ Publisherå’ŒConsumerçš„å°è£…ã€‚

v3.9.0æ–°å¢

v3.14.0 æ–°å¢:
- é›†æˆ EventBus å‘å¸ƒæ¶ˆæ¯äº‹ä»¶
- æ”¯æŒ event_bus å‚æ•°

ä½¿ç”¨ç¤ºä¾‹::

    from df_test_framework.capabilities.messengers.queue.rabbitmq import (
        RabbitMQClient, RabbitMQConfig
    )

    # åˆ›å»ºå®¢æˆ·ç«¯
    config = RabbitMQConfig()
    client = RabbitMQClient(config)

    # å£°æ˜exchangeå’Œqueue
    client.declare_exchange("test-exchange", "direct")
    client.declare_queue("test-queue")
    client.bind_queue("test-queue", "test-exchange", "test-key")

    # å‘å¸ƒæ¶ˆæ¯
    client.publish(
        exchange="test-exchange",
        routing_key="test-key",
        message={"user_id": 123, "action": "login"}
    )

    # æ¶ˆè´¹æ¶ˆæ¯
    messages = []
    client.consume(
        queue="test-queue",
        handler=lambda msg: messages.append(msg),
        max_messages=10
    )

    client.close()
"""

from __future__ import annotations

import json
import time
from collections.abc import Callable
from typing import TYPE_CHECKING, Any

from df_test_framework.core.events import (
    MessageConsumeEndEvent,
    MessageConsumeErrorEvent,
    MessageConsumeStartEvent,
    MessagePublishEndEvent,
    MessagePublishErrorEvent,
    MessagePublishStartEvent,
)
from df_test_framework.infrastructure.logging import get_logger

from .config import RabbitMQConfig

if TYPE_CHECKING:
    from df_test_framework.infrastructure.events import EventBus

try:
    import pika
    from pika.exceptions import AMQPError
except ImportError:
    raise ImportError("pika æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install 'df-test-framework[rabbitmq]'")

logger = get_logger(__name__)


class RabbitMQClient:
    """RabbitMQæ¶ˆæ¯é˜Ÿåˆ—å®¢æˆ·ç«¯

    å°è£…pikaçš„åŸºæœ¬æ“ä½œ,æä¾›ç®€åŒ–çš„æ¶ˆæ¯å‘å¸ƒå’Œæ¶ˆè´¹æ¥å£ã€‚

    Attributes:
        config: RabbitMQé…ç½®
        connection: pikaè¿æ¥å¯¹è±¡
        channel: pikaé€šé“å¯¹è±¡
    """

    def __init__(self, config: RabbitMQConfig, event_bus: EventBus | None = None):
        """åˆå§‹åŒ–RabbitMQå®¢æˆ·ç«¯

        Args:
            config: RabbitMQé…ç½®å¯¹è±¡
            event_bus: ğŸ†• v3.14.0 äº‹ä»¶æ€»çº¿ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config
        self._event_bus = event_bus
        self._connection: pika.BlockingConnection | None = None
        self._channel: pika.channel.Channel | None = None

    def _get_event_bus(self):
        """è·å– EventBus å®ä¾‹

        v3.46.1: ç®€åŒ–é€»è¾‘ï¼Œåªä½¿ç”¨æ„é€ å‡½æ•°ä¼ å…¥çš„ event_bus
        """
        return self._event_bus

    def _publish_event(self, event: Any) -> None:
        """å‘å¸ƒäº‹ä»¶åˆ° EventBusï¼ˆåŒæ­¥æ¨¡å¼ï¼‰

        v3.18.0: æ”¹ç”¨ publish_sync() ç¡®ä¿äº‹ä»¶å®Œæ•´æ€§
        """
        event_bus = self._get_event_bus()
        if event_bus:
            try:
                event_bus.publish_sync(event)
            except Exception:
                pass  # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹

    @property
    def connection(self) -> pika.BlockingConnection:
        """è·å–æˆ–åˆ›å»ºè¿æ¥"""
        if self._connection is None or self._connection.is_closed:
            credentials = pika.PlainCredentials(
                self.config.connection.username,
                self.config.connection.password.get_secret_value(),
            )

            parameters = pika.ConnectionParameters(
                host=self.config.connection.host,
                port=self.config.connection.port,
                virtual_host=self.config.connection.virtual_host,
                credentials=credentials,
                heartbeat=self.config.connection.heartbeat,
                blocked_connection_timeout=self.config.connection.blocked_connection_timeout,
                connection_attempts=self.config.connection.connection_attempts,
                retry_delay=self.config.connection.retry_delay,
            )

            self._connection = pika.BlockingConnection(parameters)
            logger.info(
                f"RabbitMQè¿æ¥æˆåŠŸ: {self.config.connection.host}:{self.config.connection.port}"
            )

        return self._connection

    @property
    def channel(self) -> pika.channel.Channel:
        """è·å–æˆ–åˆ›å»ºé€šé“"""
        if self._channel is None or self._channel.is_closed:
            self._channel = self.connection.channel()
            # è®¾ç½®QoS
            self._channel.basic_qos(prefetch_count=self.config.consume.prefetch_count)
            logger.info("RabbitMQé€šé“åˆ›å»ºæˆåŠŸ")

        return self._channel

    def declare_exchange(
        self,
        exchange: str,
        exchange_type: str = "direct",
        durable: bool = True,
        auto_delete: bool = False,
    ) -> None:
        """å£°æ˜exchange

        Args:
            exchange: exchangeåç§°
            exchange_type: exchangeç±»å‹(direct, topic, fanout, headers)
            durable: æ˜¯å¦æŒä¹…åŒ–
            auto_delete: æ— æ¶ˆè´¹è€…æ—¶æ˜¯å¦è‡ªåŠ¨åˆ é™¤
        """
        self.channel.exchange_declare(
            exchange=exchange,
            exchange_type=exchange_type,
            durable=durable,
            auto_delete=auto_delete,
        )
        logger.info(f"Exchangeå£°æ˜æˆåŠŸ: {exchange} (type={exchange_type}, durable={durable})")

    def declare_queue(
        self,
        queue: str,
        durable: bool = True,
        exclusive: bool = False,
        auto_delete: bool = False,
        arguments: dict | None = None,
    ) -> pika.frame.Method:
        """å£°æ˜é˜Ÿåˆ—

        Args:
            queue: é˜Ÿåˆ—åç§°
            durable: æ˜¯å¦æŒä¹…åŒ–
            exclusive: æ˜¯å¦ç‹¬å 
            auto_delete: æ— æ¶ˆè´¹è€…æ—¶æ˜¯å¦è‡ªåŠ¨åˆ é™¤
            arguments: é˜Ÿåˆ—å‚æ•°(å¦‚TTLã€æ­»ä¿¡é˜Ÿåˆ—ç­‰)

        Returns:
            é˜Ÿåˆ—å£°æ˜ç»“æœ
        """
        result = self.channel.queue_declare(
            queue=queue,
            durable=durable,
            exclusive=exclusive,
            auto_delete=auto_delete,
            arguments=arguments or {},
        )
        logger.info(
            f"Queueå£°æ˜æˆåŠŸ: {queue} (durable={durable}, "
            f"message_count={result.method.message_count})"
        )
        return result

    def bind_queue(
        self,
        queue: str,
        exchange: str,
        routing_key: str = "",
        arguments: dict | None = None,
    ) -> None:
        """ç»‘å®šé˜Ÿåˆ—åˆ°exchange

        Args:
            queue: é˜Ÿåˆ—åç§°
            exchange: exchangeåç§°
            routing_key: è·¯ç”±é”®
            arguments: ç»‘å®šå‚æ•°
        """
        self.channel.queue_bind(
            queue=queue,
            exchange=exchange,
            routing_key=routing_key,
            arguments=arguments or {},
        )
        logger.info(f"Queueç»‘å®šæˆåŠŸ: {queue} -> {exchange} (routing_key={routing_key})")

    def publish(
        self,
        exchange: str,
        routing_key: str,
        message: dict[str, Any],
        headers: dict | None = None,
    ) -> None:
        """å‘å¸ƒæ¶ˆæ¯

        Args:
            exchange: exchangeåç§°
            routing_key: è·¯ç”±é”®
            message: æ¶ˆæ¯å†…å®¹(å­—å…¸)
            headers: æ¶ˆæ¯å¤´(å¯é€‰)

        Raises:
            AMQPError: å‘å¸ƒå¤±è´¥æ—¶æŠ›å‡º
        """
        # åºåˆ—åŒ–æ¶ˆæ¯
        body_bytes = json.dumps(message).encode("utf-8")
        body_size = len(body_bytes)

        # v3.34.1: topic ä½¿ç”¨ exchange:routing_key æ ¼å¼
        topic = f"{exchange}:{routing_key}" if exchange else routing_key

        # v3.34.1: å‘å¸ƒ Start äº‹ä»¶
        start_event, correlation_id = MessagePublishStartEvent.create(
            messenger_type="rabbitmq",
            topic=topic,
            body_size=body_size,
            headers=headers or {},
        )
        self._publish_event(start_event)

        start_time = time.perf_counter()
        try:
            properties = pika.BasicProperties(
                delivery_mode=self.config.publish.delivery_mode,
                content_type=self.config.publish.content_type,
                content_encoding=self.config.publish.content_encoding,
                headers=headers or {},
            )

            self.channel.basic_publish(
                exchange=exchange,
                routing_key=routing_key,
                body=body_bytes,
                properties=properties,
                mandatory=self.config.publish.mandatory,
            )

            # v3.34.1: å‘å¸ƒ End äº‹ä»¶
            duration = time.perf_counter() - start_time
            end_event = MessagePublishEndEvent.create(
                correlation_id=correlation_id,
                messenger_type="rabbitmq",
                topic=topic,
                duration=duration,
            )
            self._publish_event(end_event)

            logger.debug(f"æ¶ˆæ¯å‘å¸ƒæˆåŠŸ: exchange={exchange}, routing_key={routing_key}")

        except AMQPError as e:
            # v3.34.1: å‘å¸ƒ Error äº‹ä»¶
            duration = time.perf_counter() - start_time
            error_event = MessagePublishErrorEvent.create(
                correlation_id=correlation_id,
                messenger_type="rabbitmq",
                topic=topic,
                error=e,
                duration=duration,
            )
            self._publish_event(error_event)

            logger.error(f"å‘å¸ƒæ¶ˆæ¯å¤±è´¥: {e}")
            raise

    def publish_batch(
        self,
        exchange: str,
        routing_key: str,
        messages: list[dict[str, Any]],
    ) -> int:
        """æ‰¹é‡å‘å¸ƒæ¶ˆæ¯

        Args:
            exchange: exchangeåç§°
            routing_key: è·¯ç”±é”®
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æˆåŠŸå‘å¸ƒçš„æ¶ˆæ¯æ•°é‡
        """
        success_count = 0

        for message in messages:
            try:
                self.publish(exchange, routing_key, message)
                success_count += 1
            except AMQPError as e:
                logger.error(f"æ‰¹é‡å‘å¸ƒå¤±è´¥: {e}, message={message}")

        logger.info(f"æ‰¹é‡å‘å¸ƒå®Œæˆ: {success_count}/{len(messages)}")
        return success_count

    def consume(
        self,
        queue: str,
        handler: Callable[[dict[str, Any]], None],
        max_messages: int | None = None,
        auto_ack: bool | None = None,
        consumer_group: str = "",
    ) -> int:
        """æ¶ˆè´¹æ¶ˆæ¯

        Args:
            queue: é˜Ÿåˆ—åç§°
            handler: æ¶ˆæ¯å¤„ç†å‡½æ•°
            max_messages: æœ€å¤§æ¶ˆè´¹æ¶ˆæ¯æ•°(Noneè¡¨ç¤ºæŒç»­æ¶ˆè´¹)
            auto_ack: æ˜¯å¦è‡ªåŠ¨ç¡®è®¤(Noneä½¿ç”¨é…ç½®ä¸­çš„è®¾ç½®)
            consumer_group: æ¶ˆè´¹è€…ç»„åç§°ï¼ˆv3.34.1 æ–°å¢ï¼Œç”¨äºäº‹ä»¶è®°å½•ï¼‰

        Returns:
            å·²æ¶ˆè´¹çš„æ¶ˆæ¯æ•°é‡
        """
        if auto_ack is None:
            auto_ack = self.config.consume.auto_ack

        message_count = 0

        logger.info(f"å¼€å§‹æ¶ˆè´¹: queue={queue}, auto_ack={auto_ack}")

        try:
            for method_frame, properties, body in self.channel.consume(
                queue=queue, auto_ack=auto_ack
            ):
                if method_frame is None:
                    break

                # v3.34.1: å‘å¸ƒ Start äº‹ä»¶
                body_size = len(body) if body else 0
                start_event, correlation_id = MessageConsumeStartEvent.create(
                    messenger_type="rabbitmq",
                    topic=queue,
                    consumer_group=consumer_group,
                    body_size=body_size,
                )
                self._publish_event(start_event)

                process_start = time.perf_counter()
                try:
                    message = json.loads(body.decode("utf-8"))
                    handler(message)
                    message_count += 1

                    # æ‰‹åŠ¨ç¡®è®¤
                    if not auto_ack:
                        self.channel.basic_ack(method_frame.delivery_tag)

                    # v3.34.1: å‘å¸ƒ End äº‹ä»¶
                    processing_time = time.perf_counter() - process_start
                    end_event = MessageConsumeEndEvent.create(
                        correlation_id=correlation_id,
                        messenger_type="rabbitmq",
                        topic=queue,
                        consumer_group=consumer_group,
                        processing_time=processing_time,
                    )
                    self._publish_event(end_event)

                    logger.debug(f"æ¶ˆæ¯å¤„ç†æˆåŠŸ: delivery_tag={method_frame.delivery_tag}")

                    if max_messages and message_count >= max_messages:
                        logger.info(f"è¾¾åˆ°æœ€å¤§æ¶ˆè´¹æ•°é‡: {max_messages}")
                        break

                except Exception as e:
                    # v3.34.1: å‘å¸ƒ Error äº‹ä»¶
                    processing_time = time.perf_counter() - process_start
                    error_event = MessageConsumeErrorEvent.create(
                        correlation_id=correlation_id,
                        messenger_type="rabbitmq",
                        topic=queue,
                        consumer_group=consumer_group,
                        error=e,
                        processing_time=processing_time,
                    )
                    self._publish_event(error_event)

                    logger.error(f"æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}, body={body}")
                    # æ‹’ç»æ¶ˆæ¯
                    if not auto_ack:
                        self.channel.basic_nack(method_frame.delivery_tag, requeue=False)

        except KeyboardInterrupt:
            logger.info("æ¶ˆè´¹è¢«ä¸­æ–­")
        finally:
            self.channel.cancel()
            logger.info(f"æ¶ˆè´¹å®Œæˆ: {message_count} æ¡æ¶ˆæ¯")

        return message_count

    def get_message(self, queue: str) -> dict[str, Any] | None:
        """ä»é˜Ÿåˆ—è·å–å•æ¡æ¶ˆæ¯(éé˜»å¡)

        Args:
            queue: é˜Ÿåˆ—åç§°

        Returns:
            æ¶ˆæ¯å†…å®¹,å¦‚æœé˜Ÿåˆ—ä¸ºç©ºåˆ™è¿”å›None
        """
        method_frame, properties, body = self.channel.basic_get(
            queue=queue, auto_ack=self.config.consume.auto_ack
        )

        if method_frame is None:
            return None

        message = json.loads(body.decode("utf-8"))

        # æ‰‹åŠ¨ç¡®è®¤
        if not self.config.consume.auto_ack:
            self.channel.basic_ack(method_frame.delivery_tag)

        logger.debug(f"è·å–æ¶ˆæ¯æˆåŠŸ: delivery_tag={method_frame.delivery_tag}")

        return message

    def purge_queue(self, queue: str) -> int:
        """æ¸…ç©ºé˜Ÿåˆ—

        Args:
            queue: é˜Ÿåˆ—åç§°

        Returns:
            æ¸…ç©ºçš„æ¶ˆæ¯æ•°é‡
        """
        result = self.channel.queue_purge(queue=queue)
        logger.info(f"é˜Ÿåˆ—æ¸…ç©ºæˆåŠŸ: {queue}, æ¸…ç©º{result.method.message_count}æ¡æ¶ˆæ¯")
        return result.method.message_count

    def delete_queue(self, queue: str, if_unused: bool = False) -> int:
        """åˆ é™¤é˜Ÿåˆ—

        Args:
            queue: é˜Ÿåˆ—åç§°
            if_unused: ä»…åœ¨æ— æ¶ˆè´¹è€…æ—¶åˆ é™¤

        Returns:
            åˆ é™¤çš„æ¶ˆæ¯æ•°é‡
        """
        result = self.channel.queue_delete(queue=queue, if_unused=if_unused)
        logger.info(f"é˜Ÿåˆ—åˆ é™¤æˆåŠŸ: {queue}")
        return result.method.message_count

    def delete_exchange(self, exchange: str, if_unused: bool = False) -> None:
        """åˆ é™¤exchange

        Args:
            exchange: exchangeåç§°
            if_unused: ä»…åœ¨æ— ç»‘å®šæ—¶åˆ é™¤
        """
        self.channel.exchange_delete(exchange=exchange, if_unused=if_unused)
        logger.info(f"Exchangeåˆ é™¤æˆåŠŸ: {exchange}")

    def close(self) -> None:
        """å…³é—­å®¢æˆ·ç«¯,é‡Šæ”¾èµ„æº"""
        if self._channel and not self._channel.is_closed:
            self._channel.close()
            logger.info("RabbitMQé€šé“å·²å…³é—­")

        if self._connection and not self._connection.is_closed:
            self._connection.close()
            logger.info("RabbitMQè¿æ¥å·²å…³é—­")


__all__ = ["RabbitMQClient"]
