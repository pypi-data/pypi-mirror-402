{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Tutorial 12: Posterior analysis with uncertain parameters\n",
    "\n",
    "This tutorial demonstrates how to analyze queueing models with parameter\n",
    "uncertainty using the Posterior solver. The Posterior solver works with\n",
    "Prior distributions that represent uncertainty about model parameters,\n",
    "computing posterior distributions of performance metrics.\n",
    "\n",
    "Scenario: An M/M/1 queue where the service rate is uncertain. We model\n",
    "this uncertainty using a Prior distribution with 30 alternatives,\n",
    "creating a Gaussian-like distribution of possible service rates.\n",
    "\n",
    "Copyright (c) 2012-2025, Imperial College London\n",
    "All rights reserved.\n",
    "\"\"\"\n",
    "\n",
    "from line_solver import *\n",
    "import numpy as np\n",
    "\n",
    "# Block 1: Create model with uncertain service rate\n",
    "model = Network('UncertainServiceModel')\n",
    "\n",
    "# Create nodes\n",
    "source = Source(model, 'Source')\n",
    "queue = Queue(model, 'Queue', SchedStrategy.FCFS)\n",
    "sink = Sink(model, 'Sink')\n",
    "\n",
    "# Create job class\n",
    "job_class = OpenClass(model, 'Jobs')\n",
    "\n",
    "# Set arrival rate (lambda = 0.5)\n",
    "arrival_rate = 0.5\n",
    "source.setArrival(job_class, Exp(arrival_rate))\n",
    "\n",
    "# Block 2: Define Prior distribution for uncertain service rate\n",
    "# Use many alternatives to create a smooth, continuous-looking PDF\n",
    "# Service rates range from 0.7 to 2.5 with a Gaussian-like prior\n",
    "num_alternatives = 30\n",
    "service_rates = np.linspace(0.7, 2.5, num_alternatives)\n",
    "\n",
    "# Create Gaussian-like prior probabilities centered at mu=1.3\n",
    "prior_mean = 1.3\n",
    "prior_std = 0.4\n",
    "prior_probs = np.exp(-0.5 * ((service_rates - prior_mean) / prior_std)**2)\n",
    "prior_probs = prior_probs / np.sum(prior_probs)  # Normalize to sum to 1\n",
    "\n",
    "alternatives = [Exp(rate) for rate in service_rates]\n",
    "prior = Prior(alternatives, prior_probs.tolist())\n",
    "queue.setService(job_class, prior)\n",
    "\n",
    "# Block 3: Complete model topology\n",
    "model.link(Network.serial_routing([source, queue, sink]))\n",
    "\n",
    "print('Model: M/M/1 with uncertain service rate')\n",
    "print(f'Arrival rate: lambda = {arrival_rate:.1f}')\n",
    "print(f'Number of service rate alternatives: {num_alternatives}')\n",
    "print(f'Service rate range: mu in [{service_rates.min():.2f}, {service_rates.max():.2f}]')\n",
    "print(f'Prior: Gaussian-like centered at mu={prior_mean:.1f} with std={prior_std:.1f}\\n')\n",
    "\n",
    "# Block 4: Solve with Posterior wrapper using MVA\n",
    "post = Posterior(model, MVA)\n",
    "post.run_analyzer()\n",
    "\n",
    "# Block 5: Get prior-weighted average results\n",
    "avg_table = post.get_avg_table()\n",
    "print('Prior-weighted average performance metrics:')\n",
    "print(avg_table)\n",
    "print()\n",
    "\n",
    "# Block 6: Get posterior table with per-alternative results\n",
    "post_table = post.get_posterior_table()\n",
    "print('Posterior table (showing per-alternative results):')\n",
    "print(post_table)\n",
    "print()\n",
    "\n",
    "# Block 7: Extract posterior distributions for different metrics\n",
    "# Get posterior distribution of response time at the queue\n",
    "resp_dist = post.get_posterior_dist('R', queue, job_class)\n",
    "\n",
    "# Get posterior distribution of queue length at the queue\n",
    "qlen_dist = post.get_posterior_dist('Q', queue, job_class)\n",
    "\n",
    "# Get posterior distribution of utilization at the queue\n",
    "util_dist = post.get_posterior_dist('U', queue, job_class)\n",
    "\n",
    "# Block 8: Extract values and probabilities from the EmpiricalCDF objects\n",
    "# For response time\n",
    "resp_cdf_data = resp_dist.data  # [CDF, Value]\n",
    "resp_values = resp_cdf_data[:, 1]\n",
    "resp_cdf = resp_cdf_data[:, 0]\n",
    "resp_probs = np.concatenate([[resp_cdf[0]], np.diff(resp_cdf)])  # Convert CDF to PMF\n",
    "\n",
    "# For queue length\n",
    "qlen_cdf_data = qlen_dist.data\n",
    "qlen_values = qlen_cdf_data[:, 1]\n",
    "qlen_cdf = qlen_cdf_data[:, 0]\n",
    "qlen_probs = np.concatenate([[qlen_cdf[0]], np.diff(qlen_cdf)])\n",
    "\n",
    "# For utilization\n",
    "util_cdf_data = util_dist.data\n",
    "util_values = util_cdf_data[:, 1]\n",
    "util_cdf = util_cdf_data[:, 0]\n",
    "util_probs = np.concatenate([[util_cdf[0]], np.diff(util_cdf)])\n",
    "\n",
    "# Block 9: Print posterior distribution statistics\n",
    "# Response time statistics\n",
    "expected_R = np.sum(resp_values * resp_probs)\n",
    "mode_idx_R = np.argmax(resp_probs)\n",
    "print('Response Time (R) at Queue:')\n",
    "print(f'  Expected Value E[R]: {expected_R:.4f}')\n",
    "print(f'  Mode (most likely): {resp_values[mode_idx_R]:.4f}\\n')\n",
    "\n",
    "# Queue length statistics\n",
    "expected_Q = np.sum(qlen_values * qlen_probs)\n",
    "mode_idx_Q = np.argmax(qlen_probs)\n",
    "print('Queue Length (Q) at Queue:')\n",
    "print(f'  Expected Value E[Q]: {expected_Q:.4f}')\n",
    "print(f'  Mode (most likely): {qlen_values[mode_idx_Q]:.4f}\\n')\n",
    "\n",
    "# Utilization statistics\n",
    "expected_U = np.sum(util_values * util_probs)\n",
    "mode_idx_U = np.argmax(util_probs)\n",
    "print('Utilization (U) at Queue:')\n",
    "print(f'  Expected Value E[U]: {expected_U:.4f}')\n",
    "print(f'  Mode (most likely): {util_values[mode_idx_U]:.4f}\\n')\n",
    "\n",
    "# Optional: Find median from CDF\n",
    "median_idx = np.where(resp_cdf >= 0.5)[0]\n",
    "if len(median_idx) > 0:\n",
    "    median_R = resp_values[median_idx[0]]\n",
    "    print(f'Response Time Median: {median_R:.4f}')\n"
   ],
   "id": "8a55de979bb7104a"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
