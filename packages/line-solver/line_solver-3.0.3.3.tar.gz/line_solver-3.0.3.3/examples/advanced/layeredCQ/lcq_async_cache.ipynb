{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Layered cache queueing model with asynchronous (non-blocking) cache access.\n",
    "\n",
    "This example demonstrates async cache calls where:\n",
    "- Client makes async call to cache (fire-and-forget, non-blocking)\n",
    "- Client continues immediately without waiting for cache response\n",
    "- Cache still uses POST_CACHE precedence for hit/miss determination\n",
    "- Use for prefetching, cache warming, or non-critical operations\n",
    "\n",
    "Compare with lcq_singlehost.ipynb which uses synchronous cache calls.\n",
    "\"\"\"\n",
    "\n",
    "from line_solver import *\n",
    "import numpy as np\n",
    "\n",
    "# Set verbose level\n",
    "GlobalConstants.set_verbose(VerboseLevel.SILENT)\n",
    "\n",
    "# Create layered network model\n",
    "model = LayeredNetwork('AsyncCacheLQN')\n",
    "\n",
    "# Client processor and task\n",
    "P1 = Processor(model, 'P1', 1, SchedStrategy.PS)\n",
    "T1 = Task(model, 'T1', 1, SchedStrategy.REF).on(P1)\n",
    "E1 = Entry(model, 'E1').on(T1)\n",
    "\n",
    "# Cache processor and task\n",
    "totalitems = 4\n",
    "cachecapacity = 2\n",
    "\n",
    "# Create uniform access probabilities using Python list\n",
    "access_probs = [1.0 / totalitems] * totalitems\n",
    "pAccess = DiscreteSampler(access_probs)\n",
    "\n",
    "PC = Processor(model, 'PC', 1, SchedStrategy.PS)\n",
    "C2 = CacheTask(model, 'C2', totalitems, cachecapacity, ReplacementStrategy.LRU, 1).on(PC)\n",
    "I2 = ItemEntry(model, 'I2', totalitems, pAccess).on(C2)\n",
    "\n",
    "# Definition of activities\n",
    "# Client activity with ASYNC call to cache (non-blocking, fire-and-forget)\n",
    "A1 = Activity(model, 'A1', Immediate()).on(T1).bound_to(E1).asynch_call(I2, 1)\n",
    "\n",
    "# Cache activities (unchanged from sync version)\n",
    "AC2 = Activity(model, 'AC2', Immediate()).on(C2).bound_to(I2)\n",
    "AC2h = Activity(model, 'AC2h', Exp(1.0)).on(C2).replies_to(I2)   # Cache hit\n",
    "AC2m = Activity(model, 'AC2m', Exp(0.5)).on(C2).replies_to(I2)   # Cache miss\n",
    "\n",
    "# Add cache access precedence (unchanged)\n",
    "C2.add_precedence(ActivityPrecedence.cache_access(AC2, [AC2h, AC2m]))\n",
    "\n",
    "# Solve the model\n",
    "print(\"=== Solving Async Cache Model ===\")\n",
    "lnoptions = LN.default_options()\n",
    "lnoptions.verbose = True\n",
    "options = MVA.default_options()\n",
    "options.verbose = False\n",
    "\n",
    "solver = LN(model, lambda model: MVA(model, options), lnoptions)\n",
    "AvgTable = solver.avg_table()\n",
    "\n",
    "print(\"\\n=== Average Performance Metrics ===\")\n",
    "print(AvgTable)\n",
    "\n",
    "print(\"\\n=== Compare with Synchronous Version ===\")\n",
    "print(\"To compare async vs sync cache access:\")\n",
    "print(\"1. Run this script (async): python lcq_async_cache.py\")\n",
    "print(\"2. Run sync notebook: lcq_singlehost.ipynb\")\n",
    "print(\"\")\n",
    "print(\"Expected differences:\")\n",
    "print(\"- Async: Lower client response time (no blocking)\")\n",
    "print(\"- Async: Higher client throughput (no cache bottleneck)\")\n",
    "print(\"- Similar cache hit/miss ratios (same cache logic)\")\n"
   ],
   "id": "ea893eeecefd2697"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
