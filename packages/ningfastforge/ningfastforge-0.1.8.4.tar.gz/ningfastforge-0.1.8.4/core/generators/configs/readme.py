"""README.md generategenerator"""
from core.decorators import Generator
from ..templates.base import BaseTemplateGenerator


@Generator(
    category="config",
    priority=2,
    description="Generate README.md with project documentation"
)
class ReadmeGenerator(BaseTemplateGenerator):
    """README.md File generator"""
    
    def generate(self) -> None:
        """generate README.md file"""
        project_name = self.config_reader.get_project_name()
        
        content = self._build_header(project_name)
        content += self._build_features_section()
        content += self._build_installation_section()
        content += self._build_structure_section()
        content += self._build_configuration_section()
        content += self._build_api_docs_section()
        content += self._build_development_section()
        content += self._build_license_section()
        
        self.file_ops.create_markdown_file(
            file_path="README.md",
            title=None,
            content=content,
            overwrite=True
        )
    
    def _build_header(self, project_name: str) -> str:
        """Build header"""
        return f'''# {project_name}

FastAPI project generated by [Forge](https://github.com/ning3739/forge).

'''
    
    def _build_features_section(self) -> str:
        """Build features list section"""
        features = []
        
        # Database (is now required)
        db_type = self.config_reader.get_database_type()
        orm_type = self.config_reader.get_orm_type()
        features.append(f"- ðŸ—„ï¸ **Database**: {db_type} with {orm_type}")
        
        # Migration support
        if self.config_reader.has_migration():
            features.append("- ðŸ“¦ **Database Migrations**: Alembic support")
        
        if self.config_reader.has_auth():
            auth_type = self.config_reader.get_auth_type()
            features.append(f"- ðŸ” **Authentication**: {auth_type}")
            if self.config_reader.has_refresh_token():
                features.append("- ðŸ”„ **Refresh Token**: Secure token refresh")
        
        # Redis and Celery
        if self.config_reader.has_redis():
            features.append("- ðŸ”´ **Redis**: Caching and session management")
        
        if self.config_reader.has_celery():
            features.append("- ðŸ“‹ **Background Tasks**: Celery with Redis broker")
            features.append("- ðŸ’¾ **Database Backup**: Automated backup tasks (MySQL, PostgreSQL, SQLite)")
        
        if self.config_reader.has_cors():
            features.append("- ðŸŒ **CORS**: Cross-Origin Resource Sharing enabled")
        
        # Security features (always included)
        security_features = ["Input Validation", "Password Hashing", "Rate Limiting"]
        features.append(f"- ðŸ”’ **Security**: {', '.join(security_features)}")
        
        if self.config_reader.has_testing():
            features.append("- ðŸ§ª **Testing**: pytest with async support and coverage")
        
        if self.config_reader.has_docker():
            features.append("- ðŸ³ **Docker**: Production-ready containerization")
        
        if self.config_reader.has_dev_tools():
            features.append("- ðŸ› ï¸ **Development Tools**: Black, Ruff for code quality")
        
        # Always included features
        features.append("- ðŸ“š **API Documentation**: Swagger UI and ReDoc")
        features.append("- ðŸ“Š **Logging**: Structured logging with Loguru")
        features.append("- ðŸ¥ **Health Check**: Built-in health check endpoint")
        
        return '## âœ¨ Features\n\n' + '\n'.join(features) + '\n\n'
    
    def _build_installation_section(self) -> str:
        """Build installation instructions section"""
        return '''## ðŸš€ Quick Start

### Prerequisites

- Python 3.9+
- [uv](https://docs.astral.sh/uv/) (recommended)

### Installation

#### Using uv (Recommended)

```bash
# Install dependencies
uv sync

# Run the application
uv run uvicorn app.main:app --reload
```

### Access Your API

Once running, visit:

- **API Documentation (Swagger)**: http://127.0.0.1:8000/docs
- **API Documentation (ReDoc)**: http://127.0.0.1:8000/redoc
- **Health Check**: http://127.0.0.1:8000/health

'''
    
    def _build_structure_section(self) -> str:
        """Buildprojectstructure section"""
        content = '''## Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py             # Application entry point
â”‚   â”œâ”€â”€ core/               # Core configurations
â”‚   â”‚   â”œâ”€â”€ config/         # Configuration modules
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”‚   â””â”€â”€ modules/    # Config modules (app, database, jwt, redis, celery, etc.)
â”‚   â”‚   â”œâ”€â”€ database/       # Database connection'''
        
        # Add Redis and Celery files if enabled
        if self.config_reader.has_redis():
            content += '''
â”‚   â”‚   â”œâ”€â”€ redis.py        # Redis connection manager'''
        
        if self.config_reader.has_celery():
            content += '''
â”‚   â”‚   â”œâ”€â”€ celery.py       # Celery configuration'''
        
        content += '''
â”‚   â”‚   â”œâ”€â”€ deps.py         # Dependencies
â”‚   â”‚   â”œâ”€â”€ logger.py       # Logging configuration
â”‚   â”‚   â””â”€â”€ security.py     # Security utilities
â”‚   â”œâ”€â”€ decorators/         # Custom decorators
â”‚   â”‚   â””â”€â”€ rate_limit.py   # Rate limiting decorator
â”‚   â”œâ”€â”€ models/             # Database models
â”‚   â”œâ”€â”€ schemas/            # Pydantic schemas
â”‚   â”œâ”€â”€ crud/               # CRUD operations
'''
        
        if self.config_reader.has_auth():
            content += '''â”‚   â”œâ”€â”€ services/           # Business logic
'''
        
        content += '''â”‚   â”œâ”€â”€ routers/            # API routes
â”‚   â”‚   â””â”€â”€ v1/             # API version 1'''
        
        # Add tasks directory if Celery is enabled
        if self.config_reader.has_celery():
            content += '''
â”‚   â”œâ”€â”€ tasks/              # Celery tasks
â”‚   â”‚   â”œâ”€â”€ __init__.py     # Task exports
â”‚   â”‚   â””â”€â”€ backup_database_task.py   # Database backup task'''
        
        content += '''
â”‚   â””â”€â”€ utils/              # Utility functions
'''
        
        if self.config_reader.has_migration():
            content += '''â”œâ”€â”€ alembic/                # Database migrations
â”‚   â”œâ”€â”€ versions/           # Migration versions
â”‚   â””â”€â”€ env.py              # Alembic configuration
'''
        
        content += '''â”œâ”€â”€ static/                 # Static files (images, CSS, JS, etc.)
'''
        
        if self.config_reader.has_testing():
            content += '''â”œâ”€â”€ tests/                  # Test files
â”‚   â”œâ”€â”€ conftest.py         # Pytest configuration
â”‚   â”œâ”€â”€ test_main.py        # Main API tests
â”‚   â””â”€â”€ api/                # API endpoint tests
'''
        
        if self.config_reader.has_docker():
            content += '''â”œâ”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ docker-compose.yml      # Docker Compose configuration
â”œâ”€â”€ .dockerignore           # Docker ignore file
'''
        
        content += '''â”œâ”€â”€ script/                 # Custom scripts (shell script,  etc.)
â”œâ”€â”€ secret/                 # Environment files
â”‚   â”œâ”€â”€ .env.example        # Environment variables template
â”‚   â”œâ”€â”€ .env.development    # Development environment
â”‚   â””â”€â”€ .env.production     # Production environment
â”œâ”€â”€ static/                 # Static files (images, CSS, JS, etc.)
â”œâ”€â”€ pyproject.toml          # Project dependencies
â”œâ”€â”€ .gitignore              # Git ignore file
â””â”€â”€ README.md               # This file
```

'''
        return content
    
    def _build_configuration_section(self) -> str:
        """Buildconfigurationdescriptionpartial"""
        content = '''## Configuration

Copy `.env.example` to `.env` and update the values:

```bash
cp .env.example .env
```

'''
        # databaseconfiguration(is nowrequired)
        content += self._build_database_config()
        
        return content
    
    def _build_database_config(self) -> str:
        """Builddatabaseconfigurationdescription"""
        content = '''### Database Configuration

Update the database connection string in `.env.development` and `.env.production`:

```
DATABASE_URL=postgresql://user:password@localhost:5432/dbname
```

'''
        
        if self.config_reader.has_migration():
            content += '''### Database Migrations

```bash
# Create a new migration
uv run alembic revision --autogenerate -m "description"

# Apply migrations
uv run alembic upgrade head
```

'''
        
        return content
    
    def _build_api_docs_section(self) -> str:
        """Build API documentation section"""
        return '''## ðŸ“š API Documentation

Once the application is running, visit:

- **Swagger UI**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc
- **Health Check**: http://127.0.0.1:8000/health

## ðŸ”’ Security Features

### Rate Limiting

The project includes a built-in rate limiting decorator to protect your API endpoints:

```python
from app.decorators.rate_limit import rate_limit, rate_limit_strict

# Custom rate limit
@router.get("/api/data")
@rate_limit(max_requests=100, window_seconds=60)
async def get_data(request: Request):
    return {"data": "value"}

# Predefined strict limit (10 requests/minute)
@router.post("/api/action")
@rate_limit_strict
async def perform_action(request: Request):
    return {"status": "success"}
```

**Available decorators:**
- `@rate_limit_strict` - 10 requests per minute
- `@rate_limit_moderate` - 100 requests per minute
- `@rate_limit_relaxed` - 1000 requests per hour

**Custom identifier (e.g., user-based):**
```python
@rate_limit(
    max_requests=50,
    window_seconds=3600,
    identifier_func=lambda req: req.state.user.id
)
async def user_endpoint(request: Request):
    return {"data": "user-specific"}
```

**Note:** The default implementation uses in-memory storage. For production with multiple instances, consider using Redis-based rate limiting.

'''
    
    def _build_development_section(self) -> str:
        """Build development section"""
        content = '## ðŸ› ï¸ Development\n\n'
        
        # Add Celery section if enabled
        if self.config_reader.has_celery():
            content += self._build_celery_section()
        
        if self.config_reader.has_dev_tools():
            content += self._build_dev_tools_section()
        
        if self.config_reader.has_testing():
            content += self._build_testing_section()
        
        if self.config_reader.has_docker():
            content += self._build_docker_section()
        
        return content
    
    def _build_dev_tools_section(self) -> str:
        """Build development tools section"""
        return '''### Code Formatting

```bash
# Format code with Black
black .

# Lint with Ruff
ruff check .

# Type checking with MyPy
mypy .
```

'''
    
    def _build_testing_section(self) -> str:
        """Buildtestdescription"""
        return '''### Running Tests

```bash
# Install test dependencies
uv sync --extra dev

# Or install specific test packages
uv add --dev pytest pytest-asyncio httpx aiosqlite

# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=app tests/

# Run specific test file
uv run pytest tests/api/test_auth.py -v
```

'''
    
    def _build_docker_section(self) -> str:
        """Build Docker description"""
        project_name = self.config_reader.get_project_name()
        
        # Check if project has multiple services (Redis, Celery, etc.)
        has_multiple_services = (
            self.config_reader.has_redis() or 
            self.config_reader.has_celery() or 
            self.config_reader.get_database_type() in ["MySQL", "PostgreSQL"]
        )
        
        if has_multiple_services:
            # Use Docker Compose for multi-service setup
            content = f'''### Docker

This project includes a complete Docker Compose setup with all required services.

#### Production Deployment

```bash
# Build and start all services
docker-compose up --build

# Run in background
docker-compose up -d --build

# View logs
docker-compose logs -f

# Stop all services
docker-compose down
```

#### Services Included

- **FastAPI Application**: Main API server (port 8000)
- **Database**: {self.config_reader.get_database_type()} database with health checks
- **Database Migration**: Automatic schema migrations on startup'''
            
            if self.config_reader.has_redis():
                content += '''
- **Redis**: Caching and session storage (port 6379)'''
            
            if self.config_reader.has_celery():
                content += '''
- **Celery Worker**: Background task processing
- **Celery Beat**: Scheduled task management'''
            
            content += '''

#### Environment Configuration

The Docker setup uses production environment variables from `./secret/.env.production`.
Make sure to update database credentials and other sensitive settings before deployment.

#### Development vs Production

- **Development**: Use `uv run uvicorn app.main:app --reload` for local development
- **Production**: Use `docker-compose up` for full containerized deployment

'''
            return content
        else:
            # Use simple Docker commands for single-service setup
            return f'''### Docker

```bash
# Build image
docker build -t {project_name} .

# Run container
docker run -p 8000:8000 {project_name}
```

'''
    
    def _build_license_section(self) -> str:
        """Build license section"""
        return '''## ðŸ“ License

This project was created by [Forge](https://github.com/ning3739/forge) and is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

Generated with â¤ï¸ by [Forge](https://github.com/ning3739/forge) - A powerful FastAPI project scaffolding tool.

Built with:
- [FastAPI](https://fastapi.tiangolo.com/) - Modern, fast web framework
- [SQLModel](https://sqlmodel.tiangolo.com/) - SQL databases in Python with type safety
- [Pydantic](https://pydantic-docs.helpmanual.io/) - Data validation using Python type hints
- [Alembic](https://alembic.sqlalchemy.org/) - Database migration tool
- [pytest](https://pytest.org/) - Testing framework

---

**Need help?** Check out the [Forge documentation](https://github.com/ning3739/forge) or open an issue.
'''
    
    def _build_celery_section(self) -> str:
        """Build Celery section"""
        return '''### Background Tasks (Celery)

This project uses Celery for background task processing with Redis as the message broker.

#### Starting Celery Services

**1. Start the main application:**
```bash
uv run uvicorn app.main:app --reload
```

**2. Start Celery worker:**
```bash
uv run celery -A app.core.celery.celery_app worker --loglevel=info
```

**3. Start Flower monitoring tool (optional):**
```bash
uv run celery -A app.core.celery.celery_app flower
# Access at http://localhost:5555
```

#### Database Backup Task

The project includes an automated database backup task that supports MySQL, PostgreSQL, and SQLite:

```python
from app.tasks.backup_database_task import backup_database_task

# Execute backup task asynchronously
result = backup_database_task.delay()

# With custom parameters
result = backup_database_task.delay(
    database_name="custom_db",
    retention_days=7,
    backup_dir="./custom_backups"
)

# Get task status
print(f"Task ID: {result.id}")
print(f"Task Status: {result.status}")

# Wait for result
task_result = result.get()
print(f"Backup Result: {task_result}")
```

#### Scheduled Tasks (Production Only)

For production environments, you can enable automatic scheduling by starting Celery Beat:

```bash
# Production only - start Celery Beat scheduler
uv run celery -A app.core.celery.celery_app beat --loglevel=info
```

The following tasks are automatically scheduled when Beat is running:

- **Database Backup**: Runs daily at 3:00 AM, keeps backups for 30 days
- Backups are stored locally in `./backups/database/` directory
- Supports MySQL (mysqldump), PostgreSQL (pg_dump), and SQLite (sqlite3)
- Automatic compression and cleanup of old backups

#### Configuration

Celery configuration is managed through environment variables:
- `CELERY_BROKER_URL`: Redis broker URL (default: redis://localhost:6379/1)
- `CELERY_RESULT_BACKEND`: Result backend URL (default: redis://localhost:6379/2)

**Redis Setup:**
```bash
# Install and start Redis
brew install redis  # macOS
sudo apt-get install redis-server  # Ubuntu
# Or use Docker: docker run -d -p 6379:6379 redis:alpine
```

'''
