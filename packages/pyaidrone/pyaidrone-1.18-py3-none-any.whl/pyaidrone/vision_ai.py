import os
import cv2
import numpy as np
import time
from typing import Optional, Union, List, Tuple
from collections import namedtuple

# --- [íŒŒíŠ¸ 1: ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° ë° edu.py í•„ìˆ˜ ì°¸ì¡° í•¨ìˆ˜] ---

class FPSMeter:
    def __init__(self):
        self.p_time = 0
    def get_fps(self):
        c_time = time.time()
        fps = 1 / (c_time - self.p_time) if (c_time - self.p_time) > 0 else 0
        self.p_time = c_time
        return int(fps)

def draw_box(img, box, label="", color=(0, 255, 0), thickness=2):
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)
    if label:
        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

def draw_box_xywh(img, box_xywh, label="", color=(0, 255, 0)):
    x, y, w, h = box_xywh
    draw_box(img, (x, y, x + w, y + h), label, color)

def letterbox(img, new_shape=(640, 640), color=(114, 114, 114)):
    shape = img.shape[:2]
    if isinstance(new_shape, int): new_shape = (new_shape, new_shape)
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]
    dw /= 2; dh /= 2
    if shape[::-1] != new_unpad:
        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return img, r, (left, top)

# edu.pyì—ì„œ ìƒ‰ìƒ ì¸ì‹ì„ ìœ„í•´ ì‚¬ìš©í•˜ëŠ” í•„ìˆ˜ í•¨ìˆ˜ë“¤ ì¶”ê°€
def largest_contour(contours):
    if not contours: return None
    return max(contours, key=cv2.contourArea)

def contour_centroid(contour):
    M = cv2.moments(contour)
    if M["m00"] == 0: return None
    return (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))

# --- [íŒŒíŠ¸ 2: YOLOv8 ëŒ€ì‘ yolo_decode (edu.py ë°ì´í„° í˜•ì‹ ì§€ì›)] ---

def yolo_decode(outputs, img_shape, input_shape, r, pad, threshold=0.4):
    """YOLOv8ìš© ë””ì½”ë“œ í•¨ìˆ˜. ê²°ê³¼ê°’ì„ edu.pyê°€ ê¸°ëŒ€í•˜ëŠ” ê°ì²´ í˜•íƒœë¡œ ë°˜í™˜"""
    output = np.squeeze(outputs[0]).transpose() # (8400, 84)
    
    # edu.pyì—ì„œ res.box, res.score ë“±ìœ¼ë¡œ ì ‘ê·¼í•˜ê¸° ìœ„í•œ êµ¬ì¡°
    Detection = namedtuple('Detection', ['class_id', 'score', 'box'])
    results = []
    
    for i in range(len(output)):
        scores = output[i][4:]
        max_score = np.max(scores)
        if max_score > threshold:
            cx, cy, w, h = output[i][:4]
            # ì›ë³¸ ì¢Œí‘œ ë³µì› ë¡œì§
            x1 = (cx - w / 2 - pad[0]) / r
            y1 = (cy - h / 2 - pad[1]) / r
            x2 = (cx + w / 2 - pad[0]) / r
            y2 = (cy + h / 2 - pad[1]) / r
            results.append(Detection(int(np.argmax(scores)), float(max_score), [x1, y1, x2, y2]))
            
    return results

# --- [íŒŒíŠ¸ 3: TFLiteDetector í´ë˜ìŠ¤ (Windows & Linux í˜¸í™˜)] ---

class TFLiteDetector:
    def __init__(self, model_path: str):
        # ìœˆë„ìš° í™˜ê²½(TensorFlow)ê³¼ ë¼ì¦ˆë² ë¦¬íŒŒì´(tflite-runtime) ìë™ ì„ íƒ
        try:
            import tensorflow.lite as tflite
        except ImportError:
            try:
                import tflite_runtime.interpreter as tflite
            except ImportError:
                print("âŒ TFLiteë¥¼ ì‹¤í–‰í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
        self.interpreter = tflite.Interpreter(model_path=model_path)
        self.interpreter.allocate_tensors()
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        
    def infer(self, frame, decode_func, threshold=0.4):
        """edu.pyì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª…ì¹­ì¸ 'infer'ë¡œ ìœ ì§€"""
        ih, iw = self.input_details[0]['shape'][1:3]
        img, r, pad = letterbox(frame, (ih, iw))
        
        input_data = np.expand_dims(img, axis=0).astype(np.float32)
        if self.input_details[0]['dtype'] == np.float32:
            input_data /= 255.0
            
        self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
        self.interpreter.invoke()
        
        outputs = [self.interpreter.get_tensor(out['index']) for out in self.output_details]
        return decode_func(outputs, (frame.shape[1], frame.shape[0]), (iw, ih), r, pad, threshold)

# --- [íŒŒíŠ¸ 4: VisionTracker - JPEG ì—ëŸ¬ í•´ê²° ë²„ì „] ---

class VisionTracker:
    def __init__(self):
        self.tracker = None
        self.is_tracking = False

    def set_target(self, frame, x, y):
        """í´ë¦­í•œ ì§€ì  ì£¼ë³€(80x80)ì„ ì¶”ì  ëŒ€ìƒìœ¼ë¡œ ì„¤ì • - ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”"""
        try:
            # ğŸ”§ 1. í”„ë ˆì„ ìœ íš¨ì„± ì²´í¬
            if frame is None or frame.size == 0:
                print("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ í”„ë ˆì„")
                return False
            
            h, w = frame.shape[:2]
            
            # ğŸ”§ 2. ROI ê³„ì‚°
            x_roi = int(x - 40)
            y_roi = int(y - 40)
            w_roi = 80
            h_roi = 80
            
            # ğŸ”§ 3. ê²½ê³„ ì²´í¬ ë° ë³´ì •
            x_roi = max(0, min(x_roi, w - w_roi))
            y_roi = max(0, min(y_roi, h - h_roi))
            
            # ğŸ”§ 4. ROIê°€ í”„ë ˆì„ ì•ˆì— ì™„ì „íˆ ë“¤ì–´ê°€ëŠ”ì§€ í™•ì¸
            if x_roi + w_roi > w or y_roi + h_roi > h:
                print("âš ï¸ ROIê°€ í”„ë ˆì„ ë°–ìœ¼ë¡œ ë²—ì–´ë‚¨")
                return False
            
            roi = (x_roi, y_roi, w_roi, h_roi)
            
            # ğŸ”§ 5. ì¶”ì ê¸° ìƒì„± ë° ì´ˆê¸°í™”
            self.tracker = cv2.TrackerCSRT_create()
            success = self.tracker.init(frame, roi)
            
            if success:
                self.is_tracking = True
                print(f"âœ… ì¶”ì  ì‹œì‘: ROI={roi}")
                return True
            else:
                print("âŒ ì¶”ì ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ set_target ì—ëŸ¬: {e}")
            self.is_tracking = False
            return False

    def get_error(self, frame):
        """í˜„ì¬ ì¶”ì  ì¤‘ì¸ ë¬¼ì²´ì˜ ì˜¤ì°¨ì™€ ì¢Œí‘œ ë°˜í™˜ - ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”"""
        if not self.is_tracking or self.tracker is None:
            return None
        
        try:
            # ğŸ”§ 1. í”„ë ˆì„ ìœ íš¨ì„± ì²´í¬
            if frame is None or frame.size == 0:
                return None
            
            # ğŸ”§ 2. ì¶”ì  ì—…ë°ì´íŠ¸
            success, box = self.tracker.update(frame)
            
            if success:
                x, y, w, h = [int(v) for v in box]
                
                # ğŸ”§ 3. ë°•ìŠ¤ê°€ ìœ íš¨í•œì§€ í™•ì¸
                if w <= 0 or h <= 0:
                    print("âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ë°•ìŠ¤ í¬ê¸°")
                    self.is_tracking = False
                    return None
                
                # ğŸ”§ 4. ì˜¤ì°¨ ê³„ì‚°
                error_x = (x + w // 2) - 320  # í™”ë©´ ì¤‘ì‹¬(320)ê³¼ì˜ ì˜¤ì°¨
                error_y = 240 - (y + h // 2)  # í™”ë©´ ì¤‘ì‹¬(240)ê³¼ì˜ ì˜¤ì°¨
                return error_x, error_y, (x, y, w, h)
            else:
                print("âš ï¸ ì¶”ì  ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                self.is_tracking = False
                return None
                
        except Exception as e:
            print(f"âŒ get_error ì—ëŸ¬: {e}")
            self.is_tracking = False
            return None
