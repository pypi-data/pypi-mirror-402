Metadata-Version: 2.4
Name: mcp-gemini-search
Version: 0.2.6
Summary: MCP Server for web search via Gemini's grounding API
Project-URL: Homepage, https://github.com/cubase/mcp-search-server
Project-URL: Repository, https://github.com/cubase/mcp-search-server
Author: cubase
License-Expression: MIT
License-File: LICENSE
Keywords: ai,anthropic,claude,gemini,llm,mcp,search
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Requires-Dist: httpx>=0.25.0
Requires-Dist: mcp>=1.0.0
Description-Content-Type: text/markdown

# MCP Search Server

A Model Context Protocol (MCP) server that provides web search capabilities via Gemini's grounding API.

## Features

- üîç Real-time web search powered by Google Gemini
- ‚ö° Built-in caching (5 min TTL)
- üéØ Structured search results (Title + URL + Summary)
- üåç Multi-language support

## Installation

```bash
pip install mcp-search-server
```

## Configuration

Set environment variables:

```bash
export MCP_SEARCH_URL="http://localhost:8045/v1/messages"
export MCP_SEARCH_API_KEY="your-api-key"
export MCP_SEARCH_MODEL="gemini-3-flash"  # or gemini-3-pro-high
export MCP_SEARCH_CACHE_TTL="300"  # seconds
```

## Usage

### As MCP Server (with Zed, Claude Desktop, etc.)

```json
{
  "mcpServers": {
    "mcp-search": {
      "command": "python",
      "args": ["-m", "mcp_search"],
      "env": {
        "MCP_SEARCH_URL": "http://localhost:8045/v1/messages",
        "MCP_SEARCH_API_KEY": "your-api-key",
        "MCP_SEARCH_MODEL": "gemini-3-flash"
      }
    }
  }
}
```

### As Python Library

```python
import asyncio
from mcp_search import do_search

result = asyncio.run(do_search(
    query="latest AI news",
    max_results=5,
    model="gemini-3-flash"
))
print(result)
```

## Tool Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `query` | string | ‚úÖ | Search keywords |
| `max_results` | integer | ‚ùå | Number of results (default: 8) |
| `model` | string | ‚ùå | Model ID (default: gemini-3-flash) |

## Requirements

- Python 3.10+
- [Antigravity Manager](https://github.com/lbjlaq/Antigravity-Manager) running locally

## License

MIT
