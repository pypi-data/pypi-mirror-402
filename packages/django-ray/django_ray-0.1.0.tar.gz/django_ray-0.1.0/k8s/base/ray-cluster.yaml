# Ray Cluster deployment using native Kubernetes
# For production, consider using KubeRay operator instead
#
# Optimized for: 16 CPUs, 64GB RAM, GPU available
# Adjust resources based on your Docker Desktop K8s resource allocation
---
# Ray Head Node
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ray-head
  namespace: django-ray
  labels:
    app: ray
    component: head
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ray
      component: head
  template:
    metadata:
      labels:
        app: ray
        component: head
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: ray-head
          # Custom image with django-ray installed (built from Dockerfile.ray)
          image: django-ray-worker:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 6379  # GCS server
              name: gcs
            - containerPort: 8265  # Dashboard
              name: dashboard
            - containerPort: 10001 # Client server
              name: client
            - containerPort: 8080  # Prometheus metrics
              name: metrics
          command: ["/bin/bash", "-c"]
          args:
            - |
              ray start --head \
                --port=6379 \
                --dashboard-host=0.0.0.0 \
                --dashboard-port=8265 \
                --metrics-export-port=8080 \
                --num-cpus=4 \
                --memory=8000000000 \
                --object-store-memory=2000000000 \
                --disable-usage-stats \
                --block
          env:
            - name: RAY_DASHBOARD_HOST
              value: "0.0.0.0"
            - name: RAY_METRICS_EXPORT_PORT
              value: "8080"
            - name: RAY_PROMETHEUS_HOST
              value: "http://prometheus-svc:9090"
            - name: RAY_GRAFANA_HOST
              value: "http://grafana-svc:3000"
            - name: RAY_GRAFANA_IFRAME_HOST
              value: "http://localhost:30030"
            - name: RAY_PROMETHEUS_NAME
              value: "Prometheus"
          envFrom:
            - configMapRef:
                name: django-ray-config
            - secretRef:
                name: django-ray-secret
          resources:
            requests:
              memory: "8Gi"
              cpu: "2"
            limits:
              memory: "12Gi"
              cpu: "4"
          volumeMounts:
            - name: ray-tmp
              mountPath: /tmp/ray
          readinessProbe:
            tcpSocket:
              port: 6379
            initialDelaySeconds: 10
            periodSeconds: 5
          livenessProbe:
            tcpSocket:
              port: 6379
            initialDelaySeconds: 30
            periodSeconds: 10
        # Sidecar container to import Ray dashboards into Grafana
        - name: dashboard-importer
          image: django-ray-worker:latest
          imagePullPolicy: IfNotPresent
          command: ["python3", "/scripts/import_dashboards.py"]
          env:
            - name: GRAFANA_URL
              value: "http://grafana-svc:3000"
          volumeMounts:
            - name: ray-tmp
              mountPath: /tmp/ray
            - name: import-script
              mountPath: /scripts
          resources:
            requests:
              memory: "64Mi"
              cpu: "50m"
            limits:
              memory: "128Mi"
              cpu: "100m"
      volumes:
        - name: ray-tmp
          emptyDir: {}
        - name: import-script
          configMap:
            name: grafana-dashboard-import-script
            defaultMode: 0755
---
# Ray Head Service
apiVersion: v1
kind: Service
metadata:
  name: ray-head-svc
  namespace: django-ray
  labels:
    app: ray
    component: head
spec:
  selector:
    app: ray
    component: head
  ports:
    - name: gcs
      port: 6379
      targetPort: 6379
    - name: dashboard
      port: 8265
      targetPort: 8265
      nodePort: 30265  # Access via http://localhost:30265
    - name: client
      port: 10001
      targetPort: 10001
    - name: metrics
      port: 8080
      targetPort: 8080
  type: NodePort
---
# Ray Worker Nodes
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ray-worker
  namespace: django-ray
  labels:
    app: ray
    component: worker
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ray
      component: worker
  template:
    metadata:
      labels:
        app: ray
        component: worker
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      initContainers:
        - name: wait-for-head
          image: busybox:1.36
          command: ['sh', '-c', 'until nc -z ray-head-svc 6379; do echo waiting for ray-head; sleep 2; done;']
      containers:
        - name: ray-worker
          # Custom image with django-ray installed (built from Dockerfile.ray)
          image: django-ray-worker:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080  # Prometheus metrics
              name: metrics
          command: ["/bin/bash", "-c"]
          args:
            - |
              ray start \
                --address=ray-head-svc:6379 \
                --metrics-export-port=8080 \
                --num-cpus=4 \
                --memory=8000000000 \
                --object-store-memory=2000000000 \
                --block
          env:
            # Enable Prometheus metrics export
            - name: RAY_PROMETHEUS_HOST
              value: "0.0.0.0"
            - name: RAY_METRICS_EXPORT_PORT
              value: "8080"
          envFrom:
            - configMapRef:
                name: django-ray-config
            - secretRef:
                name: django-ray-secret
          resources:
            requests:
              memory: "8Gi"
              cpu: "2"
              # Uncomment below to request GPU (requires nvidia device plugin)
              # nvidia.com/gpu: "1"
            limits:
              memory: "12Gi"
              cpu: "4"
              # nvidia.com/gpu: "1"
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - "ray status --address=ray-head-svc:6379 2>/dev/null | grep -q 'Active' || pgrep -f raylet"
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 6
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - "pgrep -f raylet || pgrep -f 'ray::'"
            initialDelaySeconds: 30
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 3

