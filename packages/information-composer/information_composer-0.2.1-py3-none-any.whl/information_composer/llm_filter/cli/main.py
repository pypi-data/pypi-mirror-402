#!/usr/bin/env python3
"""
MD_LLM_Filter CLI ä¸»ç¨‹åº
æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
- å•æ–‡ä»¶è¿‡æ»¤ï¼š-i å‚æ•°
- ç›®å½•æ‰¹é‡è¿‡æ»¤ï¼š-m å‚æ•°
- è¾“å‡ºæŒ‡å®šï¼š-o å‚æ•°
- è‡ªåŠ¨æ·»åŠ _filteredåç¼€
"""

import argparse
import asyncio
import logging
from pathlib import Path
import sys

from tqdm import tqdm

from ..core.filter import MarkdownFilter
from ..utils.text_processing import get_document_stats


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def find_markdown_files(directory: Path) -> list[Path]:
    """
    åœ¨ç›®å½•ä¸­æŸ¥æ‰¾æ‰€æœ‰markdownæ–‡ä»¶
    Args:
        directory: ç›®å½•è·¯å¾„
    Returns:
        markdownæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    markdown_files = []
    # æ”¯æŒçš„markdownæ–‡ä»¶æ‰©å±•å
    markdown_extensions = {".md", ".markdown", ".mdown", ".mkdn", ".mkd"}
    try:
        for file_path in directory.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in markdown_extensions:
                markdown_files.append(file_path)
    except Exception as e:
        logger.error(f"æ‰«æç›®å½•å¤±è´¥ {directory}: {e}")
    return sorted(markdown_files)


def create_output_path(input_path: Path, output_dir: Path | None = None) -> Path:
    """
    åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
    Args:
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•
    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    if output_dir:
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºç›®å½•ï¼Œä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
        output_file = output_dir / f"{input_path.stem}_filtered.md"
    else:
        # åœ¨è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•åˆ›å»º_filteredæ–‡ä»¶
        output_file = input_path.parent / f"{input_path.stem}_filtered.md"
    return output_file


async def process_single_file(
    input_file: Path,
    output_file: Path | None = None,
    filter_obj: MarkdownFilter | None = None,
    show_stats: bool = False,
    verbose: bool = False,
) -> bool:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        filter_obj: è¿‡æ»¤å™¨å¯¹è±¡
        show_stats: æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
    Returns:
        å¤„ç†æ˜¯å¦æˆåŠŸ
    """
    try:
        if verbose:
            logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if output_file is None:
            output_file = create_output_path(input_file)
        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file, encoding="utf-8") as f:
            content = f.read()
        # æ˜¾ç¤ºåŸå§‹ç»Ÿè®¡ä¿¡æ¯
        if show_stats:
            original_stats = get_document_stats(content)
            print(f"\nğŸ“„ æ–‡ä»¶: {input_file.name}")
            print(f"   åŸå§‹è¡Œæ•°: {original_stats['total_lines']:,}")
            print(f"   åŸå§‹å­—ç¬¦æ•°: {original_stats['characters']:,}")
            print(f"   åŸå§‹å•è¯æ•°: {original_stats['words']:,}")
        # æ‰§è¡Œè¿‡æ»¤
        if verbose:
            logger.info("æ­£åœ¨è¿‡æ»¤å†…å®¹...")
        if filter_obj is None:
            filter_obj = MarkdownFilter()
        filtered_content = await filter_obj.filter_paper(content)
        # ä¿å­˜è¾“å‡ºæ–‡ä»¶
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(filtered_content)
        if verbose:
            logger.info(f"è¿‡æ»¤å®Œæˆ: {output_file}")
        # æ˜¾ç¤ºè¿‡æ»¤åç»Ÿè®¡ä¿¡æ¯
        if show_stats:
            filtered_stats = get_document_stats(filtered_content)
            filter_stats = filter_obj.get_filter_statistics(content, filtered_content)
            print(f"   è¿‡æ»¤åè¡Œæ•°: {filtered_stats['total_lines']:,}")
            print(f"   è¿‡æ»¤åå­—ç¬¦æ•°: {filtered_stats['characters']:,}")
            print(f"   è¿‡æ»¤åå•è¯æ•°: {filtered_stats['words']:,}")
            print(
                "   è¡Œæ•°å‡å°‘: "
                f"{filter_stats['lines_reduction']:,} "
                f"({filter_stats['lines_reduction_percent']:.1f}%)"
            )
            print(
                "   å­—ç¬¦æ•°å‡å°‘: "
                f"{filter_stats['chars_reduction']:,} "
                f"({filter_stats['chars_reduction_percent']:.1f}%)"
            )
            print(f"   å‹ç¼©æ¯”: {filter_stats['compression_ratio']:.3f}")
        return True
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {input_file}: {e}")
        if verbose:
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        return False


async def process_directory(
    input_dir: Path,
    output_dir: Path | None = None,
    filter_obj: MarkdownFilter | None = None,
    show_stats: bool = False,
    verbose: bool = False,
) -> int:
    """
    å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰markdownæ–‡ä»¶
    Args:
        input_dir: è¾“å…¥ç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨è¾“å…¥ç›®å½•
        filter_obj: è¿‡æ»¤å™¨å¯¹è±¡
        show_stats: æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
    Returns:
        æˆåŠŸå¤„ç†çš„æ–‡ä»¶æ•°é‡
    """
    try:
        # æŸ¥æ‰¾æ‰€æœ‰markdownæ–‡ä»¶
        markdown_files = find_markdown_files(input_dir)
        if not markdown_files:
            logger.warning(f"åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°markdownæ–‡ä»¶")
            return 0
        logger.info(f"æ‰¾åˆ° {len(markdown_files)} ä¸ªmarkdownæ–‡ä»¶")
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir:
            output_dir.mkdir(parents=True, exist_ok=True)
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        success_count = 0
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(
            markdown_files,
            desc="å¤„ç†æ–‡ä»¶",
            unit="æ–‡ä»¶",
            disable=verbose,  # å¦‚æœverboseæ¨¡å¼å¼€å¯ï¼Œç¦ç”¨è¿›åº¦æ¡
        )
        for input_file in progress_bar:
            # æ›´æ–°è¿›åº¦æ¡æè¿°
            progress_bar.set_description(f"å¤„ç† {input_file.name}")
            if verbose:
                logger.info(f"å¤„ç†æ–‡ä»¶: {input_file.name}")
            # è®¡ç®—è¾“å‡ºæ–‡ä»¶è·¯å¾„
            if output_dir:
                # ä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
                relative_path = input_file.relative_to(input_dir)
                output_file = output_dir / f"{relative_path.stem}_filtered.md"
                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                output_file.parent.mkdir(parents=True, exist_ok=True)
            else:
                output_file = None
            # å¤„ç†æ–‡ä»¶
            success = await process_single_file(
                input_file, output_file, filter_obj, show_stats, verbose
            )
            if success:
                success_count += 1
                if not verbose:
                    progress_bar.set_postfix(
                        {
                            "æˆåŠŸ": success_count,
                            "å¤±è´¥": len(markdown_files) - success_count,
                        }
                    )
            else:
                if not verbose:
                    progress_bar.set_postfix(
                        {
                            "æˆåŠŸ": success_count,
                            "å¤±è´¥": len(markdown_files) - success_count,
                        }
                    )
        # å…³é—­è¿›åº¦æ¡
        progress_bar.close()
        return success_count
    except Exception as e:
        logger.error(f"å¤„ç†ç›®å½•å¤±è´¥ {input_dir}: {e}")
        if verbose:
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        return 0


def main() -> None:
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="MD_LLM_Filter - åŸºäºLLMçš„Markdownå­¦æœ¯è®ºæ–‡è¿‡æ»¤å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # è¿‡æ»¤å•ä¸ªæ–‡ä»¶ (è‡ªåŠ¨æ·»åŠ _filteredåç¼€)
  md-llm-filter -i paper.md
  # è¿‡æ»¤å•ä¸ªæ–‡ä»¶å¹¶æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  md-llm-filter -i paper.md -o filtered_paper.md
  # æ‰¹é‡è¿‡æ»¤ç›®å½•ä¸­çš„æ‰€æœ‰markdownæ–‡ä»¶ (æ˜¾ç¤ºè¿›åº¦æ¡)
  md-llm-filter -m papers/ -o filtered_papers/
  # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
  md-llm-filter -i paper.md --stats
  # è¯¦ç»†è¾“å‡º (ç¦ç”¨è¿›åº¦æ¡)
  md-llm-filter -m papers/ --verbose
  # æ‰¹é‡å¤„ç†å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
  md-llm-filter -m papers/ -o filtered_papers/ --stats
        """,
    )
    # è¾“å…¥å‚æ•°ç»„
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument(
        "-i", "--input-file", type=Path, help="è¾“å…¥Markdownæ–‡ä»¶è·¯å¾„"
    )
    input_group.add_argument(
        "-m", "--input-dir", type=Path, help="è¾“å…¥ç›®å½•è·¯å¾„ (æ‰¹é‡å¤„ç†æ‰€æœ‰markdownæ–‡ä»¶)"
    )
    # è¾“å‡ºå‚æ•°
    parser.add_argument("-o", "--output", type=Path, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„")
    # å…¶ä»–å‚æ•°
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºè¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument(
        "--model",
        default="qwen-plus-latest",
        help="ä½¿ç”¨çš„LLMæ¨¡å‹ (é»˜è®¤: qwen-plus-latest)",
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡ºæ¨¡å¼")
    args = parser.parse_args()
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    # éªŒè¯è¾“å…¥å‚æ•°
    if args.input_file:
        if not args.input_file.exists():
            logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
            sys.exit(1)
        if not args.input_file.is_file():
            logger.error(f"è¾“å…¥è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {args.input_file}")
            sys.exit(1)
    elif args.input_dir:
        if not args.input_dir.exists():
            logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
            sys.exit(1)
        if not args.input_dir.is_dir():
            logger.error(f"è¾“å…¥è·¯å¾„ä¸æ˜¯ç›®å½•: {args.input_dir}")
            sys.exit(1)
    # éªŒè¯è¾“å‡ºå‚æ•°
    if args.output:
        if args.input_file and args.output.is_dir():
            logger.error("å½“è¾“å…¥æ˜¯æ–‡ä»¶æ—¶ï¼Œè¾“å‡ºä¸èƒ½æ˜¯ç›®å½•")
            sys.exit(1)
        if args.input_dir and args.output.is_file():
            logger.error("å½“è¾“å…¥æ˜¯ç›®å½•æ—¶ï¼Œè¾“å‡ºä¸èƒ½æ˜¯æ–‡ä»¶")
            sys.exit(1)
    try:
        # åˆ›å»ºè¿‡æ»¤å™¨
        filter_obj = MarkdownFilter(model=args.model)
        # æ‰§è¡Œå¤„ç†
        if args.input_file:
            # å•æ–‡ä»¶å¤„ç†
            success = asyncio.run(
                process_single_file(
                    args.input_file, args.output, filter_obj, args.stats, args.verbose
                )
            )
            if success:
                output_path = args.output or create_output_path(args.input_file)
                print("\nâœ… å¤„ç†å®Œæˆï¼")
                print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input_file}")
                print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
            else:
                logger.error("æ–‡ä»¶å¤„ç†å¤±è´¥")
                sys.exit(1)
        elif args.input_dir:
            # ç›®å½•æ‰¹é‡å¤„ç†
            success_count = asyncio.run(
                process_directory(
                    args.input_dir, args.output, filter_obj, args.stats, args.verbose
                )
            )
            print("\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼")
            print(f"ğŸ“ è¾“å…¥ç›®å½•: {args.input_dir}")
            if args.output:
                print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
            print(f"ğŸ“Š æˆåŠŸå¤„ç†: {success_count} ä¸ªæ–‡ä»¶")
            if success_count == 0:
                logger.error("æ²¡æœ‰æ–‡ä»¶è¢«æˆåŠŸå¤„ç†")
                sys.exit(1)
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        if args.verbose:
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        sys.exit(1)


if __name__ == "__main__":
    main()
