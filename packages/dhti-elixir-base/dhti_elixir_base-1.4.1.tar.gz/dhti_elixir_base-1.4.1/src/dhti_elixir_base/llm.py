import json
from collections.abc import Mapping
from typing import Any

import requests
from langchain_core.language_models.llms import LLM
from pydantic import Field


class BaseLLM(LLM):

    base_url: str | None = Field(
        None, alias="base_url"
    )  #! Alias is important when inheriting from LLM
    model: str | None = Field(None, alias="model")
    api_key: str | None = Field(None, alias="api_key")
    params: Mapping[str, Any] = Field(default_factory=dict, alias="params")
    timeout: int = 60
    backend: str | None = "dhti"
    temperature: float | None = 0.1
    top_p: float | None = 0.8
    top_k: int | None = 40
    n_batch: int | None = 8
    n_threads: int | None = 4
    n_predict: int | None = 256
    max_output_tokens: int | None = 512
    repeat_last_n: int | None = 64
    repeat_penalty: float | None = 1.18

    def __init__(self, base_url: str, model: str, **kwargs):
        super().__init__(**kwargs)
        self.base_url = base_url
        self.model = model
        self.params = {**self._get_model_default_parameters, **kwargs}

    @property
    def _get_model_default_parameters(self):
        return {
            "max_output_tokens": self.max_output_tokens,
            "n_predict": self.n_predict,
            "top_k": self.top_k,
            "top_p": self.top_p,
            "temperature": self.temperature,
            "n_batch": self.n_batch,
            "repeat_penalty": self.repeat_penalty,
            "repeat_last_n": self.repeat_last_n,
        }

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """
        Get all the identifying parameters
        """
        return {
            "model": self.model,
            "base_url": self.base_url,
            "model_parameters": self._get_model_default_parameters,
        }

    @property
    def _llm_type(self) -> str:
        return "dhti"

    def _prepare_payload(self, prompt: str) -> dict:
        # Basic chat messages wrapper; user prompt placed as single user message
        return {
            "model": self.model,
            "options": self._get_model_default_parameters,
            "messages": [{"role": "user", "content": prompt}],
        }

    def _call(
        self,
        prompt: str,
        stop: list[str] | None = None,
        run_manager: Any | None = None,
        **kwargs,
    ) -> str:
        """
        Args:
            prompt: The prompt to pass into the model.
            stop: A list of strings to stop generation when encountered
            run_manager: Optional run manager for callbacks and tracing

        Returns:
            The string generated by the model
        """

        payload = self._prepare_payload(prompt)
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }
        resp = requests.post(
            self.base_url, headers=headers, json=payload, timeout=self.timeout  # type: ignore
        )
        try:
            resp.raise_for_status()
        except Exception as e:
            raise RuntimeError(
                f"API request failed: {e}; status={resp.status_code}; body={resp.text}"
            )

        data = resp.json()
        # Expecting structure like: { "choices": [ { "message": { "role":"assistant","content":"..." } } ] }
        # Adapt this path if the API differs
        if "choices" in data and len(data["choices"]) > 0:
            choice = data["choices"][0]
            # support both "message" and direct "text"
            text = None
            if (
                isinstance(choice, dict)
                and "message" in choice
                and isinstance(choice["message"], dict)
            ):
                text = choice["message"].get("content")
            elif "text" in choice:
                text = choice.get("text")
            if text is not None:
                return text
        # Fallback: return raw JSON string for debugging
        return json.dumps(data)
