[tool.poetry]
name = "tauro"
version = "0.1.5"
description = "Tauro - Data pipeline framework for batch, streaming, and hybrid workflows"
authors = ["Faustino Lopez Ramos <faustinolopezramos@gmail.com>"]
readme = "src/README.md"
license = "MIT"
homepage = "https://github.com/faustino125/tauro"
repository = "https://github.com/faustino125/tauro"
keywords = ["data-pipeline", "etl", "spark", "streaming", "orchestration", "workflow"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Environment :: Console",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries",
    "Topic :: System :: Systems Administration",
]

packages = [
    { include = "tauro", from = "src" }
]

exclude = [
    "src/tauro/**/test",
    "src/tauro/**/__pycache__"
]

[tool.poetry.dependencies]
python = "^3.10"
# Core dependencies
loguru = "^0.7.0"
PyYAML = "^6.0"
pandas = "^2.0.0"
python-dotenv = "^1.0.0"
typing-extensions = "^4.3.0"

# Optional: Big Data processing
pyspark = { version = "^3.5.0", optional = true }
pyarrow = { version = "^12.0.0", optional = true }

# Optional: Web frameworks
fastapi = { version = "^0.100.0", optional = true }
uvicorn = { version = "^0.23.0", extras = ["standard"], optional = true }
pydantic = { version = "^2.0.0", optional = true }
pydantic-settings = { version = "^2.0.0", optional = true }

# Optional: Database & Storage
motor = { version = "^3.3.0", optional = true }
pymongo = { version = "^4.4.0", optional = true }
sqlalchemy = { version = "^2.0.0", optional = true }
psycopg2-binary = { version = "^2.9.0", optional = true }

# Optional: MLOps & Tracking
mlflow = { version = "^2.10.0", optional = true }
databricks-connect = { version = "^14.0.0", optional = true }

# Optional: Monitoring & Observability
prometheus-client = { version = "^0.17.0", optional = true }

# Optional: Scheduling
APScheduler = { version = "^3.10.0", optional = true }
croniter = { version = "^2.0.0", optional = true }

# Optional: Utilities
cachetools = { version = "^5.3.0", optional = true }
numpy = { version = "^1.24.0", optional = true }
scikit-optimize = { version = "^0.9.0", optional = true }

[tool.poetry.extras]
spark = ["pyspark", "pyarrow"]
api = ["fastapi", "uvicorn", "pydantic", "pydantic-settings", "motor", "pymongo", "APScheduler", "croniter", "cachetools"]
monitoring = ["prometheus-client"]
mlops = ["mlflow", "databricks-connect"]
database = ["sqlalchemy", "psycopg2-binary"]
optimization = ["numpy", "scikit-optimize"]
all = [
    "pyspark", "pyarrow",
    "fastapi", "uvicorn", "pydantic", "pydantic-settings",
    "motor", "pymongo", "sqlalchemy", "psycopg2-binary",
    "mlflow", "databricks-connect",
    "prometheus-client",
    "APScheduler", "croniter", "cachetools",
    "numpy", "scikit-optimize"
]

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-cov = "^4.1.0"
black = "^23.12.0"
isort = "^5.13.0"
mypy = "^1.8.0"
ruff = "^0.1.0"

[tool.poetry.scripts]
tauro = "tauro.cli.cli:main"

[tool.black]
line-length = 100
target-version = ['py39', 'py310', 'py311', 'py312']

[tool.isort]
profile = "black"
line_length = 100
known_first_party = ["tauro"]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true
show_error_codes = true

[tool.pytest.ini_options]
# Point pytest to the repo's test folders
testpaths = [
  "src/tauro/cli/test",
  "src/tauro/test",
  "src/tauro/config/test",
  "src/tauro/exec/test",
]
addopts = ["-ra", "--cov=tauro", "--cov-report=term-missing"]

[tool.ruff]
line-length = 100
target-version = "py310"
select = ["E", "W", "F", "I"]
ignore = ["E501"]

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
