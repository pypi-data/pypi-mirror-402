import logging

import numpy as np

import ess.nn as nn

logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


def _scale(arr, min_val=None, max_val=None):
    if min_val is None:
        min_val = np.min(arr, axis=0)
    if max_val is None:
        max_val = np.max(arr, axis=0)

    # Avoid division by zero for constant dimensions
    denom = max_val - min_val
    denom[denom == 0] = 1.0

    scl_arr = (arr - min_val) / denom
    return scl_arr, min_val, max_val


def _inv_scale(scl_arr, min_val, max_val):
    """Internal helper to unscale array."""
    return scl_arr * (max_val - min_val) + min_val


def _force(sigma, d):
    """
    Computes a Lennard-Jones style repulsive force magnitude.

    This legacy function calculates the scalar force magnitude derived from a potential
    resembling the Lennard-Jones 12-6 potential. It is used to push points away from
    neighbors to maximize separation.

    The potential $V$ is proportional to:
    $ V(r) \\propto \\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6 $

    The force $F = -\\nabla V$ is proportional to:
    $ F(r) \\propto \\frac{1}{r} \\left[ 2\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6 \\right] $

    The implementation computes this as:
    $ \\text{ratio} = \\frac{\\sigma}{d}, \\quad A = \\text{ratio}^6 $
    $ F = \\left| \\frac{6 \\cdot (2A^2 - A)}{d} \\right| $

    Args:
        sigma (float): The characteristic distance $\\sigma$ (scaling factor).
        d (np.ndarray): Array of distances $d$.

    Returns:
        np.ndarray: The computed force magnitudes.
    """
    safe_d = np.maximum(d, 1e-9)
    ratio = sigma / safe_d
    ratio = np.minimum(ratio, 10.0)

    attrac = ratio**6
    attrac = np.minimum(attrac, 1e5)

    # Derivative-like calculation
    term = (2 * (attrac**2)) - attrac
    return np.abs(6 * term / safe_d)


def _elastic(es, neighbors, neighbors_dist):
    """
    Computes the net directional elastic force vector acting on a point.

    This function aggregates the repulsive forces from a set of neighbors. The force
    direction is the unit vector pointing from the neighbor to the current point.

    $ \\vec{F}_{total} = \\sum_{j \\in \\text{neighbors}} \\underbrace{f(|| \\vec{r}_{j} ||)}_{\\text{magnitude}} \\cdot \\underbrace{\\frac{\\vec{x} - \\vec{p}_j}{|| \\vec{x} - \\vec{p}_j ||}}_{\\text{direction}} $

    where $f(d)$ is the magnitude function defined in `_force` and $\\sigma$ is locally
    determined as $\\frac{1}{5}$ of the mean neighbor distance.

    Args:
        es (np.ndarray): The coordinate of the point being optimized $\\vec{x}$.
        neighbors (np.ndarray): Array of neighbor coordinates $\\vec{p}_j$.
        neighbors_dist (np.ndarray): Array of distances $||\\vec{x} - \\vec{p}_j||$.

    Returns:
        np.ndarray: The summed force vector $\\vec{F}_{total}$.
    """
    sigma = np.mean(neighbors_dist) / 5.0

    forces = _force(sigma, neighbors_dist)

    diff = es - neighbors
    safe_dist = np.maximum(neighbors_dist[:, np.newaxis], 1e-9)
    vecs = diff / safe_dist

    direc = np.sum(vecs * forces[:, np.newaxis], axis=0)
    return direc


def _empty_center(coor, data, neigh, *, lr: float, epochs: int, bounds: np.ndarray):
    """
    Optimizes a single point using the Empty Center Strategy.

    This is the core optimization loop for the legacy sequential approach. It iteratively
    moves a single candidate point `coor` along the gradient of the repulsive force field
    generated by the `data` points.

    **Update Rule:**
    For each epoch $t$:
    1. Find $k$ nearest neighbors in `data`.
    2. Compute net force vector $\\vec{F}$.
    3. Update position: $\\vec{x}_{t+1} = \\vec{x}_t + \\eta \\cdot \\frac{\\vec{F}}{||\\vec{F}||}$
        (using normalized direction).
    4. Clip $\\vec{x}_{t+1}$ to `bounds`.

    Args:
        coor (np.ndarray): Initial coordinate of the candidate point.
        data (np.ndarray): The static set of existing points acting as obstacles.
        neigh (nn.NearestNeighbors): The nearest neighbor index.
        lr (float): The step size $\\eta$ (movement magnitude per iteration).
        epochs (int): Maximum number of iterations.
        bounds (np.ndarray): Domain boundaries for clipping $[0, 1]$.

    Returns:
        np.ndarray: The optimized coordinate.
    """
    movestep = lr if lr is not None else 0.01

    k_req = min(data.shape[1] + 1, neigh.total_count)

    for i in range(epochs):
        # query_external replaces the old query() method
        # It queries the static points (data)
        # k = dim + 1 is a heuristic for sufficient neighbors
        adjs_, distances_ = neigh.query_static(coor, k=k_req)

        direc = _elastic(coor, data[adjs_[0]], distances_[0])
        mag = np.linalg.norm(direc)

        if mag < 1e-7:
            break

        direc /= mag
        coor += direc * movestep

        np.clip(coor, bounds[:, 0], bounds[:, 1], out=coor)

    return coor


def _esa_01(samples, bounds, n: int | None = None, seed: int | None = None):
    """
    Executes ESA Version 0.1: Independent Generation.

    This legacy version generates $n$ new points where each point is optimized
    **independently** against the original `samples`. The new points do not see or repel
    each other during the generation process.

    This is equivalent to running $n$ separate hill-climbing searches in parallel (though
    implemented sequentially here) to find local voids in the original distribution.

    $ S_{static} = \\text{samples} $
    $ p_i = \\text{Optimize}(random\\_init_i, S_{static}) \\quad \\forall i \\in 1..n $

    Args:
        samples (np.ndarray): Existing points.
        bounds (np.ndarray): Domain boundaries.
        n (int | None): Number of points to generate (defaults to `len(samples)`).
        seed (int | None): Random seed.

    Returns:
        np.ndarray: The array of generated points.
    """
    min_val = bounds[:, 0]
    max_val = bounds[:, 1]
    scaled_samples, _, _ = _scale(samples, min_val, max_val)
    n_value = n if n is not None else samples.shape[0]

    # Initialize NN with original samples
    seed_value = seed if seed is not None else 42
    neigh = nn.NumpyNN(dimension=scaled_samples.shape[1], seed=seed_value)
    neigh.add_static(scaled_samples)

    rng = np.random.default_rng(seed_value)
    coors = rng.uniform(0, 1, (n_value, scaled_samples.shape[1])).astype(np.float32)
    logger.debug(f"Coors({n_value}, {scaled_samples.shape[1]})\n{coors}")

    scaled_bounds = np.array([[0, 1]] * scaled_samples.shape[1])
    movestep = 0.01
    es_params = []
    logger.debug(f"Samples\n{scaled_samples}")

    for c in coors:
        # Optimize c against samples
        es_param = _empty_center(
            c.reshape(1, -1),
            scaled_samples,
            neigh,
            lr=movestep,
            epochs=100,
            bounds=scaled_bounds,
        )
        es_params.append(es_param[0])

    logger.debug(f"Params({len(es_params)})\n{es_params}")

    rv = np.array(es_params)
    rv = _inv_scale(rv, min_val=min_val, max_val=max_val)

    logger.debug(f"RV({rv.shape})\n{rv}")

    return rv


def _esa_02(
    samples,
    bounds,
    *,
    n: int | None = None,
    epochs: int = 100,
    lr: float = 0.01,
    seed: int | None = None,
):
    """
    Executes ESA Version 0.2: Sequential Cumulative Generation.

    In this version, points are generated one by one. Crucially, once a new point is
    optimized, it is added to the static set and becomes an obstacle for subsequent points.
    This allows the algorithm to fill space progressively.

    **Process:**
    Let $S_0$ be the initial samples.
    For $i = 1$ to $n$:
    1. $p_i = \\text{Optimize}(random\\_init, S_{i-1})$
    2. $S_i = S_{i-1} \\cup \\{p_i\\}$

    This results in a more uniform packing than v0.1 but cannot be parallelized.

    Args:
        samples (np.ndarray): Existing points.
        bounds (np.ndarray): Domain boundaries.
        n (int | None): Number of points to generate.
        epochs (int): Optimization iterations per point.
        lr (float): Step size.
        seed (int | None): Random seed.

    Returns:
        np.ndarray: The generated points (unscaled).
    """
    min_val = bounds[:, 0]
    max_val = bounds[:, 1]
    samples, _, _ = _scale(samples, min_val, max_val)
    n_value = n if n is not None else samples.shape[0]

    seed_value = seed if seed is not None else 42
    neigh = nn.NumpyNN(dimension=samples.shape[1], seed=seed_value)
    neigh.add_static(samples)

    coors = np.random.uniform(0, 1, (n_value, samples.shape[1]))
    es_params = []

    scaled_bounds = np.array([[0, 1]] * samples.shape[1])

    for c in coors:
        es_param = _empty_center(
            c.reshape(1, -1), samples, neigh, lr=lr, epochs=epochs, bounds=scaled_bounds
        )
        es_params.append(es_param[0])

        samples = np.vstack((samples, es_param))
        neigh.add_static(es_param)

    rv = np.array(es_params)
    rv = _inv_scale(rv, min_val=min_val, max_val=max_val)
    return rv
