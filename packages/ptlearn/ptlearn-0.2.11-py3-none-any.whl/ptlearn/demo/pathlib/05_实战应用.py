"""
pathlib å®æˆ˜åº”ç”¨
================
å¸¸è§çš„æ–‡ä»¶ç³»ç»Ÿæ“ä½œåœºæ™¯å’Œæœ€ä½³å®è·µ
"""

from pathlib import Path
import tempfile
import shutil

# region ç¤ºä¾‹1: å®‰å…¨åœ°åˆ›å»ºç›®å½•ç»“æ„
if True:  # æ”¹ä¸º False å¯è·³è¿‡æ­¤ç¤ºä¾‹
    def ensure_dir(path: Path) -> Path:
        """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œè¿”å› Path å¯¹è±¡"""
        path.mkdir(parents=True, exist_ok=True)
        return path

    with tempfile.TemporaryDirectory() as tmpdir:
        base = Path(tmpdir)

        # åˆ›å»ºé¡¹ç›®ç»“æ„
        project = base / "myproject"
        dirs = ["src", "tests", "docs", "config"]

        for d in dirs:
            ensure_dir(project / d)
            print(f"åˆ›å»ºç›®å½•: {d}")

        # éªŒè¯ç»“æ„
        print("\né¡¹ç›®ç»“æ„:")
        for item in sorted(project.iterdir()):
            print(f"  ğŸ“ {item.name}")
# endregion

# region ç¤ºä¾‹2: æ‰¹é‡é‡å‘½åæ–‡ä»¶
if True:  # æ”¹ä¸º False å¯è·³è¿‡æ­¤ç¤ºä¾‹
    def batch_rename(directory: Path, pattern: str, prefix: str) -> list:
        """æ‰¹é‡æ·»åŠ å‰ç¼€"""
        renamed = []
        for f in directory.glob(pattern):
            if not f.name.startswith(prefix):
                new_name = f.with_name(f"{prefix}{f.name}")
                # f.rename(new_name)  # å®é™…é‡å‘½å
                renamed.append((f.name, new_name.name))
        return renamed

    # æ¼”ç¤º (ä¸å®é™…æ‰§è¡Œ)
    demo_dir = Path("src/ptlearn/demo/pathlib")
    print("æ‰¹é‡é‡å‘½åé¢„è§ˆ (æ·»åŠ  'demo_' å‰ç¼€):")
    for old, new in batch_rename(demo_dir, "*.py", "demo_")[:3]:
        print(f"  {old} -> {new}")
# endregion

# region ç¤ºä¾‹3: æŸ¥æ‰¾å¹¶å¤„ç†ç‰¹å®šæ–‡ä»¶
if True:  # æ”¹ä¸º False å¯è·³è¿‡æ­¤ç¤ºä¾‹
    def find_large_files(directory: Path, min_size_kb: int = 10) -> list:
        """æŸ¥æ‰¾å¤§äºæŒ‡å®šå¤§å°çš„æ–‡ä»¶"""
        large_files = []
        for f in directory.rglob("*"):
            if f.is_file():
                size_kb = f.stat().st_size / 1024
                if size_kb >= min_size_kb:
                    large_files.append((f, size_kb))
        return sorted(large_files, key=lambda x: x[1], reverse=True)

    # æŸ¥æ‰¾é¡¹ç›®ä¸­çš„å¤§æ–‡ä»¶
    project_root = Path(".")
    print(f"å¤§äº 1KB çš„æ–‡ä»¶ (å‰ 5 ä¸ª):")
    for f, size in find_large_files(project_root, min_size_kb=1)[:5]:
        print(f"  {f}: {size:.1f} KB")
# endregion

# region ç¤ºä¾‹4: æ–‡ä»¶å¤‡ä»½å·¥å…·
if True:  # æ”¹ä¸º False å¯è·³è¿‡æ­¤ç¤ºä¾‹
    from datetime import datetime

    def backup_file(file_path: Path, backup_dir: Path = None) -> Path:
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½ï¼Œæ·»åŠ æ—¶é—´æˆ³"""
        if not file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        # é»˜è®¤å¤‡ä»½åˆ°åŒç›®å½•
        if backup_dir is None:
            backup_dir = file_path.parent

        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"{file_path.stem}_{timestamp}{file_path.suffix}.bak"
        backup_path = backup_dir / backup_name

        # å¤åˆ¶æ–‡ä»¶ (ä½¿ç”¨ shutil)
        # shutil.copy2(file_path, backup_path)

        return backup_path

    # æ¼”ç¤º
    demo_file = Path("pyproject.toml")
    if demo_file.exists():
        backup = backup_file(demo_file)
        print(f"å¤‡ä»½è·¯å¾„é¢„è§ˆ: {backup}")
# endregion

# region ç¤ºä¾‹5: é¡¹ç›®æ–‡ä»¶ç»Ÿè®¡
if True:  # æ”¹ä¸º False å¯è·³è¿‡æ­¤ç¤ºä¾‹
    def analyze_project(root: Path) -> dict:
        """åˆ†æé¡¹ç›®æ–‡ä»¶ç»Ÿè®¡"""
        stats = {
            "total_files": 0,
            "total_dirs": 0,
            "by_extension": {},
            "total_size": 0,
        }

        for item in root.rglob("*"):
            # è·³è¿‡éšè—æ–‡ä»¶å’Œå¸¸è§å¿½ç•¥ç›®å½•
            if any(part.startswith(".") for part in item.parts):
                continue
            if any(part in ["__pycache__", "node_modules", ".venv"] for part in item.parts):
                continue

            if item.is_file():
                stats["total_files"] += 1
                stats["total_size"] += item.stat().st_size

                ext = item.suffix.lower() or "(æ— åç¼€)"
                stats["by_extension"][ext] = stats["by_extension"].get(ext, 0) + 1
            elif item.is_dir():
                stats["total_dirs"] += 1

        return stats

    # åˆ†æå½“å‰é¡¹ç›®
    project = Path("src")
    if project.exists():
        result = analyze_project(project)
        print("é¡¹ç›®ç»Ÿè®¡:")
        print(f"  æ–‡ä»¶æ•°: {result['total_files']}")
        print(f"  ç›®å½•æ•°: {result['total_dirs']}")
        print(f"  æ€»å¤§å°: {result['total_size'] / 1024:.1f} KB")
        print("  æŒ‰æ‰©å±•å:")
        for ext, count in sorted(result["by_extension"].items(), key=lambda x: -x[1])[:5]:
            print(f"    {ext}: {count} ä¸ª")
# endregion

# region ç¤ºä¾‹6: ä¸ os.path å¯¹æ¯”
if True:  # æ”¹ä¸º False å¯è·³è¿‡æ­¤ç¤ºä¾‹
    import os

    # ä¼ ç»Ÿ os.path æ–¹å¼
    old_way = os.path.join(
        os.path.expanduser("~"),
        "documents",
        "projects",
        "myapp",
        "config.json"
    )

    # pathlib æ–¹å¼
    new_way = Path.home() / "documents" / "projects" / "myapp" / "config.json"

    print("os.path æ–¹å¼:")
    print(f"  {old_way}")
    print("\npathlib æ–¹å¼:")
    print(f"  {new_way}")
    print("\nç»“æœç›¸åŒ:", str(new_way) == old_way)

    # æ›´å¤šå¯¹æ¯”
    print("\nå¸¸ç”¨æ“ä½œå¯¹æ¯”:")
    print("  è·å–æ–‡ä»¶å: os.path.basename() vs path.name")
    print("  è·å–ç›®å½•:   os.path.dirname()  vs path.parent")
    print("  æ‹¼æ¥è·¯å¾„:   os.path.join()     vs path / 'sub'")
    print("  æ˜¯å¦å­˜åœ¨:   os.path.exists()   vs path.exists()")
    print("  è¯»å–æ–‡ä»¶:   open() + read()    vs path.read_text()")
# endregion
