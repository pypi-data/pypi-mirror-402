# This file is automatically generated by botocraft.  Do not edit directly.
# mypy: disable-error-code="index, override, assignment, union-attr, misc"
from botocore.response import StreamingBody
from botocraft.mixins.s3 import bucket_update_safe_get_lifecycle
from typing import ClassVar, Type, Optional, Literal, Dict, List, Union, Any, cast
from collections import OrderedDict
from botocraft.mixins.s3 import bucket_list_names_to_buckets
from .abstract import (
    Boto3Model,
    ReadonlyBoto3Model,
    PrimaryBoto3Model,
    ReadonlyPrimaryBoto3Model,
    Boto3ModelManager,
    ReadonlyBoto3ModelManager,
)
from botocraft.mixins.s3 import object_list_add_bucket_name_and_tags
from botocraft.services.common import Tag
from .abstract import PrimaryBoto3ModelQuerySet
from botocraft.mixins.s3 import GetObjectOutputMixin
from botocraft.mixins.s3 import BucketManagerMixin
from pydantic import Field
from datetime import datetime
from botocraft.mixins.tags import TagsDictMixin

# ===============
# Managers
# ===============


class BucketManager(BucketManagerMixin, Boto3ModelManager):
    service_name: str = "s3"

    @bucket_list_names_to_buckets
    def list(
        self,
        *,
        MaxBuckets: int | None = None,
        ContinuationToken: str | None = None,
        Prefix: str | None = None,
        BucketRegion: str | None = None,
    ) -> PrimaryBoto3ModelQuerySet:
        """
        This operation is not supported for directory buckets.

        Keyword Args:
            MaxBuckets: Maximum number of buckets to be returned in response. When the number is more than the count of buckets
                that are owned by an Amazon Web Services account, return all the buckets in response.
            ContinuationToken: ``ContinuationToken`` indicates to Amazon S3 that the list is being continued on this bucket with
                a token. ``ContinuationToken`` is obfuscated and is not a real key. You can use this ``ContinuationToken`` for
                pagination of the list results.
            Prefix: Limits the response to bucket names that begin with the specified bucket name prefix.
            BucketRegion: Limits the response to buckets that are located in the specified Amazon Web Services Region. The
                Amazon Web Services Region must be expressed according to the Amazon Web Services Region code, such as ``us-west-2``
                for the US West (Oregon) Region. For a list of the valid values for all of the Amazon Web Services Regions, see
                `Regions and Endpoints <https://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region>`_.
        """
        paginator = self.client.get_paginator("list_buckets")
        args: Dict[str, Any] = dict(
            MaxBuckets=self.serialize(MaxBuckets),
            ContinuationToken=self.serialize(ContinuationToken),
            Prefix=self.serialize(Prefix),
            BucketRegion=self.serialize(BucketRegion),
        )
        response_iterator = paginator.paginate(
            **{k: v for k, v in args.items() if v is not None}
        )
        results = []
        for _response in response_iterator:
            if list(_response.keys()) == ["ResponseMetadata"]:
                break
            if "ResponseMetadata" in _response:
                del _response["ResponseMetadata"]
            response = ListBucketsOutput(**_response)
            if response.Buckets:
                results.extend(response.Buckets)
            else:
                if getattr(response, "NextToken", None):
                    continue
                break
        self.sessionize(results)
        if results and isinstance(results[0], Boto3Model):
            return PrimaryBoto3ModelQuerySet(results)
        return results

    def get_bucket_policy(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> str:
        """
        Returns the policy of a specified bucket.

        Args:
            Bucket: The bucket name to get the bucket policy for.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_bucket_policy(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetBucketPolicyOutput(**_response)

        results: str = None
        if response is not None:
            results = response.Policy

        self.sessionize(results)
        return cast("str", results)

    def put_bucket_policy(
        self,
        Bucket: str,
        Policy: str,
        *,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ConfirmRemoveSelfBucketAccess: bool | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "None":
        """
        Applies an Amazon S3 bucket policy to an Amazon S3 bucket.

        Args:
            Bucket: The name of the bucket.
            Policy: The bucket policy as a JSON document.

        Keyword Args:
            ContentMD5: The MD5 hash of the request body.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the request when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum-algorithm``  or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the
                request with the HTTP status code ``400 Bad Request``.
            ConfirmRemoveSelfBucketAccess: Set this parameter to true to confirm that you want to remove your permissions to
                change this bucket policy in the future.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Policy=self.serialize(Policy),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ConfirmRemoveSelfBucketAccess=self.serialize(ConfirmRemoveSelfBucketAccess),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.put_bucket_policy(
            **{k: v for k, v in args.items() if v is not None}
        )

    def delete_bucket_policy(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "None":
        """
        Deletes the policy of a specified bucket.

        Args:
            Bucket: The bucket name.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.delete_bucket_policy(
            **{k: v for k, v in args.items() if v is not None}
        )

    def get_website(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "GetBucketWebsiteOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name for which to get the website configuration.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_bucket_website(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetBucketWebsiteOutput(**_response)

        results: "GetBucketWebsiteOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("GetBucketWebsiteOutput", results)

    def put_website(
        self,
        Bucket: str,
        WebsiteConfiguration: "WebsiteConfiguration",
        *,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name.
            WebsiteConfiguration: Container for the request.

        Keyword Args:
            ContentMD5: The Base64 encoded 128-bit ``MD5`` digest of the data. You must use this header as a message integrity
                check to verify that the request body was not corrupted in transit. For more information, see `RFC 1864
                <http://www.ietf.org/rfc/rfc1864.txt>`_.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the request when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            WebsiteConfiguration=self.serialize(WebsiteConfiguration),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.put_bucket_website(
            **{k: v for k, v in args.items() if v is not None}
        )

    def delete_website(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name for which you want to remove the website configuration.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.delete_bucket_website(
            **{k: v for k, v in args.items() if v is not None}
        )

    def get_tags(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> List[Tag]:
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The name of the bucket for which to get the tagging information.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_bucket_tagging(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetBucketTaggingOutput(**_response)

        results: List[Tag] = None
        if response is not None:
            results = response.TagSet

        self.sessionize(results)
        return cast("List[Tag]", results)

    def put_tags(
        self,
        Bucket: str,
        Tagging: "S3Tagging",
        *,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name.
            Tagging: Container for the ``TagSet`` and ``Tag`` elements.

        Keyword Args:
            ContentMD5: The Base64 encoded 128-bit ``MD5`` digest of the data. You must use this header as a message integrity
                check to verify that the request body was not corrupted in transit. For more information, see `RFC 1864
                <http://www.ietf.org/rfc/rfc1864.txt>`_.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the request when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Tagging=self.serialize(Tagging),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.put_bucket_tagging(
            **{k: v for k, v in args.items() if v is not None}
        )

    def delete_tags(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket that has the tag set to be removed.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.delete_bucket_tagging(
            **{k: v for k, v in args.items() if v is not None}
        )

    @bucket_update_safe_get_lifecycle
    def get_lifecycle(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "GetBucketLifecycleConfigurationOutput":
        """
        Returns the lifecycle configuration information set on the bucket. For information about lifecycle configuration, see
        `Object Lifecycle Management <https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html>`_.

        Args:
            Bucket: The name of the bucket for which to get the lifecycle information.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).

        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_bucket_lifecycle_configuration(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetBucketLifecycleConfigurationOutput(**_response)

        results: "GetBucketLifecycleConfigurationOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("GetBucketLifecycleConfigurationOutput", results)

    def put_lifecycle(
        self,
        Bucket: str,
        LifecycleConfiguration: "BucketLifecycleConfiguration",
        *,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
        TransitionDefaultMinimumObjectSize: Literal["varies_by_storage_class", "all_storage_classes_128K"] | None = None,
    ) -> "PutBucketLifecycleConfigurationOutput":
        """
        Creates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration. Keep in mind that
        this will overwrite an existing lifecycle configuration, so if you want to retain any configuration details, they must
        be included in the new lifecycle configuration. For information about lifecycle configuration, see `Managing your
        storage lifecycle <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html>`_.

        Args:
            Bucket: The name of the bucket for which to set the configuration.
            LifecycleConfiguration: Container for lifecycle rules. You can add as many as 1,000 rules.

        Keyword Args:
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the request when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            TransitionDefaultMinimumObjectSize: Indicates which default minimum object size behavior is applied to the lifecycle
                configuration.

        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            LifecycleConfiguration=self.serialize(LifecycleConfiguration),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            TransitionDefaultMinimumObjectSize=self.serialize(
                TransitionDefaultMinimumObjectSize
            ),
        )
        _response = self.client.put_bucket_lifecycle_configuration(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutBucketLifecycleConfigurationOutput(**_response)

        results: "PutBucketLifecycleConfigurationOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("PutBucketLifecycleConfigurationOutput", results)

    def delete_lifecycle(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "None":
        """
        Deletes the lifecycle configuration from the specified bucket. Amazon S3 removes
        all the lifecycle configuration rules in the lifecycle subresource associated
        with the bucket. Your objects never expire, and Amazon S3 no longer
        automatically deletes any objects on the basis of rules contained in the deleted
        lifecycle configuration.

        Args:
            Bucket: The bucket name of the lifecycle to delete.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.delete_bucket_lifecycle(
            **{k: v for k, v in args.items() if v is not None}
        )

    def get_public_access_block(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "GetPublicAccessBlockOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The name of the Amazon S3 bucket whose ``PublicAccessBlock`` configuration you want to retrieve.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_public_access_block(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetPublicAccessBlockOutput(**_response)

        results: "GetPublicAccessBlockOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("GetPublicAccessBlockOutput", results)

    def put_public_access_block(
        self,
        Bucket: str,
        PublicAccessBlockConfiguration: "S3PublicAccessBlockConfiguration",
        *,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The name of the Amazon S3 bucket whose ``PublicAccessBlock`` configuration you want to set.
            PublicAccessBlockConfiguration: The ``PublicAccessBlock`` configuration that you want to apply to this Amazon S3
                bucket. You can enable the configuration options in any combination. For more information about when Amazon S3
                considers a bucket or object public, see `The Meaning of "Public"
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public- access.html#access-control-block-
                public-access-policy-status>`_ in the *Amazon S3 User Guide*.

        Keyword Args:
            ContentMD5: The MD5 hash of the ``PutPublicAccessBlock`` request body.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            PublicAccessBlockConfiguration=self.serialize(
                PublicAccessBlockConfiguration
            ),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.put_public_access_block(
            **{k: v for k, v in args.items() if v is not None}
        )

    def delete_public_access_block(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The Amazon S3 bucket whose ``PublicAccessBlock`` configuration you want to delete.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        self.client.delete_public_access_block(
            **{k: v for k, v in args.items() if v is not None}
        )


class S3ObjectManager(Boto3ModelManager):
    service_name: str = "s3"

    def create(
        self,
        model: "S3Object",
        Bucket: str,
        ACL: Literal["private", "public-read", "public-read-write", "authenticated-read", "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control"] | None = None,
        Body: bytes | None = None,
        CacheControl: str | None = None,
        ContentDisposition: str | None = None,
        ContentEncoding: str | None = None,
        ContentLanguage: str | None = None,
        ContentLength: int | None = None,
        ContentMD5: str | None = None,
        ContentType: str | None = None,
        ChecksumCRC32: str | None = None,
        ChecksumCRC32C: str | None = None,
        ChecksumCRC64NVME: str | None = None,
        ChecksumSHA1: str | None = None,
        ChecksumSHA256: str | None = None,
        Expires: datetime | None = None,
        IfMatch: str | None = None,
        IfNoneMatch: str | None = None,
        GrantFullControl: str | None = None,
        GrantRead: str | None = None,
        GrantReadACP: str | None = None,
        GrantWriteACP: str | None = None,
        WriteOffsetBytes: int | None = None,
        Metadata: Dict[str, str] | None = None,
        ServerSideEncryption: Literal["AES256", "aws:fsx", "aws:kms", "aws:kms:dsse"] | None = None,
        WebsiteRedirectLocation: str | None = None,
        SSECustomerAlgorithm: str | None = None,
        SSECustomerKey: str | None = None,
        SSECustomerKeyMD5: str | None = None,
        SSEKMSKeyId: str | None = None,
        SSEKMSEncryptionContext: str | None = None,
        BucketKeyEnabled: bool | None = None,
        RequestPayer: Literal["requester"] | None = None,
        ObjectLockMode: Literal["GOVERNANCE", "COMPLIANCE"] | None = None,
        ObjectLockRetainUntilDate: datetime | None = None,
        ObjectLockLegalHoldStatus: Literal["ON", "OFF"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "PutObjectOutput":
        """
        End of support notice: As of October 1, 2025, Amazon S3 has discontinued support for Email Grantee Access Control Lists
        (ACLs). If you attempt to use an Email Grantee ACL in a request after October 1, 2025, the request will receive an
        ``HTTP 405`` (Method Not Allowed) error.

        Args:
            model: The :py:class:`Object` to create.
            Bucket: The bucket name to which the PUT action was initiated.

        Keyword Args:
            ACL: The canned ACL to apply to the object. For more information, see `Canned ACL
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#CannedACL>`_ in the *Amazon S3 User Guide*.
            Body: Object data.
            CacheControl: Can be used to specify caching behavior along the request/reply chain. For more information, see
                <http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9>.
            ContentDisposition: Specifies presentational information for the object. For more information, see <https://www.rfc-
                editor.org/rfc/rfc6266#section-4>.
            ContentEncoding: Specifies what content encodings have been applied to the object and thus what decoding mechanisms
                must be applied to obtain the media-type referenced by the Content-Type header field. For more information, see
                <https://www.rfc- editor.org/rfc/rfc9110.html#field.content-encoding>.
            ContentLanguage: The language the content is in.
            ContentLength: Size of the body in bytes. This parameter is useful when the size of the body cannot be determined
                automatically. For more information, see <https://www.rfc-editor.org/rfc/rfc9110.html#name-content-length>.
            ContentMD5: The Base64 encoded 128-bit ``MD5`` digest of the message (without the headers) according to RFC 1864.
                This header can be used as a message integrity check to verify that the data is the same data that was originally
                sent. Although it is optional, we recommend using the Content-MD5 mechanism as an end-to-end integrity check. For
                more information about REST request authentication, see `REST Authentication
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html>`_.
            ContentType: A standard MIME type describing the format of the contents. For more information, see <https://www.rfc-
                editor.org/rfc/rfc9110.html#name-content-type>.
            ChecksumCRC32: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 32-bit ``CRC32`` checksum of the object. For
                more information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-
                object-integrity.html>`_ in the *Amazon S3 User Guide*.
            ChecksumCRC32C: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 32-bit ``CRC32C`` checksum of the object. For
                more information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-
                object-integrity.html>`_ in the *Amazon S3 User Guide*.
            ChecksumCRC64NVME: This header can be used as a data integrity check to verify that the data received is the same
                data that was originally sent. This header specifies the Base64 encoded, 64-bit ``CRC64NVME`` checksum of the
                object. The ``CRC64NVME`` checksum is always a full object checksum. For more information, see `Checking object
                integrity in the Amazon S3 User Guide <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-
                integrity.html>`_.
            ChecksumSHA1: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 160-bit ``SHA1`` digest of the object. For more
                information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-
                integrity.html>`_ in the *Amazon S3 User Guide*.
            ChecksumSHA256: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 256-bit ``SHA256`` digest of the object. For
                more information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-
                object-integrity.html>`_ in the *Amazon S3 User Guide*.
            Expires: The date and time at which the object is no longer cacheable. For more information, see <https://www.rfc-
                editor.org/rfc/rfc7234#section-5.3>.
            IfMatch: Uploads the object only if the ETag (entity tag) value provided during the WRITE operation matches the ETag
                of the object in S3. If the ETag values do not match, the operation returns a ``412 Precondition Failed`` error.
            IfNoneMatch: Uploads the object only if the object key name does not already exist in the bucket specified.
                Otherwise, Amazon S3 returns a ``412 Precondition Failed`` error.
            GrantFullControl: Gives the grantee READ, READ_ACP, and WRITE_ACP permissions on the object.
            GrantRead: Allows grantee to read the object data and its metadata.
            GrantReadACP: Allows grantee to read the object ACL.
            GrantWriteACP: Allows grantee to write the ACL for the applicable object.
            WriteOffsetBytes: Specifies the offset for appending data to existing objects in bytes. The offset must be equal to
                the size of the existing object being appended to. If no object exists, setting this header to 0 will create a new
                object.
            Metadata: A map of metadata to store with the object in S3.
            ServerSideEncryption: The server-side encryption algorithm that was used when you store this object in Amazon S3 or
                Amazon FSx.
            WebsiteRedirectLocation: If the bucket is configured as a website, redirects requests for this object to another
                object in the same bucket or to an external URL. Amazon S3 stores the value of this header in the object metadata.
                For information about object metadata, see `Object Key and Metadata
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html>`_ in the *Amazon S3 User Guide*.
            SSECustomerAlgorithm: Specifies the algorithm to use when encrypting the object (for example, ``AES256``).
            SSECustomerKey: Specifies the customer-provided encryption key for Amazon S3 to use in encrypting data. This value
                is used to store the object and then it is discarded; Amazon S3 does not store the encryption key. The key must be
                appropriate for use with the algorithm specified in the ``x-amz-server-side-encryption-customer-algorithm`` header.
            SSECustomerKeyMD5: Specifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses this
                header for a message integrity check to ensure that the encryption key was transmitted without error.
            SSEKMSKeyId: Specifies the KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the KMS key
                doesn't exist in the same account that's issuing the command, you must use the full Key ARN not the Key ID.
            SSEKMSEncryptionContext: Specifies the Amazon Web Services KMS Encryption Context as an additional encryption
                context to use for object encryption. The value of this header is a Base64 encoded string of a UTF-8 encoded JSON,
                which contains the encryption context as key-value pairs. This value is stored as object metadata and automatically
                gets passed on to Amazon Web Services KMS for future ``GetObject`` operations on this object.
            BucketKeyEnabled: Specifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-side
                encryption using Key Management Service (KMS) keys (SSE-KMS).
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            ObjectLockMode: The Object Lock mode that you want to apply to this object.
            ObjectLockRetainUntilDate: The date and time when you want this object's Object Lock to expire. Must be formatted as
                a timestamp parameter.
            ObjectLockLegalHoldStatus: Specifies whether a legal hold will be applied to this object. For more information about
                S3 Object Lock, see `Object Lock <https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock.html>`_ in the *Amazon
                S3 User Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).

        """
        data = model.model_dump(exclude_none=True, by_alias=True)
        args = dict(
            Bucket=self.serialize(Bucket),
            Key=data.get("Key"),
            ACL=self.serialize(ACL),
            Body=self.serialize(Body),
            CacheControl=self.serialize(CacheControl),
            ContentDisposition=self.serialize(ContentDisposition),
            ContentEncoding=self.serialize(ContentEncoding),
            ContentLanguage=self.serialize(ContentLanguage),
            ContentLength=self.serialize(ContentLength),
            ContentMD5=self.serialize(ContentMD5),
            ContentType=self.serialize(ContentType),
            ChecksumAlgorithm=data.get("ChecksumAlgorithm"),
            ChecksumCRC32=self.serialize(ChecksumCRC32),
            ChecksumCRC32C=self.serialize(ChecksumCRC32C),
            ChecksumCRC64NVME=self.serialize(ChecksumCRC64NVME),
            ChecksumSHA1=self.serialize(ChecksumSHA1),
            ChecksumSHA256=self.serialize(ChecksumSHA256),
            Expires=self.serialize(Expires),
            IfMatch=self.serialize(IfMatch),
            IfNoneMatch=self.serialize(IfNoneMatch),
            GrantFullControl=self.serialize(GrantFullControl),
            GrantRead=self.serialize(GrantRead),
            GrantReadACP=self.serialize(GrantReadACP),
            GrantWriteACP=self.serialize(GrantWriteACP),
            WriteOffsetBytes=self.serialize(WriteOffsetBytes),
            Metadata=self.serialize(Metadata),
            ServerSideEncryption=self.serialize(ServerSideEncryption),
            StorageClass=data.get("StorageClass"),
            WebsiteRedirectLocation=self.serialize(WebsiteRedirectLocation),
            SSECustomerAlgorithm=self.serialize(SSECustomerAlgorithm),
            SSECustomerKey=self.serialize(SSECustomerKey),
            SSECustomerKeyMD5=self.serialize(SSECustomerKeyMD5),
            SSEKMSKeyId=self.serialize(SSEKMSKeyId),
            SSEKMSEncryptionContext=self.serialize(SSEKMSEncryptionContext),
            BucketKeyEnabled=self.serialize(BucketKeyEnabled),
            RequestPayer=self.serialize(RequestPayer),
            ObjectLockMode=self.serialize(ObjectLockMode),
            ObjectLockRetainUntilDate=self.serialize(ObjectLockRetainUntilDate),
            ObjectLockLegalHoldStatus=self.serialize(ObjectLockLegalHoldStatus),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.put_object(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutObjectOutput(**_response)

        self.sessionize(response)
        return cast("PutObjectOutput", response)

    def update(
        self,
        model: "S3Object",
        Bucket: str,
        ACL: Literal["private", "public-read", "public-read-write", "authenticated-read", "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control"] | None = None,
        Body: bytes | None = None,
        CacheControl: str | None = None,
        ContentDisposition: str | None = None,
        ContentEncoding: str | None = None,
        ContentLanguage: str | None = None,
        ContentLength: int | None = None,
        ContentMD5: str | None = None,
        ContentType: str | None = None,
        ChecksumCRC32: str | None = None,
        ChecksumCRC32C: str | None = None,
        ChecksumCRC64NVME: str | None = None,
        ChecksumSHA1: str | None = None,
        ChecksumSHA256: str | None = None,
        Expires: datetime | None = None,
        IfMatch: str | None = None,
        IfNoneMatch: str | None = None,
        GrantFullControl: str | None = None,
        GrantRead: str | None = None,
        GrantReadACP: str | None = None,
        GrantWriteACP: str | None = None,
        WriteOffsetBytes: int | None = None,
        Metadata: Dict[str, str] | None = None,
        ServerSideEncryption: Literal["AES256", "aws:fsx", "aws:kms", "aws:kms:dsse"] | None = None,
        WebsiteRedirectLocation: str | None = None,
        SSECustomerAlgorithm: str | None = None,
        SSECustomerKey: str | None = None,
        SSECustomerKeyMD5: str | None = None,
        SSEKMSKeyId: str | None = None,
        SSEKMSEncryptionContext: str | None = None,
        BucketKeyEnabled: bool | None = None,
        RequestPayer: Literal["requester"] | None = None,
        Tagging: str | None = None,
        ObjectLockMode: Literal["GOVERNANCE", "COMPLIANCE"] | None = None,
        ObjectLockRetainUntilDate: datetime | None = None,
        ObjectLockLegalHoldStatus: Literal["ON", "OFF"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "PutObjectOutput":
        """
        End of support notice: As of October 1, 2025, Amazon S3 has discontinued support for Email Grantee Access Control Lists
        (ACLs). If you attempt to use an Email Grantee ACL in a request after October 1, 2025, the request will receive an
        ``HTTP 405`` (Method Not Allowed) error.

        Args:
            model: The :py:class:`Object` to update.
            Bucket: The bucket name to which the PUT action was initiated.

        Keyword Args:
            ACL: The canned ACL to apply to the object. For more information, see `Canned ACL
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#CannedACL>`_ in the *Amazon S3 User Guide*.
            Body: Object data.
            CacheControl: Can be used to specify caching behavior along the request/reply chain. For more information, see
                <http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9>.
            ContentDisposition: Specifies presentational information for the object. For more information, see <https://www.rfc-
                editor.org/rfc/rfc6266#section-4>.
            ContentEncoding: Specifies what content encodings have been applied to the object and thus what decoding mechanisms
                must be applied to obtain the media-type referenced by the Content-Type header field. For more information, see
                <https://www.rfc- editor.org/rfc/rfc9110.html#field.content-encoding>.
            ContentLanguage: The language the content is in.
            ContentLength: Size of the body in bytes. This parameter is useful when the size of the body cannot be determined
                automatically. For more information, see <https://www.rfc-editor.org/rfc/rfc9110.html#name-content-length>.
            ContentMD5: The Base64 encoded 128-bit ``MD5`` digest of the message (without the headers) according to RFC 1864.
                This header can be used as a message integrity check to verify that the data is the same data that was originally
                sent. Although it is optional, we recommend using the Content-MD5 mechanism as an end-to-end integrity check. For
                more information about REST request authentication, see `REST Authentication
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html>`_.
            ContentType: A standard MIME type describing the format of the contents. For more information, see <https://www.rfc-
                editor.org/rfc/rfc9110.html#name-content-type>.
            ChecksumCRC32: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 32-bit ``CRC32`` checksum of the object. For
                more information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-
                object-integrity.html>`_ in the *Amazon S3 User Guide*.
            ChecksumCRC32C: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 32-bit ``CRC32C`` checksum of the object. For
                more information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-
                object-integrity.html>`_ in the *Amazon S3 User Guide*.
            ChecksumCRC64NVME: This header can be used as a data integrity check to verify that the data received is the same
                data that was originally sent. This header specifies the Base64 encoded, 64-bit ``CRC64NVME`` checksum of the
                object. The ``CRC64NVME`` checksum is always a full object checksum. For more information, see `Checking object
                integrity in the Amazon S3 User Guide <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-
                integrity.html>`_.
            ChecksumSHA1: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 160-bit ``SHA1`` digest of the object. For more
                information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-
                integrity.html>`_ in the *Amazon S3 User Guide*.
            ChecksumSHA256: This header can be used as a data integrity check to verify that the data received is the same data
                that was originally sent. This header specifies the Base64 encoded, 256-bit ``SHA256`` digest of the object. For
                more information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-
                object-integrity.html>`_ in the *Amazon S3 User Guide*.
            Expires: The date and time at which the object is no longer cacheable. For more information, see <https://www.rfc-
                editor.org/rfc/rfc7234#section-5.3>.
            IfMatch: Uploads the object only if the ETag (entity tag) value provided during the WRITE operation matches the ETag
                of the object in S3. If the ETag values do not match, the operation returns a ``412 Precondition Failed`` error.
            IfNoneMatch: Uploads the object only if the object key name does not already exist in the bucket specified.
                Otherwise, Amazon S3 returns a ``412 Precondition Failed`` error.
            GrantFullControl: Gives the grantee READ, READ_ACP, and WRITE_ACP permissions on the object.
            GrantRead: Allows grantee to read the object data and its metadata.
            GrantReadACP: Allows grantee to read the object ACL.
            GrantWriteACP: Allows grantee to write the ACL for the applicable object.
            WriteOffsetBytes: Specifies the offset for appending data to existing objects in bytes. The offset must be equal to
                the size of the existing object being appended to. If no object exists, setting this header to 0 will create a new
                object.
            Metadata: A map of metadata to store with the object in S3.
            ServerSideEncryption: The server-side encryption algorithm that was used when you store this object in Amazon S3 or
                Amazon FSx.
            WebsiteRedirectLocation: If the bucket is configured as a website, redirects requests for this object to another
                object in the same bucket or to an external URL. Amazon S3 stores the value of this header in the object metadata.
                For information about object metadata, see `Object Key and Metadata
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html>`_ in the *Amazon S3 User Guide*.
            SSECustomerAlgorithm: Specifies the algorithm to use when encrypting the object (for example, ``AES256``).
            SSECustomerKey: Specifies the customer-provided encryption key for Amazon S3 to use in encrypting data. This value
                is used to store the object and then it is discarded; Amazon S3 does not store the encryption key. The key must be
                appropriate for use with the algorithm specified in the ``x-amz-server-side-encryption-customer-algorithm`` header.
            SSECustomerKeyMD5: Specifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses this
                header for a message integrity check to ensure that the encryption key was transmitted without error.
            SSEKMSKeyId: Specifies the KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the KMS key
                doesn't exist in the same account that's issuing the command, you must use the full Key ARN not the Key ID.
            SSEKMSEncryptionContext: Specifies the Amazon Web Services KMS Encryption Context as an additional encryption
                context to use for object encryption. The value of this header is a Base64 encoded string of a UTF-8 encoded JSON,
                which contains the encryption context as key-value pairs. This value is stored as object metadata and automatically
                gets passed on to Amazon Web Services KMS for future ``GetObject`` operations on this object.
            BucketKeyEnabled: Specifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-side
                encryption using Key Management Service (KMS) keys (SSE-KMS).
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            Tagging: The tag-set for the object. The tag-set must be encoded as URL Query parameters. (For example,
                "Key1=Value1")
            ObjectLockMode: The Object Lock mode that you want to apply to this object.
            ObjectLockRetainUntilDate: The date and time when you want this object's Object Lock to expire. Must be formatted as
                a timestamp parameter.
            ObjectLockLegalHoldStatus: Specifies whether a legal hold will be applied to this object. For more information about
                S3 Object Lock, see `Object Lock <https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock.html>`_ in the *Amazon
                S3 User Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).

        """
        data = model.model_dump(exclude_none=True, by_alias=True)
        args = dict(
            Bucket=self.serialize(Bucket),
            Key=data.get("Key"),
            ACL=self.serialize(ACL),
            Body=self.serialize(Body),
            CacheControl=self.serialize(CacheControl),
            ContentDisposition=self.serialize(ContentDisposition),
            ContentEncoding=self.serialize(ContentEncoding),
            ContentLanguage=self.serialize(ContentLanguage),
            ContentLength=self.serialize(ContentLength),
            ContentMD5=self.serialize(ContentMD5),
            ContentType=self.serialize(ContentType),
            ChecksumAlgorithm=data.get("ChecksumAlgorithm"),
            ChecksumCRC32=self.serialize(ChecksumCRC32),
            ChecksumCRC32C=self.serialize(ChecksumCRC32C),
            ChecksumCRC64NVME=self.serialize(ChecksumCRC64NVME),
            ChecksumSHA1=self.serialize(ChecksumSHA1),
            ChecksumSHA256=self.serialize(ChecksumSHA256),
            Expires=self.serialize(Expires),
            IfMatch=self.serialize(IfMatch),
            IfNoneMatch=self.serialize(IfNoneMatch),
            GrantFullControl=self.serialize(GrantFullControl),
            GrantRead=self.serialize(GrantRead),
            GrantReadACP=self.serialize(GrantReadACP),
            GrantWriteACP=self.serialize(GrantWriteACP),
            WriteOffsetBytes=self.serialize(WriteOffsetBytes),
            Metadata=self.serialize(Metadata),
            ServerSideEncryption=self.serialize(ServerSideEncryption),
            StorageClass=data.get("StorageClass"),
            WebsiteRedirectLocation=self.serialize(WebsiteRedirectLocation),
            SSECustomerAlgorithm=self.serialize(SSECustomerAlgorithm),
            SSECustomerKey=self.serialize(SSECustomerKey),
            SSECustomerKeyMD5=self.serialize(SSECustomerKeyMD5),
            SSEKMSKeyId=self.serialize(SSEKMSKeyId),
            SSEKMSEncryptionContext=self.serialize(SSEKMSEncryptionContext),
            BucketKeyEnabled=self.serialize(BucketKeyEnabled),
            RequestPayer=self.serialize(RequestPayer),
            Tagging=self.serialize(Tagging),
            ObjectLockMode=self.serialize(ObjectLockMode),
            ObjectLockRetainUntilDate=self.serialize(ObjectLockRetainUntilDate),
            ObjectLockLegalHoldStatus=self.serialize(ObjectLockLegalHoldStatus),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.put_object(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutObjectOutput(**_response)

        self.sessionize(response)
        return cast("PutObjectOutput", response)

    def get(
        self,
        Bucket: str,
        Key: str,
        *,
        IfMatch: str | None = None,
        IfModifiedSince: datetime | None = None,
        IfNoneMatch: str | None = None,
        IfUnmodifiedSince: datetime | None = None,
        Range: str | None = None,
        ResponseCacheControl: str | None = None,
        ResponseContentDisposition: str | None = None,
        ResponseContentEncoding: str | None = None,
        ResponseContentLanguage: str | None = None,
        ResponseContentType: str | None = None,
        ResponseExpires: datetime | None = None,
        VersionId: str | None = None,
        SSECustomerAlgorithm: str | None = None,
        SSECustomerKey: str | None = None,
        SSECustomerKeyMD5: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        PartNumber: int | None = None,
        ExpectedBucketOwner: str | None = None,
        ChecksumMode: Literal["ENABLED"] | None = None,
    ) -> Optional["S3Object"]:
        """
        Retrieves an object from Amazon S3.

        Args:
            Bucket: The bucket name containing the object.
            Key: Key of the object to get.

        Keyword Args:
            IfMatch: Return the object only if its entity tag (ETag) is the same as the one specified in this header; otherwise,
                return a ``412 Precondition Failed`` error.
            IfModifiedSince: Return the object only if it has been modified since the specified time; otherwise, return a ``304
                Not Modified`` error.
            IfNoneMatch: Return the object only if its entity tag (ETag) is different from the one specified in this header;
                otherwise, return a ``304 Not Modified`` error.
            IfUnmodifiedSince: Return the object only if it has not been modified since the specified time; otherwise, return a
                ``412 Precondition Failed`` error.
            Range: Downloads the specified byte range of an object. For more information about the HTTP Range header, see
                <https://www.rfc- editor.org/rfc/rfc9110.html#name-range>.
            ResponseCacheControl: Sets the ``Cache-Control`` header of the response.
            ResponseContentDisposition: Sets the ``Content-Disposition`` header of the response.
            ResponseContentEncoding: Sets the ``Content-Encoding`` header of the response.
            ResponseContentLanguage: Sets the ``Content-Language`` header of the response.
            ResponseContentType: Sets the ``Content-Type`` header of the response.
            ResponseExpires: Sets the ``Expires`` header of the response.
            VersionId: Version ID used to reference a specific version of the object.
            SSECustomerAlgorithm: Specifies the algorithm to use when decrypting the object (for example, ``AES256``).
            SSECustomerKey: Specifies the customer-provided encryption key that you originally provided for Amazon S3 to encrypt
                the data before storing it. This value is used to decrypt the object when recovering it and must match the one used
                when storing the data. The key must be appropriate for use with the algorithm specified in the ``x-amz-server-side-
                encryption-customer- algorithm`` header.
            SSECustomerKeyMD5: Specifies the 128-bit MD5 digest of the customer-provided encryption key according to RFC 1321.
                Amazon S3 uses this header for a message integrity check to ensure that the encryption key was transmitted without
                error.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            PartNumber: Part number of the object being read. This is a positive integer between 1 and 10,000. Effectively
                performs a 'ranged' GET request for the part specified. Useful for downloading just a part of an object.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            ChecksumMode: To retrieve the checksum, this mode must be enabled.
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            IfMatch=self.serialize(IfMatch),
            IfModifiedSince=self.serialize(IfModifiedSince),
            IfNoneMatch=self.serialize(IfNoneMatch),
            IfUnmodifiedSince=self.serialize(IfUnmodifiedSince),
            Range=self.serialize(Range),
            ResponseCacheControl=self.serialize(ResponseCacheControl),
            ResponseContentDisposition=self.serialize(ResponseContentDisposition),
            ResponseContentEncoding=self.serialize(ResponseContentEncoding),
            ResponseContentLanguage=self.serialize(ResponseContentLanguage),
            ResponseContentType=self.serialize(ResponseContentType),
            ResponseExpires=self.serialize(ResponseExpires),
            VersionId=self.serialize(VersionId),
            SSECustomerAlgorithm=self.serialize(SSECustomerAlgorithm),
            SSECustomerKey=self.serialize(SSECustomerKey),
            SSECustomerKeyMD5=self.serialize(SSECustomerKeyMD5),
            RequestPayer=self.serialize(RequestPayer),
            PartNumber=self.serialize(PartNumber),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            ChecksumMode=self.serialize(ChecksumMode),
        )
        _response = self.client.get_object(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectOutput(**_response)

        if response:
            self.sessionize(response)
            return response
        return None

    @object_list_add_bucket_name_and_tags
    def list(
        self,
        Bucket: str,
        *,
        Delimiter: str | None = None,
        EncodingType: Literal["url"] | None = None,
        MaxKeys: int | None = None,
        Prefix: str | None = None,
        ContinuationToken: str | None = None,
        FetchOwner: bool | None = None,
        StartAfter: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        ExpectedBucketOwner: str | None = None,
        OptionalObjectAttributes: List[Literal["RestoreStatus"]] | None = None,
        Include: List[Literal["TAGS"]] | None = None,
    ) -> PrimaryBoto3ModelQuerySet:
        """
        Returns some or all (up to 1,000) of the objects in a bucket with each request. You can use the request parameters as
        selection criteria to return a subset of the objects in a bucket. A ``200 OK`` response can contain valid or invalid
        XML. Make sure to design your application to parse the contents of the response and handle it appropriately. For more
        information about listing objects, see `Listing object keys
        programmatically <https://docs.aws.amazon.com/AmazonS3/latest/userguide/ListingKeysUsingAPIs.html>`_ in the *Amazon S3
        User Guide*. To get a list of your buckets, see
        `ListBuckets <https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListBuckets.html>`_.

        Args:
            Bucket: **Directory buckets** - When you use this operation with a directory bucket, you must use virtual-hosted-
                style requests   in the format  ``Bucket-name.s3express-zone-id.region-code.amazonaws.com``. Path-style requests are
                not supported.   Directory bucket names must be unique in the chosen Zone (Availability Zone or Local Zone). Bucket
                names must follow the   format  ``bucket-base-name--zone-id--x-s3`` (for example,  ``amzn-s3-demo-bucket--usw2-az1--
                x-s3``). For information   about bucket naming restrictions, see `Directory bucket naming   rules
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/directory-bucket-naming-rules.html>`_ in the *Amazon S3 User
                Guide*.

        Keyword Args:
            Delimiter: A delimiter is a character that you use to group keys.
            EncodingType: Encoding type used by Amazon S3 to encode the `object keys
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html>`_ in the response. Responses are encoded
                only in UTF-8. An object key can contain any Unicode character. However, the XML 1.0 parser can't parse certain
                characters, such as characters with an ASCII value from 0 to 10. For characters that aren't supported in XML 1.0,
                you can add this parameter to request that Amazon S3 encode the keys in the response. For more information about
                characters to avoid in object key names, see `Object key naming guidelines
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html#object-key-guidelines>`_.
            MaxKeys: Sets the maximum number of keys returned in the response. By default, the action returns up to 1,000 key
                names. The response might contain fewer keys but will never contain more.
            Prefix: Limits the response to keys that begin with the specified prefix.
            ContinuationToken: ``ContinuationToken`` indicates to Amazon S3 that the list is being continued on this bucket with
                a token. ``ContinuationToken`` is obfuscated and is not a real key. You can use this ``ContinuationToken`` for
                pagination of the list results.
            FetchOwner: The owner field is not present in ``ListObjectsV2`` by default. If you want to return the owner field
                with each key in the result, then set the ``FetchOwner`` field to ``true``.
            StartAfter: StartAfter is where you want Amazon S3 to start listing from. Amazon S3 starts listing after this
                specified key. StartAfter can be any key in the bucket.
            RequestPayer: Confirms that the requester knows that she or he will be charged for the list objects request in V2
                style. Bucket owners need not specify this parameter in their requests.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            OptionalObjectAttributes: Specifies the optional fields that you want returned in the response. Fields that you do
                not specify are not returned.
            Include: the value to set for Include

        """
        paginator = self.client.get_paginator("list_objects_v2")
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Delimiter=self.serialize(Delimiter),
            EncodingType=self.serialize(EncodingType),
            MaxKeys=self.serialize(MaxKeys),
            Prefix=self.serialize(Prefix),
            ContinuationToken=self.serialize(ContinuationToken),
            FetchOwner=self.serialize(FetchOwner),
            StartAfter=self.serialize(StartAfter),
            RequestPayer=self.serialize(RequestPayer),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            OptionalObjectAttributes=self.serialize(OptionalObjectAttributes),
        )
        response_iterator = paginator.paginate(
            **{k: v for k, v in args.items() if v is not None}
        )
        results = []
        for _response in response_iterator:
            if list(_response.keys()) == ["ResponseMetadata"]:
                break
            if "ResponseMetadata" in _response:
                del _response["ResponseMetadata"]
            response = ListObjectsV2Output(**_response)
            if response.Contents:
                results.extend(response.Contents)
            else:
                if getattr(response, "NextToken", None):
                    continue
                break
        self.sessionize(results)
        if results and isinstance(results[0], Boto3Model):
            return PrimaryBoto3ModelQuerySet(results)
        return results

    def copy(
        self,
        Bucket: str,
        CopySource: str,
        Key: str,
        *,
        ACL: Literal["private", "public-read", "public-read-write", "authenticated-read", "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control"] | None = None,
        CacheControl: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ContentDisposition: str | None = None,
        ContentEncoding: str | None = None,
        ContentLanguage: str | None = None,
        ContentType: str | None = None,
        CopySourceIfMatch: str | None = None,
        CopySourceIfModifiedSince: datetime | None = None,
        CopySourceIfNoneMatch: str | None = None,
        CopySourceIfUnmodifiedSince: datetime | None = None,
        Expires: datetime | None = None,
        GrantFullControl: str | None = None,
        GrantRead: str | None = None,
        GrantReadACP: str | None = None,
        GrantWriteACP: str | None = None,
        IfMatch: str | None = None,
        IfNoneMatch: str | None = None,
        Metadata: Dict[str, str] | None = None,
        MetadataDirective: Literal["COPY", "REPLACE"] | None = None,
        TaggingDirective: Literal["COPY", "REPLACE"] | None = None,
        ServerSideEncryption: Literal["AES256", "aws:fsx", "aws:kms", "aws:kms:dsse"] | None = None,
        StorageClass: Literal["STANDARD", "REDUCED_REDUNDANCY", "STANDARD_IA", "ONEZONE_IA", "INTELLIGENT_TIERING", "GLACIER", "DEEP_ARCHIVE", "OUTPOSTS", "GLACIER_IR", "SNOW", "EXPRESS_ONEZONE", "FSX_OPENZFS", "FSX_ONTAP"] | None = None,
        WebsiteRedirectLocation: str | None = None,
        SSECustomerAlgorithm: str | None = None,
        SSECustomerKey: str | None = None,
        SSECustomerKeyMD5: str | None = None,
        SSEKMSKeyId: str | None = None,
        SSEKMSEncryptionContext: str | None = None,
        BucketKeyEnabled: bool | None = None,
        CopySourceSSECustomerAlgorithm: str | None = None,
        CopySourceSSECustomerKey: str | None = None,
        CopySourceSSECustomerKeyMD5: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        Tagging: str | None = None,
        ObjectLockMode: Literal["GOVERNANCE", "COMPLIANCE"] | None = None,
        ObjectLockRetainUntilDate: datetime | None = None,
        ObjectLockLegalHoldStatus: Literal["ON", "OFF"] | None = None,
        ExpectedBucketOwner: str | None = None,
        ExpectedSourceBucketOwner: str | None = None,
    ) -> "CopyObjectOutput":
        """
        Creates a copy of an object that is already stored in Amazon S3.

        Args:
            Bucket: The name of the destination bucket.
            CopySource: Specifies the source object for the copy operation. The source object can be up to 5 GB. If the source
                object is an object that was uploaded by using a multipart upload, the object copy will be a single part object
                after the source object is copied to the destination bucket.
            Key: The key of the destination object.

        Keyword Args:
            ACL: The canned access control list (ACL) to apply to the object.
            CacheControl: Specifies the caching behavior along the request/reply chain.
            ChecksumAlgorithm: Indicates the algorithm that you want Amazon S3 to use to create the checksum for the object. For
                more information, see `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-
                object-integrity.html>`_ in the *Amazon S3 User Guide*.
            ContentDisposition: Specifies presentational information for the object. Indicates whether an object should be
                displayed in a web browser or downloaded as a file. It allows specifying the desired filename for the downloaded
                file.
            ContentEncoding: Specifies what content encodings have been applied to the object and thus what decoding mechanisms
                must be applied to obtain the media-type referenced by the Content-Type header field.
            ContentLanguage: The language the content is in.
            ContentType: A standard MIME type that describes the format of the object data.
            CopySourceIfMatch: Copies the object if its entity tag (ETag) matches the specified tag.
            CopySourceIfModifiedSince: Copies the object if it has been modified since the specified time.
            CopySourceIfNoneMatch: Copies the object if its entity tag (ETag) is different than the specified ETag.
            CopySourceIfUnmodifiedSince: Copies the object if it hasn't been modified since the specified time.
            Expires: The date and time at which the object is no longer cacheable.
            GrantFullControl: Gives the grantee READ, READ_ACP, and WRITE_ACP permissions on the object.
            GrantRead: Allows grantee to read the object data and its metadata.
            GrantReadACP: Allows grantee to read the object ACL.
            GrantWriteACP: Allows grantee to write the ACL for the applicable object.
            IfMatch: Copies the object if the entity tag (ETag) of the destination object matches the specified tag. If the ETag
                values do not match, the operation returns a ``412 Precondition Failed`` error. If a concurrent operation occurs
                during the upload S3 returns a ``409 ConditionalRequestConflict`` response. On a 409 failure you should fetch the
                object's ETag and retry the upload.
            IfNoneMatch: Copies the object only if the object key name at the destination does not already exist in the bucket
                specified. Otherwise, Amazon S3 returns a ``412 Precondition Failed`` error. If a concurrent operation occurs during
                the upload S3 returns a ``409 ConditionalRequestConflict`` response. On a 409 failure you should retry the upload.
            Metadata: A map of metadata to store with the object in S3.
            MetadataDirective: Specifies whether the metadata is copied from the source object or replaced with metadata that's
                provided in the request. When copying an object, you can preserve all metadata (the default) or specify new
                metadata. If this header isnt specified, ``COPY`` is the default behavior.
            TaggingDirective: Specifies whether the object tag-set is copied from the source object or replaced with the tag-set
                that's provided in the request.
            ServerSideEncryption: The server-side encryption algorithm used when storing this object in Amazon S3. Unrecognized
                or unsupported values wont write a destination object and will receive a ``400 Bad Request`` response.
            StorageClass: If the ``x-amz-storage-class`` header is not used, the copied object will be stored in the
                ``STANDARD`` Storage Class by default. The ``STANDARD`` storage class provides high durability and high
                availability. Depending on performance needs, you can specify a different Storage Class.
            WebsiteRedirectLocation: If the destination bucket is configured as a website, redirects requests for this object
                copy to another object in the same bucket or to an external URL. Amazon S3 stores the value of this header in the
                object metadata. This value is unique to each object and is not copied when using the ``x-amz-metadata-directive``
                header. Instead, you may opt to provide this header in combination with the ``x-amz-metadata-directive`` header.
            SSECustomerAlgorithm: Specifies the algorithm to use when encrypting the object (for example, ``AES256``).
            SSECustomerKey: Specifies the customer-provided encryption key for Amazon S3 to use in encrypting data. This value
                is used to store the object and then it is discarded. Amazon S3 does not store the encryption key. The key must be
                appropriate for use with the algorithm specified in the ``x-amz-server-side-encryption-customer-algorithm`` header.
            SSECustomerKeyMD5: Specifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses this
                header for a message integrity check to ensure that the encryption key was transmitted without error.
            SSEKMSKeyId: Specifies the KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. All GET and PUT
                requests for an object protected by KMS will fail if they're not made via SSL or using SigV4. For information about
                configuring any of the officially supported Amazon Web Services SDKs and Amazon Web Services CLI, see `Specifying
                the Signature Version in Request Authentication
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingAWSSDK.html#specify-signature-version>`_ in the *Amazon S3
                User Guide*.
            SSEKMSEncryptionContext: Specifies the Amazon Web Services KMS Encryption Context as an additional encryption
                context to use for the destination object encryption. The value of this header is a base64-encoded UTF-8 string
                holding JSON with the encryption context key-value pairs.
            BucketKeyEnabled: Specifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-side
                encryption using Key Management Service (KMS) keys (SSE-KMS). If a target object uses SSE-KMS, you can enable an S3
                Bucket Key for the object.
            CopySourceSSECustomerAlgorithm: Specifies the algorithm to use when decrypting the source object (for example,
                ``AES256``).
            CopySourceSSECustomerKey: Specifies the customer-provided encryption key for Amazon S3 to use to decrypt the source
                object. The encryption key provided in this header must be the same one that was used when the source object was
                created.
            CopySourceSSECustomerKeyMD5: Specifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3
                uses this header for a message integrity check to ensure that the encryption key was transmitted without error.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            Tagging: The tag-set for the object copy in the destination bucket. This value must be used in conjunction with the
                ``x-amz- tagging-directive`` if you choose ``REPLACE`` for the ``x-amz-tagging-directive``. If you choose ``COPY``
                for the ``x-amz-tagging-directive``, you don't need to set the ``x-amz-tagging`` header, because the tag-set will be
                copied from the source object directly. The tag-set must be encoded as URL Query parameters.
            ObjectLockMode: The Object Lock mode that you want to apply to the object copy.
            ObjectLockRetainUntilDate: The date and time when you want the Object Lock of the object copy to expire.
            ObjectLockLegalHoldStatus: Specifies whether you want to apply a legal hold to the object copy.
            ExpectedBucketOwner: The account ID of the expected destination bucket owner. If the account ID that you provide
                does not match the actual owner of the destination bucket, the request fails with the HTTP status code ``403
                Forbidden`` (access denied).
            ExpectedSourceBucketOwner: The account ID of the expected source bucket owner. If the account ID that you provide
                does not match the actual owner of the source bucket, the request fails with the HTTP status code ``403 Forbidden``
                (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            CopySource=self.serialize(CopySource),
            Key=self.serialize(Key),
            ACL=self.serialize(ACL),
            CacheControl=self.serialize(CacheControl),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ContentDisposition=self.serialize(ContentDisposition),
            ContentEncoding=self.serialize(ContentEncoding),
            ContentLanguage=self.serialize(ContentLanguage),
            ContentType=self.serialize(ContentType),
            CopySourceIfMatch=self.serialize(CopySourceIfMatch),
            CopySourceIfModifiedSince=self.serialize(CopySourceIfModifiedSince),
            CopySourceIfNoneMatch=self.serialize(CopySourceIfNoneMatch),
            CopySourceIfUnmodifiedSince=self.serialize(CopySourceIfUnmodifiedSince),
            Expires=self.serialize(Expires),
            GrantFullControl=self.serialize(GrantFullControl),
            GrantRead=self.serialize(GrantRead),
            GrantReadACP=self.serialize(GrantReadACP),
            GrantWriteACP=self.serialize(GrantWriteACP),
            IfMatch=self.serialize(IfMatch),
            IfNoneMatch=self.serialize(IfNoneMatch),
            Metadata=self.serialize(Metadata),
            MetadataDirective=self.serialize(MetadataDirective),
            TaggingDirective=self.serialize(TaggingDirective),
            ServerSideEncryption=self.serialize(ServerSideEncryption),
            StorageClass=self.serialize(StorageClass),
            WebsiteRedirectLocation=self.serialize(WebsiteRedirectLocation),
            SSECustomerAlgorithm=self.serialize(SSECustomerAlgorithm),
            SSECustomerKey=self.serialize(SSECustomerKey),
            SSECustomerKeyMD5=self.serialize(SSECustomerKeyMD5),
            SSEKMSKeyId=self.serialize(SSEKMSKeyId),
            SSEKMSEncryptionContext=self.serialize(SSEKMSEncryptionContext),
            BucketKeyEnabled=self.serialize(BucketKeyEnabled),
            CopySourceSSECustomerAlgorithm=self.serialize(
                CopySourceSSECustomerAlgorithm
            ),
            CopySourceSSECustomerKey=self.serialize(CopySourceSSECustomerKey),
            CopySourceSSECustomerKeyMD5=self.serialize(CopySourceSSECustomerKeyMD5),
            RequestPayer=self.serialize(RequestPayer),
            Tagging=self.serialize(Tagging),
            ObjectLockMode=self.serialize(ObjectLockMode),
            ObjectLockRetainUntilDate=self.serialize(ObjectLockRetainUntilDate),
            ObjectLockLegalHoldStatus=self.serialize(ObjectLockLegalHoldStatus),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            ExpectedSourceBucketOwner=self.serialize(ExpectedSourceBucketOwner),
        )
        _response = self.client.copy_object(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = CopyObjectOutput(**_response)

        results: "CopyObjectOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("CopyObjectOutput", results)

    def rename(
        self,
        Bucket: str,
        Key: str,
        RenameSource: str,
        *,
        DestinationIfMatch: str | None = None,
        DestinationIfNoneMatch: str | None = None,
        DestinationIfModifiedSince: datetime | None = None,
        DestinationIfUnmodifiedSince: datetime | None = None,
        SourceIfMatch: str | None = None,
        SourceIfNoneMatch: str | None = None,
        SourceIfModifiedSince: datetime | None = None,
        SourceIfUnmodifiedSince: datetime | None = None,
        ClientToken: str | None = None,
    ) -> "RenameObjectOutput":
        """
        Renames an existing object in a directory bucket that uses the S3 Express One
        Zone storage class. You can use ``RenameObject`` by specifying an existing
        objects name as the source and the new name of the object as the destination
        within the same directory bucket.

        Args:
            Bucket: The bucket name of the directory bucket containing the object.
            Key: Key name of the object to rename.
            RenameSource: Specifies the source for the rename operation. The value must be URL encoded.

        Keyword Args:
            DestinationIfMatch: Renames the object only if the ETag (entity tag) value provided during the operation matches the
                ETag of the object in S3. The ``If-Match`` header field makes the request method conditional on ETags. If the ETag
                values do not match, the operation returns a ``412 Precondition Failed`` error.
            DestinationIfNoneMatch: Renames the object only if the destination does not already exist in the specified directory
                bucket. If the object does exist when you send a request with ``If-None-Match:*``, the S3 API will return a ``412
                Precondition Failed`` error, preventing an overwrite. The ``If-None-Match`` header prevents overwrites of existing
                data by validating that there's not an object with the same key name already in your directory bucket.
            DestinationIfModifiedSince: Renames the object if the destination exists and if it has been modified since the
                specified time.
            DestinationIfUnmodifiedSince: Renames the object if it hasn't been modified since the specified time.
            SourceIfMatch: Renames the object if the source exists and if its entity tag (ETag) matches the specified ETag.
            SourceIfNoneMatch: Renames the object if the source exists and if its entity tag (ETag) is different than the
                specified ETag. If an asterisk (``*``) character is provided, the operation will fail and return a ``412
                Precondition Failed`` error.
            SourceIfModifiedSince: Renames the object if the source exists and if it has been modified since the specified time.
            SourceIfUnmodifiedSince: Renames the object if the source exists and hasn't been modified since the specified time.
            ClientToken: A unique string with a max of 64 ASCII characters in the ASCII range of 33 - 126.
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            RenameSource=self.serialize(RenameSource),
            DestinationIfMatch=self.serialize(DestinationIfMatch),
            DestinationIfNoneMatch=self.serialize(DestinationIfNoneMatch),
            DestinationIfModifiedSince=self.serialize(DestinationIfModifiedSince),
            DestinationIfUnmodifiedSince=self.serialize(DestinationIfUnmodifiedSince),
            SourceIfMatch=self.serialize(SourceIfMatch),
            SourceIfNoneMatch=self.serialize(SourceIfNoneMatch),
            SourceIfModifiedSince=self.serialize(SourceIfModifiedSince),
            SourceIfUnmodifiedSince=self.serialize(SourceIfUnmodifiedSince),
            ClientToken=self.serialize(ClientToken),
        )
        _response = self.client.rename_object(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = RenameObjectOutput(**_response)

        results: "RenameObjectOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("RenameObjectOutput", results)

    def restore(
        self,
        Bucket: str,
        Key: str,
        *,
        VersionId: str | None = None,
        RestoreRequest: Optional["RestoreRequest"] = None,
        RequestPayer: Literal["requester"] | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> str:
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name containing the object to restore.
            Key: Object key for which the action was initiated.

        Keyword Args:
            VersionId: VersionId used to reference a specific version of the object.
            RestoreRequest: Container for restore job parameters.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            VersionId=self.serialize(VersionId),
            RestoreRequest=self.serialize(RestoreRequest),
            RequestPayer=self.serialize(RequestPayer),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.restore_object(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = RestoreObjectOutput(**_response)

        results: str = None
        if response is not None:
            results = response.RestoreOutputPath

        self.sessionize(results)
        return cast("str", results)

    def select_content(
        self,
        Bucket: str,
        Key: str,
        Expression: str,
        ExpressionType: Literal["SQL"],
        InputSerialization: "InputSerialization",
        OutputSerialization: "OutputSerialization",
        *,
        SSECustomerAlgorithm: str | None = None,
        SSECustomerKey: str | None = None,
        SSECustomerKeyMD5: str | None = None,
        RequestProgress: Optional["RequestProgress"] = None,
        ScanRange: Optional["ScanRange"] = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "SelectObjectContentEventStream":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The S3 bucket.
            Key: The object key.
            Expression: The expression that is used to query the object.
            ExpressionType: The type of the provided expression (for example, SQL).
            InputSerialization: Describes the format of the data in the object that is being queried.
            OutputSerialization: Describes the format of the data that you want Amazon S3 to return in response.

        Keyword Args:
            SSECustomerAlgorithm: The server-side encryption (SSE) algorithm used to encrypt the object. This parameter is
                needed only when the object was created using a checksum algorithm. For more information, see `Protecting data using
                SSE-C keys <https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html>`_ in the *Amazon
                S3 User Guide*.
            SSECustomerKey: The server-side encryption (SSE) customer managed key. This parameter is needed only when the object
                was created using a checksum algorithm. For more information, see `Protecting data using SSE-C keys
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html>`_ in the *Amazon S3 User
                Guide*.
            SSECustomerKeyMD5: The MD5 server-side encryption (SSE) customer managed key. This parameter is needed only when the
                object was created using a checksum algorithm. For more information, see `Protecting data using SSE-C keys
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html>`_ in the *Amazon S3 User
                Guide*.
            RequestProgress: Specifies if periodic request progress information should be enabled.
            ScanRange: Specifies the byte range of the object to get the records from. A record is processed when its first byte
                is contained by the range. This parameter is optional, but when specified, it must not be empty. See RFC 2616,
                Section 14.35.1 about how to specify the start and end of the range.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            Expression=self.serialize(Expression),
            ExpressionType=self.serialize(ExpressionType),
            InputSerialization=self.serialize(InputSerialization),
            OutputSerialization=self.serialize(OutputSerialization),
            SSECustomerAlgorithm=self.serialize(SSECustomerAlgorithm),
            SSECustomerKey=self.serialize(SSECustomerKey),
            SSECustomerKeyMD5=self.serialize(SSECustomerKeyMD5),
            RequestProgress=self.serialize(RequestProgress),
            ScanRange=self.serialize(ScanRange),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.select_object_content(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = SelectObjectContentOutput(**_response)

        results: "SelectObjectContentEventStream" = None
        if response is not None:
            results = response.Payload

        self.sessionize(results)
        return cast("SelectObjectContentEventStream", results)

    def delete(
        self,
        Bucket: str,
        Delete: "Delete",
        *,
        MFA: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        BypassGovernanceRetention: bool | None = None,
        ExpectedBucketOwner: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
    ) -> "S3Object":
        """
        This operation enables you to delete multiple objects from a bucket using a
        single HTTP request. If you know the object keys that you want to delete, then
        this operation provides a suitable alternative to sending individual delete
        requests, reducing per-request overhead.

        Args:
            Bucket: The bucket name containing the objects to delete.
            Delete: Container for the request.

        Keyword Args:
            MFA: The concatenation of the authentication device's serial number, a space, and the value that is displayed on
                your authentication device. Required to permanently delete a versioned object if versioning is configured with MFA
                delete enabled.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            BypassGovernanceRetention: Specifies whether you want to delete this object even if it has a Governance-type Object
                Lock in place. To use this header, you must have the ``s3:BypassGovernanceRetention`` permission.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum-algorithm``  or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the
                request with the HTTP status code ``400 Bad Request``.
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Delete=self.serialize(Delete),
            MFA=self.serialize(MFA),
            RequestPayer=self.serialize(RequestPayer),
            BypassGovernanceRetention=self.serialize(BypassGovernanceRetention),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
        )
        _response = self.client.delete_objects(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = DeleteObjectsOutput(**_response)
        return cast("S3Object", response.Deleted)

    def get_tags(
        self,
        Bucket: str,
        Key: str,
        *,
        VersionId: str | None = None,
        ExpectedBucketOwner: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
    ) -> List[Tag]:
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name containing the object for which to get the tagging information.
            Key: Object key for which to get the tagging information.

        Keyword Args:
            VersionId: The versionId of the object for which to get the tagging information.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            VersionId=self.serialize(VersionId),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            RequestPayer=self.serialize(RequestPayer),
        )
        _response = self.client.get_object_tagging(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectTaggingOutput(**_response)

        results: List[Tag] = None
        if response is not None:
            results = response.TagSet

        self.sessionize(results)
        return cast("List[Tag]", results)

    def put_tags(
        self,
        Bucket: str,
        Key: str,
        Tagging: "S3Tagging",
        *,
        VersionId: str | None = None,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
    ) -> str:
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name containing the object.
            Key: Name of the object key.
            Tagging: Container for the ``TagSet`` and ``Tag`` elements

        Keyword Args:
            VersionId: The versionId of the object that the tag-set will be added to.
            ContentMD5: The MD5 hash for the request body.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            RequestPayer: Confirms that the requester knows that she or he will be charged for the tagging object request.
                Bucket owners need not specify this parameter in their requests.
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            Tagging=self.serialize(Tagging),
            VersionId=self.serialize(VersionId),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            RequestPayer=self.serialize(RequestPayer),
        )
        _response = self.client.put_object_tagging(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutObjectTaggingOutput(**_response)

        results: str = None
        if response is not None:
            results = response.VersionId

        self.sessionize(results)
        return cast("str", results)

    def delete_tags(
        self,
        Bucket: str,
        Key: str,
        *,
        VersionId: str | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "DeleteObjectTaggingOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name containing the objects from which to remove the tags.
            Key: The key that identifies the object in the bucket from which to remove all tags.

        Keyword Args:
            VersionId: The versionId of the object that the tag-set will be removed from.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            VersionId=self.serialize(VersionId),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.delete_object_tagging(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = DeleteObjectTaggingOutput(**_response)

        results: "DeleteObjectTaggingOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("DeleteObjectTaggingOutput", results)

    def get_acl(
        self,
        Bucket: str,
        Key: str,
        *,
        VersionId: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "GetObjectAclOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name that contains the object for which to get the ACL information.
            Key: The key of the object for which to get the ACL information.

        Keyword Args:
            VersionId: Version ID used to reference a specific version of the object.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            VersionId=self.serialize(VersionId),
            RequestPayer=self.serialize(RequestPayer),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_object_acl(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectAclOutput(**_response)

        results: "GetObjectAclOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("GetObjectAclOutput", results)

    def put_acl(
        self,
        Bucket: str,
        Key: str,
        *,
        ACL: Literal["private", "public-read", "public-read-write", "authenticated-read", "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control"] | None = None,
        AccessControlPolicy: Optional["AccessControlPolicy"] = None,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        GrantFullControl: str | None = None,
        GrantRead: str | None = None,
        GrantReadACP: str | None = None,
        GrantWrite: str | None = None,
        GrantWriteACP: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        VersionId: str | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "PutObjectAclOutput":
        """
        End of support notice: As of October 1, 2025, Amazon S3 has discontinued support for Email Grantee Access Control Lists
        (ACLs). If you attempt to use an Email Grantee ACL in a request after October 1, 2025, the request will receive an
        ``HTTP 405`` (Method Not Allowed) error.

        Args:
            Bucket: The bucket name that contains the object to which you want to attach the ACL.
            Key: Key for which the PUT action was initiated.

        Keyword Args:
            ACL: The canned ACL to apply to the object. For more information, see `Canned ACL
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#CannedACL>`_.
            AccessControlPolicy: Contains the elements that set the ACL permissions for an object per grantee.
            ContentMD5: The Base64 encoded 128-bit ``MD5`` digest of the data. This header must be used as a message integrity
                check to verify that the request body was not corrupted in transit. For more information, go to `RFC 1864.>
                <http://www.ietf.org/rfc/rfc1864.txt>`_
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            GrantFullControl: Allows grantee the read, write, read ACP, and write ACP permissions on the bucket.
            GrantRead: Allows grantee to list the objects in the bucket.
            GrantReadACP: Allows grantee to read the bucket ACL.
            GrantWrite: Allows grantee to create new objects in the bucket.
            GrantWriteACP: Allows grantee to write the ACL for the applicable bucket.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            VersionId: Version ID used to reference a specific version of the object.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).

        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            ACL=self.serialize(ACL),
            AccessControlPolicy=self.serialize(AccessControlPolicy),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            GrantFullControl=self.serialize(GrantFullControl),
            GrantRead=self.serialize(GrantRead),
            GrantReadACP=self.serialize(GrantReadACP),
            GrantWrite=self.serialize(GrantWrite),
            GrantWriteACP=self.serialize(GrantWriteACP),
            RequestPayer=self.serialize(RequestPayer),
            VersionId=self.serialize(VersionId),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.put_object_acl(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutObjectAclOutput(**_response)

        results: "PutObjectAclOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("PutObjectAclOutput", results)

    def get_legal_hold(
        self,
        Bucket: str,
        Key: str,
        *,
        VersionId: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "S3ObjectLockLegalHold":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name containing the object whose legal hold status you want to retrieve.
            Key: The key name for the object whose legal hold status you want to retrieve.

        Keyword Args:
            VersionId: The version ID of the object whose legal hold status you want to retrieve.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            VersionId=self.serialize(VersionId),
            RequestPayer=self.serialize(RequestPayer),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_object_legal_hold(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectLegalHoldOutput(**_response)

        results: "S3ObjectLockLegalHold" = None
        if response is not None:
            results = response.LegalHold

        self.sessionize(results)
        return cast("S3ObjectLockLegalHold", results)

    def put_legal_hold(
        self,
        Bucket: str,
        Key: str,
        *,
        LegalHold: Optional["S3ObjectLockLegalHold"] = None,
        RequestPayer: Literal["requester"] | None = None,
        VersionId: str | None = None,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "PutObjectLegalHoldOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name containing the object that you want to place a legal hold on.
            Key: The key name for the object that you want to place a legal hold on.

        Keyword Args:
            LegalHold: Container element for the legal hold configuration you want to apply to the specified object.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            VersionId: The version ID of the object that you want to place a legal hold on.
            ContentMD5: The MD5 hash for the request body.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            LegalHold=self.serialize(LegalHold),
            RequestPayer=self.serialize(RequestPayer),
            VersionId=self.serialize(VersionId),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.put_object_legal_hold(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutObjectLegalHoldOutput(**_response)

        results: "PutObjectLegalHoldOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("PutObjectLegalHoldOutput", results)

    def get_lock_configuration(
        self, Bucket: str, *, ExpectedBucketOwner: str | None = None
    ) -> "S3ObjectLockConfiguration":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket whose Object Lock configuration you want to retrieve.

        Keyword Args:
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_object_lock_configuration(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectLockConfigurationOutput(**_response)

        results: "S3ObjectLockConfiguration" = None
        if response is not None:
            results = response.ObjectLockConfiguration

        self.sessionize(results)
        return cast("S3ObjectLockConfiguration", results)

    def put_lock_configuration(
        self,
        Bucket: str,
        *,
        ObjectLockConfiguration: Optional["S3ObjectLockConfiguration"] = None,
        RequestPayer: Literal["requester"] | None = None,
        Token: str | None = None,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "PutObjectLockConfigurationOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket whose Object Lock configuration you want to create or replace.

        Keyword Args:
            ObjectLockConfiguration: The Object Lock configuration that you want to apply to the specified bucket.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            Token: A token to allow Object Lock to be enabled for an existing bucket.
            ContentMD5: The MD5 hash for the request body.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            ObjectLockConfiguration=self.serialize(ObjectLockConfiguration),
            RequestPayer=self.serialize(RequestPayer),
            Token=self.serialize(Token),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.put_object_lock_configuration(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutObjectLockConfigurationOutput(**_response)

        results: "PutObjectLockConfigurationOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("PutObjectLockConfigurationOutput", results)

    def get_retention(
        self,
        Bucket: str,
        Key: str,
        *,
        VersionId: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "ObjectLockRetention":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name containing the object whose retention settings you want to retrieve.
            Key: The key name for the object whose retention settings you want to retrieve.

        Keyword Args:
            VersionId: The version ID for the object whose retention settings you want to retrieve.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            VersionId=self.serialize(VersionId),
            RequestPayer=self.serialize(RequestPayer),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_object_retention(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectRetentionOutput(**_response)

        results: "ObjectLockRetention" = None
        if response is not None:
            results = response.Retention

        self.sessionize(results)
        return cast("ObjectLockRetention", results)

    def put_retention(
        self,
        Bucket: str,
        Key: str,
        *,
        Retention: Optional["ObjectLockRetention"] = None,
        RequestPayer: Literal["requester"] | None = None,
        VersionId: str | None = None,
        BypassGovernanceRetention: bool | None = None,
        ContentMD5: str | None = None,
        ChecksumAlgorithm: Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "PutObjectRetentionOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name that contains the object you want to apply this Object Retention configuration to.
            Key: The key name for the object that you want to apply this Object Retention configuration to.

        Keyword Args:
            Retention: The container element for the Object Retention configuration.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            VersionId: The version ID for the object that you want to apply this Object Retention configuration to.
            BypassGovernanceRetention: Indicates whether this action should bypass Governance-mode restrictions.
            ContentMD5: The MD5 hash for the request body.
            ChecksumAlgorithm: Indicates the algorithm used to create the checksum for the object when you use the SDK. This
                header will not provide any additional functionality if you don't use the SDK. When you send this header, there must
                be a corresponding ``x-amz- checksum`` or ``x-amz-trailer`` header sent. Otherwise, Amazon S3 fails the request with
                the HTTP status code ``400 Bad Request``. For more information, see `Checking object integrity
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            Retention=self.serialize(Retention),
            RequestPayer=self.serialize(RequestPayer),
            VersionId=self.serialize(VersionId),
            BypassGovernanceRetention=self.serialize(BypassGovernanceRetention),
            ContentMD5=self.serialize(ContentMD5),
            ChecksumAlgorithm=self.serialize(ChecksumAlgorithm),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.put_object_retention(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = PutObjectRetentionOutput(**_response)

        results: "PutObjectRetentionOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("PutObjectRetentionOutput", results)

    def get_attributes(
        self,
        Bucket: str,
        Key: str,
        ObjectAttributes: List[
            Literal["ETag", "Checksum", "ObjectParts", "StorageClass", "ObjectSize"]
        ],
        *,
        VersionId: str | None = None,
        MaxParts: int | None = None,
        PartNumberMarker: int | None = None,
        SSECustomerAlgorithm: str | None = None,
        SSECustomerKey: str | None = None,
        SSECustomerKeyMD5: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        ExpectedBucketOwner: str | None = None,
    ) -> "GetObjectAttributesOutput":
        """
        Retrieves all of the metadata from an object without returning the object
        itself. This operation is useful if you're interested only in an object's
        metadata.

        Args:
            Bucket: The name of the bucket that contains the object.
            Key: The object key.
            ObjectAttributes: Specifies the fields at the root level that you want returned in the response. Fields that you do
                not specify are not returned.

        Keyword Args:
            VersionId: The version ID used to reference a specific version of the object.
            MaxParts: Sets the maximum number of parts to return. For more information, see `Uploading and copying objects using
                multipart upload in Amazon S3 <https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html>`_  in the
                *Amazon Simple Storage Service user guide*.
            PartNumberMarker: Specifies the part after which listing should begin. Only parts with higher part numbers will be
                listed. For more information, see `Uploading and copying objects using multipart upload in Amazon S3
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html>`_  in the *Amazon Simple Storage Service
                user guide*.
            SSECustomerAlgorithm: Specifies the algorithm to use when encrypting the object (for example, AES256).
            SSECustomerKey: Specifies the customer-provided encryption key for Amazon S3 to use in encrypting data. This value
                is used to store the object and then it is discarded; Amazon S3 does not store the encryption key. The key must be
                appropriate for use with the algorithm specified in the ``x-amz-server-side-encryption-customer-algorithm`` header.
            SSECustomerKeyMD5: Specifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses this
                header for a message integrity check to ensure that the encryption key was transmitted without error.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            ObjectAttributes=self.serialize(ObjectAttributes),
            VersionId=self.serialize(VersionId),
            MaxParts=self.serialize(MaxParts),
            PartNumberMarker=self.serialize(PartNumberMarker),
            SSECustomerAlgorithm=self.serialize(SSECustomerAlgorithm),
            SSECustomerKey=self.serialize(SSECustomerKey),
            SSECustomerKeyMD5=self.serialize(SSECustomerKeyMD5),
            RequestPayer=self.serialize(RequestPayer),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
        )
        _response = self.client.get_object_attributes(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectAttributesOutput(**_response)

        results: "GetObjectAttributesOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("GetObjectAttributesOutput", results)

    def get_versions(
        self,
        Bucket: str,
        *,
        Delimiter: str | None = None,
        EncodingType: Literal["url"] | None = None,
        KeyMarker: str | None = None,
        MaxKeys: int | None = None,
        Prefix: str | None = None,
        VersionIdMarker: str | None = None,
        ExpectedBucketOwner: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        OptionalObjectAttributes: List[Literal["RestoreStatus"]] | None = None,
    ) -> "ListObjectVersionsOutput":
        """
        This operation is not supported for directory buckets.

        Args:
            Bucket: The bucket name that contains the objects.

        Keyword Args:
            Delimiter: A delimiter is a character that you specify to group keys. All keys that contain the same string between
                the ``prefix`` and the first occurrence of the delimiter are grouped under a single result element in
                ``CommonPrefixes``. These groups are counted as one result against the ``max-keys`` limitation. These keys are not
                returned elsewhere in the response.
            EncodingType: Encoding type used by Amazon S3 to encode the `object keys
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html>`_ in the response. Responses are encoded
                only in UTF-8. An object key can contain any Unicode character. However, the XML 1.0 parser can't parse certain
                characters, such as characters with an ASCII value from 0 to 10. For characters that aren't supported in XML 1.0,
                you can add this parameter to request that Amazon S3 encode the keys in the response. For more information about
                characters to avoid in object key names, see `Object key naming guidelines
                <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html#object-key-guidelines>`_.
            KeyMarker: Specifies the key to start with when listing objects in a bucket.
            MaxKeys: Sets the maximum number of keys returned in the response. By default, the action returns up to 1,000 key
                names. The response might contain fewer keys but will never contain more. If additional keys satisfy the search
                criteria, but were not returned because ``max-keys`` was exceeded, the response contains
                ``<isTruncated>true</isTruncated>``. To return the additional keys, see ``key-marker`` and ``version-id-marker``.
            Prefix: Use this parameter to select only those keys that begin with the specified prefix. You can use prefixes to
                separate a bucket into different groupings of keys. (You can think of using ``prefix`` to make groups in the same
                way that you'd use a folder in a file system.) You can use ``prefix`` with ``delimiter`` to roll up numerous objects
                into a single result under ``CommonPrefixes``.
            VersionIdMarker: Specifies the object version you want to start listing from.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            OptionalObjectAttributes: Specifies the optional fields that you want returned in the response. Fields that you do
                not specify are not returned.
        """
        paginator = self.client.get_paginator("list_object_versions")
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Delimiter=self.serialize(Delimiter),
            EncodingType=self.serialize(EncodingType),
            KeyMarker=self.serialize(KeyMarker),
            MaxKeys=self.serialize(MaxKeys),
            Prefix=self.serialize(Prefix),
            VersionIdMarker=self.serialize(VersionIdMarker),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            RequestPayer=self.serialize(RequestPayer),
            OptionalObjectAttributes=self.serialize(OptionalObjectAttributes),
        )
        response_iterator = paginator.paginate(
            **{k: v for k, v in args.items() if v is not None}
        )

        results: "ListObjectVersionsOutput" = []

        for _response in response_iterator:
            response = ListObjectVersionsOutput(**_response)
            results.append(response)

        self.sessionize(results)
        return cast("ListObjectVersionsOutput", results)

    def download(
        self,
        Bucket: str,
        Key: str,
        *,
        IfMatch: str | None = None,
        IfModifiedSince: datetime | None = None,
        IfNoneMatch: str | None = None,
        IfUnmodifiedSince: datetime | None = None,
        Range: str | None = None,
        ResponseCacheControl: str | None = None,
        ResponseContentDisposition: str | None = None,
        ResponseContentEncoding: str | None = None,
        ResponseContentLanguage: str | None = None,
        ResponseContentType: str | None = None,
        ResponseExpires: datetime | None = None,
        VersionId: str | None = None,
        SSECustomerAlgorithm: str | None = None,
        SSECustomerKey: str | None = None,
        SSECustomerKeyMD5: str | None = None,
        RequestPayer: Literal["requester"] | None = None,
        PartNumber: int | None = None,
        ExpectedBucketOwner: str | None = None,
        ChecksumMode: Literal["ENABLED"] | None = None,
    ) -> "GetObjectOutput":
        """
        Retrieves an object from Amazon S3.

        Args:
            Bucket: The bucket name containing the object.
            Key: Key of the object to get.

        Keyword Args:
            IfMatch: Return the object only if its entity tag (ETag) is the same as the one specified in this header; otherwise,
                return a ``412 Precondition Failed`` error.
            IfModifiedSince: Return the object only if it has been modified since the specified time; otherwise, return a ``304
                Not Modified`` error.
            IfNoneMatch: Return the object only if its entity tag (ETag) is different from the one specified in this header;
                otherwise, return a ``304 Not Modified`` error.
            IfUnmodifiedSince: Return the object only if it has not been modified since the specified time; otherwise, return a
                ``412 Precondition Failed`` error.
            Range: Downloads the specified byte range of an object. For more information about the HTTP Range header, see
                <https://www.rfc- editor.org/rfc/rfc9110.html#name-range>.
            ResponseCacheControl: Sets the ``Cache-Control`` header of the response.
            ResponseContentDisposition: Sets the ``Content-Disposition`` header of the response.
            ResponseContentEncoding: Sets the ``Content-Encoding`` header of the response.
            ResponseContentLanguage: Sets the ``Content-Language`` header of the response.
            ResponseContentType: Sets the ``Content-Type`` header of the response.
            ResponseExpires: Sets the ``Expires`` header of the response.
            VersionId: Version ID used to reference a specific version of the object.
            SSECustomerAlgorithm: Specifies the algorithm to use when decrypting the object (for example, ``AES256``).
            SSECustomerKey: Specifies the customer-provided encryption key that you originally provided for Amazon S3 to encrypt
                the data before storing it. This value is used to decrypt the object when recovering it and must match the one used
                when storing the data. The key must be appropriate for use with the algorithm specified in the ``x-amz-server-side-
                encryption-customer- algorithm`` header.
            SSECustomerKeyMD5: Specifies the 128-bit MD5 digest of the customer-provided encryption key according to RFC 1321.
                Amazon S3 uses this header for a message integrity check to ensure that the encryption key was transmitted without
                error.
            RequestPayer: Confirms that the requester knows that they will be charged for the request. Bucket owners need not
                specify this parameter in their requests. If either the source or destination S3 bucket has Requester Pays enabled,
                the requester will pay for corresponding charges to copy the object. For information about downloading objects from
                Requester Pays buckets, see `Downloading Objects in Requester Pays Buckets
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectsinRequesterPaysBuckets.html>`_ in the *Amazon S3 User
                Guide*.
            PartNumber: Part number of the object being read. This is a positive integer between 1 and 10,000. Effectively
                performs a 'ranged' GET request for the part specified. Useful for downloading just a part of an object.
            ExpectedBucketOwner: The account ID of the expected bucket owner. If the account ID that you provide does not match
                the actual owner of the bucket, the request fails with the HTTP status code ``403 Forbidden`` (access denied).
            ChecksumMode: To retrieve the checksum, this mode must be enabled.
        """
        args: Dict[str, Any] = dict(
            Bucket=self.serialize(Bucket),
            Key=self.serialize(Key),
            IfMatch=self.serialize(IfMatch),
            IfModifiedSince=self.serialize(IfModifiedSince),
            IfNoneMatch=self.serialize(IfNoneMatch),
            IfUnmodifiedSince=self.serialize(IfUnmodifiedSince),
            Range=self.serialize(Range),
            ResponseCacheControl=self.serialize(ResponseCacheControl),
            ResponseContentDisposition=self.serialize(ResponseContentDisposition),
            ResponseContentEncoding=self.serialize(ResponseContentEncoding),
            ResponseContentLanguage=self.serialize(ResponseContentLanguage),
            ResponseContentType=self.serialize(ResponseContentType),
            ResponseExpires=self.serialize(ResponseExpires),
            VersionId=self.serialize(VersionId),
            SSECustomerAlgorithm=self.serialize(SSECustomerAlgorithm),
            SSECustomerKey=self.serialize(SSECustomerKey),
            SSECustomerKeyMD5=self.serialize(SSECustomerKeyMD5),
            RequestPayer=self.serialize(RequestPayer),
            PartNumber=self.serialize(PartNumber),
            ExpectedBucketOwner=self.serialize(ExpectedBucketOwner),
            ChecksumMode=self.serialize(ChecksumMode),
        )
        _response = self.client.get_object(
            **{k: v for k, v in args.items() if v is not None}
        )
        response = GetObjectOutput(**_response)

        results: "GetObjectOutput" = None
        if response is not None:
            results = response

        self.sessionize(results)
        return cast("GetObjectOutput", results)


# ==============
# Service Models
# ==============


class S3ErrorDocument(Boto3Model):
    """
    The error information.
    """

    Key: str
    """
    The object key name to use when a 4XX class error occurs.
    """


class S3IndexDocument(Boto3Model):
    """
    Container for the ``Suffix`` element.
    """

    Suffix: str
    """
    A suffix that is appended to a request that is for a directory on the website
    endpoint.

    (For example, if the suffix is
    ``index.html`` and you make a request to ``samplebucket/images/``, the data that is returned will be for the object with
    the key name ``images/index.html``.) The suffix must not be empty and must not include a slash character.
    """


class S3RedirectAllRequestsTo(Boto3Model):
    """
    Specifies the redirect behavior of all requests to a website endpoint of an Amazon
    S3 bucket.
    """

    HostName: str
    """
    Name of the host where requests are redirected.
    """
    Protocol: Literal["http", "https"] | None = None
    """
    Protocol to use when redirecting requests.

    The default is the protocol that is used in the original request.
    """


class S3Condition(Boto3Model):
    """
    A container for describing a condition that must be met for the specified redirect
    to apply.

    For example, 1. If request
    is for pages in the ``/docs`` folder, redirect to the ``/documents`` folder. 2. If request results in HTTP error 4xx,
    redirect request to another host where you might process the error.
    """

    HttpErrorCodeReturnedEquals: str | None = None
    """
    The HTTP error code when the redirect is applied.

    In the event of an error, if the error code equals this value, then
    the specified redirect is applied. Required when parent element ``Condition`` is specified and sibling
    ``KeyPrefixEquals`` is not specified. If both are specified, then both must be true for the redirect to be applied.
    """
    KeyPrefixEquals: str | None = None
    """
    The object key name prefix when the redirect is applied.

    For example, to redirect requests for ``ExamplePage.html``, the
    key prefix will be ``ExamplePage.html``. To redirect request for all pages with the prefix ``docs/``, the key prefix
    will be ``/docs``, which identifies all objects in the ``docs/`` folder. Required when the parent element ``Condition``
    is specified and sibling ``HttpErrorCodeReturnedEquals`` is not specified. If both conditions are specified, both must
    be true for the redirect to be applied.
    """


class Redirect(Boto3Model):
    """
    Specifies how requests are redirected.

    In the event of an error, you can specify a different error code to return.
    """

    HostName: str | None = None
    """
    The host name to use in the redirect request.
    """
    HttpRedirectCode: str | None = None
    """
    The HTTP redirect code to use on the response.

    Not required if one of the siblings is present.
    """
    Protocol: Literal["http", "https"] | None = None
    """
    Protocol to use when redirecting requests.

    The default is the protocol that is used in the original request.
    """
    ReplaceKeyPrefixWith: str | None = None
    """
    The object key prefix to use in the redirect request.

    For example, to redirect requests for all pages with prefix
    ``docs/`` (objects in the ``docs/`` folder) to ``documents/``, you can set a condition block with ``KeyPrefixEquals``
    set to ``docs/`` and in the Redirect set ``ReplaceKeyPrefixWith`` to ``/documents``. Not required if one of the siblings
    is present. Can be present only if ``ReplaceKeyWith`` is not provided.
    """
    ReplaceKeyWith: str | None = None
    """
    The specific object key to use in the redirect request.

    For example, redirect request to ``error.html``. Not required if
    one of the siblings is present. Can be present only if ``ReplaceKeyPrefixWith`` is not provided.
    """


class S3RoutingRule(Boto3Model):
    """
    Specifies the redirect behavior and when a redirect is applied.

    For more information about routing rules, see
    `Configuring advanced conditional redirects <https://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-page-
    redirect.html#advanced-conditional-redirects>`_ in the *Amazon S3 User Guide*.
    """

    Condition: S3Condition | None = None
    """
    A container for describing a condition that must be met for the specified redirect
    to apply.

    For example, 1. If request
    is for pages in the ``/docs`` folder, redirect to the ``/documents`` folder. 2. If request results in HTTP error 4xx,
    redirect request to another host where you might process the error.
    """
    Redirect: "Redirect"
    """
    Container for redirect information.

    You can redirect requests to another host, to another page, or with another
    protocol. In the event of an error, you can specify a different error code to
    return.
    """


class WebsiteConfiguration(Boto3Model):
    """
    Specifies website configuration parameters for an Amazon S3 bucket.
    """

    ErrorDocument: S3ErrorDocument | None = None
    """
    The name of the error document for the website.
    """
    IndexDocument: S3IndexDocument | None = None
    """
    The name of the index document for the website.
    """
    RedirectAllRequestsTo: S3RedirectAllRequestsTo | None = None
    """
    The redirect behavior for every request to this bucket's website endpoint.
    """
    RoutingRules: List["S3RoutingRule"] | None = None
    """
    Rules that define when a redirect is applied and the redirect behavior.
    """


class LifecycleExpiration(Boto3Model):
    """
    Container for the expiration for the lifecycle of the object.

    For more information see,
    `Managing your storage lifecycle <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html>`_
    in the *Amazon S3 User
    Guide*.
    """

    Date: datetime | None = None
    """
    Indicates at what date the object is to be moved or deleted.

    The date value must conform to the ISO 8601 format. The time is always midnight UTC.
    """
    Days: int | None = None
    """
    Indicates the lifetime, in days, of the objects that are subject to the rule.

    The value must be a non-zero positive integer.
    """
    ExpiredObjectDeleteMarker: bool | None = None
    """
    Indicates whether Amazon S3 will remove a delete marker with no noncurrent versions.

    If set to true, the delete marker will be expired; if set to false the policy takes
    no action. This cannot be specified with Days or Date in a Lifecycle Expiration
    Policy.
    """


class LifecycleRuleAndOperator(TagsDictMixin, Boto3Model):
    """
    This is used in a Lifecycle Rule Filter to apply a logical AND to two or more
    predicates.

    The Lifecycle Rule will apply to any object matching all of the predicates
    configured inside the And operator.
    """

    tag_class: ClassVar[Type] = Tag
    Prefix: str | None = None
    """
    Prefix identifying one or more objects to which the rule applies.
    """
    Tags: List[Tag] | None = None
    """
    All of these tags must exist in the object's tag set in order for the rule to apply.
    """
    ObjectSizeGreaterThan: int | None = None
    """
    Minimum object size to which the rule applies.
    """
    ObjectSizeLessThan: int | None = None
    """
    Maximum object size to which the rule applies.
    """


class LifecycleRuleFilter(Boto3Model):
    """
    The ``Filter`` is used to identify objects that a Lifecycle Rule applies to.

    A ``Filter`` can have exactly one of
    ``Prefix``, ``Tag``, ``ObjectSizeGreaterThan``, ``ObjectSizeLessThan``, or ``And`` specified. If the ``Filter`` element
    is left empty, the Lifecycle Rule applies to all objects in the bucket.
    """

    RuleTag: Tag = Field(default=None, alias="Tag")
    """
    This tag must exist in the object's tag set in order for the rule to apply.
    """
    Prefix: str | None = None
    """
    Prefix identifying one or more objects to which the rule applies.
    """
    ObjectSizeGreaterThan: int | None = None
    """
    Minimum object size to which the rule applies.
    """
    ObjectSizeLessThan: int | None = None
    """
    Maximum object size to which the rule applies.
    """
    And: LifecycleRuleAndOperator | None = None
    """
    This is used in a Lifecycle Rule Filter to apply a logical AND to two or more
    predicates.

    The Lifecycle Rule will apply to any object matching all of the predicates
    configured inside the And operator.
    """


class Transition(Boto3Model):
    """
    Specifies when an object transitions to a specified storage class.

    For more information about Amazon S3 lifecycle configuration rules, see
    `Transitioning Objects Using Amazon S3 Lifecycle <https://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general-considerations.html>`_
    in the
    *Amazon S3 User Guide*.
    """

    Date: datetime | None = None
    """
    Indicates when objects are transitioned to the specified storage class.

    The date value must be in ISO 8601 format. The time is always midnight UTC.
    """
    Days: int | None = None
    """
    Indicates the number of days after creation when objects are transitioned to the
    specified storage class.

    If the
    specified storage class is ``INTELLIGENT_TIERING``, ``GLACIER_IR``, ``GLACIER``, or ``DEEP_ARCHIVE``, valid values are
    ``0`` or positive integers. If the specified storage class is ``STANDARD_IA`` or ``ONEZONE_IA``, valid values are
    positive integers greater than ``30``. Be aware that some storage classes have a minimum storage duration and that
    you're charged for transitioning objects before their minimum storage duration. For more information, see  `Constraints
    and considerations for transitions <https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-
    considerations.html#lifecycle-configuration-constraints>`_ in the *Amazon S3 User Guide*.
    """
    StorageClass: Literal["GLACIER", "STANDARD_IA", "ONEZONE_IA", "INTELLIGENT_TIERING", "DEEP_ARCHIVE", "GLACIER_IR"] | None = None
    """
    The storage class to which you want the object to transition.
    """


class NoncurrentVersionTransition(Boto3Model):
    """
    Container for the transition rule that describes when noncurrent objects transition
    to the ``STANDARD_IA``, ``ONEZONE_IA``, ``INTELLIGENT_TIERING``, ``GLACIER_IR``,
    ``GLACIER``, or ``DEEP_ARCHIVE`` storage class.

    If your bucket
    is versioning-enabled (or versioning is suspended), you can set this action to request that Amazon S3 transition
    noncurrent object versions to the ``STANDARD_IA``, ``ONEZONE_IA``, ``INTELLIGENT_TIERING``, ``GLACIER_IR``, ``GLACIER``,
    or ``DEEP_ARCHIVE`` storage class at a specific period in the object's lifetime.
    """

    NoncurrentDays: int | None = None
    """
    Specifies the number of days an object is noncurrent before Amazon S3 can perform
    the associated action.

    For information about the noncurrent days calculations, see
    `How Amazon S3 Calculates How Long an Object Has Been Noncurrent <https://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html#non-current-days-calculations>`_
    in
    the *Amazon S3 User Guide*.
    """
    StorageClass: Literal["GLACIER", "STANDARD_IA", "ONEZONE_IA", "INTELLIGENT_TIERING", "DEEP_ARCHIVE", "GLACIER_IR"] | None = None
    """
    The class of storage used to store the object.
    """
    NewerNoncurrentVersions: int | None = None
    """
    Specifies how many noncurrent versions Amazon S3 will retain in the same storage
    class before transitioning objects.

    You can specify up to 100 noncurrent versions to retain. Amazon S3 will transition
    any additional noncurrent versions beyond the specified number to retain. For more
    information about noncurrent versions, see
    `Lifecycle configuration elements <https://docs.aws.amazon.com/AmazonS3/latest/userguide/intro-lifecycle-rules.html>`_
    in the *Amazon S3 User
    Guide*.
    """


class S3NoncurrentVersionExpiration(Boto3Model):
    """
    Specifies when noncurrent object versions expire. Upon expiration, Amazon S3
    permanently deletes the noncurrent object versions. You set this lifecycle
    configuration action on a bucket that has versioning enabled (or suspended) to
    request that Amazon S3 delete noncurrent object versions at a specific period in the
    object's lifetime.

    This parameter applies to general purpose buckets only. It is not supported for
    directory bucket lifecycle configurations.
    """

    NoncurrentDays: int | None = None
    """
    Specifies the number of days an object is noncurrent before Amazon S3 can perform
    the associated action.

    The value must be a non-zero positive integer. For information about the noncurrent
    days calculations, see
    `How Amazon S3 Calculates When an Object Became Noncurrent <https://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html#non-
    current-days-calculations>`_ in the *Amazon S3 User Guide*.
    """
    NewerNoncurrentVersions: int | None = None
    """
    Specifies how many noncurrent versions Amazon S3 will retain.

    You can specify up to 100 noncurrent versions to retain. Amazon S3 will permanently
    delete any additional noncurrent versions beyond the specified number to retain. For
    more information about noncurrent versions, see
    `Lifecycle configuration elements <https://docs.aws.amazon.com/AmazonS3/latest/userguide/intro-lifecycle-rules.html>`_
    in the *Amazon S3 User
    Guide*.
    """


class S3AbortIncompleteMultipartUpload(Boto3Model):
    """
    Specifies the days since the initiation of an incomplete multipart upload that
    Amazon S3 will wait before permanently removing all parts of the upload.

    For more information, see
    `Aborting Incomplete Multipart Uploads Using a Bucket Lifecycle Configuration <https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html#mpu-abort-incomplete-mpu-
    lifecycle-config>`_ in the *Amazon S3 User Guide*.
    """

    DaysAfterInitiation: int | None = None
    """
    Specifies the number of days after which Amazon S3 aborts an incomplete multipart
    upload.
    """


class LifecycleRule(Boto3Model):
    """
    A lifecycle rule for individual objects in an Amazon S3 bucket.

    For more information see,
    `Managing your storage lifecycle <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html>`_
    in the *Amazon S3 User
    Guide*.
    """

    Expiration: LifecycleExpiration | None = None
    """
    Specifies the expiration for the lifecycle of the object in the form of date, days
    and, whether the object has a delete marker.
    """
    ID: str | None = None
    """
    Unique identifier for the rule.

    The value cannot be longer than 255 characters.
    """
    Prefix: str | None = None
    """
    The general purpose bucket prefix that identifies one or more objects to which the
    rule applies.

    We recommend using
    ``Filter`` instead of ``Prefix`` for new PUTs. Previous configurations where a prefix is defined will continue to
    operate as before.
    """
    Filter: LifecycleRuleFilter | None = None
    """
    The ``Filter`` is used to identify objects that a Lifecycle Rule applies to.

    A ``Filter`` must have exactly one of
    ``Prefix``, ``Tag``, ``ObjectSizeGreaterThan``, ``ObjectSizeLessThan``, or ``And`` specified. ``Filter`` is required if
    the ``LifecycleRule`` does not contain a ``Prefix`` element.
    """
    Status: Literal["Enabled", "Disabled"]
    """
    If 'Enabled', the rule is currently being applied.

    If 'Disabled', the rule is not currently being applied.
    """
    Transitions: List["Transition"] | None = None
    """
    Specifies when an Amazon S3 object transitions to a specified storage class.
    """
    NoncurrentVersionTransitions: List["NoncurrentVersionTransition"] | None = None
    """
    Specifies the transition rule for the lifecycle rule that describes when noncurrent
    objects transition to a specific storage class.

    If your bucket is versioning-enabled (or versioning is suspended), you can set this
    action to request that Amazon S3 transition noncurrent object versions to a specific
    storage class at a set period in the object's lifetime.
    """
    NoncurrentVersionExpiration: S3NoncurrentVersionExpiration | None = None
    """
    Specifies when noncurrent object versions expire.

    Upon expiration, Amazon S3 permanently deletes the noncurrent object versions. You
    set this lifecycle configuration action on a bucket that has versioning enabled (or
    suspended) to request that Amazon S3 delete noncurrent object versions at a specific
    period in the object's lifetime.
    """
    AbortIncompleteMultipartUpload: S3AbortIncompleteMultipartUpload | None = None
    """
    Specifies the days since the initiation of an incomplete multipart upload that
    Amazon S3 will wait before permanently removing all parts of the upload.

    For more information, see
    `Aborting Incomplete Multipart Uploads Using a Bucket Lifecycle Configuration <https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html#mpu-abort-incomplete-mpu-
    lifecycle-config>`_ in the *Amazon S3 User Guide*.
    """


class BucketLifecycleConfiguration(Boto3Model):
    """
    Specifies the lifecycle configuration for objects in an Amazon S3 bucket.

    For more information, see
    `Object Lifecycle Management <https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html>`_
    in the *Amazon S3 User Guide*.
    """

    Rules: List["LifecycleRule"]
    """
    A lifecycle rule for individual objects in an Amazon S3 bucket.
    """


class S3PublicAccessBlockConfiguration(Boto3Model):
    """
    The PublicAccessBlock configuration that you want to apply to this Amazon S3 bucket.

    You can enable the configuration
    options in any combination. Bucket-level settings work alongside account-level settings (which may inherit from
    organization-level policies). For more information about when Amazon S3 considers a bucket or object public, see `The
    Meaning of "Public" <https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html#access-
    control-block-public-access-policy-status>`_ in the *Amazon S3 User Guide*.
    """

    BlockPublicAcls: bool | None = None
    """
    Specifies whether Amazon S3 should block public access control lists (ACLs) for this
    bucket and objects in this bucket.

    Setting this element to ``TRUE`` causes the following behavior:
    """
    IgnorePublicAcls: bool | None = None
    """
    Specifies whether Amazon S3 should ignore public ACLs for this bucket and objects in
    this bucket.

    Setting this element
    to ``TRUE`` causes Amazon S3 to ignore all public ACLs on this bucket and objects in this bucket.
    """
    BlockPublicPolicy: bool | None = None
    """
    Specifies whether Amazon S3 should block public bucket policies for this bucket.

    Setting this element to ``TRUE`` causes
    Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.
    """
    RestrictPublicBuckets: bool | None = None
    """
    Specifies whether Amazon S3 should restrict public bucket policies for this bucket.

    Setting this element to ``TRUE``
    restricts access to this bucket to only Amazon Web Services service principals and authorized users within this account
    if the bucket has a public policy.
    """


class Bucket(TagsDictMixin, PrimaryBoto3Model):
    tag_class: ClassVar[Type] = Tag
    manager_class: ClassVar[Type[Boto3ModelManager]] = BucketManager

    BucketName: str
    """
    The name of the bucket.

    This is a unique identifier for the bucket, globally.
    """
    BucketArn: str | None = Field(frozen=True)
    """
    The ARN of the bucket.

    This is a unique identifier for the bucket. Some older buckets don't have an ARN.
    """
    Region: str
    """
    The region of the bucket.

    This is the region of the bucket.
    """
    CreationDate: datetime = Field(frozen=True)
    """
    The creation date of the bucket.

    This is the date the bucket was created.
    """
    ACL: Literal["private", "public-read", "public-read-write", "authenticated-read", "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control"] | None = "private"
    """
    The ACL for the bucket.

    This is the ACL for the bucket.
    """
    LoggingConfiguration: Optional["BucketLoggingConfiguration"]
    """
    The logging configuration for the bucket.
    """
    VersioningEnabled: bool
    """
    Whether the bucket versioning is enabled.
    """
    MFADelete: bool = False
    """
    Specifies whether MFA delete is enabled in the bucket versioning configuration.
    """
    ObjectOwnership: Literal["BucketOwnerEnforced", "BucketOwnerPreferred", "ObjectWriter"] | None = "BucketOwnerPreferred"
    """
    The object ownership configuration for the bucket.
    """
    CORSRules: List["S3CORSRule"] | None = None
    """
    The CORS rules for the bucket.
    """
    Tags: List[Tag] = Field(default_factory=list)
    """
    The tags of the queue.

    This is a list of Tag objects.
    """

    @property
    def pk(self) -> str | None:
        """
        Return the primary key of the model.   This is the value of the
        :py:attr:`BucketName` attribute.

        Returns:
            The primary key of the model instance.
        """
        return self.BucketName

    @property
    def name(self) -> str | None:
        """
        Return the name of the model.   This is the value of the :py:attr:`BucketName`
        attribute.

        Returns:
            The name of the model instance.
        """
        return self.BucketName

    def __hash__(self) -> int:
        """
        Return the hash of the model.

        This is the value of the
        :py:attr:`BucketName` attribute.
        """
        return hash(self.BucketName)

    def get_policy(self) -> "str":
        """
        Returns the policy of a specified bucket.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .get_bucket_policy(
                cast("str", self.BucketName),
            )
        )

    def put_policy(self, Policy: str) -> "None":
        """
        Applies an Amazon S3 bucket policy to an Amazon S3 bucket.

        Args:
            Policy: The bucket policy as a JSON document.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .put_bucket_policy(
                cast("str", self.BucketName),
                Policy,
            )
        )

    def delete_policy(self) -> "None":
        """
        Deletes the policy of a specified bucket.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .delete_bucket_policy(
                cast("str", self.BucketName),
            )
        )

    def get_website(self) -> "GetBucketWebsiteOutput":
        """
        This operation is not supported for directory buckets.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .get_website(
                cast("str", self.BucketName),
            )
        )

    def put_website(self, WebsiteConfiguration: WebsiteConfiguration) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            WebsiteConfiguration: Container for the request.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .put_website(
                cast("str", self.BucketName),
                WebsiteConfiguration,
            )
        )

    def delete_website(self) -> "None":
        """
        This operation is not supported for directory buckets.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .delete_website(
                cast("str", self.BucketName),
            )
        )

    def get_lifecycle(self) -> "GetBucketLifecycleConfigurationOutput":
        """
        Returns the lifecycle configuration information set on the bucket.

        For information about lifecycle configuration, see
        `Object Lifecycle Management <https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html>`_.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .get_lifecycle(
                cast("str", self.BucketName),
            )
        )

    def put_lifecycle(
        self, LifecycleConfiguration: "BucketLifecycleConfiguration"
    ) -> "PutBucketLifecycleConfigurationOutput":
        """
        Creates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration. Keep in mind that
        this will overwrite an existing lifecycle configuration, so if you want to retain any configuration details, they must
        be included in the new lifecycle configuration. For information about lifecycle configuration, see `Managing your
        storage lifecycle <https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html>`_.

        Args:
            LifecycleConfiguration: Container for lifecycle rules. You can add as many as 1,000 rules.

        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .put_lifecycle(
                cast("str", self.BucketName),
                LifecycleConfiguration,
            )
        )

    def delete_lifecycle(self) -> "None":
        """
        Deletes the lifecycle configuration from the specified bucket.

        Amazon S3 removes all the lifecycle configuration rules in the lifecycle
        subresource associated with the bucket. Your objects never expire, and Amazon S3
        no longer automatically deletes any objects on the basis of rules contained in
        the deleted lifecycle configuration.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .delete_lifecycle(
                cast("str", self.BucketName),
            )
        )

    def get_public_access_block(self) -> "GetPublicAccessBlockOutput":
        """
        This operation is not supported for directory buckets.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .get_public_access_block(
                cast("str", self.BucketName),
            )
        )

    def put_public_access_block(
        self, PublicAccessBlockConfiguration: "S3PublicAccessBlockConfiguration"
    ) -> "None":
        """
        This operation is not supported for directory buckets.

        Args:
            PublicAccessBlockConfiguration: The ``PublicAccessBlock`` configuration that you want to apply to this Amazon S3
                bucket. You can enable the configuration options in any combination. For more information about when Amazon S3
                considers a bucket or object public, see `The Meaning of "Public"
                <https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public- access.html#access-control-block-
                public-access-policy-status>`_ in the *Amazon S3 User Guide*.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .put_public_access_block(
                cast("str", self.BucketName),
                PublicAccessBlockConfiguration,
            )
        )

    def delete_public_access_block(self) -> "None":
        """
        This operation is not supported for directory buckets.
        """

        return (
            cast("BucketManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .delete_public_access_block(
                cast("str", self.BucketName),
            )
        )


class S3Owner(Boto3Model):
    """
    Container for the owner's display name and ID.
    """

    DisplayName: str | None = None
    """
    
    """
    ID: str | None = None
    """
    Container for the ID of the owner.
    """


class S3RestoreStatus(Boto3Model):
    """Specifies the restoration status of an object. Objects in certain storage classes must be restored before they can be
    retrieved. For more information about these storage classes and how to work with archived objects, see  `Working with
    archived objects <https://docs.aws.amazon.com/AmazonS3/latest/userguide/archived-objects.html>`_ in the *Amazon S3 User
    Guide*.

    This functionality is not supported for directory buckets. Directory buckets only support ``EXPRESS_ONEZONE`` (the S3
    Express One Zone storage class) in Availability Zones and ``ONEZONE_IA`` (the S3 One Zone-Infrequent Access storage
    class) in Dedicated Local Zones.
    """

    IsRestoreInProgress: bool | None = None
    """
    Specifies whether the object is currently being restored.

    If the object restoration is in progress, the header returns
    the value ``TRUE``. For example:
    """
    RestoreExpiryDate: datetime | None = None
    """
    Indicates when the restored copy will expire.

    This value is populated only if the object has already been restored. For
    example:
    """


class S3Object(TagsDictMixin, PrimaryBoto3Model):
    """
    An object consists of data and its descriptive metadata.
    """

    tag_class: ClassVar[Type] = Any
    manager_class: ClassVar[Type[Boto3ModelManager]] = S3ObjectManager

    Key: str | None = None
    """
    The name that you assign to an object.

    You use the object key to retrieve the object.
    """
    LastModified: datetime = Field(default=None, frozen=True)
    """
    Creation date of the object.
    """
    ETag: str = Field(default=None, frozen=True)
    """
    The entity tag is a hash of the object.

    The ETag reflects changes only to the contents of an object, not its metadata.
    The ETag may or may not be an MD5 digest of the object data. Whether or not it is depends on how the object was created
    and how it is encrypted as described below:
    """
    ChecksumAlgorithm: List[Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"]] | None = None
    """
    The algorithm that was used to create a checksum of the object.
    """
    ChecksumType: Literal["COMPOSITE", "FULL_OBJECT"] = Field(default=None, frozen=True)
    """
    The checksum type that is used to calculate the objects checksum value.

    For more information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    Size: int = Field(default=None, frozen=True)
    """
    Size in bytes of the object.
    """
    StorageClass: Literal["STANDARD", "REDUCED_REDUNDANCY", "GLACIER", "STANDARD_IA", "ONEZONE_IA", "INTELLIGENT_TIERING", "DEEP_ARCHIVE", "OUTPOSTS", "GLACIER_IR", "SNOW", "EXPRESS_ONEZONE", "FSX_OPENZFS", "FSX_ONTAP"] | None = None
    """
    The class of storage used to store the object.
    """
    Owner: S3Owner = Field(default=None, frozen=True)
    """
    The owner of the object.
    """
    RestoreStatus: S3RestoreStatus = Field(default=None, frozen=True)
    """
    Specifies the restoration status of an object.

    Objects in certain storage classes must be restored before they can be retrieved.
    For more information about these storage classes and how to work with archived
    objects, see
    `Working with archived objects <https://docs.aws.amazon.com/AmazonS3/latest/userguide/archived-objects.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    BucketName: str | None = None
    """
    The name of the bucket.

    This is a unique identifier for the bucket, globally.
    """
    Tags: Any | None = None
    """
    The body of the object.
    """

    @property
    def name(self) -> str | None:
        """
        Return the name of the model.   This is the value of the :py:attr:`Key`
        attribute.

        Returns:
            The name of the model instance.
        """
        return self.Key

    @property
    def pk(self) -> OrderedDict[str, Any]:
        return OrderedDict(
            {
                "Bucket": self.BucketName,
                "Key": self.Key,
            }
        )

    def contents(self) -> "GetObjectOutput":
        """
        Retrieves an object from Amazon S3.
        """

        return (
            cast("S3ObjectManager", self.objects)  # type: ignore[attr-defined]
            .using(self.session)
            .get(
                cast("str", self.BucketName),
                cast("str", self.Key),
            )
        )


class S3Grantee(Boto3Model):
    """
    Container for the person being granted permissions.
    """

    DisplayName: str | None = None
    """
    
    """
    EmailAddress: str | None = None
    """
    
    """
    ID: str | None = None
    """
    The canonical user ID of the grantee.
    """
    Type: Literal["CanonicalUser", "AmazonCustomerByEmail", "Group"]
    """
    Type of grantee.
    """
    URI: str | None = None
    """
    URI of the grantee group.
    """


class TargetGrant(Boto3Model):
    """
    Container for granting information.

    Buckets that use the bucket owner enforced setting for Object Ownership don't support target grants. For more
    information, see `Permissions server access log delivery <https://docs.aws.amazon.com/AmazonS3/latest/userguide/enable-
    server-access-logging.html#grant-log-delivery-permissions-general>`_ in the *Amazon S3 User Guide*.
    """

    Grantee: S3Grantee | None = None
    """
    Container for the person being granted permissions.
    """
    Permission: Literal["FULL_CONTROL", "READ", "WRITE"] | None = None
    """
    Logging permissions assigned to the grantee for the bucket.
    """


class S3SimplePrefix(Boto3Model):
    """
    To use simple format for S3 keys for log objects, set SimplePrefix to an empty
    object.

    ``[DestinationPrefix][YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString]``
    """



class S3PartitionedPrefix(Boto3Model):
    """Amazon S3 keys for log objects are partitioned in the following format:

    ``[DestinationPrefix][SourceAccountId]/[SourceRegion]/[SourceBucket]/[YYYY]/[MM]/[DD]/[YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-
    [UniqueString]``

    PartitionedPrefix defaults to EventTime delivery when server access logs are delivered.
    """

    PartitionDateSource: Literal["EventTime", "DeliveryTime"] | None = None
    """
    Specifies the partition date source for the partitioned prefix.

    ``PartitionDateSource`` can be ``EventTime`` or
    ``DeliveryTime``.
    """


class S3TargetObjectKeyFormat(Boto3Model):
    """
    Amazon S3 key format for log objects.

    Only one format, PartitionedPrefix or SimplePrefix, is allowed.
    """

    SimplePrefix: S3SimplePrefix | None = None
    """
    To use the simple format for S3 keys for log objects.

    To specify SimplePrefix format, set SimplePrefix to {}.
    """
    PartitionedPrefix: S3PartitionedPrefix | None = None
    """
    Partitioned S3 key for log objects.
    """


class BucketLoggingConfiguration(Boto3Model):
    """
    Describes where logs are stored and the prefix that Amazon S3 assigns to all log
    object keys for a bucket.

    For more information, see
    `PUT Bucket logging <https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTlogging.html>`_
    in the
    *Amazon S3 API Reference*.
    """

    TargetBucket: str
    """
    Specifies the bucket where you want Amazon S3 to store server access logs.

    You can have your logs delivered to any
    bucket that you own, including the same bucket that is being logged. You can also configure multiple buckets to deliver
    their logs to the same target bucket. In this case, you should choose a different ``TargetPrefix`` for each source
    bucket so that the delivered log files can be distinguished by key.
    """
    TargetGrants: List["TargetGrant"] | None = None
    """
    Container for granting information.
    """
    TargetPrefix: str
    """
    A prefix for all log object keys.

    If you store log files from multiple Amazon S3 buckets in a single bucket, you can
    use a prefix to distinguish which log files came from which bucket.
    """
    TargetObjectKeyFormat: S3TargetObjectKeyFormat | None = None
    """
    Amazon S3 key format for log objects.
    """


class S3CORSRule(Boto3Model):
    """
    Specifies a cross-origin access rule for an Amazon S3 bucket.
    """

    ID: str | None = None
    """
    Unique identifier for the rule.

    The value cannot be longer than 255 characters.
    """
    AllowedHeaders: List[str] | None = None
    """
    Headers that are specified in the ``Access-Control-Request-Headers`` header.

    These headers are allowed in a preflight OPTIONS request. In response to any
    preflight OPTIONS request, Amazon S3 returns any requested headers that are allowed.
    """
    AllowedMethods: List[str]
    """
    An HTTP method that you allow the origin to execute.

    Valid values are ``GET``, ``PUT``, ``HEAD``, ``POST``, and
    ``DELETE``.
    """
    AllowedOrigins: List[str]
    """
    One or more origins you want customers to be able to access the bucket from.
    """
    ExposeHeaders: List[str] | None = None
    """
    One or more headers in the response that you want customers to be able to access
    from their applications (for example, from a JavaScript ``XMLHttpRequest`` object).
    """
    MaxAgeSeconds: int | None = None
    """
    The time in seconds that your browser is to cache the preflight response for the
    specified resource.
    """


# =======================
# Request/Response Models
# =======================


class ListBucketsOutput(Boto3Model):
    Buckets: List["Bucket"] | None = None
    """
    The list of buckets owned by the requester.
    """
    Owner: S3Owner | None = None
    """
    The owner of the buckets listed.
    """
    ContinuationToken: str | None = None
    """
    ``ContinuationToken`` is included in the response when there are more buckets that
    can be listed with pagination.

    The
    next ``ListBuckets`` request to Amazon S3 can be continued with this ``ContinuationToken``. ``ContinuationToken`` is
    obfuscated and is not a real bucket.
    """
    Prefix: str | None = None
    """
    If ``Prefix`` was sent with the request, it is included in the response.
    """


class GetBucketPolicyOutput(Boto3Model):
    Policy: str | None = None
    """
    The bucket policy as a JSON document.
    """


class GetBucketWebsiteOutput(Boto3Model):
    RedirectAllRequestsTo: S3RedirectAllRequestsTo | None = None
    """
    Specifies the redirect behavior of all requests to a website endpoint of an Amazon
    S3 bucket.
    """
    IndexDocument: S3IndexDocument | None = None
    """
    The name of the index document for the website (for example ``index.html``).
    """
    ErrorDocument: S3ErrorDocument | None = None
    """
    The object key name of the website error document to use for 4XX class errors.
    """
    RoutingRules: List["S3RoutingRule"] | None = None
    """
    Rules that define when a redirect is applied and the redirect behavior.
    """


class GetBucketTaggingOutput(Boto3Model):
    TagSet: List[Tag]
    """
    Contains the tag set.
    """


class S3Tagging(Boto3Model):
    """
    Container for ``TagSet`` elements.
    """

    TagSet: List[Tag]
    """
    A collection for a set of tags.
    """


class GetBucketLifecycleConfigurationOutput(Boto3Model):
    Rules: List["LifecycleRule"] | None = None
    """
    Container for a lifecycle rule.
    """
    TransitionDefaultMinimumObjectSize: Literal["varies_by_storage_class", "all_storage_classes_128K"] | None = None
    """
    Indicates which default minimum object size behavior is applied to the lifecycle
    configuration.
    """


class PutBucketLifecycleConfigurationOutput(Boto3Model):
    TransitionDefaultMinimumObjectSize: Literal["varies_by_storage_class", "all_storage_classes_128K"] | None = None
    """
    Indicates which default minimum object size behavior is applied to the lifecycle
    configuration.
    """


class GetPublicAccessBlockOutput(Boto3Model):
    PublicAccessBlockConfiguration: S3PublicAccessBlockConfiguration | None = None
    """
    The ``PublicAccessBlock`` configuration currently in effect for this Amazon S3
    bucket.
    """


class PutObjectOutput(Boto3Model):
    Expiration: str | None = None
    """
If the expiration is configured for the object (see `PutBucketLifecycleConfiguration <https://docs.aws.amazon.com/Amazon
S3/latest/API/API_PutBucketLifecycleConfiguration.html>`_) in the *Amazon S3 User Guide*, the response includes this
header. It includes the ``expiry-date`` and ``rule-id`` key-value pairs that provide information about object
expiration. The value of the ``rule-id`` is URL-encoded.
    """
    ETag: str | None = None
    """
    Entity tag for the uploaded object.
    """
    ChecksumCRC32: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32 checksum`` of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use an API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumCRC32C: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32C`` checksum of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use an API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumCRC64NVME: str | None = None
    """
    The Base64 encoded, 64-bit ``CRC64NVME`` checksum of the object.

    This header is present if the object was uploaded with
    the ``CRC64NVME`` checksum algorithm, or if it was uploaded without a checksum (and Amazon S3 added the default
    checksum, ``CRC64NVME``, to the uploaded object). For more information about how checksums are calculated with multipart
    uploads, see `Checking object integrity in the Amazon S3 User
    Guide <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_.
    """
    ChecksumSHA1: str | None = None
    """
    The Base64 encoded, 160-bit ``SHA1`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use the API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumSHA256: str | None = None
    """
    The Base64 encoded, 256-bit ``SHA256`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use an API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumType: Literal["COMPOSITE", "FULL_OBJECT"] | None = None
    """
    This header specifies the checksum type of the object, which determines how part-
    level checksums are combined to create an object-level checksum for multipart
    objects.

    For ``PutObject`` uploads, the checksum type is always ``FULL_OBJECT``.
    You can use this header as a data integrity check to verify that the checksum type that is received is the same checksum
    that was specified. For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    ServerSideEncryption: Literal["AES256", "aws:fsx", "aws:kms", "aws:kms:dsse"] | None = None
    """
    The server-side encryption algorithm used when you store this object in Amazon S3 or
    Amazon FSx.
    """
    VersionId: str | None = None
    """
    Version ID of the object.
    """
    SSECustomerAlgorithm: str | None = None
    """
    If server-side encryption with a customer-provided encryption key was requested, the
    response will include this header to confirm the encryption algorithm that's used.
    """
    SSECustomerKeyMD5: str | None = None
    """
    If server-side encryption with a customer-provided encryption key was requested, the
    response will include this header to provide the round-trip message integrity
    verification of the customer-provided encryption key.
    """
    SSEKMSKeyId: str | None = None
    """
    If present, indicates the ID of the KMS key that was used for object encryption.
    """
    SSEKMSEncryptionContext: str | None = None
    """
    If present, indicates the Amazon Web Services KMS Encryption Context to use for
    object encryption.

    The value of this
    header is a Base64 encoded string of a UTF-8 encoded JSON, which contains the encryption context as key-value pairs.
    This value is stored as object metadata and automatically gets passed on to Amazon Web Services KMS for future
    ``GetObject`` operations on this object.
    """
    BucketKeyEnabled: bool | None = None
    """
    Indicates whether the uploaded object uses an S3 Bucket Key for server-side
    encryption with Key Management Service (KMS) keys (SSE-KMS).
    """
    Size: int | None = None
    """
    The size of the object in bytes.

    This value is only be present if you append to an object.
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class GetObjectOutput(GetObjectOutputMixin, Boto3Model):
    Body: StreamingBody | None = None
    """
    The body of the object.
    """
    DeleteMarker: bool | None = None
    """
    Indicates whether the object retrieved was (true) or was not (false) a Delete
    Marker.

    If false, this response header does not appear in the response.
    """
    AcceptRanges: str | None = None
    """
    Indicates that a range of bytes was specified in the request.
    """
    Expiration: str | None = None
    """
If the object expiration is configured (see  ```PutBucketLifecycleConfiguration`` <https://docs.aws.amazon.com/AmazonS3/
latest/API/API_PutBucketLifecycleConfiguration.html>`_ ), the response includes this header. It includes the ``expiry-
date`` and ``rule-id`` key-value pairs providing object expiration information. The value of the ``rule-id`` is URL-
encoded.
    """
    Restore: str | None = None
    """
    Provides information about object restoration action and expiration time of the
    restored object copy.
    """
    LastModified: datetime | None = None
    """
    Date and time when the object was last modified.
    """
    ContentLength: int | None = None
    """
    Size of the body in bytes.
    """
    ETag: str | None = None
    """
    An entity tag (ETag) is an opaque identifier assigned by a web server to a specific
    version of a resource found at a URL.
    """
    ChecksumCRC32: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32`` checksum of the object.

    This checksum is only present if the object was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumCRC32C: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32C`` checksum of the object.

    This checksum is only present if the checksum was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumCRC64NVME: str | None = None
    """
    The Base64 encoded, 64-bit ``CRC64NVME`` checksum of the object.

    For more information, see
    `Checking object integrity in the Amazon S3 User Guide <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_.
    """
    ChecksumSHA1: str | None = None
    """
    The Base64 encoded, 160-bit ``SHA1`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumSHA256: str | None = None
    """
    The Base64 encoded, 256-bit ``SHA256`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumType: Literal["COMPOSITE", "FULL_OBJECT"] | None = None
    """
    The checksum type, which determines how part-level checksums are combined to create
    an object-level checksum for multipart objects.

    You can use this header response to verify that the checksum type that is received is the same
    checksum type that was specified in the ``CreateMultipartUpload`` request. For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    MissingMeta: int | None = None
    """
    This is set to the number of metadata entries not returned in the headers that are
    prefixed with ``x-amz-meta-``.

    This can happen if you create metadata using an API like SOAP that supports more
    flexible metadata than the REST API. For example, using SOAP, you can create
    metadata whose values are not legal HTTP headers.
    """
    VersionId: str | None = None
    """
    Version ID of the object.
    """
    CacheControl: str | None = None
    """
    Specifies caching behavior along the request/reply chain.
    """
    ContentDisposition: str | None = None
    """
    Specifies presentational information for the object.
    """
    ContentEncoding: str | None = None
    """
    Indicates what content encodings have been applied to the object and thus what
    decoding mechanisms must be applied to obtain the media-type referenced by the
    Content-Type header field.
    """
    ContentLanguage: str | None = None
    """
    The language the content is in.
    """
    ContentRange: str | None = None
    """
    The portion of the object returned in the response.
    """
    ContentType: str | None = None
    """
    A standard MIME type describing the format of the object data.
    """
    Expires: datetime | None = None
    """
    The date and time at which the object is no longer cacheable.
    """
    WebsiteRedirectLocation: str | None = None
    """
    If the bucket is configured as a website, redirects requests for this object to
    another object in the same bucket or to an external URL.

    Amazon S3 stores the value of this header in the object metadata.
    """
    ServerSideEncryption: Literal["AES256", "aws:fsx", "aws:kms", "aws:kms:dsse"] | None = None
    """
    The server-side encryption algorithm used when you store this object in Amazon S3 or
    Amazon FSx.
    """
    Metadata: Dict[str, str] | None = None
    """
    A map of metadata to store with the object in S3.
    """
    SSECustomerAlgorithm: str | None = None
    """
    If server-side encryption with a customer-provided encryption key was requested, the
    response will include this header to confirm the encryption algorithm that's used.
    """
    SSECustomerKeyMD5: str | None = None
    """
    If server-side encryption with a customer-provided encryption key was requested, the
    response will include this header to provide the round-trip message integrity
    verification of the customer-provided encryption key.
    """
    SSEKMSKeyId: str | None = None
    """
    If present, indicates the ID of the KMS key that was used for object encryption.
    """
    BucketKeyEnabled: bool | None = None
    """
    Indicates whether the object uses an S3 Bucket Key for server-side encryption with
    Key Management Service (KMS) keys (SSE-KMS).
    """
    StorageClass: Literal["STANDARD", "REDUCED_REDUNDANCY", "STANDARD_IA", "ONEZONE_IA", "INTELLIGENT_TIERING", "GLACIER", "DEEP_ARCHIVE", "OUTPOSTS", "GLACIER_IR", "SNOW", "EXPRESS_ONEZONE", "FSX_OPENZFS", "FSX_ONTAP"] | None = None
    """
    Provides storage class information of the object.

    Amazon S3 returns this header for all objects except for S3 Standard storage class
    objects.
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """
    ReplicationStatus: Literal["COMPLETE", "PENDING", "FAILED", "REPLICA", "COMPLETED"] | None = None
    """
    Amazon S3 can return this if your request involves a bucket that is either a source
    or destination in a replication rule.
    """
    PartsCount: int | None = None
    """
    The count of parts this object has.

    This value is only returned if you specify ``partNumber`` in your request and the
    object was uploaded as a multipart upload.
    """
    TagCount: int | None = None
    """
    The number of tags, if any, on the object, when you have the relevant permission to
    read object tags.
    """
    ObjectLockMode: Literal["GOVERNANCE", "COMPLIANCE"] | None = None
    """
    The Object Lock mode that's currently in place for this object.
    """
    ObjectLockRetainUntilDate: datetime | None = None
    """
    The date and time when this object's Object Lock will expire.
    """
    ObjectLockLegalHoldStatus: Literal["ON", "OFF"] | None = None
    """
    Indicates whether this object has an active legal hold.

    This field is only returned if you have permission to view an object's legal hold
    status.
    """


class CommonPrefix(Boto3Model):
    """
    Container for all (if there are any) keys between Prefix and the next occurrence of
    the string specified by a delimiter.

    CommonPrefixes lists keys that act like subdirectories in the directory specified by
    Prefix. For example, if the prefix is notes/ and the delimiter is a slash (/) as in
    notes/summer/july, the common prefix is notes/summer/.
    """

    Prefix: str | None = None
    """
    Container for the specified common prefix.
    """


class ListObjectsV2Output(Boto3Model):
    IsTruncated: bool | None = None
    """
    Set to ``false`` if all of the results were returned.

    Set to ``true`` if more keys are available to return. If the
    number of results exceeds that specified by ``MaxKeys``, all of the results might not be returned.
    """
    Contents: List["S3Object"] | None = None
    """
    Metadata about each object returned.
    """
    Name: str | None = None
    """
    The bucket name.
    """
    Prefix: str | None = None
    """
    Keys that begin with the indicated prefix.
    """
    Delimiter: str | None = None
    """
    Causes keys that contain the same string between the ``prefix`` and the first
    occurrence of the delimiter to be rolled up into a single result element in the
    ``CommonPrefixes`` collection.

    These rolled-up keys are not returned elsewhere in
    the response. Each rolled-up result counts as only one return against the ``MaxKeys`` value.
    """
    MaxKeys: int | None = None
    """
    Sets the maximum number of keys returned in the response.

    By default, the action returns up to 1,000 key names. The response might contain
    fewer keys but will never contain more.
    """
    CommonPrefixes: List["CommonPrefix"] | None = None
    """
    All of the keys (up to 1,000) that share the same prefix are grouped together.

    When counting the total numbers of returns by this API operation, this group of keys
    is considered as one item.
    """
    EncodingType: Literal["url"] | None = None
    """
    Encoding type used by Amazon S3 to encode object key names in the XML response.
    """
    KeyCount: int | None = None
    """
    ``KeyCount`` is the number of keys returned with this request.

    ``KeyCount`` will always be less than or equal to the
    ``MaxKeys`` field. For example, if you ask for 50 keys, your result will include 50 keys or fewer.
    """
    ContinuationToken: str | None = None
    """
    If ``ContinuationToken`` was sent with the request, it is included in the response.

    You can use the returned
    ``ContinuationToken`` for pagination of the list response.
    """
    NextContinuationToken: str | None = None
    """
    ``NextContinuationToken`` is sent when ``isTruncated`` is true, which means there
    are more keys in the bucket that can be listed.

    The next list requests to Amazon S3 can be continued with this ``NextContinuationToken``.
    ``NextContinuationToken`` is obfuscated and is not a real key
    """
    StartAfter: str | None = None
    """
    If StartAfter was sent with the request, it is included in the response.
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class S3CopyObjectResult(Boto3Model):
    """
    Container for all response elements.
    """

    ETag: str | None = None
    """
    Returns the ETag of the new object.

    The ETag reflects only changes to the contents of an object, not its metadata.
    """
    LastModified: datetime | None = None
    """
    Creation date of the object.
    """
    ChecksumType: Literal["COMPOSITE", "FULL_OBJECT"] | None = None
    """
    The checksum type that is used to calculate the objects checksum value.

    For more information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumCRC32: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32`` checksum of the object.

    This checksum is only present if the object was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumCRC32C: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32C`` checksum of the object.

    This checksum is only present if the checksum was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumCRC64NVME: str | None = None
    """
    The Base64 encoded, 64-bit ``CRC64NVME`` checksum of the object.

    This checksum is present if the object being copied was
    uploaded with the ``CRC64NVME`` checksum algorithm, or if the object was uploaded without a checksum (and Amazon S3
    added the default checksum, ``CRC64NVME``, to the uploaded object). For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    ChecksumSHA1: str | None = None
    """
    The Base64 encoded, 160-bit ``SHA1`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    ChecksumSHA256: str | None = None
    """
    The Base64 encoded, 256-bit ``SHA256`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. For more
    information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """


class CopyObjectOutput(Boto3Model):
    CopyObjectResult: S3CopyObjectResult | None = None
    """
    Container for all response elements.
    """
    Expiration: str | None = None
    """
    If the object expiration is configured, the response includes this header.
    """
    CopySourceVersionId: str | None = None
    """
    Version ID of the source object that was copied.
    """
    VersionId: str | None = None
    """
    Version ID of the newly created copy.
    """
    ServerSideEncryption: Literal["AES256", "aws:fsx", "aws:kms", "aws:kms:dsse"] | None = None
    """
    The server-side encryption algorithm used when you store this object in Amazon S3 or
    Amazon FSx.
    """
    SSECustomerAlgorithm: str | None = None
    """
    If server-side encryption with a customer-provided encryption key was requested, the
    response will include this header to confirm the encryption algorithm that's used.
    """
    SSECustomerKeyMD5: str | None = None
    """
    If server-side encryption with a customer-provided encryption key was requested, the
    response will include this header to provide the round-trip message integrity
    verification of the customer-provided encryption key.
    """
    SSEKMSKeyId: str | None = None
    """
    If present, indicates the ID of the KMS key that was used for object encryption.
    """
    SSEKMSEncryptionContext: str | None = None
    """
    If present, indicates the Amazon Web Services KMS Encryption Context to use for
    object encryption.

    The value of this header is a Base64 encoded UTF-8 string holding JSON with the
    encryption context key-value pairs.
    """
    BucketKeyEnabled: bool | None = None
    """
    Indicates whether the copied object uses an S3 Bucket Key for server-side encryption
    with Key Management Service (KMS) keys (SSE-KMS).
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class RenameObjectOutput(Boto3Model):
    pass


class S3GlacierJobParameters(Boto3Model):
    """
    Container for S3 Glacier job parameters.
    """

    Tier: Literal["Standard", "Bulk", "Expedited"]
    """
    Retrieval tier at which the restore will be processed.
    """


class S3CSVInput(Boto3Model):
    """
    Describes how an uncompressed comma-separated values (CSV)-formatted input object is
    formatted.
    """

    QuoteEscapeCharacter: str | None = None
    """
    A single character used for escaping the quote character inside an already escaped
    value.
    """
    FileHeaderInfo: Literal["USE", "IGNORE", "NONE"] | None = None
    """
    Describes the first line of input.

    Valid values are:
    """
    Comments: str | None = None
    """
    A single character used to indicate that a row should be ignored when the character
    is present at the start of that row.

    You can specify any character to indicate a comment line. The default character is ``#``.
    """
    RecordDelimiter: str | None = None
    """
    A single character used to separate individual records in the input.

    Instead of the default value, you can specify an arbitrary delimiter.
    """
    FieldDelimiter: str | None = None
    """
    A single character used to separate individual fields in a record.

    You can specify an arbitrary delimiter.
    """
    QuoteCharacter: str | None = None
    """
    A single character used for escaping when the field delimiter is part of the value.

    For example, if the value is ``a,
    b``, Amazon S3 wraps this field value in quotation marks, as follows: ``" a , b "``.
    """
    AllowQuotedRecordDelimiter: bool | None = None
    """
    Specifies that CSV field values may contain quoted record delimiters and such
    records should be allowed.

    Default value is FALSE. Setting this value to TRUE may lower performance.
    """


class JSONInput(Boto3Model):
    """
    Specifies JSON as object's input serialization format.
    """

    Type: Literal["DOCUMENT", "LINES"] | None = None
    """
    The type of JSON.

    Valid values: Document, Lines.
    """


class ParquetInput(Boto3Model):
    """
    Container for Parquet.
    """



class InputSerialization(Boto3Model):
    """
    Describes the serialization format of the object.
    """

    CSV: S3CSVInput | None = None
    """
    Describes the serialization of a CSV-encoded object.
    """
    CompressionType: Literal["NONE", "GZIP", "BZIP2"] | None = None
    """
    Specifies object's compression format.

    Valid values: NONE, GZIP, BZIP2. Default Value: NONE.
    """
    JSON: JSONInput | None = None
    """
    Specifies JSON as object's input serialization format.
    """
    Parquet: ParquetInput | None = None
    """
    Specifies Parquet as object's input serialization format.
    """


class CSVOutput(Boto3Model):
    """
    Describes how uncompressed comma-separated values (CSV)-formatted results are
    formatted.
    """

    QuoteFields: Literal["ALWAYS", "ASNEEDED"] | None = None
    """
    Indicates whether to use quotation marks around output fields.
    """
    QuoteEscapeCharacter: str | None = None
    """
    The single character used for escaping the quote character inside an already escaped
    value.
    """
    RecordDelimiter: str | None = None
    """
    A single character used to separate individual records in the output.

    Instead of the default value, you can specify an arbitrary delimiter.
    """
    FieldDelimiter: str | None = None
    """
    The value used to separate individual fields in a record.

    You can specify an arbitrary delimiter.
    """
    QuoteCharacter: str | None = None
    """
    A single character used for escaping when the field delimiter is part of the value.

    For example, if the value is ``a,
    b``, Amazon S3 wraps this field value in quotation marks, as follows: ``" a , b "``.
    """


class JSONOutput(Boto3Model):
    """
    Specifies JSON as request's output serialization format.
    """

    RecordDelimiter: str | None = None
    """
    The value used to separate individual records in the output.

    If no value is specified, Amazon S3 uses a newline character ('n').
    """


class OutputSerialization(Boto3Model):
    """
    Describes how results of the Select job are serialized.
    """

    CSV: CSVOutput | None = None
    """
    Describes the serialization of CSV-encoded Select results.
    """
    JSON: JSONOutput | None = None
    """
    Specifies JSON as request's output serialization format.
    """


class S3SelectParameters(Boto3Model):
    """Amazon S3 Select is no longer available to new customers. Existing customers of Amazon S3 Select can continue to use the
    feature as usual. `Learn more <http://aws.amazon.com/blogs/storage/how-to-optimize-querying-your-data-in-amazon-s3/>`_

    Describes the parameters for Select job types.

    Learn `How to optimize querying your data in Amazon S3 <http://aws.amazon.com/blogs/storage/how-to-optimize-querying-
    your-data-in-amazon-s3/>`_ using `Amazon Athena <https://docs.aws.amazon.com/athena/latest/ug/what-is.html>`_, `S3 Object
    Lambda <https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html>`_, or client-side filtering.
    """

    InputSerialization: "InputSerialization"
    """
    Describes the serialization format of the object.
    """
    ExpressionType: Literal["SQL"]
    """
    The type of the provided expression (for example, SQL).
    """
    Expression: str
    """
    Amazon S3 Select is no longer available to new customers.

    Existing customers of Amazon S3 Select can continue to use the feature as usual.
    `Learn more <http://aws.amazon.com/blogs/storage/how-to-optimize-querying-your-data-in-amazon-s3/>`_
    """
    OutputSerialization: "OutputSerialization"
    """
    Describes how the results of the Select job are serialized.
    """


class S3Encryption(Boto3Model):
    """
    Contains the type of server-side encryption used.
    """

    EncryptionType: Literal["AES256", "aws:fsx", "aws:kms", "aws:kms:dsse"]
    """
    The server-side encryption algorithm used when storing job results in Amazon S3 (for
    example, AES256, ``aws:kms``).
    """
    KMSKeyId: str | None = None
    """
    If the encryption type is ``aws:kms``, this optional value specifies the ID of the
    symmetric encryption customer managed key to use for encryption of job results.

    Amazon S3 only supports symmetric encryption KMS keys. For more information, see
    `Asymmetric keys in KMS <https://docs.aws.amazon.com/kms/latest/developerguide/symmetric-asymmetric.html>`_
    in the
    *Amazon Web Services Key Management Service Developer Guide*.
    """
    KMSContext: str | None = None
    """
    If the encryption type is ``aws:kms``, this optional value can be used to specify
    the encryption context for the restore results.
    """


class Grant(Boto3Model):
    """
    Container for grant information.
    """

    Grantee: S3Grantee | None = None
    """
    The person being granted permissions.
    """
    Permission: Literal["FULL_CONTROL", "WRITE", "WRITE_ACP", "READ", "READ_ACP"] | None = None
    """
    Specifies the permission given to the grantee.
    """


class MetadataEntry(Boto3Model):
    """
    A metadata key-value pair to store with an object.
    """

    Name: str | None = None
    """
    Name of the object.
    """
    Value: str | None = None
    """
    Value of the object.
    """


class S3Location(Boto3Model):
    """
    Describes an Amazon S3 location that will receive the results of the restore
    request.
    """

    BucketName: str
    """
    The name of the bucket where the restore results will be placed.
    """
    Prefix: str
    """
    The prefix that is prepended to the restore results for this request.
    """
    Encryption: S3Encryption | None = None
    """
    Contains the type of server-side encryption used.
    """
    CannedACL: Literal["private", "public-read", "public-read-write", "authenticated-read", "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control"] | None = None
    """
    The canned ACL to apply to the restore results.
    """
    AccessControlList: List["Grant"] | None = None
    """
    A list of grants that control access to the staged results.
    """
    Tagging: S3Tagging | None = None
    """
    The tag-set that is applied to the restore results.
    """
    UserMetadata: List["MetadataEntry"] | None = None
    """
    A list of metadata to store with the restore results in S3.
    """
    StorageClass: Literal["STANDARD", "REDUCED_REDUNDANCY", "STANDARD_IA", "ONEZONE_IA", "INTELLIGENT_TIERING", "GLACIER", "DEEP_ARCHIVE", "OUTPOSTS", "GLACIER_IR", "SNOW", "EXPRESS_ONEZONE", "FSX_OPENZFS", "FSX_ONTAP"] | None = None
    """
    The class of storage used to store the restore results.
    """


class S3OutputLocation(Boto3Model):
    """
    Describes the location where the restore job's output is stored.
    """

    S3: S3Location | None = None
    """
    Describes an S3 location that will receive the results of the restore request.
    """


class RestoreRequest(Boto3Model):
    """
    Container for restore job parameters.
    """

    Days: int | None = None
    """
    Lifetime of the active copy in days.

    Do not use with restores that specify ``OutputLocation``.
    """
    GlacierJobParameters: S3GlacierJobParameters | None = None
    """
    S3 Glacier related parameters pertaining to this job.

    Do not use with restores that specify ``OutputLocation``.
    """
    Type: Literal["SELECT"] | None = None
    """
    Amazon S3 Select is no longer available to new customers.

    Existing customers of Amazon S3 Select can continue to use the feature as usual.
    `Learn more <http://aws.amazon.com/blogs/storage/how-to-optimize-querying-your-data-in-amazon-s3/>`_
    """
    Tier: Literal["Standard", "Bulk", "Expedited"] | None = None
    """
    Retrieval tier at which the restore will be processed.
    """
    Description: str | None = None
    """
    The optional description for the job.
    """
    SelectParameters: S3SelectParameters | None = None
    """
    Amazon S3 Select is no longer available to new customers.

    Existing customers of Amazon S3 Select can continue to use the feature as usual.
    `Learn more <http://aws.amazon.com/blogs/storage/how-to-optimize-querying-your-data-in-amazon-s3/>`_
    """
    OutputLocation: S3OutputLocation | None = None
    """
    Describes the location where the restore job's output is stored.
    """


class RestoreObjectOutput(Boto3Model):
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """
    RestoreOutputPath: str | None = None
    """
    Indicates the path in the provided S3 output location where Select results will be
    restored to.
    """


class RequestProgress(Boto3Model):
    """
    Container for specifying if periodic ``QueryProgress`` messages should be sent.
    """

    Enabled: bool | None = None
    """
    Specifies whether periodic QueryProgress frames should be sent.

    Valid values: TRUE, FALSE. Default value: FALSE.
    """


class ScanRange(Boto3Model):
    """
    Specifies the byte range of the object to get the records from.

    A record is processed when its first byte is contained by the range. This parameter
    is optional, but when specified, it must not be empty. See RFC 2616, Section 14.35.1
    about how to specify the start and end of the range.
    """

    Start: int | None = None
    """
    Specifies the start of the byte range.

    This parameter is optional. Valid values: non-negative integers. The default
    value is 0. If only ``start`` is supplied, it means scan from that point to the end of the file. For example,
    ``<scanrange><start>50</start></scanrange>`` means scan from byte 50 until the end of the file.
    """
    End: int | None = None
    """
    Specifies the end of the byte range.

    This parameter is optional. Valid values: non-negative integers. The default value
    is one less than the size of the object being queried. If only the End parameter is supplied, it is interpreted to mean
    scan the last N bytes of the file. For example, ``<scanrange><end>50</end></scanrange>`` means scan the last 50 bytes.
    """


class RecordsEvent(Boto3Model):
    """
    The container for the records event.
    """

    Payload: bytes | None = None
    """
    The byte array of partial, one or more result records.

    S3 Select doesn't guarantee that a record will be self-contained
    in one record frame. To ensure continuous streaming of data, S3 Select might split the same record across multiple
    record frames instead of aggregating the results in memory. Some S3 clients (for example, the SDK for Java) handle this
    behavior by creating a ``ByteStream`` out of the response by default. Other clients might not handle this behavior by
    default. In those cases, you must aggregate the results on the client side and parse the response.
    """


class Stats(Boto3Model):
    """
    Container for the stats details.
    """

    BytesScanned: int | None = None
    """
    The total number of object bytes scanned.
    """
    BytesProcessed: int | None = None
    """
    The total number of uncompressed object bytes processed.
    """
    BytesReturned: int | None = None
    """
    The total number of bytes of records payload data returned.
    """


class StatsEvent(Boto3Model):
    """
    Container for the Stats Event.
    """

    Details: Stats | None = None
    """
    The Stats event details.
    """


class Progress(Boto3Model):
    """
    This data type contains information about progress of an operation.
    """

    BytesScanned: int | None = None
    """
    The current number of object bytes scanned.
    """
    BytesProcessed: int | None = None
    """
    The current number of uncompressed object bytes processed.
    """
    BytesReturned: int | None = None
    """
    The current number of bytes of records payload data returned.
    """


class ProgressEvent(Boto3Model):
    """
    This data type contains information about the progress event of an operation.
    """

    Details: Progress | None = None
    """
    The Progress event details.
    """


class ContinuationEvent(Boto3Model):
    pass


class EndEvent(Boto3Model):
    """
    A message that indicates the request is complete and no more messages will be sent.

    You should not assume that the
    request is complete until the client receives an ``EndEvent``.
    """



class SelectObjectContentEventStream(Boto3Model):
    """
    The container for selecting objects from a content event stream.
    """

    Records: RecordsEvent | None = None
    """
    The Records Event.
    """
    Stats: StatsEvent | None = None
    """
    The Stats Event.
    """
    Progress: ProgressEvent | None = None
    """
    The Progress Event.
    """
    Cont: ContinuationEvent | None = None
    """
    The Continuation Event.
    """
    End: EndEvent | None = None
    """
    The End Event.
    """


class SelectObjectContentOutput(Boto3Model):
    Payload: SelectObjectContentEventStream | None = None
    """
    The array of results.
    """


class ObjectIdentifier(Boto3Model):
    """
    Object Identifier is unique value to identify objects.
    """

    Key: str
    """
    Key name of the object.
    """
    VersionId: str | None = None
    """
    Version ID for the specific version of the object to delete.
    """
    ETag: str | None = None
    """
    An entity tag (ETag) is an identifier assigned by a web server to a specific version
    of a resource found at a URL.

    This
    header field makes the request method conditional on ``ETags``.
    """
    LastModifiedTime: datetime | None = None
    """
    If present, the objects are deleted only if its modification times matches the
    provided ``Timestamp``.
    """
    Size: int | None = None
    """
    If present, the objects are deleted only if its size matches the provided size in
    bytes.
    """


class Delete(Boto3Model):
    """
    Container for the objects to delete.
    """

    Objects: List["ObjectIdentifier"]
    """
    The object to delete.
    """
    Quiet: bool | None = None
    """
    Element to enable quiet mode for the request.

    When you add this element, you must set its value to ``true``.
    """


class DeletedObject(Boto3Model):
    """
    Information about the deleted object.
    """

    Key: str | None = None
    """
    The name of the deleted object.
    """
    VersionId: str | None = None
    """
    The version ID of the deleted object.
    """
    DeleteMarker: bool | None = None
    """
    Indicates whether the specified object version that was permanently deleted was
    (true) or was not (false) a delete marker before deletion.

    In a simple DELETE, this header indicates whether (true) or not (false) the current
    version of the object is a delete marker. To learn more about delete markers, see
    `Working with delete markers <https://docs.aws.amazon.com/AmazonS3/latest/userguide/DeleteMarker.html>`_.
    """
    DeleteMarkerVersionId: str | None = None
    """
    The version ID of the delete marker created as a result of the DELETE operation.

    If you delete a specific object version, the value returned by this header is the
    version ID of the object version deleted.
    """


class Error(Boto3Model):
    """
    Container for all error elements.
    """

    Key: str | None = None
    """
    The error key.
    """
    VersionId: str | None = None
    """
    The version ID of the error.
    """
    Code: str | None = None
    """
    The error code is a string that uniquely identifies an error condition.

    It is meant to be read and understood by programs that detect and handle errors by
    type. The following is a list of Amazon S3 error codes. For more information, see
    `Error responses <https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html>`_.
    """
    Message: str | None = None
    """
    The error message contains a generic description of the error condition in English.

    It is intended for a human audience. Simple programs display the message directly to
    the end user if they encounter an error condition they don't know how or don't care
    to handle. Sophisticated programs with more exhaustive error handling and proper
    internationalization are more likely to ignore the error message.
    """


class DeleteObjectsOutput(Boto3Model):
    Deleted: List["DeletedObject"] | None = None
    """
    Container element for a successful delete.

    It identifies the object that was successfully deleted.
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """
    Errors: List["Error"] | None = None
    """
    Container for a failed delete action that describes the object that Amazon S3
    attempted to delete and the error it encountered.
    """


class GetObjectTaggingOutput(Boto3Model):
    VersionId: str | None = None
    """
    The versionId of the object for which you got the tagging information.
    """
    TagSet: List[Tag]
    """
    Contains the tag set.
    """


class PutObjectTaggingOutput(Boto3Model):
    VersionId: str | None = None
    """
    The versionId of the object the tag-set was added to.
    """


class DeleteObjectTaggingOutput(Boto3Model):
    VersionId: str | None = None
    """
    The versionId of the object the tag-set was removed from.
    """


class GetObjectAclOutput(Boto3Model):
    Owner: S3Owner | None = None
    """
    Container for the bucket owner's ID.
    """
    Grants: List["Grant"] | None = None
    """
    A list of grants.
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class AccessControlPolicy(Boto3Model):
    """
    Contains the elements that set the ACL permissions for an object per grantee.
    """

    Grants: List["Grant"] | None = None
    """
    A list of grants.
    """
    Owner: S3Owner | None = None
    """
    Container for the bucket owner's display name and ID.
    """


class PutObjectAclOutput(Boto3Model):
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class S3ObjectLockLegalHold(Boto3Model):
    """
    A legal hold configuration for an object.
    """

    Status: Literal["ON", "OFF"] | None = None
    """
    Indicates whether the specified object has a legal hold in place.
    """


class GetObjectLegalHoldOutput(Boto3Model):
    LegalHold: S3ObjectLockLegalHold | None = None
    """
    The current legal hold status for the specified object.
    """


class PutObjectLegalHoldOutput(Boto3Model):
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class S3DefaultRetention(Boto3Model):
    """
    The container element for optionally specifying the default Object Lock retention
    settings for new objects placed in the specified bucket.

    * The ``DefaultRetention`` settings require both a mode and a period.
    * The ``DefaultRetention`` period can be either ``Days`` or ``Years`` but you must select one. You cannot specify
      ``Days`` and ``Years`` at the same time.
    """

    Mode: Literal["GOVERNANCE", "COMPLIANCE"] | None = None
    """
    The default Object Lock retention mode you want to apply to new objects placed in
    the specified bucket.

    Must be used
    with either ``Days`` or ``Years``.
    """
    Days: int | None = None
    """
    The number of days that you want to specify for the default retention period.

    Must be used with ``Mode``.
    """
    Years: int | None = None
    """
    The number of years that you want to specify for the default retention period.

    Must be used with ``Mode``.
    """


class S3ObjectLockRule(Boto3Model):
    """
    The container element for an Object Lock rule.
    """

    DefaultRetention: S3DefaultRetention | None = None
    """
    The default Object Lock retention mode and period that you want to apply to new
    objects placed in the specified bucket.

    Bucket settings require both a mode and a period. The period can be either ``Days`` or ``Years`` but you must select
    one. You cannot specify ``Days`` and ``Years`` at the same time.
    """


class S3ObjectLockConfiguration(Boto3Model):
    """
    The container element for Object Lock configuration parameters.
    """

    ObjectLockEnabled: Literal["Enabled"] | None = None
    """
    Indicates whether this bucket has an Object Lock configuration enabled.

    Enable ``ObjectLockEnabled`` when you apply
    ``ObjectLockConfiguration`` to a bucket.
    """
    Rule: S3ObjectLockRule | None = None
    """
    Specifies the Object Lock rule for the specified object.

    Enable the this rule when you apply ``ObjectLockConfiguration``
    to a bucket. Bucket settings require both a mode and a period. The period can be either ``Days`` or ``Years`` but you
    must select one. You cannot specify ``Days`` and ``Years`` at the same time.
    """


class GetObjectLockConfigurationOutput(Boto3Model):
    ObjectLockConfiguration: S3ObjectLockConfiguration | None = None
    """
    The specified bucket's Object Lock configuration.
    """


class PutObjectLockConfigurationOutput(Boto3Model):
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class ObjectLockRetention(Boto3Model):
    """
    A Retention configuration for an object.
    """

    Mode: Literal["GOVERNANCE", "COMPLIANCE"] | None = None
    """
    Indicates the Retention mode for the specified object.
    """
    RetainUntilDate: datetime | None = None
    """
    The date on which this Object Lock Retention will expire.
    """


class GetObjectRetentionOutput(Boto3Model):
    Retention: ObjectLockRetention | None = None
    """
    The container element for an object's retention settings.
    """


class PutObjectRetentionOutput(Boto3Model):
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """


class S3Checksum(Boto3Model):
    """
    Contains all the possible checksum or digest values for an object.
    """

    ChecksumCRC32: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32 checksum`` of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use an API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumCRC32C: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32C`` checksum of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use an API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumCRC64NVME: str | None = None
    """
    The Base64 encoded, 64-bit ``CRC64NVME`` checksum of the object.

    This checksum is present if the object was uploaded
    with the ``CRC64NVME`` checksum algorithm, or if the object was uploaded without a checksum (and Amazon S3 added the
    default checksum, ``CRC64NVME``, to the uploaded object). For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    ChecksumSHA1: str | None = None
    """
    The Base64 encoded, 160-bit ``SHA1`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use the API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumSHA256: str | None = None
    """
    The Base64 encoded, 256-bit ``SHA256`` digest of the object.

    This checksum is only present if the checksum was uploaded with the object. When you
    use an API operation on an object that was uploaded using multipart uploads, this
    value may not be a direct checksum value of the full object. Instead, it's a
    calculation based on the checksum values of each individual part. For more
    information about how checksums are calculated with multipart uploads, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html#large-object-checksums>`_
    in the *Amazon S3 User Guide*.
    """
    ChecksumType: Literal["COMPOSITE", "FULL_OBJECT"] | None = None
    """
    The checksum type that is used to calculate the objects checksum value.

    For more information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """


class ObjectPart(Boto3Model):
    """
    A container for elements related to an individual part.
    """

    PartNumber: int | None = None
    """
    The part number identifying the part.

    This value is a positive integer between 1 and 10,000.
    """
    Size: int | None = None
    """
    The size of the uploaded part in bytes.
    """
    ChecksumCRC32: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32`` checksum of the part.

    This checksum is present if the multipart upload request was
    created with the ``CRC32`` checksum algorithm. For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    ChecksumCRC32C: str | None = None
    """
    The Base64 encoded, 32-bit ``CRC32C`` checksum of the part.

    This checksum is present if the multipart upload request was
    created with the ``CRC32C`` checksum algorithm. For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    ChecksumCRC64NVME: str | None = None
    """
    The Base64 encoded, 64-bit ``CRC64NVME`` checksum of the part.

    This checksum is present if the multipart upload request
    was created with the ``CRC64NVME`` checksum algorithm, or if the object was uploaded without a checksum (and Amazon S3
    added the default checksum, ``CRC64NVME``, to the uploaded object). For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    ChecksumSHA1: str | None = None
    """
    The Base64 encoded, 160-bit ``SHA1`` checksum of the part.

    This checksum is present if the multipart upload request was
    created with the ``SHA1`` checksum algorithm. For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """
    ChecksumSHA256: str | None = None
    """
    The Base64 encoded, 256-bit ``SHA256`` checksum of the part.

    This checksum is present if the multipart upload request
    was created with the ``SHA256`` checksum algorithm. For more information, see `Checking object
    integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_ in the *Amazon S3 User
    Guide*.
    """


class GetObjectAttributesParts(Boto3Model):
    """
    A collection of parts associated with a multipart upload.
    """

    TotalPartsCount: int | None = None
    """
    The total number of parts.
    """
    PartNumberMarker: int | None = None
    """
    The marker for the current part.
    """
    NextPartNumberMarker: int | None = None
    """
    When a list is truncated, this element specifies the last part in the list, as well
    as the value to use for the ``PartNumberMarker`` request parameter in a subsequent
    request.
    """
    MaxParts: int | None = None
    """
    The maximum number of parts allowed in the response.
    """
    IsTruncated: bool | None = None
    """
    Indicates whether the returned list of parts is truncated.

    A value of ``true`` indicates that the list was truncated. A
    list can be truncated if the number of parts exceeds the limit returned in the ``MaxParts`` element.
    """
    Parts: List["ObjectPart"] | None = None
    """
    A container for elements related to a particular part.

    A response can contain zero or more ``Parts`` elements.
    """


class GetObjectAttributesOutput(Boto3Model):
    DeleteMarker: bool | None = None
    """
    Specifies whether the object retrieved was (``true``) or was not (``false``) a
    delete marker.

    If ``false``, this
    response header does not appear in the response. To learn more about delete markers, see `Working with delete
    markers <https://docs.aws.amazon.com/AmazonS3/latest/userguide/DeleteMarker.html>`_.
    """
    LastModified: datetime | None = None
    """
    Date and time when the object was last modified.
    """
    VersionId: str | None = None
    """
    The version ID of the object.
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """
    ETag: str | None = None
    """
    An ETag is an opaque identifier assigned by a web server to a specific version of a
    resource found at a URL.
    """
    Checksum: S3Checksum | None = None
    """
    The checksum or digest of the object.
    """
    ObjectParts: GetObjectAttributesParts | None = None
    """
    A collection of parts associated with a multipart upload.
    """
    StorageClass: Literal["STANDARD", "REDUCED_REDUNDANCY", "STANDARD_IA", "ONEZONE_IA", "INTELLIGENT_TIERING", "GLACIER", "DEEP_ARCHIVE", "OUTPOSTS", "GLACIER_IR", "SNOW", "EXPRESS_ONEZONE", "FSX_OPENZFS", "FSX_ONTAP"] | None = None
    """
    Provides the storage class information of the object.

    Amazon S3 returns this header for all objects except for S3 Standard storage class
    objects.
    """
    ObjectSize: int | None = None
    """
    The size of the object in bytes.
    """


class ObjectVersion(Boto3Model):
    """
    The version of an object.
    """

    ETag: str | None = None
    """
    The entity tag is an MD5 hash of that version of the object.
    """
    ChecksumAlgorithm: List[Literal["CRC32", "CRC32C", "SHA1", "SHA256", "CRC64NVME"]] | None = None
    """
    The algorithm that was used to create a checksum of the object.
    """
    ChecksumType: Literal["COMPOSITE", "FULL_OBJECT"] | None = None
    """
    The checksum type that is used to calculate the objects checksum value.

    For more information, see
    `Checking object integrity <https://docs.aws.amazon.com/AmazonS3/latest/userguide/checking-object-integrity.html>`_
    in the *Amazon S3 User
    Guide*.
    """
    Size: int | None = None
    """
    Size in bytes of the object.
    """
    StorageClass: Literal["STANDARD"] | None = None
    """
    The class of storage used to store the object.
    """
    Key: str | None = None
    """
    The object key.
    """
    VersionId: str | None = None
    """
    Version ID of an object.
    """
    IsLatest: bool | None = None
    """
    Specifies whether the object is (true) or is not (false) the latest version of an
    object.
    """
    LastModified: datetime | None = None
    """
    Date and time when the object was last modified.
    """
    Owner: S3Owner | None = None
    """
    Specifies the owner of the object.
    """
    RestoreStatus: S3RestoreStatus | None = None
    """
    Specifies the restoration status of an object.

    Objects in certain storage classes must be restored before they can be retrieved.
    For more information about these storage classes and how to work with archived
    objects, see
    `Working with archived objects <https://docs.aws.amazon.com/AmazonS3/latest/userguide/archived-objects.html>`_
    in the *Amazon S3 User
    Guide*.
    """


class DeleteMarkerEntry(Boto3Model):
    """
    Information about the delete marker.
    """

    Owner: S3Owner | None = None
    """
    The account that created the delete marker.
    """
    Key: str | None = None
    """
    The object key.
    """
    VersionId: str | None = None
    """
    Version ID of an object.
    """
    IsLatest: bool | None = None
    """
    Specifies whether the object is (true) or is not (false) the latest version of an
    object.
    """
    LastModified: datetime | None = None
    """
    Date and time when the object was last modified.
    """


class ListObjectVersionsOutput(Boto3Model):
    IsTruncated: bool | None = None
    """
    A flag that indicates whether Amazon S3 returned all of the results that satisfied
    the search criteria.

    If your results
    were truncated, you can make a follow-up paginated request by using the ``NextKeyMarker`` and ``NextVersionIdMarker``
    response parameters as a starting place in another request to return the rest of the results.
    """
    KeyMarker: str | None = None
    """
    Marks the last key returned in a truncated response.
    """
    VersionIdMarker: str | None = None
    """
    Marks the last version of the key returned in a truncated response.
    """
    NextKeyMarker: str | None = None
    """
    When the number of responses exceeds the value of ``MaxKeys``, ``NextKeyMarker``
    specifies the first key not returned that satisfies the search criteria.

    Use this value for the key-marker request parameter in a subsequent request.
    """
    NextVersionIdMarker: str | None = None
    """
    When the number of responses exceeds the value of ``MaxKeys``,
    ``NextVersionIdMarker`` specifies the first object version not returned that
    satisfies the search criteria.

    Use this value for the ``version-id-marker`` request parameter
    in a subsequent request.
    """
    Versions: List["ObjectVersion"] | None = None
    """
    Container for version information.
    """
    DeleteMarkers: List["DeleteMarkerEntry"] | None = None
    """
    Container for an object that is a delete marker.

    To learn more about delete markers, see
    `Working with delete markers <https://docs.aws.amazon.com/AmazonS3/latest/userguide/DeleteMarker.html>`_.
    """
    Name: str | None = None
    """
    The bucket name.
    """
    Prefix: str | None = None
    """
    Selects objects that start with the value supplied by this parameter.
    """
    Delimiter: str | None = None
    """
    The delimiter grouping the included keys.

    A delimiter is a character that you specify to group keys. All keys that
    contain the same string between the prefix and the first occurrence of the delimiter are grouped under a single result
    element in ``CommonPrefixes``. These groups are counted as one result against the ``max-keys`` limitation. These keys
    are not returned elsewhere in the response.
    """
    MaxKeys: int | None = None
    """
    Specifies the maximum number of objects to return.
    """
    CommonPrefixes: List["CommonPrefix"] | None = None
    """
    All of the keys rolled up into a common prefix count as a single return when
    calculating the number of returns.
    """
    EncodingType: Literal["url"] | None = None
    """
    Encoding type used by Amazon S3 to encode object key names in the XML response.
    """
    RequestCharged: Literal["requester"] | None = None
    """
    If present, indicates that the requester was successfully charged for the request.

    For more information, see
    `Using Requester Pays buckets for storage transfers and usage <https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html>`_
    in the *Amazon Simple Storage
    Service user guide*.
    """
