

[pipelex]

[pipelex.storage_config]
is_fetch_remote_content_enabled = true
method = "in_memory"                   # local, in_memory, s3, gcp

[pipelex.storage_config.local]
uri_format = "{primary_id}/{secondary_id}/{hash}.{extension}"
local_storage_path = ".pipelex/storage"

[pipelex.storage_config.in_memory]
uri_format = "{primary_id}/{secondary_id}/{hash}.{extension}"

[pipelex.storage_config.s3]
uri_format = "{primary_id}/{secondary_id}/{hash}.{extension}"
bucket_name = ""
region = ""
signed_urls_lifespan_seconds = 3600

[pipelex.storage_config.gcp]
uri_format = "{primary_id}/{secondary_id}/{hash}.{extension}"
bucket_name = ""
project_id = ""
signed_urls_lifespan_seconds = 3600

[pipelex.observer_config]
observer_dir = "results/observer"

[pipelex.scan_config]
excluded_dirs = [
    ".venv",
    "venv",
    "env",
    ".env",
    "virtualenv",
    ".virtualenv",
    ".git",
    "__pycache__",
    ".pytest_cache",
    ".mypy_cache",
    ".ruff_cache",
    "node_modules",
    "results",
]

[pipelex.builder_config]
fix_loop_max_attempts = 10
default_output_dir = "."
default_bundle_file_name = "bundle"
default_directory_base_name = "pipeline"

[pipelex.feature_config]
# WIP/Experimental feature flags
is_reporting_enabled = true

[pipelex.reporting_config]
is_log_costs_to_console = false
is_generate_cost_report_file_enabled = false
cost_report_dir_path = "reports"
cost_report_base_name = "cost_report"
cost_report_extension = "csv"
cost_report_unit_scale = 1.0

####################################################################################################
# Log config
####################################################################################################

[pipelex.log_config]
default_log_level = "INFO"
console_log_target = "stdout"
console_print_target = "stdout"
is_console_logging_enabled = true

json_logs_indent = 4
presentation_line_width = 120
silenced_problem_ids = ["azure_openai_no_stream_options"]
caller_info_template = "file_line"
is_caller_info_enabled = false

log_mode = "rich"

poor_loggers = []
generic_poor_logger = "#poor-log"

[pipelex.log_config.package_log_levels]
# for logger names, the dots "." have been replaced by "-" to avoid toml parsing issues
# TODO: use quotes to re-enable names with dots
anthropic = "INFO"
asyncio = "INFO"
botocore = "INFO"
botocore-credentials = "WARNING"
google = "INFO"
httpx = "WARNING"
httpcore = "INFO"
openai = "INFO"
instructor = "INFO"
urllib3-connectionpool = "INFO"
urllib3-util-retry = "INFO"

pipelex = "INFO"


[pipelex.log_config.rich_log_config]
is_show_time = false
is_show_level = true
is_link_path_enabled = true
is_markup_enabled = true
highlighter_name = "json"
is_rich_tracebacks = true
is_tracebacks_word_wrap = true
is_tracebacks_show_locals = false
tracebacks_suppress = []
keywords_to_hilight = []

[pipelex.aws_config]
api_key_method = "env"

####################################################################################################
# Cogt inference config
####################################################################################################

[cogt]

[cogt.model_deck_config]
is_model_fallback_enabled = true
missing_presets_reaction = "log"

[cogt.tenacity_config]
max_retries = 50      # Maximum number of retry attempts before giving up
wait_multiplier = 0.2 # Multiplier applied to the wait time between retries (in seconds)
wait_max = 20         # Maximum wait time between retries (in seconds)
wait_exp_base = 1.3   # Base for exponential backoff calculation

[cogt.llm_config]
default_max_images = 100
is_structure_prompt_enabled = true
is_dump_text_prompts_enabled = false
is_dump_response_text_enabled = false

[cogt.llm_config.instructor_config]
is_dump_kwargs_enabled = false
is_dump_response_enabled = false
is_dump_error_enabled = false

[cogt.llm_config.anthropic_config]
structured_output_timeout_seconds = 1200

[cogt.llm_config.llm_job_config]
max_retries = 3

[cogt.llm_config.generic_templates]
structure_from_preliminary_text_system = """
You are a data modeling expert specialized in extracting structure from text.
"""

structure_from_preliminary_text_user = """
Extract and structure information from this text:

{{ preliminary_text | tag }}

Now generate the JSON in the required format.
Do not create information that is not in the text.
"""

output_structure_prompt = """


---
The instance we want to generate will be for the following class:
{{ class_structure_str }}

Don't bother with JSON formatting, we'll do that as a second step.
For now, just output markdown with the details of the instance.
DO NOT create new information.
If some information is not present for an attribute, output the default value or None according to the field definition.
"""

output_structure_prompt_no_preliminary_text = """


---
The instance we want to generate will be for the following class:
{{ class_structure_str }}

DO NOT create information.
If some information is not present for an attribute, output the default value or None according to the attribute definition.
"""

####################################################################################################
# Image generation config
####################################################################################################

[cogt.img_gen_config.img_gen_job_config]
is_sync_mode = false

[cogt.img_gen_config.img_gen_param_defaults]
nb_steps = 28           # 28 is a good default for Flux, possible values are [1,2,4,8] for SDXL Lightning
quality = "low"
aspect_ratio = "square" # "square", "landscape_4_3", "landscape_16_9", "landscape_21_9", "portrait_3_4", "portrait_9_16", "portrait_9_21"
guidance_scale = 2.5
background = "auto"
is_moderated = true
safety_tolerance = 5
is_raw = false
seed = "auto"

[cogt.img_gen_config.quality_to_steps_maps]
flux = { "low" = 14, "medium" = 28, "high" = 56 }
sdxl_lightning = { "low" = 2, "medium" = 4, "high" = 8 }
qwen_image = { "low" = 10, "medium" = 20, "high" = 28 }

####################################################################################################
# Extract config
####################################################################################################

[cogt.extract_config]
default_page_views_dpi = 72

####################################################################################################
# Gateway test config
####################################################################################################

[cogt.gateway_test_config.config_id_substitutions]
# this is an empty dict, it's only used by Pipelex staff to override the ¨Pipelex Gateway¨ config
# in order to test new model integrations or debug issues with the Gateway

####################################################################################################
# Prompting config
####################################################################################################

[pipelex.prompting_config]
default_prompting_style = { tag_style = "xml" }

[pipelex.prompting_config.prompting_styles]
openai = { tag_style = "ticks" }
anthropic = { tag_style = "xml" }
mistral = { tag_style = "square_brackets" }
gemini = { tag_style = "xml" }

[pipelex.structure_config]
is_default_text_then_structure = false # turn this to true to get better results: generates text before structuring

####################################################################################################
# Pipe run config
####################################################################################################

[pipelex.pipe_run_config]
pipe_stack_limit = 20

####################################################################################################
# Pipeline execution config
####################################################################################################

[pipelex.pipeline_execution_config]
is_normalize_data_urls_to_storage = true
is_mock_inputs = false
is_generate_graph = false

[pipelex.pipeline_execution_config.graph_config]

[pipelex.pipeline_execution_config.graph_config.data_inclusion]
stuff_json_content = true
stuff_text_content = true
stuff_html_content = true
error_stack_traces = true

[pipelex.pipeline_execution_config.graph_config.graphs_inclusion]
graphspec_json = true
mermaidflow_mmd = true
mermaidflow_html = true
reactflow_viewspec = true
reactflow_html = true

[pipelex.pipeline_execution_config.graph_config.mermaid_config]
direction = "top_down"
is_include_data_edges = true
is_include_contains_edges = false
is_include_selected_outcome_edges = true
is_show_stuff_codes = false

[pipelex.pipeline_execution_config.graph_config.mermaid_config.style]
theme = "dark"

[pipelex.pipeline_execution_config.graph_config.reactflow_config]
is_use_cdn = true
layout_direction = "TB"
nodesep = 50
ranksep = 80
edge_type = "bezier"
initial_zoom = 1.0
pan_to_top = true
default_title = "Pipelex Graph"

[pipelex.pipeline_execution_config.graph_config.reactflow_config.style]
theme = "dark"

####################################################################################################
# Dry run config
####################################################################################################

[pipelex.dry_run_config]
apply_to_jinja2_rendering = false
text_gen_truncate_length = 256
nb_list_items = 3
nb_extract_pages = 4
allowed_to_fail_pipes = [
    "infinite_loop_1", # Loop but only for testing purposes
    "pipe_builder",    # Still not fully proofed
]
image_urls = [
    "https://storage.googleapis.com/public_test_files_7fa6_4277_9ab/fashion/fashion_photo_1.jpg",
    "https://storage.googleapis.com/public_test_files_7fa6_4277_9ab/fashion/fashion_photo_2.png",
]

####################################################################################################
# PLX config
####################################################################################################

[pipelex.plx_config.inline_tables]
spaces_inside_curly_braces = true

[pipelex.plx_config.strings]
prefer_literal = false
force_multiline = false
length_limit_to_multiline = 100
ensure_trailing_newline = true
ensure_leading_blank_line = true

[pipelex.plx_config.concepts]
structure_field_ordering = ["type", "description", "choices", "required"]

[pipelex.plx_config.pipes]
field_ordering = ["type", "description", "inputs", "output"]

####################################################################################################
# Migration config
####################################################################################################

[migration.migration_maps.config]
definition = "description"
ocr_config = "extract_config"
ocr = "extract"
img_gen = "model"
llm_handle = "model"
llm = "model"
llm_to_structure = "model_to_structure"

[migration.migration_maps.plx]
img_gen = "model"
ocr = "model"
llm_handle = "model"
llm = "model"
llm_to_structure = "model_to_structure"


[migration.migration_maps.telemetry]
