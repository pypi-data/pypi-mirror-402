####################################################################################################
# Pipelex Model Deck - Base Configuration
####################################################################################################
#
# This file defines model aliases and presets for:
# - LLMs (language models for text generation and structured output)
# - Image generation models (for creating images from text prompts)
# - Document extraction models (OCR and text extraction from PDFs/images)
#
# Documentation: https://docs.pipelex.com
# Support: https://go.pipelex.com/discord
#
####################################################################################################

####################################################################################################
# LLM Choices
####################################################################################################

# Default llm choices for a PipeLLM generation.

[llm.choice_defaults]
for_text = "cheap_llm"
for_object = "cheap_llm_for_structured"


####################################################################################################
# Waterfalls : list of models that will be tried in order until one of them succeeds.
####################################################################################################

[waterfalls]
# --- Waterfalls for LLMs ---------------------------------------------------------------------
cheap_llm = [
    "gpt-4o-mini",
    "gemini-2.5-flash-lite",
    "mistral-small",
    "claude-3-haiku",
    "grok-3-mini",
]
cheap_llm_for_structured = ["gpt-4o-mini", "mistral-small", "claude-3-haiku"]
cheap_llm_for_vision = [
    "gemini-2.5-flash-lite",
    "gpt-4o-mini",
    "claude-3-haiku",
]
cheap_llm_for_creativity = [
    "gemini-2.5-flash",
    "grok-3-mini",
    "gpt-4o-mini",
    "claude-4.5-haiku",
]
smart_llm = [
    "claude-4.5-opus",
    "claude-4.5-sonnet",
    "gemini-3.0-pro",
    "gpt-5.1",
    "claude-4.1-opus",
    "gemini-2.5-pro",
    "claude-4-sonnet",
    "grok-4-fast-non-reasoning",
]
smart_llm_with_vision = [
    "claude-4.5-opus",
    "claude-4.5-sonnet",
    "gemini-3.0-pro",
    "gpt-5.1",
    "claude-4.1-opus",
    "gemini-2.5-pro",
    "claude-4-sonnet",
    "grok-4-fast-non-reasoning",
]
smart_llm_for_structured = [
    "claude-4.5-opus",
    "claude-4.5-sonnet",
    "gemini-3.0-pro",
    "gpt-5.1",
    "claude-4.1-opus",
    "claude-4-sonnet",
]
llm_for_creativity = [
    "claude-4.5-opus",
    "claude-4.1-opus",
    "gemini-2.5-pro",
    "gpt-5.1",
]
llm_for_large_codebase = [
    "gemini-2.5-pro",
    "claude-4.5-sonnet",
    "gemini-3.0-pro",
    "gpt-5.1",
    "gemini-2.5-flash",
    "grok-4-fast-non-reasoning",
]

# --- Waterfalls for Extracts ---------------------------------------------------------------------
pdf_text_extractor = [
    "azure-document-intelligence",
    "mistral-ocr",
    "pypdfium2-extract-pdf",
]
image_text_extractor = ["mistral-ocr"]

####################################################################################################
# Aliases
####################################################################################################

[aliases]
base-claude = "claude-4.5-sonnet"
base-gpt = "gpt-4o"
base-gemini = "gemini-2.5-flash"
base-mistral = "mistral-medium"
base-groq = "llama-3.3-70b-versatile"
base-grok = "grok-4-fast-non-reasoning"

best-gpt = "gpt-5.1"
best-claude = "claude-4.5-opus"
best-gemini = "gemini-3.0-pro"
best-mistral = "mistral-medium"

# Groq-specific aliases
fast-groq = "llama-3.1-8b-instant"
vision-groq = "llama-4-scout-17b-16e-instruct"

# Image generation aliases
base-img-gen = "flux-pro/v1.1"
best-img-gen = "flux-2"
fast-img-gen = "fast-lightning-sdxl"

####################################################################################################
# LLM Presets
####################################################################################################

[llm.presets]

# LLM Presets — Specific skills -------------------------------------------------------------

# Generation skills
llm_for_factual_writing = { model = "base-gpt", temperature = 0.1 }
llm_for_creative_writing = { model = "base-gpt", temperature = 0.9 }
llm_for_writing_cheap = { model = "gpt-4o-mini", temperature = 0.3 }

# Retrieve and answer questions skills
llm_to_answer_questions_cheap = { model = "gpt-4o-mini", temperature = 0.3 }
llm_to_answer_questions = { model = "base-claude", temperature = 0.3 }
llm_to_retrieve = { model = "base-claude", temperature = 0.1 }

# Engineering skills
llm_to_engineer = { model = "smart_llm_for_structured", temperature = 0.2 }
llm_to_code = { model = "base-claude", temperature = 0.1 }
llm_to_analyze_large_codebase = { model = "base-claude", temperature = 0.1 }

# Vision skills
llm_for_img_to_text_cheap = { model = "gpt-4o-mini", temperature = 0.1 }
llm_for_img_to_text = { model = "base-claude", temperature = 0.1 }
llm_for_diagram_to_text = { model = "best-claude", temperature = 0.3 }
llm_for_table_to_text = { model = "base-claude", temperature = 0.3 }

# Image generation prompting skills
llm_to_prompt_img_gen = { model = "base-claude", temperature = 0.2 }
llm_to_prompt_img_gen_cheap = { model = "gpt-4o-mini", temperature = 0.5 }

# Groq-specific presets (fast inference, low cost)
llm_groq_fast_text = { model = "fast-groq", temperature = 0.7 }
llm_groq_balanced = { model = "base-groq", temperature = 0.5 }
llm_groq_vision = { model = "vision-groq", temperature = 0.3 }

# LLM Presets — For Testing ---------------------------------------------------------------------

llm_for_testing_gen_text = { model = "cheap_llm", temperature = 0.5 }
llm_for_testing_gen_object = { model = "cheap_llm_for_structured", temperature = 0.1 }
llm_for_testing_vision = { model = "cheap_llm_for_vision", temperature = 0.5 }
llm_for_testing_vision_structured = { model = "cheap_llm_for_vision", temperature = 0.5 }


####################################################################################################
# Extract Presets
####################################################################################################

[extract]
choice_default = "extract_ocr_from_document"

[extract.presets]
extract_ocr_from_document = { model = "azure-document-intelligence", max_nb_images = 100, image_min_size = 50 }
extract_basic_from_pdf = { model = "pypdfium2-extract-pdf", max_nb_images = 100, image_min_size = 50 }

####################################################################################################
# Image Generation Presets
####################################################################################################

[img_gen]
choice_default = "gen_image_basic"

[img_gen.presets]

# General purpose
gen_image_basic = { model = "base-img-gen", quality = "medium", guidance_scale = 7.5, is_moderated = true, safety_tolerance = 3 }
gen_image_fast = { model = "fast-img-gen", nb_steps = 4, guidance_scale = 5.0, is_moderated = true, safety_tolerance = 3 }
gen_image_high_quality = { model = "best-img-gen", quality = "high", guidance_scale = 8.0, is_moderated = true, safety_tolerance = 3 }
gen_image_openai_low_quality = { model = "gpt-image-1", quality = "low" }

# Specific skills
img_gen_for_art = { model = "best-img-gen", quality = "high", guidance_scale = 9.0, is_moderated = false, safety_tolerance = 5 }
img_gen_for_diagram = { model = "base-img-gen", quality = "medium", guidance_scale = 7.0, is_moderated = true, safety_tolerance = 2 }
img_gen_for_mockup = { model = "base-img-gen", quality = "medium", guidance_scale = 6.5, is_moderated = true, safety_tolerance = 3 }
img_gen_for_product = { model = "best-img-gen", quality = "high", guidance_scale = 8.5, is_moderated = true, safety_tolerance = 2 }
img_gen_for_testing = { model = "gpt-image-1-mini", quality = "low" }
