"""
Tests for BackgroundTaskManager.

Focuses on proving BEHAVIOR works, not structure.
Following CLAUDE.md guidelines:
- Tests prove features work, not just that code runs
- Edge cases covered (errors, timeouts, cancellation)
- Minimal mocking (only OutputInterface for error logging)
- Tests would fail if feature breaks
"""

import pytest
import asyncio
import threading
from scrappy.orchestrator.background import BackgroundTaskManager


class TestBackgroundTaskSubmission:
    """Test that background task submission and tracking actually work."""

    @pytest.mark.asyncio
    async def test_submit_returns_unique_task_id(self):
        """Submitting a task should return a unique ID for tracking."""
        manager = BackgroundTaskManager()

        async def dummy_task():
            await asyncio.sleep(0.01)

        task_id = manager.submit_background_task(dummy_task())

        assert task_id is not None
        assert isinstance(task_id, str)
        assert len(task_id) > 0

        # Cleanup: wait for task to complete
        await manager.wait_for_background_tasks(timeout=1.0)

    @pytest.mark.asyncio
    async def test_submit_multiple_tasks_returns_different_ids(self):
        """Each submitted task should get a unique ID."""
        manager = BackgroundTaskManager()

        async def dummy_task():
            await asyncio.sleep(0.01)

        task_id_1 = manager.submit_background_task(dummy_task())
        task_id_2 = manager.submit_background_task(dummy_task())
        task_id_3 = manager.submit_background_task(dummy_task())

        assert task_id_1 != task_id_2
        assert task_id_2 != task_id_3
        assert task_id_1 != task_id_3

        # Cleanup: wait for tasks to complete
        await manager.wait_for_background_tasks(timeout=1.0)

    @pytest.mark.asyncio
    async def test_tracks_active_tasks(self):
        """Manager should track submitted tasks as active."""
        manager = BackgroundTaskManager()

        async def slow_task():
            await asyncio.sleep(0.1)

        # Submit tasks
        manager.submit_background_task(slow_task())
        manager.submit_background_task(slow_task())

        # Should be tracked
        status = manager.get_task_status()
        assert status['pending_tasks'] >= 2

        # Cleanup: wait for tasks to complete
        await manager.wait_for_background_tasks(timeout=1.0)

    @pytest.mark.asyncio
    async def test_task_actually_executes_in_background(self):
        """Submitted task should execute without blocking caller."""
        manager = BackgroundTaskManager()

        executed = []

        async def task_that_appends():
            await asyncio.sleep(0.02)
            executed.append('done')

        # Submit task (should not block)
        manager.submit_background_task(task_that_appends())

        # Task hasn't completed yet
        assert len(executed) == 0

        # Wait for it to complete
        await asyncio.sleep(0.05)

        # Now it should be done
        assert len(executed) == 1
        assert executed[0] == 'done'


class TestBackgroundTaskCompletion:
    """Test that tasks complete and are removed from tracking."""

    @pytest.mark.asyncio
    async def test_removes_task_from_active_when_complete(self):
        """Completed tasks should be removed from active tracking."""
        manager = BackgroundTaskManager()

        async def quick_task():
            await asyncio.sleep(0.01)

        manager.submit_background_task(quick_task())

        # Wait for completion
        await asyncio.sleep(0.05)

        # Should no longer be active
        status = manager.get_task_status()
        assert status['pending_tasks'] == 0

    @pytest.mark.asyncio
    async def test_wait_for_tasks_waits_until_completion(self):
        """wait_for_background_tasks should wait for all tasks to finish."""
        manager = BackgroundTaskManager()

        completed = []

        async def task_that_completes():
            await asyncio.sleep(0.02)
            completed.append('done')

        # Submit multiple tasks
        manager.submit_background_task(task_that_completes())
        manager.submit_background_task(task_that_completes())

        # Tasks not yet complete
        assert len(completed) == 0

        # Wait for all
        result = await manager.wait_for_background_tasks(timeout=1.0)

        # All should be complete now
        assert len(completed) == 2
        assert result['status'] in ['no_pending', 'completed']

    @pytest.mark.asyncio
    async def test_wait_returns_immediately_when_no_tasks(self):
        """wait_for_background_tasks should return immediately if no tasks pending."""
        manager = BackgroundTaskManager()

        result = await manager.wait_for_background_tasks(timeout=1.0)

        assert result['status'] == 'no_pending'
        assert result['completed'] == 0
        # When no pending, 'errors' key is returned instead of 'pending'
        assert 'errors' in result

    @pytest.mark.asyncio
    async def test_wait_returns_completion_stats(self):
        """wait_for_background_tasks should return stats about what completed."""
        manager = BackgroundTaskManager()

        async def quick_task():
            await asyncio.sleep(0.01)

        # Submit 3 tasks
        manager.submit_background_task(quick_task())
        manager.submit_background_task(quick_task())
        manager.submit_background_task(quick_task())

        result = await manager.wait_for_background_tasks(timeout=1.0)

        assert result['completed'] == 3
        assert result['pending'] == 0


class TestBackgroundTaskErrors:
    """Test that errors in tasks are captured and don't crash the system."""

    @pytest.mark.asyncio
    async def test_handles_task_raising_exception(self):
        """Tasks that raise exceptions should be captured, not crash manager."""
        manager = BackgroundTaskManager()

        async def failing_task():
            await asyncio.sleep(0.01)
            raise ValueError("Task failed!")

        manager.submit_background_task(failing_task())

        # Wait for task to fail
        await asyncio.sleep(0.05)

        # Manager should still be operational
        status = manager.get_task_status()
        assert status is not None

    @pytest.mark.asyncio
    async def test_records_task_errors(self):
        """Errors from tasks should be recorded in error log."""
        manager = BackgroundTaskManager()

        async def failing_task():
            await asyncio.sleep(0.01)
            raise RuntimeError("Something went wrong")

        manager.submit_background_task(failing_task())

        # Wait for task to fail
        await asyncio.sleep(0.05)

        # Error should be recorded
        status = manager.get_task_status()
        assert status['total_errors'] > 0
        assert len(status['recent_errors']) > 0

    @pytest.mark.asyncio
    async def test_get_status_returns_error_count(self):
        """get_task_status should include error count."""
        manager = BackgroundTaskManager()

        async def failing_task():
            raise ValueError("Error")

        # Submit multiple failing tasks
        manager.submit_background_task(failing_task())
        manager.submit_background_task(failing_task())

        await asyncio.sleep(0.05)

        status = manager.get_task_status()
        assert 'total_errors' in status
        assert status['total_errors'] == 2

    @pytest.mark.asyncio
    async def test_clear_errors_empties_error_list(self):
        """clear_background_errors should remove all recorded errors."""
        manager = BackgroundTaskManager()

        async def failing_task():
            raise ValueError("Error")

        manager.submit_background_task(failing_task())
        await asyncio.sleep(0.05)

        # Should have errors
        assert manager.get_task_status()['total_errors'] > 0

        # Clear errors
        manager.clear_background_errors()

        # Should be empty
        assert manager.get_task_status()['total_errors'] == 0


class TestBackgroundTaskCancellation:
    """Test task cancellation behavior."""

    @pytest.mark.asyncio
    async def test_cancel_task_cancels_by_id(self):
        """cancel_task should cancel the task with the given ID."""
        manager = BackgroundTaskManager()

        async def long_running_task():
            await asyncio.sleep(10)

        task_id = manager.submit_background_task(long_running_task())

        # Task should be active
        assert manager.get_task_status()['pending_tasks'] > 0

        # Cancel it
        result = manager.cancel_task(task_id)

        assert result is True

        # Give it a moment to cancel
        await asyncio.sleep(0.05)

        # Should no longer be pending
        assert manager.get_task_status()['pending_tasks'] == 0

    @pytest.mark.asyncio
    async def test_cancel_returns_false_for_unknown_task_id(self):
        """Cancelling unknown task ID should return False."""
        manager = BackgroundTaskManager()

        result = manager.cancel_task("nonexistent-id")

        assert result is False
        # Depending on implementation, may have 0 errors or cancelled error isn't counted
        # The key is it shouldn't crash

    @pytest.mark.asyncio
    async def test_cancel_all_tasks_cancels_all_pending(self):
        """cancel_all_tasks should cancel all pending tasks and return count."""
        manager = BackgroundTaskManager()

        async def long_running_task():
            await asyncio.sleep(10)

        # Submit multiple tasks
        manager.submit_background_task(long_running_task())
        manager.submit_background_task(long_running_task())
        manager.submit_background_task(long_running_task())

        # Should have 3 pending
        assert manager.get_task_status()['pending_tasks'] == 3

        # Cancel all
        cancelled = manager.cancel_all_tasks()

        assert cancelled == 3

        # Give tasks a moment to process cancellation
        await asyncio.sleep(0.05)

        # Should no longer be pending
        assert manager.get_task_status()['pending_tasks'] == 0

    @pytest.mark.asyncio
    async def test_cancel_all_returns_zero_when_no_tasks(self):
        """cancel_all_tasks should return 0 when no tasks are pending."""
        manager = BackgroundTaskManager()

        cancelled = manager.cancel_all_tasks()

        assert cancelled == 0


class TestEdgeCases:
    """Test boundary conditions and edge cases."""

    @pytest.mark.asyncio
    async def test_wait_respects_timeout(self):
        """wait_for_background_tasks should timeout if tasks don't complete."""
        manager = BackgroundTaskManager()

        async def very_slow_task():
            await asyncio.sleep(10)

        manager.submit_background_task(very_slow_task())

        # Wait with short timeout
        result = await manager.wait_for_background_tasks(timeout=0.05)

        # Should timeout with pending tasks
        assert result['status'] in ['timeout', 'completed']
        if result['status'] == 'timeout':
            assert result['pending'] > 0

    @pytest.mark.asyncio
    async def test_handles_multiple_simultaneous_completions(self):
        """Multiple tasks completing at same time should be handled correctly."""
        manager = BackgroundTaskManager()

        async def quick_task():
            await asyncio.sleep(0.01)

        # Submit many tasks that will complete around the same time
        for _ in range(10):
            manager.submit_background_task(quick_task())

        # Wait for all to complete
        result = await manager.wait_for_background_tasks(timeout=1.0)

        # All should complete successfully
        assert result['completed'] == 10
        assert result['pending'] == 0

    @pytest.mark.asyncio
    async def test_get_status_returns_active_count(self):
        """get_task_status should return count of active tasks."""
        manager = BackgroundTaskManager()

        async def slow_task():
            await asyncio.sleep(0.2)

        # Submit 3 tasks
        manager.submit_background_task(slow_task())
        manager.submit_background_task(slow_task())
        manager.submit_background_task(slow_task())

        status = manager.get_task_status()

        assert 'pending_tasks' in status
        assert status['pending_tasks'] == 3

        # Cleanup: wait for tasks to complete
        await manager.wait_for_background_tasks(timeout=1.0)

    @pytest.mark.asyncio
    async def test_error_tracking_preserves_error_info(self):
        """Error records should include useful debugging information."""
        manager = BackgroundTaskManager()

        async def task_with_specific_error():
            raise ValueError("Specific error message")

        manager.submit_background_task(task_with_specific_error())
        await asyncio.sleep(0.05)

        status = manager.get_task_status()
        errors = status['recent_errors']

        assert len(errors) > 0
        error = errors[0]

        # Should have error details
        assert 'error' in error or 'message' in error
        assert 'type' in error or 'error_type' in error


class TestBackgroundTaskManagerThreadSafety:
    """Test thread safety of BackgroundTaskManager.

    Phase 5 of AGENT_BUG_REMEDIATION_PLAN.md:
    - Verifies _tasks dict operations are thread-safe
    - Verifies _errors deque operations are thread-safe
    - Stress tests concurrent access patterns
    """

    @pytest.mark.asyncio
    async def test_concurrent_task_submission(self):
        """Multiple rapid submissions should not corrupt task tracking."""
        manager = BackgroundTaskManager()
        task_ids = []

        async def slow_task():
            await asyncio.sleep(0.1)

        # Submit 10 tasks rapidly from the main async context
        # This tests that internal data structures handle rapid concurrent modifications
        for _ in range(10):
            task_id = manager.submit_background_task(slow_task())
            task_ids.append(task_id)

        # Should have exactly 10 unique task IDs
        assert len(task_ids) == 10
        assert len(set(task_ids)) == 10  # All unique

        # Verify status is consistent
        status = manager.get_task_status()
        assert status['pending_tasks'] == 10

        # Cleanup: wait for tasks to complete
        await manager.wait_for_background_tasks(timeout=1.0)

    @pytest.mark.asyncio
    async def test_concurrent_status_access(self):
        """Concurrent status reads should not corrupt data."""
        manager = BackgroundTaskManager()

        async def slow_task():
            await asyncio.sleep(0.2)

        # Submit some tasks
        for _ in range(5):
            manager.submit_background_task(slow_task())

        statuses = []
        lock = threading.Lock()

        def read_status():
            for _ in range(10):
                status = manager.get_task_status()
                with lock:
                    statuses.append(status)

        # Start multiple threads reading status
        threads = []
        for _ in range(5):
            t = threading.Thread(target=read_status)
            threads.append(t)
            t.start()

        for t in threads:
            t.join()

        # Should have 50 status reads (5 threads x 10 reads each)
        assert len(statuses) == 50
        # All statuses should be valid dicts
        for status in statuses:
            assert 'pending_tasks' in status
            assert 'recent_errors' in status
            assert 'total_errors' in status

        # Cleanup: wait for tasks to complete
        await manager.wait_for_background_tasks(timeout=1.0)

    @pytest.mark.asyncio
    async def test_error_deque_thread_safety(self):
        """Error recording via deque should be thread-safe."""
        manager = BackgroundTaskManager()

        async def failing_task():
            raise ValueError("Test error")

        # Submit 20 failing tasks
        for _ in range(20):
            manager.submit_background_task(failing_task())

        # Wait for all to fail
        await asyncio.sleep(0.1)

        # Check status from multiple threads simultaneously
        statuses = []
        lock = threading.Lock()

        def check_errors():
            for _ in range(5):
                status = manager.get_task_status()
                with lock:
                    statuses.append(status['total_errors'])

        threads = []
        for _ in range(5):
            t = threading.Thread(target=check_errors)
            threads.append(t)
            t.start()

        for t in threads:
            t.join()

        # All reads should show 20 errors (all tasks failed)
        assert all(count == 20 for count in statuses)

    @pytest.mark.asyncio
    async def test_error_deque_maxlen_respected(self):
        """Error deque should auto-limit to 50 entries."""
        manager = BackgroundTaskManager()

        async def failing_task(n):
            raise ValueError(f"Error {n}")

        # Submit 60 failing tasks (more than maxlen of 50)
        for i in range(60):
            manager.submit_background_task(failing_task(i))

        # Wait for all to fail
        await asyncio.sleep(0.2)

        status = manager.get_task_status()
        # Should cap at 50 due to deque maxlen
        assert status['total_errors'] == 50

    @pytest.mark.asyncio
    async def test_concurrent_cancel_and_status_access(self):
        """Concurrent cancel and status operations should not cause corruption."""
        manager = BackgroundTaskManager()
        submitted_ids = []
        cancelled_results = []
        status_results = []
        lock = threading.Lock()

        async def slow_task():
            await asyncio.sleep(1.0)

        # Submit tasks from async context
        for _ in range(5):
            task_id = manager.submit_background_task(slow_task())
            submitted_ids.append(task_id)

        def cancel_from_thread():
            """Cancel tasks from a separate thread."""
            for task_id in submitted_ids:
                result = manager.cancel_task(task_id)
                with lock:
                    cancelled_results.append(result)

        def read_status_from_thread():
            """Read status from a separate thread."""
            for _ in range(10):
                status = manager.get_task_status()
                with lock:
                    status_results.append(status)

        # Start canceller and status reader threads
        cancel_thread = threading.Thread(target=cancel_from_thread)
        status_thread = threading.Thread(target=read_status_from_thread)

        cancel_thread.start()
        status_thread.start()

        cancel_thread.join()
        status_thread.join()

        # Should not have crashed - that's the key test
        # All status reads should be valid
        assert len(status_results) == 10
        for status in status_results:
            assert 'pending_tasks' in status
            assert 'recent_errors' in status

