"use strict";(self.webpackChunk_amphi_pipeline_metadata_panel=self.webpackChunk_amphi_pipeline_metadata_panel||[]).push([[732],{732(e,n,t){t.r(n),t.d(n,{VariableInspectionHandler:()=>p,default:()=>C});var a=t(14),s=t(489),i=t(124),r=t(840),o=t(466),d=t(602),l=t(503);class _{constructor(e){this._isDisposed=!1,this._disposed=new d.Signal(this),this._inspected=new d.Signal(this),this._rendermime=null,this._connector=e}get disposed(){return this._disposed}get isDisposed(){return this._isDisposed}get inspected(){return this._inspected}get rendermime(){return this._rendermime}dispose(){this.isDisposed||(this._isDisposed=!0,this._disposed.emit(),d.Signal.clearData(this))}performDelete(e){}performAllDelete(){}}class p extends _{constructor(e){var n;super(e.connector),this._inspectionChanged=new d.Signal(this),this._handleQueryResponse=e=>{switch(e.header.msg_type){case"execute_result":{const n=e.content;n.data["text/html"];let t=n.data["text/plain"];"'"!==t.slice(0,1)&&'"'!==t.slice(0,1)||(t=t.slice(1,-1),t=t.replace(/\\"/g,'"').replace(/\\'/g,"'")),this._inspectionChanged.emit(t);const a=JSON.parse(t),s={contextName:"",kernelName:this._connector.kernelName||""};this._inspected.emit({title:s,payload:a});break}case"display_data":{let n=e.content.data["text/plain"];"'"!==n.slice(0,1)&&'"'!==n.slice(0,1)||(n=n.slice(1,-1),n=n.replace(/\\"/g,'"').replace(/\\'/g,"'"));const t=JSON.parse(n),a={contextName:"",kernelName:this._connector.kernelName||""};this._inspected.emit({title:a,payload:t});break}}},this._queryCall=(e,n)=>{switch(n.header.msg_type){case"execute_input":{const e=n.content.code;e===this._queryCommand||e===this._matrixQueryCommand||e.startsWith(this._widgetQueryCommand)||this.performInspection();break}}},this._id=e.id,this._rendermime=null!==(n=e.rendermime)&&void 0!==n?n:null,this._queryCommand=e.queryCommand,this._matrixQueryCommand=e.matrixQueryCommand,this._widgetQueryCommand=e.widgetQueryCommand,this._deleteCommand=e.deleteCommand,this._deleteAllCommand=e.deleteAllCommand,this._initScript=e.initScript,this._ready=this._connector.ready.then(()=>{this._initOnKernel().then(e=>{this._connector.iopubMessage.connect(this._queryCall)})}),this._connector.kernelRestarted.connect((e,n)=>{this._inspected.emit({title:{contextName:"<b>Restarting kernel...</b> "},payload:[]}),this._ready=n.then(()=>{this._initOnKernel().then(e=>{this._connector.iopubMessage.connect(this._queryCall)})})})}get id(){return this._id}get ready(){return this._ready}performInspection(){const e={code:this._queryCommand,stop_on_error:!1,store_history:!1};this._connector.fetch(e,this._handleQueryResponse)}performWidgetInspection(e){const n={code:this._widgetQueryCommand+"("+e+")",stop_on_error:!1,store_history:!1};return this._connector.execute(n)}performMatrixInspection(e,n=1e4){const t={code:this._matrixQueryCommand+"("+e+", "+n+")",stop_on_error:!1,store_history:!1},a=this._connector;return new Promise((e,n)=>{a.fetch(t,t=>{switch(t.header.msg_type){case"execute_result":{let n=t.content.data["text/plain"];n=n.replace(/^'|'$/g,""),n=n.replace(/\\"/g,'"'),n=n.replace(/\\'/g,"\\\\'");const a=JSON.parse(n),s=new l.JSONModel(a);e(s);break}case"error":n("Kernel error on 'matrixQuery' call!")}})})}performPreview(e){const n={code:e,stop_on_error:!1,store_history:!1},t=this._connector;return new Promise((e,a)=>{t.fetch(n,n=>{switch(n.header.msg_type){case"execute_result":{const t=n.content;if(t.data["text/html"]){const n=t.data["text/html"];e(n)}break}case"error":a("Kernel error on 'preview query' call!")}})})}performDelete(e){const n={code:this._deleteCommand+"('"+e+"')",stop_on_error:!1,store_history:!1};this._connector.fetch(n,this._handleQueryResponse)}performAllDelete(){const e={code:this._deleteAllCommand+"()",stop_on_error:!1,store_history:!1};this._connector.fetch(e,this._handleQueryResponse)}_initOnKernel(){const e={code:this._initScript,stop_on_error:!1,silent:!0};return this._connector.fetch(e,()=>{})}}class c extends _{constructor(e){super(e)}performInspection(){const e={contextName:". <b>Language currently not supported.</b> ",kernelName:this._connector.kernelName||""};this._inspected.emit({title:e,payload:[]})}performMatrixInspection(e,n){return new Promise((e,n)=>{n("Cannot inspect matrices w/ the DummyHandler!")})}performPreview(e){return new Promise((e,n)=>{n("Cannot preview df w/ the DummyHandler!")})}performWidgetInspection(e){return this._connector.execute({code:"",stop_on_error:!1,store_history:!1})}}class m{static getScript(e){return new Promise((n,t)=>{e in m.scripts?n(m.scripts[e]):t("Language "+e+" not supported yet!")})}}m.py_script='\nimport json\nimport sys\nimport types\nimport re\nfrom warnings import filterwarnings\nimport subprocess\n\nfilterwarnings("ignore", category=UserWarning, message=\'.*pandas only supports SQLAlchemy connectable.*\')\n\nfrom importlib import __import__\nfrom IPython import get_ipython\nfrom IPython.core.magics.namespace import NamespaceMagics\nfrom IPython.display import display, HTML\n\ndef safe_pip_install(*args):\n    """\n    Run \'python -m pip install ...\' but never crash the script\n    if installation fails for any reason.\n    """\n    try:\n        subprocess.run(\n            [sys.executable, "-m", "pip", "install", "--quiet", *args, "--disable-pip-version-check"],\n            check=False,  # do not raise on non-zero exit\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n        )\n    except Exception:\n        # Completely swallow any unexpected error (no crash)\n        pass\n\nsafe_pip_install("pandas>=2.0")\nsafe_pip_install("sqlalchemy>=2.0")\nsafe_pip_install("python-dotenv")\n\n_amphi_metadatapanel_nms = NamespaceMagics()\n_amphi_metadatapanel_Jupyter = get_ipython()\n# _amphi_metadatapanel_nms.shell = _amphi_metadatapanel_Jupyter.kernel.shell  \n__np = None\n__pd = None\n__pl = None\n__pyspark = None\n__tf = None\n__K = None\n__torch = None\n__ipywidgets = None\n__xr = None\n  \ndef _attempt_import(module):\n    try:\n        return __import__(module)\n    except ImportError:\n        return None\n\n\ndef _check_imported():\n    global __np, __pd, __pyspark, __tf, __K, __torch, __ipywidgets, __xr\n\n    __np = _attempt_import(\'numpy\')\n    __pd = _attempt_import(\'pandas\')\n    __pyspark = _attempt_import(\'pyspark\')\n    __tf = _attempt_import(\'tensorflow\')\n    __K = _attempt_import(\'keras.backend\') or _attempt_import(\'tensorflow.keras.backend\')\n    __torch = _attempt_import(\'torch\')\n    __ipywidgets = _attempt_import(\'ipywidgets\')\n    __xr = _attempt_import(\'xarray\')\n\n\ndef _amphi_metadatapanel_getsizeof(x):\n    if type(x).__name__ in [\'ndarray\', \'Series\']:\n        return x.nbytes\n    elif __pyspark and isinstance(x, __pyspark.sql.DataFrame):\n        return "?"\n    elif __tf and isinstance(x, __tf.Variable):\n        return "?"\n    elif __torch and isinstance(x, __torch.Tensor):\n        return x.element_size() * x.nelement()\n    elif __pd and type(x).__name__ == \'DataFrame\':\n        return x.memory_usage().sum()\n    else:\n        return sys.getsizeof(x)\n\n\ndef _amphi_metadatapanel_getshapeof(x):\n    if __pd and isinstance(x, __pd.DataFrame):\n        return "%d rows x %d cols" % x.shape\n    if __pd and isinstance(x, __pd.Series):\n        return "%d rows" % x.shape\n    if __np and isinstance(x, __np.ndarray):\n        shape = " x ".join([str(i) for i in x.shape])\n        return "%s" % shape\n    if __pyspark and isinstance(x, __pyspark.sql.DataFrame):\n        return "? rows x %d cols" % len(x.columns)\n    if __tf and isinstance(x, __tf.Variable):\n        shape = " x ".join([str(int(i)) for i in x.shape])\n        return "%s" % shape\n    if __tf and isinstance(x, __tf.Tensor):\n        shape = " x ".join([str(int(i)) for i in x.shape])\n        return "%s" % shape\n    if __torch and isinstance(x, __torch.Tensor):\n        shape = " x ".join([str(int(i)) for i in x.shape])\n        return "%s" % shape\n    if __xr and isinstance(x, __xr.DataArray):\n        shape = " x ".join([str(int(i)) for i in x.shape])\n        return "%s" % shape\n    if isinstance(x, list):\n        return "%s" % len(x)\n    if isinstance(x, dict):\n        return "%s keys" % len(x)\n    return None\n\n\ndef _amphi_metadatapanel_getcontentof(x):\n    def check_unnamed_columns(df):\n        # Consider columns with purely integer labels as unnamed, all others (including empty strings) as named\n        unnamed_columns = [col for col in df.columns if isinstance(col, int)]\n        return unnamed_columns\n\n    # Check if the input is a Pandas DataFrame and handle it\n    if __pd and isinstance(x, __pd.DataFrame):\n        unnamed_cols = check_unnamed_columns(x)\n        colnames = \', \'.join([f"{col} ({dtype}, {\'unnamed\' if col in unnamed_cols else \'named\'})" for col, dtype in zip(x.columns, x.dtypes)])\n        content = "%s" % colnames\n\n    # Check if the input is an Ibis Table and handle it similarly\n    elif "ibis" in globals() and isinstance(x, ibis.expr.types.Table):\n        schema = x.schema()\n        colnames = \', \'.join([f"{col} ({dtype}, named)" for col, dtype in schema.items()])\n        content = "%s" % colnames\n\n    # Handle other types accordingly\n    elif __pd and isinstance(x, __pd.Series):\n        content = f"{x.name} ({x.dtype}, {\'unnamed\' if x.name == \'\' or isinstance(x.name, int) else \'named\'}), " + str(x.values).replace(" ", ", ")[1:-1]\n        content = content.replace("\\n", "")\n    elif __np and isinstance(x, __np.ndarray):\n        content = f"ndarray (shape={x.shape}, dtype={x.dtype})"\n    elif __xr and isinstance(x, __xr.DataArray):\n        content = f"DataArray (shape={x.shape}, dtype={x.dtype})"\n    else:\n        content = f"{type(x).__name__}, " + str(x)\n\n    return content\n\n\ndef _amphi_metadatapanel_is_matrix(x):\n    # True if type(x).__name__ in ["DataFrame", "ndarray", "Series"] else False\n    if __pd and isinstance(x, __pd.DataFrame):\n        return True\n    if __pd and isinstance(x, __pd.Series):\n        return True\n    if __np and isinstance(x, __np.ndarray) and len(x.shape) <= 2:\n        return True\n    if __pyspark and isinstance(x, __pyspark.sql.DataFrame):\n        return True\n    if __tf and isinstance(x, __tf.Variable) and len(x.shape) <= 2:\n        return True\n    if __tf and isinstance(x, __tf.Tensor) and len(x.shape) <= 2:\n        return True\n    if __torch and isinstance(x, __torch.Tensor) and len(x.shape) <= 2:\n        return True\n    if __xr and isinstance(x, __xr.DataArray) and len(x.shape) <= 2:\n        return True\n    if isinstance(x, list):\n        return True\n    return False\n\n\ndef _amphi_metadatapanel_is_widget(x):\n    return __ipywidgets and issubclass(x, __ipywidgets.DOMWidget)\n\n\ndef get_camel_case_variables():\n    camel_case_pattern = re.compile(r\'^[a-z]+(?:[A-Z][a-z]+)*(?:\\d+)?$\')\n    variable_names = []\n    for key, value in globals().items():\n        # Skip built-in, imported modules/objects, and certain IPython/Jupyter objects\n        if not key.startswith(\'_\') and not hasattr(__builtins__, key) and not key in [\'exit\', \'quit\', \'get_ipython\', \'In\', \'Out\'] and not isinstance(value, (type(sys), types.ModuleType)) and camel_case_pattern.match(key):\n            variable_names.append(key)\n    return variable_names\n\ndef _amphi_metadatapanel_dict_list():\n    _check_imported()\n\n    def keep_cond(obj):\n        try:\n            if isinstance(obj, str):\n                return True\n            if __tf and isinstance(obj, __tf.Variable):\n                return True\n            if __pd and __pd is not None and (\n                isinstance(obj, __pd.core.frame.DataFrame)\n                or isinstance(obj, __pd.core.series.Series)):\n                return True\n            if __xr and __xr is not None and isinstance(obj, __xr.DataArray):\n                return True\n            if str(obj)[0] == "<":\n                return False\n            return True\n        except:\n            return False\n\n    camel_case_vars = get_camel_case_variables()\n    vardic = [\n        {\n            \'varName\': var_name,\n            \'varType\': type(eval(var_name)).__name__, \n            \'varSize\': str(_amphi_metadatapanel_getsizeof(eval(var_name))), \n            \'varShape\': str(_amphi_metadatapanel_getshapeof(eval(var_name))) if _amphi_metadatapanel_getshapeof(eval(var_name)) else \'\', \n            \'varContent\': str(_amphi_metadatapanel_getcontentof(eval(var_name))),\n            \'isMatrix\': _amphi_metadatapanel_is_matrix(eval(var_name)),\n            \'isWidget\': _amphi_metadatapanel_is_widget(type(eval(var_name)))\n        }\n        for var_name in camel_case_vars if keep_cond(eval(var_name))\n    ]\n    return json.dumps(vardic, ensure_ascii=False)\n  \n# 1) Updated Python helper function to add column types in parentheses\n\ndef _amphi_metadatapanel_getmatrixcontent(x, max_rows=10000):\n    # to do: add something to handle this in the future\n    threshold = max_rows\n\n    if __pd and __pyspark and isinstance(x, __pyspark.sql.DataFrame):\n        df = x.limit(threshold).toPandas()\n        return _amphi_metadatapanel_getmatrixcontent(df.copy())\n    elif __np and __pd and type(x).__name__ == "DataFrame":\n        if threshold is not None:\n            x = x.head(threshold)\n        # Force all column names to string\n        x.columns = x.columns.map(str)\n        # Append the column dtype in parentheses\n        dtypes_map = x.dtypes\n        rename_map = {}\n        for col in x.columns:\n            col_type = str(dtypes_map[col])\n            rename_map[col] = f"{col} ({col_type})"\n        x = x.rename(columns=rename_map)\n        return x.to_json(orient="table", default_handler=_amphi_metadatapanel_default, force_ascii=False)\n    elif __np and __pd and type(x).__name__ == "Series":\n        if threshold is not None:\n            x = x.head(threshold)\n        return x.to_json(orient="table", default_handler=_amphi_metadatapanel_default, force_ascii=False)\n    elif __np and __pd and type(x).__name__ == "ndarray":\n        df = __pd.DataFrame(x)\n        return _amphi_metadatapanel_getmatrixcontent(df)\n    elif __tf and (isinstance(x, __tf.Variable) or isinstance(x, __tf.Tensor)):\n        df = __K.get_value(x)\n        return _amphi_metadatapanel_getmatrixcontent(df)\n    elif __torch and isinstance(x, __torch.Tensor):\n        df = x.cpu().numpy()\n        return _amphi_metadatapanel_getmatrixcontent(df)\n    elif __xr and isinstance(x, __xr.DataArray):\n        df = x.to_numpy()\n        return _amphi_metadatapanel_getmatrixcontent(df)\n    elif isinstance(x, list):\n        s = __pd.Series(x)\n        return _amphi_metadatapanel_getmatrixcontent(s)\n\n  \n  \ndef _amphi_metadatapanel_displaywidget(widget):\n    display(widget)\n  \n  \ndef _amphi_metadatapanel_default(o):\n    if isinstance(o, __np.number): return int(o)  \n    raise TypeError\n  \ndef _amphi_metadatapanel_deletevariable(x):\n    exec("del %s" % x, globals())\n\ndef _amphi_metadatapanel_deleteallvariables():\n    camel_case_pattern = re.compile(r\'^[a-z]+(?:[A-Z][a-z]+)*(?:\\d+)?$\')\n    variable_names = []\n    for key, value in list(globals().items()):\n        if not key.startswith(\'_\') and not hasattr(__builtins__, key) and not key in [\'exit\', \'quit\', \'get_ipython\', \'In\', \'Out\', \'Session\', \'session\', \'warehouse\', \'mpd\'] and not isinstance(value, (type(sys), types.ModuleType)) and camel_case_pattern.match(key):\n            exec("del %s" % key, globals())\n\ndef __amphi_display(obj, dfName=None, nodeId=None, runtime=None):\n    """\n    Display a pandas/Snowpark DataFrame, an ibis Table, or a matplotlib Figure/Axes with metadata.\n    """\n    # Common metadata\n    metadata = {\n        "runtime": None if runtime is None else runtime,\n        "nodeId": nodeId or None,\n        "dfName": dfName or None,\n    }\n\n    # Try pandas DataFrame (supports both __pd and pd globals)\n    _pd = globals().get("__pd") or globals().get("pd")\n    if _pd is not None and isinstance(obj, _pd.DataFrame):\n        metadata["runtime"] = metadata["runtime"] or "local (pandas)"\n        result_df = obj.copy()\n        result_df.columns = [f"{col} ({obj[col].dtype})" for col in obj.columns]\n        return display(result_df, metadata=metadata)\n\n    # Try Snowflake Snowpark pandas API (modin-like)\n    mpd = globals().get("mpd")\n    if mpd is not None and hasattr(mpd, "DataFrame"):\n        try:\n            if isinstance(obj, mpd.DataFrame):\n                metadata["runtime"] = metadata["runtime"] or "Snowflake (Snowpark pandas API)"\n                result_df = obj.copy()\n                result_df.columns = [f"{col} ({obj[col].dtype})" for col in obj.columns]\n                return display(result_df, metadata=metadata)\n        except Exception:\n            pass\n\n    # Try ibis Table\n    ibis = globals().get("ibis")\n    if ibis is not None:\n        try:\n            import ibis.expr.types as itypes\n            if isinstance(obj, itypes.Table):\n                metadata["runtime"] = metadata["runtime"] or "ibis"\n                schema = obj.schema()\n                result_df = obj.execute()\n                result_df.columns = [f"{col} ({dtype})" for col, dtype in schema.items()]\n                return display(result_df, metadata=metadata)\n        except Exception:\n            pass\n\n    try:\n        from matplotlib.figure import Figure\n        from matplotlib.axes import Axes\n        import matplotlib.pyplot as plt\n\n        if isinstance(obj, Figure):\n            metadata["runtime"] = metadata["runtime"] or "matplotlib"\n            display(obj, metadata=metadata)\n            plt.close(obj)          # key line\n            return None\n\n        if isinstance(obj, Axes):\n            metadata["runtime"] = metadata["runtime"] or "matplotlib"\n            fig = obj.figure\n            display(fig, metadata=metadata)\n            plt.close(fig)          # key line\n            return None\n    except Exception:\n        pass\n\n    # Fallback if unsupported\n    raise ValueError(\n        "Unsupported type: expected pandas/Snowpark DataFrame, ibis Table, or matplotlib Figure/Axes."\n    )\n\n\ndef __amphi_display_pandas_dataframe(df, dfName=None, nodeId=None, runtime="local (pandas)"):\n    df_with_types = df.copy()\n    df_with_types.columns = [f"{col} ({df[col].dtype})" for col in df.columns]\n\n    # Use the parameters to define metadata\n    metadata = {}\n    metadata[\'runtime\'] = runtime\n    if nodeId:\n        metadata[\'nodeId\'] = nodeId\n    if dfName:\n        metadata[\'dfName\'] = dfName\n\n    display(df_with_types, metadata=metadata)\n\ndef _amphi_display_documents_as_html(documents):\n    html_content = "<div id=\'documents\'>"\n    total_docs = len(documents)\n    maxDoc = 10\n    \n    if total_docs > maxDoc:\n        # Display first maxDoc // 2 documents\n        for i, doc in enumerate(documents[:(maxDoc // 2)]):\n            html_content += "<div class=\'_amphi_document\'>"\n            html_content += f"<div class=\'_amphi_nb\'>{i+1}</div>"\n            html_content += f"<div class=\'_amphi_page_content\'><strong>Document Content:</strong> {doc.page_content}</div>"\n            html_content += f"<div class=\'_amphi_metadata\'><strong>Metadata:</strong> {doc.metadata}</div>"\n            html_content += "</div>"\n        \n        # Ellipsis to indicate skipped documents\n        html_content += "<div>...</div>"\n        \n        # Display last maxDoc // 2 documents\n        for i, doc in enumerate(documents[-(maxDoc // 2):], start=total_docs - (maxDoc // 2)):\n            html_content += "<div class=\'_amphi_document\'>"\n            html_content += f"<div class=\'_amphi_nb\'>{i+1}</div>"\n            html_content += f"<div class=\'_amphi_page_content\'><strong>Document Content:</strong> {doc.page_content}</div>"\n            html_content += f"<div class=\'_amphi_metadata\'><strong>Metadata:</strong> {doc.metadata}</div>"\n            html_content += "</div>"\n    else:\n        # Display all documents if total is maxDoc or less\n        for i, doc in enumerate(documents):\n            html_content += "<div class=\'_amphi_document\'>"\n            html_content += f"<div class=\'_amphi_nb\'>{i+1}</div>"\n            html_content += f"<div class=\'_amphi_page_content\'><strong>Document Content:</strong> {doc.page_content}</div>"\n            html_content += f"<div class=\'_amphi_metadata\'><strong>Metadata:</strong> {doc.metadata}</div>"\n            html_content += "</div>"\n    \n    html_content += "</div>"\n    display(HTML(html_content))\n',m.scripts={python3:{initScript:m.py_script,queryCommand:"_amphi_metadatapanel_dict_list()",matrixQueryCommand:"_amphi_metadatapanel_getmatrixcontent",widgetQueryCommand:"_amphi_metadatapanel_displaywidget",deleteCommand:"_amphi_metadatapanel_deletevariable",deleteAllCommand:"_amphi_metadatapanel_deleteallvariables"},python2:{initScript:m.py_script,queryCommand:"_amphi_metadatapanel_dict_list()",matrixQueryCommand:"_amphi_metadatapanel_getmatrixcontent",widgetQueryCommand:"_amphi_metadatapanel_displaywidget",deleteCommand:"_amphi_metadatapanel_deletevariable",deleteAllCommand:"_amphi_metadatapanel_deleteallvariables"},python:{initScript:m.py_script,queryCommand:"_amphi_metadatapanel_dict_list()",matrixQueryCommand:"_amphi_metadatapanel_getmatrixcontent",widgetQueryCommand:"_amphi_metadatapanel_displaywidget",deleteCommand:"_amphi_metadatapanel_deletevariable",deleteAllCommand:"_amphi_metadatapanel_deleteallvariables"}};class h{constructor(e){this._kernelRestarted=new d.Signal(this),this._session=e.session,this._session.statusChanged.connect((e,n)=>{switch(n){case"restarting":case"autorestarting":this._kernelRestarted.emit(this._session.ready)}})}get kernelRestarted(){return this._kernelRestarted}get kernelLanguage(){var e;return(null===(e=this._session.session)||void 0===e?void 0:e.kernel)?this._session.session.kernel.info.then(e=>e.language_info.name):Promise.resolve("")}get kernelName(){return this._session.kernelDisplayName}get ready(){return this._session.ready}get iopubMessage(){return this._session.iopubMessage}fetch(e,n){var t;const a=null===(t=this._session.session)||void 0===t?void 0:t.kernel;if(!a)return Promise.reject(new Error("Require kernel to perform variable inspection!"));const s=a.requestExecute(e);return s.onIOPub=e=>{n(e)},s.done}execute(e){var n;if(!(null===(n=this._session.session)||void 0===n?void 0:n.kernel))throw new Error("No session available.");return this._session.session.kernel.requestExecute(e)}}class u{constructor(){this._source=null,this._panel=null,this._handlers={}}hasHandler(e){return!!this._handlers[e]}getHandler(e){return this._handlers[e]}addHandler(e){this._handlers[e.id]=e}get panel(){return this._panel}set panel(e){this.panel!==e&&(this._panel=e,e&&!e.source&&(e.source=this._source))}get source(){return this._source}set source(e){this._source!==e&&(this._source&&this._source.disposed.disconnect(this._onSourceDisposed,this),this._source=e,this._panel&&!this._panel.isDisposed&&(this._panel.source=this._source),this._source&&this._source.disposed.connect(this._onSourceDisposed,this))}_onSourceDisposed(){this._source=null}}var f,y=t(247);class x extends y.Widget{constructor(e){super(),this._source=null,this.app=e,this.addClass("amphi-MetadataPanel"),this._title=f.createTitle(),this._title.className="amphi-MetadataPanel-title",this._table=f.createTable(),this._table.className="amphi-MetadataPanel-table",this.node.appendChild(this._title),this.node.appendChild(this._table)}get source(){return this._source}set source(e){this._source!==e&&(this._source&&(this._source.inspected.disconnect(this.onInspectorUpdate,this),this._source.disposed.disconnect(this.onSourceDisposed,this)),this._source=e,this._source&&(this._source.inspected.connect(this.onInspectorUpdate,this),this._source.disposed.connect(this.onSourceDisposed,this),this._source.performInspection()))}dispose(){this.isDisposed||(this.source=null,super.dispose())}onInspectorUpdate(e,n){if(console.log("Update detected"),!this.isAttached)return;n.title;const t=n.payload;let a;this._table.deleteTFoot(),this._table.createTFoot(),this._table.tFoot.className="amphi-MetadataPanel-content";let s="";for(let e=0;e<t.length;e++){const n=t[e],i=n.varName;n.varType,a=this._table.tFoot.insertRow(),a.className="amphi-MetadataPanel-table-row";let o=a.insertCell(0);if(n.isMatrix){o.title="View Preview",o.className="amphi-MetadataPanel-previewButton";const e=r.searchIcon.element();e.onclick=e=>{var n;const t="pipeline-console:open";this.app.commands.execute(t,{}).catch(e=>{console.error(`An error occurred during the execution of ${t}.\n${e}`)}),null===(n=this._source)||void 0===n||n.performPreview(i).then(e=>{})},o.append(e)}else o.innerHTML="";let d=a.insertCell(1);d.className="amphi-MetadataPanel-varName",d.innerHTML="<b>"+i+"</b><br><small><i>"+n.varShape+"</i></small>",a.insertCell(2).innerHTML=n.varContent.split(",").join("<br>"),s=i}const i=this._table.tFoot;if(i){const e=Array.from(i.rows);for(let n=e.length-1;n>=0;n--)i.appendChild(e[n])}}onSourceDisposed(e,n){this.source=null}_showSample(e,n){const t=new y.Widget;t.node.innerHTML=e,t.node.className="preview_data",t.title.label=n,t.title.closable=!0,t.id="widget-"+(new Date).getTime()+"-"+Math.random().toString(36).substr(2,9);let a=null;for(const e of this.app.shell.widgets("main"))if("amphi-logConsole"===e.id){a=e;break}this.app.shell.add(t,"main",{ref:a.id,mode:"tab-after"}),this.app.shell.activateById(t.id)}_showMatrix(e,n,t){const a=new l.DataGrid;a.dataModel=e,a.title.label=t+": "+n,a.title.closable=!0,this.parent.layout.addWidget(a)}}!function(e){const n=new Map(Object.entries({"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#39;","/":"&#x2F;"}));e.escapeHtml=function(e){return String(e).replace(/[&<>"'/]/g,e=>n.get(e))},e.createTable=function(){const e=document.createElement("table");e.createTHead();const n=e.tHead.insertRow(0);return n.insertCell(0).innerHTML="",n.insertCell(1).innerHTML="Component Output",n.insertCell(2).innerHTML="Schema",e},e.createTitle=function(e=""){const n=document.createElement("p");return n.innerHTML=e,n}}(f||(f={}));var g=t(262);const b=new g.Token("jupyterlab_extension/metadatapanel:IMetadataPanelManager");new g.Token("jupyterlab_extension/metadatapanel:IMetadataPanel");var v,w=t(490);!function(e){e.open="metadatapanel:open"}(v||(v={}));const C=[{id:"@amphi/pipeline-metadata-panel",requires:[a.ICommandPalette,s.ILayoutRestorer,s.ILabShell,w.ISettingRegistry],provides:b,autoStart:!0,activate:(e,n,t,s,i)=>{const o=new u,d=v.open,l="Open Metadata Panel",_=new a.WidgetTracker({namespace:"metadatapanel"});return e.commands.addCommand(d,{label:l,execute:()=>{let n=null;for(const t of e.shell.widgets("main"))if("amphi-logConsole"===t.id){n=t;break}o.panel&&!o.panel.isDisposed||(o.panel=function(){const n=new x(e);return n.id="amphi-metadataPanel",n.title.label="Metadata Panel",n.title.icon=r.inspectorIcon,n.title.closable=!0,n.disposed.connect(()=>{o.panel===n&&(o.panel=null)}),_.add(n),n}()),n&&n.isAttached?o.panel.isAttached||e.shell.add(o.panel,"main",{ref:n.id,mode:"tab-after"}):o.panel.isAttached||e.shell.add(o.panel,"main",{mode:"split-bottom"}),o.source&&o.source.performInspection(),e.shell.activateById(o.panel.id)}}),n.addItem({command:d,category:"Metadata Panel"}),e.commands.addCommand("pipeline-metadata-panel:delete-all",{label:l,execute:()=>{o.source&&o.source.performAllDelete()}}),t.restore(_,{command:d,args:()=>({}),name:()=>"metadatapanel"}),console.log("JupyterLab extension @amphi/pipeline-metadata-panel is activated!"),o}},{id:"@amphi/pipeline-metadata-panel:consoles",requires:[b,i.IConsoleTracker,s.ILabShell],autoStart:!0,activate:(e,n,t,a)=>{const s={};t.widgetAdded.connect((e,t)=>{n.hasHandler(t.sessionContext.path)?s[t.id]=new Promise((e,a)=>{e(n.getHandler(t.sessionContext.path))}):s[t.id]=new Promise((e,a)=>{const i=t.sessionContext,r=new h({session:i}),o=r.ready.then(()=>r.kernelLanguage.then(e=>m.getScript(e)));o.then(a=>{const o=a.initScript,d={queryCommand:a.queryCommand,matrixQueryCommand:a.matrixQueryCommand,widgetQueryCommand:a.widgetQueryCommand,deleteCommand:a.deleteCommand,deleteAllCommand:a.deleteAllCommand,connector:r,initScript:o,id:i.path},l=new p(d);n.addHandler(l),t.disposed.connect(()=>{delete s[t.id],l.dispose()}),l.ready.then(()=>{e(l)})}),o.catch(n=>{const a=new c(r);t.disposed.connect(()=>{delete s[t.id],a.dispose()}),e(a)})}),i(a)});const i=(e,a)=>{var i;const r=null!==(i=null==a?void 0:a.newValue)&&void 0!==i?i:e.currentWidget;r&&t.has(r)&&s[r.id].then(e=>{e&&(n.source=e,n.source.performInspection())})};i(a),a.currentChanged.connect(i),e.contextMenu.addItem({command:v.open,selector:".jp-CodeConsole"})}},{id:"@amphi/pipeline-metadata-panel:pipelines",requires:[b,o.IPipelineTracker,s.ILabShell,w.ISettingRegistry],autoStart:!0,activate:(e,n,t,a,s)=>{const i={};let r="";function o(e){r=e.get("customCodeInitialization").composite,console.log(`Settings: Amphi Metadata extension: customCodeInitialization is set to '${r}'`)}s.load("@amphi/pipeline-metadata-panel:pipelines").then(e=>{o(e),e.changed.connect(o),t.widgetAdded.connect((e,t)=>{n.hasHandler(t.context.sessionContext.path)?i[t.id]=new Promise((e,a)=>{e(n.getHandler(t.context.sessionContext.path))}):i[t.id]=new Promise((e,a)=>{const s=t.context.sessionContext,o=new h({session:s}),d=o.ready.then(()=>o.kernelLanguage.then(e=>m.getScript(e)));d.then(a=>{const d=a.initScript+"\n"+r,l={queryCommand:a.queryCommand,matrixQueryCommand:a.matrixQueryCommand,widgetQueryCommand:a.widgetQueryCommand,deleteCommand:a.deleteCommand,deleteAllCommand:a.deleteAllCommand,connector:o,initScript:d,id:s.path},_=new p(l);n.addHandler(_),t.disposed.connect(()=>{delete i[t.id],_.dispose()}),_.ready.then(()=>{e(_)})}),d.catch(n=>{const a=new c(o);t.disposed.connect(()=>{delete i[t.id],a.dispose()}),e(a)})}),s(a)});const s=(e,a)=>{var s;const r=null!==(s=null==a?void 0:a.newValue)&&void 0!==s?s:e.currentWidget;r&&t.has(r)&&i[r.id].then(e=>{e&&(n.source=e,n.source.performInspection())})};s(a),a.currentChanged.connect(s)}).catch(e=>{console.error(`Something went wrong when reading the settings.\n${e}`)})}}]}}]);