Metadata-Version: 2.4
Name: amp-rsl-rl
Version: 1.1.0
Summary: Adversarial Motion Prior (AMP) reinforcement learning extension for PPO based on RSL-RL.
Author-email: Giulio Romualdi <giulio.romualdi@iit.it>, Giuseppe L'Erario <giuseppe.lerario@iit.it>
Maintainer-email: Giulio Romualdi <giulio.romualdi@iit.it>, Giuseppe L'Erario <giuseppe.lerario@iit.it>
License-Expression: BSD-3-Clause
Project-URL: Homepage, https://github.com/ami-iit/amp-rsl-rl
Project-URL: Repository, https://github.com/ami-iit/amp-rsl-rl
Project-URL: BugTracker, https://github.com/ami-iit/amp-rsl-rl/issues
Project-URL: Changelog, https://github.com/ami-iit/amp-rsl-rl/releases
Keywords: reinforcement-learning,robotics,motion-priors,ppo
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.21.0
Requires-Dist: scipy>=1.7.0
Requires-Dist: rsl-rl-lib>=3.0.0
Requires-Dist: torch>=2.6.0
Requires-Dist: tensordict>=0.7.0
Provides-Extra: examples
Requires-Dist: huggingface_hub; extra == "examples"
Dynamic: license-file

# AMP-RSL-RL

AMP-RSL-RL is a reinforcement learning library that extends the Proximal Policy Optimization (PPO) implementation of [RSL-RL](https://github.com/leggedrobotics/rsl_rl) to incorporate Adversarial Motion Priors (AMP). This framework enables humanoid agents to learn motor skills from motion capture data using adversarial imitation learning techniques.

---

## ğŸ“¦ Installation

The repository is available on PyPI under the package name **amp-rl-rsl**. You can install it directly using pip:

```bash
pip install amp-rsl-rl
```

Alternatively, if you prefer to clone the repository and install it locally, follow these steps:

1. Clone the repository:
    ```bash
    git clone https://github.com/gbionics/amp_rsl_rl.git
    cd amp_rsl_rl
    ```

2. Install the package:
    ```bash
    pip install .
    ```

For editable/development mode:

```bash
pip install -e .
```

If you want to run the examples, please install with:

```bash
pip install .[examples]
```

The required dependencies include:

- `numpy`
- `scipy`
- `torch`
- `rsl-rl-lib`

These will be automatically installed via pip.

---

## ğŸ“‚ Project Structure

```
amp_rsl_rl/
â”‚
â”œâ”€â”€ algorithms/        # AMP and PPO implementations
â”œâ”€â”€ networks/          # Neural networks for policy and discriminator
â”œâ”€â”€ runners/           # Training and evaluation routines
â”œâ”€â”€ storage/           # Replay buffer for experience collection
â”œâ”€â”€ utils/             # Dataset loaders and motion tools
```

---

## ğŸ“ Dataset Structure

The AMP-RSL-RL framework expects motion capture datasets in `.npy` format. Each `.npy` file must contain a Python dictionary with the following keys:

- **`joints_list`**: `List[str]`  
  A list of joint names. These should correspond to the joint order expected by the agent.

- **`joint_positions`**: `List[np.ndarray]`  
  A list where each element is a NumPy array representing the joint positions at a frame. All arrays should have the same shape `(N,)`, where `N` is the number of joints.

- **`root_position`**: `List[np.ndarray]`  
  A list of 3D vectors representing the position of the base (root) of the agent in world coordinates for each frame.

- **`root_quaternion`**: `List[np.ndarray]`  
  A list of unit quaternions in **`xyzw`** format (SciPy convention), representing the base orientation of the agent for each frame.

- **`fps`**: `float`  
  The number of frames per second in the original dataset. This is used to resample the data to match the simulator's timestep.

### Example

Hereâ€™s an example of how the structure might look when loaded in Python:

```python
{
    "joints_list": ["hip", "knee", "ankle"],
    "joint_positions": [np.array([0.1, -0.2, 0.3]), np.array([0.11, -0.21, 0.31]), ...],
    "root_position": [np.array([0.0, 0.0, 1.0]), np.array([0.01, 0.0, 1.0]), ...],
    "root_quaternion": [np.array([0.0, 0.0, 0.0, 1.0]), np.array([0.0, 0.0, 0.1, 0.99]), ...],
    "fps": 120.0
}
```

All lists must have the same number of entries (i.e. one per frame). The dataset should represent smooth motion captured over time.

---

## ğŸ“š Supported Dataset

For a ready-to-use motion capture dataset, you can use the [AMP Dataset on Hugging Face](https://huggingface.co/datasets/ami-iit/amp-dataset). This dataset is curated to work seamlessly with the AMP-RSL-RL framework.

---

## ğŸ§‘â€ğŸ’» Authors

- **Giulio Romualdi** â€“ [@GiulioRomualdi](https://github.com/GiulioRomualdi)
- **Giuseppe L'Erario** â€“ [@Giulero](https://github.com/Giulero)

---

## ğŸ“„ License

BSD 3-Clause License Â© 2025 Istituto Italiano di Tecnologia
