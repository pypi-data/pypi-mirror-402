#!/usr/bin/env python3
"""
Nancy Brain MCP Server

A Model Context Protocol server that exposes Nancy's RAG (Retrieval-Augmented Generation)
fun                types.Tool(
                    name="set_retrieval_weights",
                    description="Set retrieval weights for specific documents to adjust their search ranking priority",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "doc_id": {
                                "type": "string",
                                "description": "Specific document ID to set weight for (e.g., 'microlensing_tools/MulensModel/README.md')"
                            },
                            "weight": {
                                "type": "number",
                                "description": "Weight multiplier value (will be clamped between 0.5-2.0)",
                                "minimum": 0.1,
                                "maximum": 5.0
                            },
                            "namespace": {
                                "type": "string",
                                "description": "Namespace for the weight setting",
                                "default": "global"
                            },
                            "ttl_days": {
                                "type": "integer",
                                "description": "Time-to-live in days for the weight setting",
                                "minimum": 1
                            }
                        },
                        "required": ["doc_id", "weight"]
                    }
                ),with MCP-compatible clients like Claude Desktop, VS Code, and other AI tools.

This server provides tools for:
- Searching through Nancy's knowledge base
- Retrieving specific document passages
- Exploring the document tree structure
- Managing retrieval weights and priorities

Usage:
    python -m connectors.mcp_server.server [config_path] [embeddings_path] [weights_path]
"""

import os

# Fix OpenMP issue before importing any ML libraries
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import sys
import asyncio
import argparse
from pathlib import Path
from typing import Any, Dict, List, Optional

from mcp.server import Server, InitializationOptions, NotificationOptions
from mcp import types
from mcp import stdio_server

from rag_core.service import RAGService


class NancyMCPServer:
    """Nancy Brain MCP Server implementation."""

    def __init__(self):
        self.server = Server("nancy-brain")
        self.rag_service: Optional[RAGService] = None
        self._setup_handlers()

    def _setup_handlers(self):
        """Set up MCP server handlers."""

        @self.server.list_tools()
        async def handle_list_tools() -> list[types.Tool]:
            """List available tools."""
            return [
                types.Tool(
                    name="search_knowledge_base",
                    description="Search Nancy's knowledge base for relevant documents and code",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Search query for the knowledge base",
                            },
                            "limit": {
                                "type": "integer",
                                "description": "Maximum number of results to return",
                                "default": 6,
                            },
                            "toolkit": {
                                "type": "string",
                                "description": "Filter by specific toolkit/category",
                                "enum": ["microlensing_tools", "general_tools"],
                            },
                            "doctype": {
                                "type": "string",
                                "description": "Filter by document type",
                                "enum": ["code", "documentation", "notebook"],
                            },
                            "threshold": {
                                "type": "number",
                                "description": "Minimum relevance score threshold",
                                "default": 0.0,
                            },
                        },
                        "required": ["query"],
                    },
                ),
                types.Tool(
                    name="retrieve_document_passage",
                    description="Retrieve a specific passage from a document by ID and line range",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "doc_id": {
                                "type": "string",
                                "description": "Document ID (e.g., 'microlensing_tools/MulensModel/README.md')",
                            },
                            "start": {
                                "type": "integer",
                                "description": "Starting line number (0-based)",
                                "default": 0,
                            },
                            "end": {
                                "type": "integer",
                                "description": "Ending line number (exclusive)",
                            },
                        },
                        "required": ["doc_id"],
                    },
                ),
                types.Tool(
                    name="retrieve_multiple_passages",
                    description="Retrieve multiple document passages in a single request",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "items": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "doc_id": {"type": "string"},
                                        "start": {"type": "integer", "default": 0},
                                        "end": {"type": "integer"},
                                    },
                                    "required": ["doc_id"],
                                },
                                "description": "List of document passages to retrieve",
                            }
                        },
                        "required": ["items"],
                    },
                ),
                types.Tool(
                    name="explore_document_tree",
                    description="Explore the document tree structure and list available documents",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "path": {
                                "type": "string",
                                "description": "Path prefix to filter results (e.g., 'microlensing_tools/MulensModel')",
                                "default": "",
                            },
                            "max_depth": {
                                "type": "integer",
                                "description": "Maximum depth to traverse",
                                "default": 3,
                            },
                        },
                    },
                ),
                types.Tool(
                    name="set_retrieval_weights",
                    description="Set retrieval weights to prioritize certain namespaces or document types",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "namespace": {
                                "type": "string",
                                "description": "Namespace to set weight for (e.g., 'microlensing_tools')",
                            },
                            "weight": {
                                "type": "number",
                                "description": "Weight value (higher = more priority)",
                                "minimum": 0.0,
                            },
                        },
                        "required": ["namespace", "weight"],
                    },
                ),
                types.Tool(
                    name="get_system_status",
                    description="Get Nancy Brain system status and health information",
                    inputSchema={"type": "object", "properties": {}},
                ),
            ]

        @self.server.call_tool()
        async def handle_call_tool(
            name: str, arguments: Dict[str, Any]
        ) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:
            """Handle tool calls."""
            if not self.rag_service:
                return [
                    types.TextContent(
                        type="text",
                        text="‚ùå Nancy Brain service not initialized. Please check server configuration.",
                    )
                ]

            try:
                if name == "search_knowledge_base":
                    return await self._handle_search(arguments)
                elif name == "retrieve_document_passage":
                    return await self._handle_retrieve(arguments)
                elif name == "retrieve_multiple_passages":
                    return await self._handle_retrieve_batch(arguments)
                elif name == "explore_document_tree":
                    return await self._handle_tree(arguments)
                elif name == "set_retrieval_weights":
                    return await self._handle_set_weights(arguments)
                elif name == "get_system_status":
                    return await self._handle_status(arguments)
                else:
                    return [types.TextContent(type="text", text=f"‚ùå Unknown tool: {name}")]
            except Exception as e:
                return [types.TextContent(type="text", text=f"‚ùå Error executing {name}: {str(e)}")]

    async def _handle_search(self, args: Dict[str, Any]) -> list[types.TextContent]:
        """Handle search_knowledge_base tool."""
        if not self.rag_service:
            return [
                types.TextContent(
                    type="text",
                    text="‚ùå Nancy Brain service not initialized. Please check server configuration.",
                )
            ]

        query = args["query"]
        limit = args.get("limit", 6)
        toolkit = args.get("toolkit")
        doctype = args.get("doctype")
        threshold = args.get("threshold", 0.0)

        results = await self.rag_service.search_docs(
            query=query,
            limit=limit,
            toolkit=toolkit,
            doctype=doctype,
            threshold=threshold,
        )

        if not results:
            return [types.TextContent(type="text", text=f"üîç No results found for query: '{query}'")]

        # Format results
        response_text = f"üîç **Search Results for:** '{query}'\n\n"

        for i, result in enumerate(results, 1):
            score = result.get("score", 0.0)
            doc_id = result.get("id", result.get("doc_id", "unknown"))
            text = result.get("text", "")

            response_text += f"**{i}. {doc_id}** (score: {score:.3f})\n"
            response_text += f"```\n{text[:300]}{'...' if len(text) > 300 else ''}\n```\n\n"

        return [types.TextContent(type="text", text=response_text)]

    async def _handle_retrieve(self, args: Dict[str, Any]) -> list[types.TextContent]:
        """Handle retrieve_document_passage tool."""
        doc_id = args["doc_id"]
        start = args.get("start", 0)
        end = args.get("end")

        result = await self.rag_service.retrieve(doc_id, start, end)

        if not result:
            return [types.TextContent(type="text", text=f"‚ùå Document not found: {doc_id}")]

        text = result.get("text", "")
        github_url = result.get("github_url", "")
        # Get total lines in document
        try:
            from rag_core.store import Store

            store = Store(self.rag_service.embeddings_path.parent)
            doc_path = store.base_path / doc_id
            if not doc_path.exists():
                doc_path = store.base_path / f"{doc_id}.txt"
            total_lines = 0
            if doc_path.exists():
                with open(doc_path, "r") as f:
                    total_lines = sum(1 for _ in f)
        except Exception:
            total_lines = None

        # Explicitly indicate line range and partial/full
        partial = start != 0 or (end is not None and total_lines is not None and end < total_lines)
        response_text = f"üìÑ **Document:** {doc_id}\n"
        if github_url:
            response_text += f"üîó **GitHub:** {github_url}\n"
        response_text += f"**Lines:** {start} - {end if end is not None else 'EOF'}"
        if total_lines is not None:
            response_text += f" / {total_lines} total"
        if partial:
            response_text += "\n‚ö†Ô∏è *Partial passage returned*"
        fence = "```"
        response_text += f"\n\n{fence}\n{text}\n{fence}"

        return [types.TextContent(type="text", text=response_text)]

    async def _handle_retrieve_batch(self, args: Dict[str, Any]) -> list[types.TextContent]:
        """Handle retrieve_multiple_passages tool."""
        items = args["items"]

        results = await self.rag_service.retrieve_batch(items)

        if not results:
            return [types.TextContent(type="text", text="‚ùå No documents retrieved")]

        response_text = f"üìÑ **Retrieved {len(results)} passages:**\n\n"

        from rag_core.store import Store

        store = Store(self.rag_service.embeddings_path.parent)
        for i, result in enumerate(results, 1):
            doc_id = result.get("doc_id", "unknown")
            text = result.get("text", "")
            github_url = result.get("github_url", "")
            start = items[i - 1].get("start", 0)
            end = items[i - 1].get("end")
            # Get total lines in document
            try:
                doc_path = store.base_path / doc_id
                if not doc_path.exists():
                    doc_path = store.base_path / f"{doc_id}.txt"
                total_lines = 0
                if doc_path.exists():
                    with open(doc_path, "r") as f:
                        total_lines = sum(1 for _ in f)
            except Exception:
                total_lines = None
            partial = start != 0 or (end is not None and total_lines is not None and end < total_lines)
            response_text += f"**{i}. {doc_id}**\n"
            if github_url:
                response_text += f"üîó {github_url}\n"
            response_text += f"**Lines:** {start} - {end if end is not None else 'EOF'}"
            if total_lines is not None:
                response_text += f" / {total_lines} total"
            if partial:
                response_text += "\n‚ö†Ô∏è *Partial passage returned*"
            fence = "```"
            response_text += f"\n\n{fence}\n{text}\n{fence}"
            if i < len(results):
                response_text += "\n"
        return [types.TextContent(type="text", text=response_text)]

    async def _handle_tree(self, args: Dict[str, Any]) -> list[types.TextContent]:
        """Handle explore_document_tree tool."""
        path = args.get("path", "")
        max_depth = args.get("max_depth", 3)

        tree_data = await self.rag_service.list_tree(path, max_depth)

        response_text = "üå≥ **Document Tree"
        if path:
            response_text += f" (path: {path})"
        response_text += ":**\n\n"

        def format_tree(items, indent=0):
            formatted = ""
            for item in items[:50]:  # Limit for readability
                prefix = "  " * indent
                if isinstance(item, dict):
                    name = item.get("name", "unknown")
                    if item.get("type") == "file":
                        formatted += f"{prefix}üìÑ {name}\n"
                    else:
                        formatted += f"{prefix}üìÅ {name}/\n"
                        if "children" in item:
                            formatted += format_tree(item["children"], indent + 1)
                else:
                    formatted += f"{prefix}üìÑ {item}\n"
            return formatted

        response_text += format_tree(tree_data)

        return [types.TextContent(type="text", text=response_text)]

    async def _handle_set_weights(self, args: Dict[str, Any]) -> list[types.TextContent]:
        """Handle set_retrieval_weights tool."""
        if not self.rag_service:
            return [
                types.TextContent(
                    type="text",
                    text="‚ùå Nancy Brain service not initialized. Please check server configuration.",
                )
            ]

        doc_id = args["doc_id"]
        weight = args["weight"]
        namespace = args.get("namespace", "global")
        ttl_days = args.get("ttl_days")

        await self.rag_service.set_weight(doc_id, weight, namespace, ttl_days)

        # Show the actual clamped weight
        clamped_weight = max(0.5, min(weight, 2.0))

        response_text = "‚öñÔ∏è **Weight Updated:**\n"
        response_text += f"Document: `{doc_id}`\n"
        response_text += f"Requested Weight: `{weight}`\n"
        if clamped_weight != weight:
            response_text += f"Actual Weight: `{clamped_weight}` (clamped to safe range 0.5-2.0)\n"
        else:
            response_text += f"Applied Weight: `{weight}`\n"
        response_text += f"Namespace: `{namespace}`\n"
        if ttl_days:
            response_text += f"TTL: `{ttl_days}` days\n"
        response_text += "\nThis will adjust the document's ranking in future searches."

        return [types.TextContent(type="text", text=response_text)]

    async def _handle_status(self, args: Dict[str, Any]) -> list[types.TextContent]:
        """Handle get_system_status tool."""
        if not self.rag_service:
            return [types.TextContent(type="text", text="‚ùå Nancy Brain service not initialized.")]

        # Use the merged system status (health + version + env + dependencies)
        try:
            status_info = await self.rag_service.system_status() if hasattr(self.rag_service, "system_status") else None
        except Exception:
            status_info = None
        health_info = None
        if not status_info:
            # Fallback: merge health and version manually
            health_info = await self.rag_service.health()
            version_info = await self.rag_service.version()
            status_info = {
                **version_info,
                "status": health_info.get("status", "unknown"),
                "registry_loaded": health_info.get("registry_loaded"),
                "store_loaded": health_info.get("store_loaded"),
                "search_loaded": health_info.get("search_loaded"),
            }
        else:
            # If system_status exists, try to get health info for details
            try:
                health_info = await self.rag_service.health()
            except Exception:
                health_info = None

        response_text = "üè• **Nancy Brain System Status**\n\n"
        status = status_info.get("status", "unknown")
        status_emoji = "‚úÖ" if status == "ok" else "‚ùå"
        response_text += f"{status_emoji} **Status:** {status}\n"

        # Add subsystem details
        registry_loaded = status_info.get("registry_loaded")
        store_loaded = status_info.get("store_loaded")
        search_loaded = status_info.get("search_loaded")
        # If not present, try to get from health_info
        if registry_loaded is None and health_info:
            registry_loaded = health_info.get("registry_loaded")
        if store_loaded is None and health_info:
            store_loaded = health_info.get("store_loaded")
        if search_loaded is None and health_info:
            search_loaded = health_info.get("search_loaded")

        def checkmark(val):
            return "‚úÖ" if val else "‚ùå"

        response_text += "\n**Subsystems:**\n"
        response_text += f"- Registry: {checkmark(registry_loaded)}\n"
        response_text += f"- Store: {checkmark(store_loaded)}\n"
        response_text += f"- Search: {checkmark(search_loaded)}\n"

        response_text += f"\nüè∑Ô∏è **Version:** {status_info.get('index_version', 'unknown')}\n"
        response_text += f"üî® **Build SHA:** {status_info.get('build_sha', 'unknown')}\n"
        response_text += f"üìÖ **Built At:** {status_info.get('built_at', 'unknown')}\n"
        response_text += f"üêç **Python:** {status_info.get('python_version', 'unknown')} ({status_info.get('python_implementation', 'unknown')})\n"
        response_text += f"üåé **Environment:** {status_info.get('environment', 'unknown')}\n"
        dependencies = status_info.get("dependencies", {})
        if dependencies:
            response_text += "üì¶ **Dependencies:**\n"
            for dep, ver in dependencies.items():
                response_text += f"  - {dep}: {ver}\n"

        return [types.TextContent(type="text", text=response_text)]

    async def initialize(
        self,
        config_path: Path,
        embeddings_path: Path,
        weights_path: Optional[Path] = None,
    ):
        """Initialize the RAG service."""
        try:
            self.rag_service = RAGService(
                config_path=config_path,
                embeddings_path=embeddings_path,
                weights_path=weights_path,
            )
            print("‚úÖ Nancy Brain MCP Server initialized successfully")
            print(f"üìÇ Config: {config_path}")
            print(f"üîç Embeddings: {embeddings_path}")
            if weights_path:
                print(f"‚öñÔ∏è Weights: {weights_path}")
        except Exception as e:
            print(f"‚ùå Failed to initialize Nancy Brain: {e}")
            raise

    async def run(self):
        """Run the MCP server."""
        # Using stdio transport (most common for MCP)
        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(
                read_stream,
                write_stream,
                InitializationOptions(
                    server_name="nancy-brain",
                    server_version="1.0.0",
                    capabilities=self.server.get_capabilities(
                        notification_options=NotificationOptions(),
                        experimental_capabilities={},
                    ),
                ),
            )


async def main():
    """Main entry point."""

    parser = argparse.ArgumentParser(description="Nancy Brain MCP Server")
    parser.add_argument("config_path", help="Path to repositories.yml config file")
    parser.add_argument("embeddings_path", help="Path to embeddings directory")
    parser.add_argument(
        "--weights",
        help="Path to index_weights.yaml file (extension/path weights only, NOT model weights)",
        default="config/index_weights.yaml",
    )
    parser.add_argument(
        "--http", help="Run Nancy Brain MCP server in HTTP mode (for Custom GPT connections)", action="store_true"
    )
    parser.add_argument(
        "--http-and-stdio",
        help="Run Nancy Brain MCP server in BOTH HTTP and stdio modes (for testing both interfaces)",
        action="store_true",
    )
    parser.add_argument(
        "--port",
        help="HTTP port to listen on (default: 8000)",
        type=int,
        default=8000,
    )

    args = parser.parse_args()

    config_path = Path(args.config_path)
    embeddings_path = Path(args.embeddings_path)
    weights_path = Path(args.weights) if args.weights else Path("config/index_weights.yaml")
    port = args.port

    # Validate paths
    if not config_path.exists():
        print(f"‚ùå Config file not found: {config_path}")
        sys.exit(1)

    if not embeddings_path.exists():
        print(f"‚ùå Embeddings directory not found: {embeddings_path}")
        sys.exit(1)

    if weights_path and not weights_path.exists():
        print(f"‚ùå Weights file not found: {weights_path}")
        sys.exit(1)

    # Validate that the weights file is NOT a model weights file (should not contain per-document weights)
    import yaml

    try:
        with open(weights_path, "r") as f:
            data = yaml.safe_load(f) or {}
            forbidden_keys = {"model_weights", "doc_weights", "documents"}
            if any(k in data for k in forbidden_keys):
                print(
                    f"‚ùå ERROR: The weights file '{weights_path}' appears to be a model weights file (contains {forbidden_keys}). Please provide an index_weights.yaml file for extension/path weights only."
                )
                sys.exit(1)
    except Exception as e:
        print(f"‚ùå Failed to validate weights file: {e}")
        sys.exit(1)

    # Create and run server
    server = NancyMCPServer()

    try:
        await server.initialize(config_path, embeddings_path, weights_path)

        def build_http_app():
            from fastapi import FastAPI, Request

            app = FastAPI()

            @app.get("/health")
            async def health():
                if hasattr(server.rag_service, "system_status"):
                    status = await server.rag_service.system_status()
                else:
                    status = {"status": "ok"}
                return status

            @app.get("/search")
            async def search(query: str = "", limit: int = 5):
                results = await server.rag_service.search_docs(query=query, limit=limit)
                return {"hits": results}

            @app.post("/retrieve")
            async def retrieve(request: Request):
                data = await request.json()
                doc_id = data.get("doc_id")
                start = data.get("start")
                end = data.get("end")
                try:
                    result = await server.rag_service.retrieve(doc_id, start, end)
                    return {"passage": result}
                except FileNotFoundError:
                    from fastapi.responses import JSONResponse

                    return JSONResponse({"error": f"Document not found: {doc_id}"}, status_code=404)
                except Exception as exc:
                    from fastapi.responses import JSONResponse

                    return JSONResponse({"error": str(exc)}, status_code=500)

            @app.post("/embeddings/sql")
            async def embeddings_sql(request: Request):
                data = await request.json()
                sql = data.get("sql", "")
                # Reuse search_docs as a lightweight fallback for SQL-like queries
                try:
                    rows = await server.rag_service.search_docs(query=sql, limit=500)
                except Exception:
                    rows = []
                return {"rows": rows}

            @app.get("/doc/{doc_id}/url")
            async def doc_url(doc_id: str):
                meta = server.rag_service.registry.get_meta(doc_id)
                return {"github_url": meta.github_url}

            @app.post("/mcp")
            async def mcp_endpoint(request: Request):
                payload = await request.json()
                return {"received": payload}

            return app

        if args.http_and_stdio:
            # Run BOTH HTTP and stdio servers concurrently inside this event loop.
            import uvicorn

            app = build_http_app()

            print(f"üåê Nancy Brain MCP Server running in HTTP mode on port {port}")
            print("üîó Nancy Brain MCP Server also running in stdio mode")

            config = uvicorn.Config(app, host="0.0.0.0", port=port, loop="asyncio")
            http_server = uvicorn.Server(config)

            http_task = asyncio.create_task(http_server.serve())
            stdio_task = asyncio.create_task(server.run())

            await asyncio.gather(http_task, stdio_task)
        elif args.http:
            # HTTP mode only
            import uvicorn

            app = build_http_app()

            print(f"üåê Nancy Brain MCP Server running in HTTP mode on port {port}")

            config = uvicorn.Config(app, host="0.0.0.0", port=port, loop="asyncio")
            http_server = uvicorn.Server(config)
            await http_server.serve()
        else:
            # Default: stdio mode (secure, recommended for bot)
            await server.run()
    except KeyboardInterrupt:
        print("\nüëã Nancy Brain MCP Server shutting down...")
    except Exception as e:
        print(f"‚ùå Server error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
