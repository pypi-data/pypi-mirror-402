{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac927d1-8c72-403b-8f87-3037c50c8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jnius_config\n",
    "jnius_config.set_classpath('.', 'hyflex/*')\n",
    "from jnius import autoclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f216d290-835c-44ca-b3d3-c8fe21b2fd17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import configparser\n",
    "import time\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10033ea-4e91-430a-92fd-071fb0c9cf08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义 Solution 类\n",
    "class Solution:\n",
    "    def __init__(self, id, solution, fitness):\n",
    "        self.id = id\n",
    "        self.solution = solution\n",
    "        self.fitness = fitness\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.solution)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return (self.fitness, self.id) < (other.fitness, other.id)\n",
    "\n",
    "    def __le__(self, other):\n",
    "        return self.fitness <= other.fitness\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return (self.fitness, self.id) > (other.fitness, other.id)\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        return self.fitness >= other.fitness\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def compare(self, other):\n",
    "        return self.solution == other.solution\n",
    "\n",
    "    def distance(self, other):\n",
    "        return 0\n",
    "\n",
    "# 定义 ListSolution 类\n",
    "class ListSolution(Solution):\n",
    "    def __init__(self, id=0, solution=[], fitness=float('inf')):\n",
    "        super().__init__(id, solution, fitness)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.solution)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.solution)\n",
    "\n",
    "    def distance(self, other):\n",
    "        diff = [1 if a != b else 0 for a, b in zip(self.solution, other.solution)]\n",
    "        diff.extend([1] * abs(len(self) - len(other)))\n",
    "        return np.mean(diff)\n",
    "\n",
    "    def generate_random(self, n=10):\n",
    "        self.solution = tuple(np.random.permutation(n))\n",
    "\n",
    "# 定义 StatsInfo 类\n",
    "class StatsInfo:\n",
    "    def __init__(self, initial_fitness):\n",
    "        self.fitness_hist = []  # 记录每次迭代的当前适应度值\n",
    "        self.best_fitness_hist = []  # 记录每次迭代的最佳适应度值\n",
    "        self.heuristic_hist = []  # 记录应用的启发式方法\n",
    "        self.reward_hist = []  # 记录每次迭代的奖励值\n",
    "        self.best_solution = None  # 最佳解决方案\n",
    "        self.run_id = 0  # 运行标识符\n",
    "        self.run_time = 0.0  # 运行时间\n",
    "        self.initial_fitness = initial_fitness  # 初始适应度值\n",
    "        self.best_fitness = None  # 最佳适应度值\n",
    "        self.iterations = 0  # 迭代次数\n",
    "        self.state_hist = []  # 记录每次迭代的状态\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.best_fitness)\n",
    "\n",
    "    def push_heuristic(self, heuristic, reward, state=None):\n",
    "        self.heuristic_hist.append(heuristic)\n",
    "        self.reward_hist.append(reward)\n",
    "        if state:\n",
    "            self.state_hist.append(state)\n",
    "\n",
    "    def push_fitness(self, current, best):\n",
    "        self.fitness_hist.append(current)\n",
    "        self.best_fitness_hist.append(best)\n",
    "\n",
    "    def save(self, outdir='.', save_csv=False):\n",
    "        filepath = f'{outdir}/{self.run_id}.dat'\n",
    "        pickle.dump(self, open(filepath, 'wb'))\n",
    "        if save_csv:\n",
    "            self.save_csv(outdir)\n",
    "\n",
    "    def save_csv(self, outdir='.'):\n",
    "        filename = 'fitness_history'\n",
    "        history = self.best_fitness_hist\n",
    "        initial = self.initial_fitness\n",
    "        open_flag = 'w'\n",
    "        if os.path.isfile(f'{outdir}/{filename}.csv'):\n",
    "            open_flag = 'a'\n",
    "        with open(f'{outdir}/{filename}.csv', open_flag, newline='') as evol_file:\n",
    "            w = csv.writer(evol_file, delimiter=';')\n",
    "            if open_flag == 'w':\n",
    "                w.writerow(('run', 'iter', 'fitness'))\n",
    "                w.writerow((self.run_id, 0, initial))\n",
    "            for it, fitness in enumerate(history):\n",
    "                line = (self.run_id, it+1, fitness)\n",
    "                w.writerow(line)\n",
    "\n",
    "                \n",
    "# 定义 HyperHeuristic 类\n",
    "class HyperHeuristic:\n",
    "    def __init__(self, problem, agent, credit_assignment, acceptance):\n",
    "        self.problem = problem\n",
    "        self.agent = agent\n",
    "        self.credit_assignment = credit_assignment\n",
    "        self.acceptance = acceptance\n",
    "\n",
    "    def __elapsed_time(self):\n",
    "        self.elapsed = time.process_time() - self.start_time\n",
    "        return self.elapsed\n",
    "\n",
    "    def run(self, time_limit=3):\n",
    "        self.problem.initialise_solution()\n",
    "        current_fitness = self.problem.get_fitness()\n",
    "        iterations = 0\n",
    "        stats = StatsInfo(current_fitness)\n",
    "        stats.push_fitness(current_fitness, current_fitness)\n",
    "        self.start_time = time.process_time()\n",
    "        while self.__elapsed_time() < time_limit:\n",
    "            llh = self.agent.select()\n",
    "            fitness = self.problem.apply_heuristic(llh)\n",
    "            delta = current_fitness - fitness\n",
    "            reward = self.credit_assignment.get_reward(llh, fitness, current_fitness)\n",
    "            if self.acceptance.is_solution_accepted(delta):\n",
    "                self.problem.accept_solution()\n",
    "                current_fitness = fitness\n",
    "            self.agent.update(action=llh, reward=reward, solution=self.problem.get_solution(), elapsed=self.elapsed)\n",
    "            stats.push_fitness(current_fitness, self.problem.get_best_fitness())\n",
    "            stats.push_heuristic(llh, reward, self.agent.get_env_state())\n",
    "            iterations += 1\n",
    "        stats.best_fitness = self.problem.get_best_fitness()\n",
    "        stats.run_time = self.elapsed\n",
    "        stats.iterations = iterations\n",
    "        return stats\n",
    "\n",
    "# 定义 AcceptAll 类\n",
    "class AcceptAll:\n",
    "    def is_solution_accepted(self, *args):\n",
    "        return True\n",
    "\n",
    "# 定义 RawImprovementPenalty 类\n",
    "class RawImprovementPenalty:\n",
    "    def __init__(self, config, actions, *args):\n",
    "        pass\n",
    "\n",
    "    def get_reward(self, action, new_fitness, past_fitness, *args):\n",
    "        fir = (past_fitness - new_fitness) / past_fitness\n",
    "        return fir\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "# 定义 StateBuilder 类\n",
    "class StateBuilder:\n",
    "    def __init__(self, state_classes, config, **kwargs):\n",
    "        self.states = [state_cls(config, **kwargs) for state_cls in state_classes]\n",
    "\n",
    "    def reset(self):\n",
    "        for state_obj in self.states:\n",
    "            state_obj.reset()\n",
    "\n",
    "    def get_state(self):\n",
    "        state = []\n",
    "        for state_obj in self.states:\n",
    "            state.extend(state_obj.get_state())\n",
    "        return state\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for state_obj in self.states:\n",
    "            state_obj.update(**kwargs)\n",
    "\n",
    "# 定义 FitnessImprovementRate 类\n",
    "class FitnessImprovementRate:\n",
    "    def __init__(self, config, **kwargs):\n",
    "        self.discrete = config['FIR'].getboolean('discrete', False)\n",
    "        self.fir = 0\n",
    "        self.last_fitness = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.fir = 0\n",
    "        self.last_fitness = None\n",
    "\n",
    "    def _get_discrete_state(self):\n",
    "        if self.fir > 0:\n",
    "            return 1\n",
    "        elif self.fir == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def get_state(self):\n",
    "        if self.discrete:\n",
    "            return [self._get_discrete_state()]\n",
    "        return [self.fir]\n",
    "\n",
    "    def update(self, solution, **kwargs):\n",
    "        if self.last_fitness is not None:\n",
    "            self.fir = (self.last_fitness - solution.fitness) / self.last_fitness\n",
    "        self.last_fitness = solution.fitness\n",
    "\n",
    "# 定义 ElapsedTime 类\n",
    "class ElapsedTime:\n",
    "    def __init__(self, config, time_limit, **kwargs):\n",
    "        self.time_limit = time_limit\n",
    "        self.elapsed = 0\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def get_state(self):\n",
    "        return [self.elapsed / self.time_limit]\n",
    "\n",
    "    def update(self, elapsed, **kwargs):\n",
    "        self.elapsed = elapsed\n",
    "\n",
    "# 定义 Agent 类\n",
    "class Agent:\n",
    "    def __init__(self, actions, policy):\n",
    "        self.actions = actions\n",
    "        self.policy = policy\n",
    "\n",
    "    def reset(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def select(self):\n",
    "        action_idx = self.policy.select(self)\n",
    "        return self.actions[action_idx]\n",
    "\n",
    "    def get_env_state(self):\n",
    "        return None\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "# 定义 RandomAgent 类\n",
    "class RandomAgent(Agent):\n",
    "    def __init__(self, config, actions, state_env, prior=[], **kwargs):\n",
    "        super().__init__(actions, RoulettePolicy(config))\n",
    "        self.prior = prior\n",
    "        n_actions = len(actions)\n",
    "        if len(prior) != n_actions:\n",
    "            self.prior = [float(1/n_actions)] * n_actions\n",
    "        self.value_estimates = self.prior\n",
    "        self.state_env = state_env\n",
    "        self.state = self.state_env.get_state()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Random Selection'\n",
    "\n",
    "    def reset(self):\n",
    "        self.value_estimates = self.prior\n",
    "\n",
    "    def get_env_state(self):\n",
    "        return self.state\n",
    "\n",
    "    def update(self, action, reward, solution, elapsed):\n",
    "        self.state_env.update(action=action, \n",
    "                              reward=reward, \n",
    "                              solution=solution, \n",
    "                              elapsed=elapsed)\n",
    "        self.state = self.state_env.get_state()\n",
    "\n",
    "# 定义 RoulettePolicy 类\n",
    "class RoulettePolicy:\n",
    "    def __init__(self, config):\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Roulette Wheel'\n",
    "\n",
    "    def select(self, agent):\n",
    "        sample = range(len(agent.actions))\n",
    "        return random.choices(sample, weights=agent.value_estimates)[0]\n",
    "\n",
    "# 定义 HyFlexDomain 类\n",
    "class HyFlexDomain:\n",
    "    solution_indexer = count(1)\n",
    "\n",
    "    def __init__(self, problem_str, instance_id, seed):\n",
    "        with open(f'hyflex/problems_json/{problem_str}.json', 'r') as json_file:\n",
    "            self.problem_dict = json.load(json_file)\n",
    "        ProblemClass = autoclass(self.problem_dict['class'])\n",
    "        self.problem = ProblemClass(seed)\n",
    "        self.problem.loadInstance(instance_id)\n",
    "        try:\n",
    "            self.instance_name = self.problem_dict['instances'][str(instance_id)]\n",
    "        except KeyError:\n",
    "            self.instance_name = f'id_{instance_id}'\n",
    "        self.actions = self.problem_dict['actions']\n",
    "\n",
    "    def initialise_solution(self, idx=0):\n",
    "        self.problem.initialiseSolution(idx)\n",
    "\n",
    "    def get_fitness(self, idx=0):\n",
    "        return self.problem.getFunctionValue(idx)\n",
    "\n",
    "    def apply_heuristic(self, llh, src_idx=0, dest_idx=1):\n",
    "        return self.problem.applyHeuristic(int(llh), int(src_idx), int(dest_idx))\n",
    "\n",
    "    def accept_solution(self, src_idx=1, dest_idx=0):\n",
    "        self.problem.copySolution(src_idx, dest_idx)\n",
    "\n",
    "    def get_best_fitness(self):\n",
    "        return self.problem.getBestSolutionValue()\n",
    "\n",
    "    def get_solution(self, idx=0):\n",
    "        solution_str = self.problem.solutionToString(idx)\n",
    "        id = next(self.solution_indexer)\n",
    "        return Solution(id, solution_str, self.get_fitness(idx))\n",
    "\n",
    "# 定义 BinPacking 类\n",
    "class BinPacking(HyFlexDomain):\n",
    "    re_bin_items = re.compile(r'(\\d+\\.0, )')\n",
    "\n",
    "    def __init__(self, instance_id, seed):\n",
    "        super().__init__('BP', instance_id, seed)\n",
    "\n",
    "    def get_solution(self, idx=0):\n",
    "        solution_str = self.problem.solutionToString(idx)\n",
    "        sorted_bins = []\n",
    "        for bin in solution_str.split('\\n')[:-2]:\n",
    "            items = [float(it.strip('[, ]')) for it in re.findall(self.re_bin_items, bin)]\n",
    "            sorted_bins.append(sorted(items))\n",
    "        sorted_bins.sort()\n",
    "        fitness = self.get_fitness(idx)\n",
    "        id = next(self.solution_indexer)\n",
    "        return ListSolution(id, sorted_bins, fitness)\n",
    "\n",
    "\n",
    "# 定义 TSP 类\n",
    "class TravelingSalesman(HyFlexDomain):\n",
    "    def __init__(self, instance_id, seed):\n",
    "        HyFlexDomain.__init__(self, 'TSP', instance_id, seed)\n",
    "\n",
    "    def get_solution(self, idx=0):\n",
    "        solution_str = self.problem.solutionToString(idx)\n",
    "        solution_str = solution_str.split('\\n')[1].strip()\n",
    "        permutation = tuple((int(x) for x in solution_str.split(' ')))\n",
    "        fitness = self.get_fitness(idx)\n",
    "        id = next(self.solution_indexer)\n",
    "        return ListSolution(id, permutation, fitness)\n",
    "    \n",
    "\n",
    "_output_path_dir = \"/home/Chaofan_Tu/Documents/hyflex3/hhrl/results/\"\n",
    "\n",
    "# 定义代理对象的字典，包含了各种代理的名称和对应的类\n",
    "agent_dict = {\n",
    "        'RAND': RandomAgent,\n",
    "        }\n",
    "# 定义奖励对象的字典，包含了各种奖励的名称和对应的类\n",
    "reward_dict = {\n",
    "        'RIP': RawImprovementPenalty,\n",
    "        }\n",
    "# 定义状态对象的字典，包含了各种状态的名称和对应的类\n",
    "state_dict = {\n",
    "        'S7': [FitnessImprovementRate, ElapsedTime],\n",
    "        }\n",
    "# 定义接受对象的字典，包含了各种接受对象的名称和对应的类\n",
    "acceptance_dict = {\n",
    "    'ALL': AcceptAll,\n",
    "        }\n",
    "# 定义问题对象的字典，包含了各种问题的名称和对应的类\n",
    "domain_dict = {\n",
    "        'TSP': TravelingSalesman,\n",
    "        'BP': BinPacking,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c2f7e0-e872-4307-b98b-d8d00372011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n",
      "self_problem_dict: {'class': 'BinPacking.BinPacking', 'actions': [0, 1, 2, 3, 4, 5, 6], 'instances': {'0': 'falkenauer/falk1000-1', '1': 'falkenauer/falk1000-2', '2': 'schoenfield/schoenfieldhard1', '3': 'schoenfield/schoenfieldhard2', '4': '2000/10-30/instance1', '5': '2000/10-30/instance2', '6': 'trip1002/instance1', '7': 'trip2004/instance1', '8': 'testdual4/binpack0', '9': 'testdual7/binpack0'}}\n"
     ]
    }
   ],
   "source": [
    "seed = random.randint(0, 10000)\n",
    "seed = 1501\n",
    "print(seed)\n",
    "instance_id = 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(f'hyflex/problems_json/BP.json', 'r') as json_file:\n",
    "        self_problem_dict = json.load(json_file)\n",
    "    print(f'self_problem_dict: {self_problem_dict}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6cf44f1-1af4-4542-b728-fa24d3385fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "#import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "problem_str = 'BP'\n",
    "instance_id = 0\n",
    "seed = random.randint(0, 10000)\n",
    "problemjson_path = 'hyflex/problems_json'\n",
    "\n",
    "\n",
    "class HyflexEnv(gym.Env):\n",
    "    def __init__(self, \n",
    "                 problem_str, \n",
    "                 instance_id, \n",
    "                 seed=seed, \n",
    "                 problemjson_path=problemjson_path):\n",
    "        super(HyflexEnv, self).__init__()\n",
    "        \n",
    "        self.problem_str = problem_str\n",
    "        self.instance_id = instance_id\n",
    "        self.seed = seed\n",
    "        self.problemjson_path = problemjson_path\n",
    "        self.steps = 0\n",
    "        \n",
    "        # 加载问题字典\n",
    "        with open(f'{self.problemjson_path}/{self.problem_str}.json', 'r') as json_file:\n",
    "            self.problem_dict = json.load(json_file)\n",
    "        \n",
    "        self.n_actions = self.problem_dict['actions']\n",
    "        \n",
    "        # 定义动作空间和观察空间\n",
    "        self.action_space = gym.spaces.Discrete(len(self.n_actions))\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(1,))\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        # 重置环境，重新初始化问题实例\n",
    "        self.problem_instance = domain_dict[self.problem_str](self.instance_id, self.seed)\n",
    "        self.problem_instance.initialise_solution()\n",
    "        \n",
    "        # 更新当前适应度和最佳适应度\n",
    "        self.current_fitness = self.problem_instance.get_fitness()\n",
    "        self.best_fitness = self.current_fitness\n",
    "        \n",
    "        # 重置步数\n",
    "        self.steps = 0\n",
    "        self.done = False\n",
    "        self._seed = 0\n",
    "        \n",
    "        # 返回初始观察值\n",
    "        return np.array([self.current_fitness])\n",
    "        \n",
    "    def step(self, llh):\n",
    "        # 应用动作并计算新的适应度\n",
    "        new_fitness = self.problem_instance.apply_heuristic(self.n_actions[llh])\n",
    "        \n",
    "        # 计算适应度变化量\n",
    "        delta = new_fitness - self.current_fitness\n",
    "        \n",
    "        #print(delta)\n",
    "        \n",
    "        # 更新当前适应度\n",
    "        self.current_fitness = new_fitness\n",
    "        \n",
    "        # 如果新适应度优于最佳适应度，则接受新解\n",
    "        if new_fitness > self.best_fitness:\n",
    "            self.best_fitness = new_fitness\n",
    "            self.problem_instance.accept_solution()\n",
    "        \n",
    "        # 判断是否达到终止条件\n",
    "        if self.steps > 10000:\n",
    "            self.done = True\n",
    "        \n",
    "        self.steps += 1\n",
    "        if self.steps % 1000 == 0:\n",
    "            print(f\"self.steps:{self.steps}\")\n",
    "        \n",
    "        # 返回新的观察值、奖励、是否结束和其他信息\n",
    "        return np.array([self.current_fitness]), delta, self.done, {}\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        # 可视化环境\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        # 清理环境\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "env = HyflexEnv('BP', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb91654-4e0e-4000-b4ff-855e0de52782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Chaofan_Tu/miniconda3/envs/hyflex/lib/python3.9/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "self.steps:1000\n",
      "self.steps:2000\n",
      "self.steps:3000\n",
      "self.steps:4000\n",
      "self.steps:5000\n",
      "self.steps:6000\n",
      "self.steps:7000\n",
      "self.steps:8000\n",
      "self.steps:9000\n",
      "self.steps:10000\n",
      "self.steps:1000\n",
      "self.steps:2000\n",
      "self.steps:3000\n",
      "self.steps:4000\n",
      "self.steps:5000\n",
      "self.steps:6000\n",
      "self.steps:7000\n",
      "self.steps:8000\n",
      "self.steps:9000\n",
      "self.steps:10000\n",
      "self.steps:1000\n",
      "self.steps:2000\n",
      "self.steps:3000\n",
      "self.steps:4000\n",
      "self.steps:5000\n",
      "self.steps:6000\n",
      "self.steps:7000\n",
      "self.steps:8000\n",
      "self.steps:9000\n",
      "self.steps:10000\n",
      "self.steps:1000\n",
      "self.steps:2000\n",
      "self.steps:3000\n",
      "self.steps:4000\n",
      "self.steps:5000\n",
      "self.steps:6000\n",
      "self.steps:7000\n",
      "self.steps:8000\n",
      "self.steps:9000\n",
      "self.steps:10000\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 40008    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.27e-07 |\n",
      "|    n_updates        | 9976     |\n",
      "----------------------------------\n",
      "self.steps:1000\n",
      "self.steps:2000\n",
      "self.steps:3000\n",
      "self.steps:4000\n",
      "self.steps:5000\n",
      "self.steps:6000\n",
      "self.steps:7000\n",
      "self.steps:8000\n",
      "self.steps:9000\n",
      "self.steps:1000\n",
      "self.steps:2000\n",
      "self.steps:3000\n",
      "self.steps:4000\n",
      "self.steps:5000\n",
      "self.steps:6000\n",
      "self.steps:7000\n",
      "self.steps:8000\n",
      "self.steps:9000\n",
      "self.steps:10000\n",
      "Step reward: [0.], Total reward: [0.6951903]\n",
      "Current Fitness: [[0.1083772]]\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 创建环境\n",
    "    env = HyflexEnv('BP', 0)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    \n",
    "    # 配置DQN模型\n",
    "    model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.learn(total_timesteps=50000)\n",
    "    \n",
    "    # 保存模型\n",
    "    model.save(\"hyflex_dqn.zip\")\n",
    "    \n",
    "    # 加载模型\n",
    "    model = DQN.load(\"hyflex_dqn.zip\", env=env)\n",
    "    \n",
    "    # 评估模型\n",
    "    total_reward = 0\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    print(f\"Step reward: {reward}, Total reward: {total_reward}\")\n",
    "    print(f\"Current Fitness: {obs}\")\n",
    "    print(\"END\")\n",
    "    \n",
    "    # 关闭环境\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddc1e5-dc21-4217-8a40-23d3e10bb92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel_hyflex",
   "language": "python",
   "name": "hyflex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
