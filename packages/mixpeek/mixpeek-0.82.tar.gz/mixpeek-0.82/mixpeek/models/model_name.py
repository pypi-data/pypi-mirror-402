# coding: utf-8

"""
    Mixpeek API

    This is the Mixpeek API, providing access to various endpoints for data processing and retrieval.

    The version of the OpenAPI document: 0.82
    Contact: info@mixpeek.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
from inspect import getfullargspec
import json
import pprint
import re  # noqa: F401
from pydantic import BaseModel, ConfigDict, Field, StrictStr, ValidationError, field_validator
from typing import Optional
from mixpeek.models.anthropic_model import AnthropicModel
from mixpeek.models.google_model import GoogleModel
from mixpeek.models.open_ai_model import OpenAIModel
from typing import Union, Any, List, Set, TYPE_CHECKING, Optional, Dict
from typing_extensions import Literal, Self
from pydantic import Field

MODELNAME_ANY_OF_SCHEMAS = ["AnthropicModel", "GoogleModel", "OpenAIModel"]

class ModelName(BaseModel):
    """
    REQUIRED when enabled=True. Specific LLM model to use for cluster labeling. All models are defined as enums for type safety.  OpenAI Models (provider='openai'): - gpt-4o-2024-08-06: Highest quality, best for production ($2.50/$10 per 1M tokens) - gpt-4o-mini-2024-07-18: Cost-effective, recommended for most use cases ($0.15/$0.60 per 1M tokens) - gpt-4.1-2025-04-14: Latest model, future-proofed - gpt-4.1-mini-2025-04-14: Latest cost-optimized model - o3-mini-2025-01-31: Advanced reasoning, best for complex clustering  Google Models (provider='google'): - gemini-2.0-flash: Fastest, latest multimodal model, recommended ($0.075/$0.30 per 1M tokens) - gemini-2.0-flash-exp: Experimental version with latest features ($0.075/$0.30 per 1M tokens)  Anthropic Models (provider='anthropic'): - claude-3-5-sonnet-20241022: Best reasoning, 200K context ($3/$15 per 1M tokens) - claude-3-5-haiku-20241022: Fast, cost-effective ($0.25/$1.25 per 1M tokens)  Recommendation: - Use gemini-2.0-flash (DEFAULT) - cheapest option with multimodal support - Use gpt-4o-mini-2024-07-18 for OpenAI compatibility - Use gpt-4o-2024-08-06 for highest quality when cost is not a concern
    """

    # data type: OpenAIModel
    anyof_schema_1_validator: Optional[OpenAIModel] = None
    # data type: GoogleModel
    anyof_schema_2_validator: Optional[GoogleModel] = None
    # data type: AnthropicModel
    anyof_schema_3_validator: Optional[AnthropicModel] = None
    if TYPE_CHECKING:
        actual_instance: Optional[Union[AnthropicModel, GoogleModel, OpenAIModel]] = None
    else:
        actual_instance: Any = None
    any_of_schemas: Set[str] = { "AnthropicModel", "GoogleModel", "OpenAIModel" }

    model_config = {
        "validate_assignment": True,
        "protected_namespaces": (),
    }

    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator('actual_instance')
    def actual_instance_must_validate_anyof(cls, v):
        instance = ModelName.model_construct()
        error_messages = []
        # validate data type: OpenAIModel
        if not isinstance(v, OpenAIModel):
            error_messages.append(f"Error! Input type `{type(v)}` is not `OpenAIModel`")
        else:
            return v

        # validate data type: GoogleModel
        if not isinstance(v, GoogleModel):
            error_messages.append(f"Error! Input type `{type(v)}` is not `GoogleModel`")
        else:
            return v

        # validate data type: AnthropicModel
        if not isinstance(v, AnthropicModel):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AnthropicModel`")
        else:
            return v

        if error_messages:
            # no match
            raise ValueError("No match found when setting the actual_instance in ModelName with anyOf schemas: AnthropicModel, GoogleModel, OpenAIModel. Details: " + ", ".join(error_messages))
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Dict[str, Any]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        # anyof_schema_1_validator: Optional[OpenAIModel] = None
        try:
            instance.actual_instance = OpenAIModel.from_json(json_str)
            return instance
        except (ValidationError, ValueError) as e:
             error_messages.append(str(e))
        # anyof_schema_2_validator: Optional[GoogleModel] = None
        try:
            instance.actual_instance = GoogleModel.from_json(json_str)
            return instance
        except (ValidationError, ValueError) as e:
             error_messages.append(str(e))
        # anyof_schema_3_validator: Optional[AnthropicModel] = None
        try:
            instance.actual_instance = AnthropicModel.from_json(json_str)
            return instance
        except (ValidationError, ValueError) as e:
             error_messages.append(str(e))

        if error_messages:
            # no match
            raise ValueError("No match found when deserializing the JSON string into ModelName with anyOf schemas: AnthropicModel, GoogleModel, OpenAIModel. Details: " + ", ".join(error_messages))
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(self) -> Optional[Union[Dict[str, Any], AnthropicModel, GoogleModel, OpenAIModel]]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())


