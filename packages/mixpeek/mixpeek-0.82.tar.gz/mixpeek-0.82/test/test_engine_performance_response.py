# coding: utf-8

"""
    Mixpeek API

    This is the Mixpeek API, providing access to various endpoints for data processing and retrieval.

    The version of the OpenAPI document: 0.82
    Contact: info@mixpeek.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from mixpeek.models.engine_performance_response import EnginePerformanceResponse

class TestEnginePerformanceResponse(unittest.TestCase):
    """EnginePerformanceResponse unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> EnginePerformanceResponse:
        """Test EnginePerformanceResponse
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `EnginePerformanceResponse`
        """
        model = EnginePerformanceResponse()
        if include_optional:
            return EnginePerformanceResponse(
                time_range = mixpeek.models.time_range.TimeRange(
                    start = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    end = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), ),
                metrics = [
                    mixpeek.models.performance_metric.PerformanceMetric(
                        time_bucket = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        execution_count = 56, 
                        avg_latency_ms = 1.337, 
                        p50_latency_ms = 1.337, 
                        p95_latency_ms = 1.337, 
                        p99_latency_ms = 1.337, 
                        max_latency_ms = 1.337, )
                    ],
                summary = mixpeek.models.performance_summary.PerformanceSummary(
                    total_executions = 56, 
                    avg_latency_ms = 1.337, 
                    p50_latency_ms = 1.337, 
                    p95_latency_ms = 1.337, 
                    p99_latency_ms = 1.337, 
                    max_latency_ms = 1.337, 
                    total_time_seconds = 1.337, )
            )
        else:
            return EnginePerformanceResponse(
                time_range = mixpeek.models.time_range.TimeRange(
                    start = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                    end = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), ),
                metrics = [
                    mixpeek.models.performance_metric.PerformanceMetric(
                        time_bucket = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                        execution_count = 56, 
                        avg_latency_ms = 1.337, 
                        p50_latency_ms = 1.337, 
                        p95_latency_ms = 1.337, 
                        p99_latency_ms = 1.337, 
                        max_latency_ms = 1.337, )
                    ],
        )
        """

    def testEnginePerformanceResponse(self):
        """Test EnginePerformanceResponse"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
