# Copyright 2026 Boring for Gemini Authors
# SPDX-License-Identifier: Apache-2.0
"""
Vibe Coder Pro Tools - è®“ Vibe Coder ç¨‹å¼ç¢¼é”åˆ°å·¥ç¨‹å¸«æ°´æº–ã€‚

åŒ…å«:
- boring_test_gen: è‡ªå‹•ç”Ÿæˆå–®å…ƒæ¸¬è©¦ (æ”¯æ´å¤šèªè¨€) + RAG é¢¨æ ¼åƒè€ƒ
- boring_code_review: AI ç¨‹å¼ç¢¼å¯©æŸ¥ (æ”¯æ´å¤šèªè¨€) + BrainManager Pattern æ•´åˆ
- boring_vibe_check: éŠæˆ²åŒ–å¥æª¢ (æ•´åˆ Lint, Security, Doc) + Storage æ­·å²è¿½è¹¤
- boring_impact_check: è¡æ“Šåˆ†æ (å¤šå±¤ä¾è³´è¿½è¹¤) + RAG èªç¾©åˆ†æ

V10.21 æ•´åˆ:
- BrainManager: åƒè€ƒå·²å­¸ç¿’çš„ Pattern é€²è¡Œå¯©æŸ¥
- RAG: èªç¾©æœå°‹ç¾æœ‰æ¸¬è©¦é¢¨æ ¼ã€ä¾è³´åˆ†æ
- Storage: è¨˜éŒ„ Vibe Score æ­·å²è¶¨å‹¢

ç§»æ¤è‡ª vibe_tools.py (V10.26.0)
"""

import logging
from pathlib import Path

logger = logging.getLogger(__name__)
from typing import Annotated

from pydantic import Field

from ...paths import get_boring_path
from ...security import SecurityScanner  # Phase 14 Enhancement

# V11.2.2: Standardization
from ...types import BoringResult, create_error_result, create_success_result
from ..verbosity import is_minimal, is_standard, is_verbose

# Lazy loaded engine
_vibe_engine = None


def get_vibe_engine():
    """Get the VibeEngine singleton, initializing it lazily."""
    global _vibe_engine
    if _vibe_engine is None:
        from ...vibe.engine import VibeEngine
        from ...vibe.handlers.generic import GenericHandler
        from ...vibe.handlers.javascript import JavascriptHandler
        from ...vibe.handlers.python import PythonHandler

        _vibe_engine = VibeEngine()
        _vibe_engine.register_handler(PythonHandler())
        _vibe_engine.register_handler(JavascriptHandler())
        _vibe_engine.register_handler(GenericHandler())

    return _vibe_engine


# =============================================================================
# Boring Core Integration Helpers (V10.21)
# =============================================================================
def _get_brain_manager(project_root: Path):
    """Get BrainManager instance for pattern retrieval."""
    try:
        from ...intelligence import BrainManager

        return BrainManager(project_root)
    except Exception:
        return None


def _get_storage(project_root: Path):
    """Get SQLiteStorage instance for metrics recording."""
    try:
        from ...services.storage import SQLiteStorage

        # Phase 10: Use unified path .boring/memory
        memory_dir = get_boring_path(project_root, "memory")
        storage = SQLiteStorage(memory_dir)
        return storage
    except ImportError:
        # Missing dependency (unlikely, but possible)
        return None
    except Exception as e:
        # Any other initialization error (permissions, disk space, etc.)
        # Log to stderr for debugging, but don't crash the tool
        import sys

        sys.stderr.write(f"[boring] Warning: Failed to initialize Storage: {e}\n")
        return None


def _get_rag_retriever(project_root: Path):
    """Get RAGRetriever instance for semantic search."""
    try:
        from ..rag.rag_retriever import RAGRetriever

        retriever = RAGRetriever(project_root)
        if retriever.is_available:
            return retriever
    except Exception as e:
        logger.debug("RAGRetriever unavailable: %s", e)
    return None


def _get_project_root_or_error_impl(
    project_path_str: str | None,
) -> tuple[str | None, dict | None]:
    """Module-level implementation of get_project_root_or_error."""
    if project_path_str:
        path = Path(project_path_str)
        try:
            if not path.exists():
                return None, {"message": f"Project path does not exist: {path}"}
            return str(path), None
        except Exception as e:
            return None, {"message": f"Invalid project path: {e}"}

    # Fallback to settings
    try:
        from ...core.config import settings

        return str(settings.PROJECT_ROOT), None
    except ImportError:
        return ".", None


def run_vibe_check(
    target_path: str = ".",
    project_path: str | None = None,
    max_files: int = 10,
    verbosity: str = "standard",
) -> BoringResult:
    """
    Module-level Vibe Check implementation.
    Can be called directly by FlowEngine or other components.
    """
    root_str, error = _get_project_root_or_error_impl(project_path)
    if error:
        return create_error_result(error.get("message", "Unknown error"))

    project_root = Path(root_str)
    # Handle both absolute and relative paths
    if target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":"):
        # Absolute path (Unix-style or Windows-style)
        target = Path(target_path)
    elif target_path == ".":
        target = project_root
    else:
        # Relative path
        target = project_root / target_path

    if not target.exists():
        return create_error_result(f"âŒ æ‰¾ä¸åˆ°ç›®æ¨™: {target}")

    # 1. æ”¶é›†æª”æ¡ˆ
    files_to_check = []
    if target.is_file():
        files_to_check.append(target)
    else:
        candidates = [
            p
            for p in target.rglob("*")
            if p.is_file()
            and p.suffix in [".py", ".js", ".ts"]
            and not any(x in p.parts for x in ["node_modules", ".git", "venv"])
        ][:max_files]
        files_to_check.extend(candidates)

    if not files_to_check:
        return create_error_result("âš ï¸ æ‰¾ä¸åˆ°å¯åˆ†æçš„ç¨‹å¼ç¢¼æª”æ¡ˆ (.py, .js, .ts)")

    # Scoring Variables
    base_score = 100
    deductions = 0
    issues_found = []
    doc_missing = 0
    security_issues = []

    # Lazy load engine
    engine = get_vibe_engine()

    # 2. é€æª”åˆ†æ
    for f in files_to_check:
        try:
            content = f.read_text(encoding="utf-8", errors="ignore")

            # A. Code Review (Lint/Quality)
            rev_res = engine.perform_code_review(str(f), content, focus="all")
            for issue in rev_res.issues:
                deduction = (
                    5 if issue.severity == "low" else 10 if issue.severity == "medium" else 15
                )
                deductions += deduction
                issues_found.append(f"[{f.name}:{issue.line}] {issue.message}")

            # B. Doc Check
            doc_res = engine.extract_documentation(str(f), content)
            for item in doc_res.items:
                if not item.docstring:
                    deductions += 5
                    doc_missing += 1

        except Exception:
            continue

    # 3. Security Scan (Phase 14 Enhancement)
    try:
        scanner = SecurityScanner(project_root)
        sec_report = scanner.scan_for_secrets(target if target.is_dir() else target.parent)
        for sec_issue in sec_report.issues:
            severity_deduction = (
                20
                if sec_issue.severity == "CRITICAL"
                else 15
                if sec_issue.severity == "HIGH"
                else 10
            )
            deductions += severity_deduction
            security_issues.append(
                f"ğŸ”’ [{sec_issue.severity}] {sec_issue.description} ({sec_issue.file_path}:{sec_issue.line_number})"
            )
    except Exception:
        pass  # Security scan is optional enhancement

    # 3.5 Memory Injection (Phase 20 Enhancement)
    brain_advice = []
    try:
        from ...intelligence import BrainManager

        brain = BrainManager(project_root)

        seen_patterns = set()
        for issue in issues_found:
            msg_part = issue.split("] ", 1)[-1] if "] " in issue else issue
            patterns = brain.match_error_pattern(msg_part)
            if patterns:
                best_match = patterns[0]
                if best_match.pattern_id not in seen_patterns:
                    brain_advice.append(
                        f"ğŸ§  Brain Recall: For '{msg_part}', previously solving by: {best_match.solution}"
                    )
                    seen_patterns.add(best_match.pattern_id)
                    deductions -= 5
    except Exception as e:
        logger.debug("Brain pattern matching failed: %s", e)

    # 4. è¨ˆç®—åˆ†æ•¸
    final_score = max(0, base_score - deductions)

    # 5. è©•ç´š
    if final_score >= 95:
        tier = "S-Tier (God Like) ğŸ†"
    elif final_score >= 85:
        tier = "A-Tier (Professional) ğŸ¥‡"
    elif final_score >= 75:
        tier = "B-Tier (Solid) ğŸ¥ˆ"
    elif final_score >= 60:
        tier = "C-Tier (Meh) ğŸ¥‰"
    else:
        tier = "F-Tier (Spaghetti) ğŸ"

    # 6. ç”Ÿæˆ One-Click Fix Prompt
    fix_prompt = ""
    if final_score < 100:
        fix_prompt = f"Please act as a Senior Engineer to fix the low Vibe Score ({final_score}) for the following files:\n"
        fix_prompt += f"Target: `{target_path}`\n\n"
        fix_prompt += "Tasks:\n"

        if issues_found:
            fix_prompt += "1. Fix the following code quality issues:\n"
            for i in issues_found[:10]:
                fix_prompt += f"   - {i}\n"
            if len(issues_found) > 10:
                fix_prompt += f"   - ... and {len(issues_found) - 10} more issues.\n"

        if doc_missing > 0:
            fix_prompt += f"2. Add missing docstrings/JSDoc to {doc_missing} functions/classes to meet Google Style Guide.\n"

        if security_issues:
            fix_prompt += "3. âš ï¸ CRITICAL: Remove or rotate the following exposed secrets:\n"
            for sec in security_issues[:5]:
                fix_prompt += f"   - {sec}\n"

        fix_prompt += "\nReturn the corrected code directly."
    else:
        fix_prompt = "ğŸ‰ Perfect Score! No fixes needed. Maybe go touch some grass? ğŸŒ±"

    # 7. V10.21: Storage æ­·å²è¿½è¹¤
    score_trend = ""
    previous_score = None
    storage = _get_storage(project_root)
    if storage:
        try:
            # è¨˜éŒ„æœ¬æ¬¡åˆ†æ•¸
            storage.record_metric(
                name="vibe_score",
                value=float(final_score),
                metadata={
                    "target": target_path,
                    "issues": len(issues_found),
                    "doc_missing": doc_missing,
                    "security_issues": len(security_issues),
                    "tier": tier,
                },
            )

            # å–å¾—æ­·å²åˆ†æ•¸
            history = storage.get_metrics("vibe_score", limit=5)
            if len(history) > 1:
                previous_score = history[1].get("metric_value")
                if previous_score is not None:
                    diff = final_score - previous_score
                    if diff > 0:
                        score_trend = f"ğŸ“ˆ +{diff:.0f} (vs ä¸Šæ¬¡ {previous_score:.0f})"
                    elif diff < 0:
                        score_trend = f"ğŸ“‰ {diff:.0f} (vs ä¸Šæ¬¡ {previous_score:.0f})"
                    else:
                        score_trend = f"â¡ï¸ ç¶­æŒ {previous_score:.0f}"
        except Exception as e:
            logger.debug("Failed to track vibe score history: %s", e)

    storage_status = "âœ… åˆ†æ•¸å·²è¨˜éŒ„" if storage else "âš ï¸ Storage æœªå•Ÿç”¨"

    # Import verbosity control
    from boring.mcp.verbosity import Verbosity, get_verbosity

    verb_level = get_verbosity(verbosity)

    # Generate vibe_summary based on verbosity
    if verb_level == Verbosity.MINIMAL:
        # MINIMAL: Only score and tier (~50 tokens)
        vibe_summary = f"ğŸ“Š Vibe Score: {final_score}/100 | {tier}"
        if score_trend:
            vibe_summary += f"\n{score_trend}"
        vibe_summary += "\nğŸ’¡ Use verbosity='standard' for details"

    elif verb_level == Verbosity.VERBOSE:
        # VERBOSE: Full detailed report (~800+ tokens)
        summary_lines = [
            f"ğŸ“Š Vibe Check: `{target_path}`",
            f"Score: {final_score}/100 | {tier}",
            "",
        ]

        if score_trend:
            summary_lines.append(f"{score_trend}\n")

        # Code Quality Issues
        if issues_found:
            summary_lines.append(f"ğŸ” Code Quality Issues ({len(issues_found)}):")
            for issue in issues_found[:20]:  # Show up to 20
                summary_lines.append(f"  - {issue}")
            if len(issues_found) > 20:
                summary_lines.append(f"  ... and {len(issues_found) - 20} more")
            summary_lines.append("")

        # Security Issues
        if security_issues:
            summary_lines.append(f"ğŸ”’ Security Issues ({len(security_issues)}):")
            for sec in security_issues[:10]:
                summary_lines.append(f"  - {sec}")
            if len(security_issues) > 10:
                summary_lines.append(f"  ... and {len(security_issues) - 10} more")
            summary_lines.append("")

        # Documentation
        if doc_missing > 0:
            summary_lines.append(f"ğŸ“ Documentation: {doc_missing} missing docstrings")
            summary_lines.append("")

        summary_lines.append(f"ğŸ”— {storage_status}")
        vibe_summary = "\n".join(summary_lines)

    else:  # STANDARD
        # STANDARD: Score + top issues (~300 tokens)
        summary_lines = [f"ğŸ“Š Vibe Score: {final_score}/100 | {tier}", ""]

        if score_trend:
            summary_lines.append(f"{score_trend}\n")

        # Top 5 quality issues
        if issues_found:
            summary_lines.append(
                f"ğŸ” Top Issues ({min(5, len(issues_found))}/{len(issues_found)}):"
            )
            for issue in issues_found[:5]:
                summary_lines.append(f"  - {issue}")
            if len(issues_found) > 5:
                summary_lines.append(f"  ... and {len(issues_found) - 5} more")
            summary_lines.append("")

        # Critical security issues
        if security_issues:
            critical_sec = [s for s in security_issues if "CRITICAL" in s or "HIGH" in s]
            if critical_sec:
                summary_lines.append(f"ğŸ”’ Critical Security ({len(critical_sec)}):")
                for sec in critical_sec[:3]:
                    summary_lines.append(f"  - {sec}")
                summary_lines.append("")

        if doc_missing > 0:
            summary_lines.append(f"ğŸ“ {doc_missing} missing docstrings\n")

        summary_lines.append(f"ğŸ”— {storage_status}")
        summary_lines.append("\nğŸ’¡ Use verbosity='verbose' for full report")
        vibe_summary = "\n".join(summary_lines)

    return create_success_result(
        message=vibe_summary,
        data={
            "vibe_score": final_score,
            "tier": tier,
            "vibe_summary": vibe_summary,
        },
    )


def run_predict_errors(
    file_path: str,
    limit: int = 5,
    project_path: str | None = None,
) -> BoringResult:
    """
    ğŸ”® é æ¸¬éŒ¯èª¤ - æ ¹æ“šæ­·å²æ¨¡å¼é æ¸¬å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ã€‚
    Implementation for boring_predict_errors tool and CLI.

    V10.22 Intelligence:
    - åˆ†ææª”æ¡ˆé¡å‹èˆ‡éå»éŒ¯èª¤çš„é—œè¯
    - æä¾›ä¿¡å¿ƒåˆ†æ•¸å’Œé é˜²å»ºè­°
    - å­¸ç¿’å°ˆæ¡ˆç‰¹å®šçš„éŒ¯èª¤æ¨¡å¼
    """
    project_root_str, error = _get_project_root_or_error_impl(project_path)
    if error:
        return create_error_result(error.get("message", "Unknown error"))

    project_root = Path(project_root_str)
    # Ensure file_path is a string (fix for OptionInfo crash)
    file_path = str(file_path or ".")

    # Fast-Fail Auth Check (V14.0.1)
    try:
        from ...llm.sdk import create_gemini_client

        # This will raise ValueError if no auth is found
        _ = create_gemini_client(log_dir=project_root / "logs")
    except (ValueError, RuntimeError) as e:
        return create_error_result(
            f"ğŸš« Authentication required for Predictive Intelligence.\n{str(e)}",
            error_details="AUTH_REQUIRED",
        )

    # Try to use PredictiveAnalyzer
    predictions = []
    try:
        from ...intelligence import PredictiveAnalyzer

        analyzer = PredictiveAnalyzer(project_root)
        predictions = analyzer.predict_errors(file_path, limit)
    except ImportError as e:
        logger.debug("PredictiveAnalyzer not available: %s", e)

    # Fallback to storage-based prediction
    if not predictions:
        storage = _get_storage(project_root)
        if storage:
            predictions_data = storage.get_error_predictions(file_path, limit)
            for p in predictions_data:
                predictions.append(type("Prediction", (), p)())

    if not predictions:
        return create_error_result(
            f"ğŸ“Š å°šç„¡è¶³å¤ æ­·å²è³‡æ–™é€²è¡Œé æ¸¬ã€‚ç¹¼çºŒä½¿ç”¨ç³»çµ±ç´¯ç©è³‡æ–™ï¼\næª”æ¡ˆ: {file_path}",
            error_details="NO_DATA",
        )

    # Format results
    result_items = []
    for p in predictions:
        result_items.append(
            {
                "error_type": p.error_type
                if hasattr(p, "error_type")
                else p.get("error_type", "Unknown"),
                "confidence": getattr(p, "confidence", p.get("confidence", 0.5)),
                "message": getattr(p, "predicted_message", p.get("message", "")),
                "prevention_tip": getattr(p, "prevention_tip", p.get("prevention_tip", "")),
                "frequency": getattr(p, "historical_frequency", p.get("frequency", 0)),
            }
        )

    # Static analysis (Predictor)
    static_items = []
    try:
        from ...intelligence.predictor import Predictor

        predictor = Predictor(project_root)
        static_issues = predictor.analyze_file(Path(file_path))

        for issue in static_issues:
            static_items.append(
                {
                    "severity": issue.severity,
                    "category": issue.category,
                    "message": issue.message,
                    "file_path": issue.file_path,
                    "line_number": issue.line_number,
                    "code_snippet": issue.code_snippet,
                    "confidence": issue.confidence,
                    "pattern_id": issue.pattern_id,
                    "suggested_fix": issue.suggested_fix,
                }
            )
    except Exception:
        static_items = []

    # Build summary
    top = result_items[0] if result_items else None
    summary = f"ğŸ”® **Error Predictions for** `{file_path}`\n\n"
    for i, item in enumerate(result_items[:5], 1):
        conf_bar = (
            "ğŸŸ¢" if item["confidence"] >= 0.7 else "ğŸŸ¡" if item["confidence"] >= 0.4 else "âšª"
        )
        summary += f"{i}. {conf_bar} **{item['error_type']}** ({item['confidence'] * 100:.0f}% confidence)\n"
        summary += f"   ğŸ’¡ {item['prevention_tip']}\n"
    if static_items:
        summary += f"\nğŸ§  **Static Findings**: {len(static_items)} issue(s) detected."

    return create_success_result(
        message=summary,
        data={
            "predictions": result_items,
            "top_prediction": top,
            "file_path": file_path,
            "static_issues": static_items,
            "vibe_summary": summary,
        },
    )


def register_vibe_tools(mcp, audited, helpers, engine=None, brain_manager_factory=None):
    """
    Register Vibe Coder Pro tools with the MCP server.
    """
    _get_project_root_or_error = helpers["get_project_root_or_error"]
    global_engine = engine or get_vibe_engine()
    _get_brain = brain_manager_factory or _get_brain_manager

    # === boring_test_gen ===
    @mcp.tool(
        description="è‡ªå‹•ç”Ÿæˆå–®å…ƒæ¸¬è©¦ (Auto-generate unit tests). "
        "èªª: 'å¹«æˆ‘å¯«æ¸¬è©¦', 'ç”Ÿæˆ auth.py çš„æ¸¬è©¦', 'Generate tests for api.ts'. "
        "æˆ‘æœƒåˆ†æç¨‹å¼ç¢¼ä¸¦ç”Ÿæˆ pytest/jest æ¸¬è©¦æ¡ˆä¾‹ï¼æ”¯æ´ Python, JS, TS. "
        "ğŸ†• V10.21: æ•´åˆ RAG åƒè€ƒç¾æœ‰æ¸¬è©¦é¢¨æ ¼ï¼",
        annotations={"readOnlyHint": False, "openWorldHint": False, "idempotentHint": False},
    )
    @audited
    def boring_test_gen(
        file_path: Annotated[str, Field(description="è¦ç”Ÿæˆæ¸¬è©¦çš„æª”æ¡ˆè·¯å¾‘ (ç›¸å°æˆ–çµ•å°)")],
        output_dir: Annotated[
            str | None, Field(description="æ¸¬è©¦è¼¸å‡ºç›®éŒ„ (é è¨­: tests/unit/ æˆ– tests/)")
        ] = None,
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
    ) -> BoringResult:
        """
        ğŸ§ª è‡ªå‹•ç”Ÿæˆå–®å…ƒæ¸¬è©¦ - åˆ†ææª”æ¡ˆä¸¦ç”Ÿæˆå»ºè­°æ¸¬è©¦ç¨‹å¼ç¢¼ã€‚
        æ”¯æ´å¹³å°: Python (pytest), JavaScript/TypeScript (jest/vitest)

        V10.21 æ•´åˆ:
        - RAG æœå°‹ç¾æœ‰æ¸¬è©¦ï¼Œåƒè€ƒå°ˆæ¡ˆæ¸¬è©¦é¢¨æ ¼
        - ç”Ÿæˆä¸€è‡´æ€§æ›´é«˜çš„æ¸¬è©¦ç¨‹å¼ç¢¼
        """
        project_root, error = _get_project_root_or_error(project_path)
        if error:
            return create_error_result(error.get("message", "Unknown error"))

        # è§£ææª”æ¡ˆè·¯å¾‘
        target_file = Path(file_path)
        if not target_file.is_absolute():
            target_file = project_root / file_path

        if not target_file.exists():
            return create_error_result(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")

        try:
            # 1. ä½¿ç”¨ Engine åˆ†æ
            source = target_file.read_text(encoding="utf-8")
            result = global_engine.analyze_for_test_gen(str(target_file), source)

            if not result.functions and not result.classes:
                return create_success_result(
                    message="ğŸ˜… æ²’æœ‰æ‰¾åˆ°å¯æ¸¬è©¦çš„å°å‡ºå‡½å¼æˆ–é¡åˆ¥", data={"file": str(target_file)}
                )

            # 2. V10.21: RAG æœå°‹ç¾æœ‰æ¸¬è©¦é¢¨æ ¼
            test_style_hints = []
            rag = _get_rag_retriever(project_root)
            if rag:
                try:
                    # æœå°‹ç¾æœ‰æ¸¬è©¦æª”æ¡ˆ
                    existing_tests = rag.retrieve(
                        query=f"test {target_file.stem} pytest unittest",
                        top_k=3,
                        chunk_types=["function"],
                    )
                    if existing_tests:
                        for r in existing_tests[:2]:
                            if "test_" in r.chunk.name.lower():
                                test_style_hints.append(f"# åƒè€ƒç¾æœ‰æ¸¬è©¦: {r.chunk.name}")
                except Exception:
                    pass  # RAG is optional enhancement

            # 3. ç”Ÿæˆæ¸¬è©¦ç¨‹å¼ç¢¼ (with style hints)
            test_code = global_engine.generate_test_code(result, str(project_root))

            # Prepend style hints if available
            if test_style_hints:
                style_comment = "\n".join(test_style_hints)
                test_code = f"# V10.21: å·²åƒè€ƒç¾æœ‰æ¸¬è©¦é¢¨æ ¼\n{style_comment}\n\n{test_code}"

            # 4. æ±ºå®šè¼¸å‡ºè·¯å¾‘
            if output_dir:
                test_dir = project_root / output_dir
            else:
                # è‡ªå‹•åˆ¤æ–·é è¨­ç›®éŒ„
                if result.source_language == "python":
                    test_dir = project_root / "tests" / "unit"
                else:
                    test_dir = project_root / "tests"

            test_dir.mkdir(parents=True, exist_ok=True)
            test_filename = (
                f"test_{target_file.stem}.py"
                if result.source_language == "python"
                else f"{target_file.stem}.test{target_file.suffix}"
            )
            test_file = test_dir / test_filename

            # 5. å¯«å…¥æ¸¬è©¦æª”æ¡ˆ
            test_file.write_text(test_code, encoding="utf-8")

            rag_status = "âœ… RAG é¢¨æ ¼åƒè€ƒ" if test_style_hints else "âš ï¸ RAG æœªå•Ÿç”¨"

            return create_success_result(
                message=f"âœ… å·²ç”Ÿæˆ {result.source_language} æ¸¬è©¦ï¼\næª”æ¡ˆ: {test_file.relative_to(project_root)}\n{rag_status}",
                data={
                    "test_file": str(test_file),
                    "functions_count": len(result.functions),
                    "classes_count": len(result.classes),
                    "rag_enhanced": bool(test_style_hints),
                    "vibe_summary": f"ğŸ§ª ç‚º `{target_file.name}` ç”Ÿæˆäº† {len(result.functions)} å€‹æ¸¬è©¦\n"
                    f"ğŸ“ æ¸¬è©¦æª”æ¡ˆ: `{test_file.relative_to(project_root)}`\n"
                    f"ğŸŒ èªè¨€: {result.source_language}\n"
                    f"ğŸ”— {rag_status}",
                },
            )

        except ValueError as e:
            return create_error_result(
                f"âŒ ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {target_file.suffix}", error_details=str(e)
            )
        except Exception as e:
            return create_error_result(f"âŒ åˆ†æå¤±æ•—: {str(e)}")

    # === boring_code_review ===
    @mcp.tool(
        description="AI ç¨‹å¼ç¢¼å¯©æŸ¥ (AI Code Review). "
        "èªª: 'å¯©æŸ¥æˆ‘çš„ç¨‹å¼ç¢¼', 'Review my code', 'å¹«æˆ‘çœ‹çœ‹å“ªè£¡å¯ä»¥æ”¹é€²'. "
        "æˆ‘æœƒåˆ†æç¨‹å¼ç¢¼å“è³ªä¸¦çµ¦å‡ºæ”¹å–„å»ºè­°ï¼æ”¯æ´ Python, JS, TS. "
        "ğŸ†• V10.21: æ•´åˆ BrainManager åƒè€ƒå·²å­¸ç¿’çš„ Patternï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_code_review(
        file_path: Annotated[str, Field(description="è¦å¯©æŸ¥çš„æª”æ¡ˆè·¯å¾‘")],
        focus: Annotated[
            str | None,
            Field(
                description="å¯©æŸ¥é‡é»: 'all', 'naming', 'error_handling', 'performance', 'security'"
            ),
        ] = "all",
        verbosity: Annotated[
            str,
            Field(
                description="Output verbosity: 'minimal' (summary only ~100 tokens), 'standard' (categorized issues ~500 tokens), 'verbose' (full details with brain patterns ~1000+ tokens). Default: 'standard'."
            ),
        ] = "standard",
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
    ) -> BoringResult:
        """
        ğŸ” AI ç¨‹å¼ç¢¼å¯©æŸ¥ - åˆ†æç¨‹å¼ç¢¼å“è³ªä¸¦çµ¦å‡ºæ”¹å–„å»ºè­°ã€‚
        æ”¯æ´å¹³å°: Python, JavaScript, TypeScript

        V10.21 æ•´åˆ:
        - BrainManager: åƒè€ƒå°ˆæ¡ˆå·²å­¸ç¿’çš„ Patternï¼Œå¯©æŸ¥æ›´ç²¾æº–
        - æ­·å²éŒ¯èª¤æ¨¡å¼: è­˜åˆ¥æ›¾ç¶“çŠ¯éçš„éŒ¯èª¤
        """
        project_root, error = _get_project_root_or_error(project_path)
        if error:
            return create_error_result(error.get("message", "Unknown error"))

        target_file = Path(file_path)
        if not target_file.is_absolute():
            target_file = project_root / file_path

        if not target_file.exists():
            return create_error_result(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")

        try:
            source = target_file.read_text(encoding="utf-8")
            result = global_engine.perform_code_review(str(target_file), source, focus)

            # V10.21: BrainManager æ•´åˆ - å–å¾—ç›¸é—œ Pattern
            brain_patterns = []
            brain = _get_brain(project_root)
            if brain:
                try:
                    # æœå°‹èˆ‡å¯©æŸ¥ç›¸é—œçš„ Pattern
                    patterns = brain.get_relevant_patterns(
                        context=f"{focus} review {target_file.name}", limit=3
                    )
                    for p in patterns:
                        if p.get("pattern_type") in ["code_style", "error_solution", "code_fix"]:
                            brain_patterns.append(
                                {
                                    "type": p.get("pattern_type"),
                                    "description": p.get("description", "")[:100],
                                    "suggestion": p.get("solution", "")[:150],
                                }
                            )
                except Exception:
                    pass  # BrainManager is optional enhancement

            if not result.issues:
                brain_status = (
                    f"\nğŸ§  å·²åƒè€ƒ {len(brain_patterns)} å€‹å°ˆæ¡ˆ Pattern" if brain_patterns else ""
                )
                message = f"âœ… ç¨‹å¼ç¢¼å“è³ªè‰¯å¥½ï¼æ²’æœ‰ç™¼ç¾æ˜é¡¯å•é¡Œã€‚{brain_status}"

                if is_minimal(verbosity):
                    message = f"âœ… {target_file.name}: ç„¡å•é¡Œ"

                return create_success_result(
                    message=message,
                    data={
                        "file": str(target_file),
                        "issues_count": 0,
                        "brain_patterns_used": len(brain_patterns),
                        "vibe_summary": message,
                    },
                )

            # æŒ‰åš´é‡ç¨‹åº¦æ’åº
            result.issues.sort(key=lambda x: {"high": 0, "medium": 1, "low": 2}.get(x.severity, 3))

            # Format output based on verbosity
            if is_minimal(verbosity):
                # MINIMAL: Only summary statistics
                severity_counts = {"high": 0, "medium": 0, "low": 0}
                for issue in result.issues:
                    severity_counts[issue.severity] = severity_counts.get(issue.severity, 0) + 1

                summary_lines = [
                    f"ğŸ” {target_file.name}: {len(result.issues)} å•é¡Œ",
                    f"ğŸ”´ High: {severity_counts['high']} | ğŸŸ¡ Medium: {severity_counts['medium']} | ğŸŸ¢ Low: {severity_counts['low']}",
                ]
                if brain_patterns:
                    summary_lines.append(f"ğŸ§  {len(brain_patterns)} patterns")

                summary_lines.append("ğŸ’¡ Use verbosity='standard' for details")

            elif is_verbose(verbosity):
                # VERBOSE: Full details with brain patterns
                summary_lines = [f"ğŸ” Code Review: `{target_file.name}`", ""]
                for i, issue in enumerate(result.issues, 1):  # Show ALL issues in verbose
                    severity_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                        issue.severity, "âšª"
                    )
                    summary_lines.append(
                        f"{i}. {severity_icon} **{issue.category}** (Line {issue.line}): {issue.message}"
                    )
                    if issue.suggestion:
                        summary_lines.append(f"   ğŸ’¡ å»ºè­°: {issue.suggestion}")

                # Include all brain patterns in verbose
                if brain_patterns:
                    summary_lines.append("")
                    summary_lines.append(
                        f"ğŸ§  **å°ˆæ¡ˆ Pattern å»ºè­°** ({len(brain_patterns)} patterns):"
                    )
                    for bp in brain_patterns:
                        summary_lines.append(f"   - [{bp['type']}] {bp['description']}")
                        summary_lines.append(f"     â†’ {bp['suggestion']}")
            else:
                # STANDARD: Current behavior (top 10 issues)
                summary_lines = [f"ğŸ” Code Review: `{target_file.name}`", ""]
                for i, issue in enumerate(result.issues[:10], 1):
                    severity_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                        issue.severity, "âšª"
                    )
                    summary_lines.append(
                        f"{i}. {severity_icon} **{issue.category}**: {issue.message}"
                    )
                    if issue.suggestion:
                        summary_lines.append(f"   ğŸ’¡ å»ºè­°: {issue.suggestion}")

                # V10.21: åŠ å…¥ Brain Pattern å»ºè­°
                if brain_patterns:
                    summary_lines.append("")
                    summary_lines.append("ğŸ§  **å°ˆæ¡ˆ Pattern å»ºè­°**:")
                    for bp in brain_patterns[:2]:
                        summary_lines.append(f"   - {bp['description']}: {bp['suggestion']}")

            # Generate Fix Prompt
            fix_prompt = f"Please review `{target_file.name}` and fix the following {len(result.issues)} issues:\n"
            for issue in result.issues:
                fix_prompt += f"- [{issue.severity.upper()}] {issue.category}: {issue.message}\n"
                if issue.suggestion:
                    fix_prompt += f"  (Suggestion: {issue.suggestion})\n"

            # åŠ å…¥ Brain Pattern åˆ° Fix Prompt
            if brain_patterns:
                fix_prompt += "\nğŸ§  Project-specific patterns to follow:\n"
                for bp in brain_patterns:
                    fix_prompt += f"- {bp['description']}: {bp['suggestion']}\n"

            fix_prompt += "\nReturn the fixed specific functions or class code blocks."

            brain_status = "âœ… Brain Pattern æ•´åˆ" if brain_patterns else "âš ï¸ BrainManager æœªå•Ÿç”¨"

            return create_success_result(
                message="\n".join(summary_lines) + f"\n\nğŸ”— {brain_status}",
                data={
                    "file": str(target_file),
                    "issues_count": len(result.issues),
                    "brain_patterns_used": len(brain_patterns),
                    "brain_enhanced": bool(brain_patterns),
                    "issues": [
                        {
                            "category": i.category,
                            "severity": i.severity,
                            "message": i.message,
                            "line": i.line,
                        }
                        for i in result.issues
                    ],
                    "brain_patterns": brain_patterns,
                    "suggested_fix_prompt": fix_prompt,
                },
            )

        except ValueError:
            return create_error_result(f"âŒ ä¸æ”¯æ´çš„æ ¼å¼: {target_file.suffix}")
        except Exception as e:
            return create_error_result(f"âŒ å¯©æŸ¥å¤±æ•—: {str(e)}")

    # === boring_perf_tips ===
    @mcp.tool(
        description="æ•ˆèƒ½åˆ†ææç¤º (Performance Tips). "
        "èªª: 'åˆ†ææ•ˆèƒ½', 'æ•ˆèƒ½å„ªåŒ–å»ºè­°', 'Check performance of api.py'. "
        "æˆ‘æœƒå°ˆæ³¨æª¢æŸ¥æ•ˆèƒ½ç“¶é ¸ (å¦‚ N+1 query, I/O in loop) ä¸¦æä¾›å„ªåŒ–å»ºè­°ï¼æ”¯æ´ Py, JS, TS.",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_perf_tips(
        file_path: Annotated[str, Field(description="è¦åˆ†æçš„æª”æ¡ˆè·¯å¾‘")],
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
        verbosity: Annotated[
            str,
            Field(description="è¼¸å‡ºè©³ç´°ç¨‹åº¦: 'minimal', 'standard' (é è¨­), 'verbose'"),
        ] = "standard",
    ) -> BoringResult:
        """
        âš¡ æ•ˆèƒ½åˆ†ææç¤º - å°ˆæ³¨æ–¼ç¨‹å¼ç¢¼æ•ˆèƒ½ç“¶é ¸æª¢æ¸¬ã€‚
        æ”¯æ´å¹³å°: Python, JavaScript, TypeScript
        """
        project_root, error = _get_project_root_or_error(project_path)
        if error:
            return create_error_result(error.get("message", "Unknown error"))

        target_file = Path(file_path)
        if not target_file.is_absolute():
            target_file = project_root / file_path

        if not target_file.exists():
            return create_error_result(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")

        try:
            source = target_file.read_text(encoding="utf-8")
            # åƒ…å°ˆæ³¨æ–¼ performance
            result = global_engine.perform_code_review(
                str(target_file), source, focus="performance"
            )

            if not result.issues:
                msg = "âš¡ æ•ˆèƒ½åˆ†æå®Œæˆï¼šæœªç™¼ç¾æ˜é¡¯ç“¶é ¸ã€‚"
                if is_minimal(verbosity):
                    msg = f"âš¡ {target_file.name}: ç„¡æ•ˆèƒ½å•é¡Œ"

                return create_success_result(
                    message=msg,
                    data={
                        "file": str(target_file),
                        "tips_count": 0,
                        "vibe_summary": msg,
                    },
                )

            # Generate Perf Fix Prompt
            fix_prompt = f"Please analyze performance bottlenecks in `{target_file.name}` and apply the following optimizations:\n"
            for issue in result.issues:
                fix_prompt += f"- {issue.message} (Line {issue.line})\n"
                if issue.suggestion:
                    fix_prompt += f"  Tip: {issue.suggestion}\n"

            # --- Verbosity Logic ---

            # 1. MINIMAL: Summary only
            if is_minimal(verbosity):
                severity_counts = {"high": 0, "medium": 0, "low": 0}
                for issue in result.issues:
                    severity_counts[issue.severity] = severity_counts.get(issue.severity, 0) + 1

                return create_success_result(
                    message=f"âš¡ {target_file.name}: {len(result.issues)} æ•ˆèƒ½å•é¡Œ",
                    data={
                        "vibe_summary": (
                            f"âš¡ {target_file.name}: {len(result.issues)} æ•ˆèƒ½å•é¡Œ\n"
                            f"ğŸŒ High: {severity_counts['high']} | ğŸ¢ Medium/Low: {severity_counts['medium'] + severity_counts['low']}\n"
                            f"ğŸ’¡ Use verbosity='standard' for tips"
                        ),
                        "file": str(target_file),
                        "tips_count": len(result.issues),
                    },
                )

            # 2. STANDARD: Top 5 issues
            if is_standard(verbosity):
                summary_lines = [f"âš¡ Performance Tips: `{target_file.name}`", ""]
                # Show top 5
                for i, issue in enumerate(result.issues[:5], 1):
                    icon = "ğŸŒ" if issue.severity == "high" else "ğŸ¢"
                    summary_lines.append(f"{i}. {icon} **{issue.message}** (Line {issue.line})")
                    if issue.suggestion:
                        summary_lines.append(f"   ğŸš€ å„ªåŒ–: {issue.suggestion}")

                if len(result.issues) > 5:
                    summary_lines.append(f"\n... and {len(result.issues) - 5} more issues.")
                    summary_lines.append("ğŸ’¡ Use verbosity='verbose' for full list.")

                return create_success_result(
                    message="\n".join(summary_lines),
                    data={
                        "file": str(target_file),
                        "tips_count": len(result.issues),
                        "vibe_summary": "\n".join(summary_lines),
                        "suggested_fix_prompt": fix_prompt,
                    },
                )

            # 3. VERBOSE: Full list (Legacy behavior)
            summary_lines = [f"âš¡ Performance Tips: `{target_file.name}`", ""]
            for i, issue in enumerate(result.issues, 1):
                icon = "ğŸŒ" if issue.severity == "high" else "ğŸ¢"
                summary_lines.append(f"{i}. {icon} **{issue.message}** (Line {issue.line})")
                if issue.suggestion:
                    summary_lines.append(f"   ğŸš€ å„ªåŒ–: {issue.suggestion}")

            return create_success_result(
                message="\n".join(summary_lines),
                data={
                    "file": str(target_file),
                    "tips_count": len(result.issues),
                    "tips": [
                        {"message": i.message, "line": i.line, "suggestion": i.suggestion}
                        for i in result.issues
                    ],
                    "vibe_summary": "\n".join(summary_lines),
                    "suggested_fix_prompt": fix_prompt,
                },
            )

        except ValueError:
            return create_error_result(f"âŒ ä¸æ”¯æ´çš„æ ¼å¼: {target_file.suffix}")
        except Exception as e:
            return create_error_result(f"âŒ åˆ†æå¤±æ•—: {str(e)}")

    # === boring_arch_check ===
    @mcp.tool(
        description="æ¶æ§‹åˆ†æ (Architecture Analysis). "
        "èªª: 'åˆ†æå°ˆæ¡ˆæ¶æ§‹', 'Show me the dependencies', 'çœ‹çœ‹èª°å¼•ç”¨èª°', 'è©²å¦‚ä½•é‡æ§‹'. "
        "æˆ‘æœƒç”Ÿæˆ Mermaid ä¾è³´åœ–ï¼Œè®“ä½ ä¸€ç›®äº†ç„¶å°ˆæ¡ˆçµæ§‹ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_arch_check(
        target_path: Annotated[str, Field(description="File or directory to scan.")] = ".",
        output_format: Annotated[
            str, Field(description="Output format: 'mermaid' or 'json'.")
        ] = "mermaid",
    ) -> BoringResult:
        """
        Analyze project dependencies and architecture.

        Generates a dependency graph showing how files import each other.
        Use this to understand the structure of a codebase.
        """
        root_str, error = _get_project_root_or_error(
            None
        )  # project_path is now optional and handled by get_root
        if error:
            return create_error_result(error.get("message", "Unknown error"))

        project_root = Path(root_str)
        # Handle both absolute and relative paths
        if target_path != "." and (
            target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":")
        ):
            target = Path(target_path)
        elif target_path == ".":
            target = project_root
        else:
            target = project_root / target_path

        files_to_scan = []
        if target.is_file():
            files_to_scan.append(target)
        elif target.is_dir():
            files_to_scan.extend(
                [
                    p
                    for p in target.rglob("*")
                    if p.is_file()
                    and p.suffix.lower() in [".py", ".js", ".ts", ".jsx", ".tsx"]
                    and not any(
                        x in p.parts for x in ["node_modules", ".git", "__pycache__", "venv"]
                    )
                ]
            )
        else:
            return create_error_result(f"âŒ Target not found: {target}")

        edges = []
        nodes = set()

        for file_path in files_to_scan:
            try:
                rel_path = file_path.relative_to(project_root).as_posix()
                content = file_path.read_text(encoding="utf-8", errors="ignore")

                vibe_engine = get_vibe_engine()
                deps = vibe_engine.extract_dependencies(str(file_path), content)

                if deps:
                    nodes.add(rel_path)
                    for dep in deps:
                        # Simple normalization
                        dep_name = dep
                        if dep.startswith("."):
                            # Attempt simple resolve?
                            # For visualization, generic name is arguably better than huge guess
                            pass

                        edge = (rel_path, dep_name)
                        edges.append(edge)
            except Exception:
                continue

        if output_format == "json":
            return create_success_result(
                message="âœ… Dependency analysis complete (JSON)",
                data={"nodes": list(nodes), "edges": edges},
            )

        # Mermaid format
        lines = ["graph TD"]
        max_edges = 100

        # Limit edges to avoid explosion
        processed_count = 0
        for src, dst in edges:
            if processed_count >= max_edges:
                lines.append(f"    %% Truncated after {max_edges} edges")
                break

            # Simple sanitization for Mermaid IDs
            def clean_id(s):
                return s.replace("/", "_").replace(".", "_").replace("-", "_").replace("@", "")

            s_id = clean_id(src)
            d_id = clean_id(dst)

            # Add node labels
            lines.append(f'    {s_id}["{src}"] --> {d_id}["{dst}"]')
            processed_count += 1

        mermaid_graph = "\n".join(lines)
        return create_success_result(
            message=mermaid_graph,
            data={"mermaid": mermaid_graph, "node_count": len(nodes), "edge_count": len(edges)},
        )

    # === boring_doc_gen ===
    @mcp.tool(
        description="è‡ªå‹•ç”Ÿæˆæ–‡æª” (Auto-generate Documentation). "
        "èªª: 'å¹«æˆ‘å¯«æ–‡æª”', 'Generate docs for api.py', 'API æ–‡æª”', 'è‡ªå‹•è¨»è§£'. "
        "æˆ‘æœƒæ“·å– Docstrings/JSDoc ä¸¦ç”Ÿæˆ Markdown åƒè€ƒæ–‡æª”ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_doc_gen(
        target_path: Annotated[str, Field(description="File or directory to scan.")] = ".",
    ) -> BoringResult:
        """
        Extract documentation comments and generate an API reference.

        Supports:
        - Python Docstrings (Module, Class, Function)
        - JavaScript/TypeScript JSDoc (/** ... */)

        Returns Markdown content.
        """
        root_str, error = _get_project_root_or_error(None)
        if error:
            return create_error_result(error.get("message", "Unknown error"))

        project_root = Path(root_str)
        # Handle both absolute and relative paths
        if target_path != "." and (
            target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":")
        ):
            target = Path(target_path)
        elif target_path == ".":
            target = project_root
        else:
            target = project_root / target_path

        files_to_scan = []
        if target.is_file():
            files_to_scan.append(target)
        elif target.is_dir():
            files_to_scan.extend(
                [
                    p
                    for p in target.rglob("*")
                    if p.is_file()
                    and p.suffix.lower() in [".py", ".js", ".ts", ".jsx", ".tsx"]
                    and not any(
                        x in p.parts
                        for x in ["node_modules", ".git", "__pycache__", "venv", "dist", "build"]
                    )
                ]
            )
        else:
            return create_error_result(f"âŒ Target not found: {target}")

        doc_output = [f"# API Documentation\n\nGenerated for: `{target_path}`\n"]

        for file_path in sorted(files_to_scan):
            try:
                content = file_path.read_text(encoding="utf-8", errors="ignore")
                rel_path = file_path.relative_to(project_root).as_posix()

                vibe_engine = get_vibe_engine()
                result = vibe_engine.extract_documentation(str(file_path), content)

                if not result.items and not result.module_doc:
                    continue

                doc_output.append(f"## File: `{rel_path}`\n")
                if result.module_doc:
                    doc_output.append(f"> {result.module_doc.strip()}\n")

                doc_output.append("")

                for item in result.items:
                    icon = "ğŸ“¦" if item.type == "class" else "Æ’"
                    doc_output.append(f"### {icon} `{item.name}`")
                    doc_output.append(f"**Signature:** `{item.signature}`\n")
                    if item.docstring:
                        doc_output.append(f"{item.docstring}\n")
                    else:
                        doc_output.append("*No documentation.*\n")
                    doc_output.append("---\n")

            except Exception as e:
                doc_output.append(f"<!-- Error processing {file_path.name}: {e} -->\n")

        doc_content = "\n".join(doc_output)
        return create_success_result(
            message=doc_content,
            data={"documentation": doc_content, "files_scanned": len(files_to_scan)},
        )

    # === boring_vibe_check ===
    @mcp.tool(
        description="Vibe Score å¥æª¢ (Gamified Health Check). "
        "èªª: 'Vibe Check my project', 'å¥æª¢ utils.py', 'Give me a vibe score'. "
        "æˆ‘æœƒæ•´åˆ Lint, Security, Doc æª¢æŸ¥ï¼Œè¨ˆç®— 0-100 åˆ†æ•¸ï¼Œä¸¦æä¾›ä¸€éµä¿®å¾© Promptï¼ "
        "ğŸ†• V10.21: æ•´åˆ Storage è¨˜éŒ„æ­·å²åˆ†æ•¸è¶¨å‹¢ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_vibe_check(
        target_path: Annotated[str, Field(description="è¦å¥æª¢çš„æª”æ¡ˆæˆ–ç›®éŒ„")] = ".",
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
        max_files: Annotated[int, Field(description="æœ€å¤§æƒææª”æ¡ˆæ•¸ (é è¨­ 10)")] = 10,
        verbosity: Annotated[
            str,
            Field(
                description="Output verbosity: 'minimal' (score + tier only ~50 tokens), 'standard' (score + top issues ~300 tokens), 'verbose' (full report ~800+ tokens). Default: 'standard'."
            ),
        ] = "standard",
    ) -> BoringResult:  # Forward reference or use BoringResult directly if imported
        """
        ğŸ“Š Vibe Check - å…¨é¢å¥åº·åº¦æª¢æŸ¥èˆ‡è©•åˆ†ã€‚
        æ•´åˆå¤šé …æŒ‡æ¨™ (Lint, Security, Doc)ï¼Œæä¾›éŠæˆ²åŒ–è©•åˆ†èˆ‡ä¸€éµä¿®å¾© Promptã€‚

        V10.21 æ•´åˆ:
        - Storage: è¨˜éŒ„ Vibe Score æ­·å²ï¼Œè¿½è¹¤å°ˆæ¡ˆå¥åº·è¶¨å‹¢
        - é¡¯ç¤ºèˆ‡ä¸Šæ¬¡åˆ†æ•¸çš„å°æ¯”
        """
        return run_vibe_check(target_path, project_path, max_files, verbosity)

    # === boring_impact_check ===
    @mcp.tool(
        description="è¡æ“Šåˆ†æ (Impact Analysis). "
        "èªª: 'Check impact of modifying utils.py', 'æ”¹é€™éš»æª”æ¡ˆæœƒå½±éŸ¿èª°', 'Impact check'. "
        "æˆ‘æœƒåˆ†æåå‘ä¾è³´ (æ”¯æ´å¤šå±¤è¿½è¹¤)ï¼Œå‘Šè¨´ä½ ä¿®æ”¹æ­¤æª”æ¡ˆæœƒå½±éŸ¿å“ªäº›æ¨¡çµ„ï¼Œä¸¦çµ¦å‡ºé©—è­‰ Promptï¼ "
        "ğŸ†• V10.21: æ•´åˆ RAG èªç¾©åˆ†ææ›´ç²¾æº–ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_impact_check(
        target_path: Annotated[str, Field(description="è¨ˆç•«ä¿®æ”¹çš„ç›®æ¨™æª”æ¡ˆ")],
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„ (è‡ªå‹•åµæ¸¬)")] = None,
        max_depth: Annotated[
            int, Field(description="è¿½è¹¤æ·±åº¦ (1=ç›´æ¥ä¾è³´, 2=é–“æ¥ä¾è³´, é è¨­ 2)")
        ] = 2,
    ) -> BoringResult:
        """
        ğŸ“¡ Impact Analysis - é åˆ¤ä¿®æ”¹å¸¶ä¾†çš„å…¨å±€è¡æ“Šã€‚
        Reverse Dependency Analysis with multi-level tracking (Phase 15 Enhancement).

        V10.21 æ•´åˆ:
        - RAG èªç¾©æœå°‹: æ‰¾å‡ºèªç¾©ç›¸é—œçš„æª”æ¡ˆï¼ˆä¸åªæ˜¯ importï¼‰
        - æ›´ç²¾æº–çš„è¡æ“Šåˆ†æ
        """
        root_str, error = _get_project_root_or_error(project_path)
        if error:
            return create_error_result(error.get("message", "Unknown error"))

        project_root = Path(root_str)
        # Handle both absolute and relative paths
        if target_path != "." and (
            target_path.startswith("/") or (len(target_path) > 1 and target_path[1] == ":")
        ):
            target = Path(target_path)
        elif target_path == ".":
            target = project_root
        else:
            target = project_root / target_path

        if not target.exists() or not target.is_file():
            return create_error_result(f"âŒ æ‰¾ä¸åˆ°ç›®æ¨™æª”æ¡ˆ: {target_path}")

        # 1. è­˜åˆ¥ç›®æ¨™ç‰¹å¾µ for fuzzy matching
        target_stem = target.stem  # e.g., "utils"
        rel_target = target.relative_to(project_root).as_posix()

        # V10.21: RAG èªç¾©åˆ†æ - æ‰¾å‡ºèªç¾©ç›¸é—œçš„æª”æ¡ˆ
        semantic_related = []
        rag = _get_rag_retriever(project_root)
        if rag:
            try:
                # è®€å–ç›®æ¨™æª”æ¡ˆå…§å®¹ï¼Œæå–é—œéµè©
                target_content = target.read_text(encoding="utf-8", errors="ignore")[:500]

                # èªç¾©æœå°‹ç›¸é—œå‡½æ•¸/é¡åˆ¥
                results = rag.retrieve(
                    query=f"{target_stem} {target_content[:100]}",
                    top_k=5,
                    chunk_types=["function", "class"],
                )
                for r in results:
                    if r.chunk.file_path != str(target):
                        rel_path = Path(r.chunk.file_path).relative_to(project_root).as_posix()
                        if rel_path not in semantic_related:
                            semantic_related.append(rel_path)
            except Exception:
                pass  # RAG is optional enhancement

        # 2. å…¨å°ˆæ¡ˆæƒæå»ºç«‹å®Œæ•´ä¾è³´åœ–
        files_to_scan = [
            p
            for p in project_root.rglob("*")
            if p.is_file()
            and p.suffix in [".py", ".js", ".ts", ".jsx", ".tsx"]
            and not any(
                x in p.parts
                for x in ["node_modules", ".git", "venv", "__pycache__", "dist", "build"]
            )
        ]

        # Build dependency graph: { file_rel_path -> [dependencies] }
        dep_graph = {}
        file_stems = {}  # stem -> [rel_paths]

        vibe_engine = get_vibe_engine()
        for f in files_to_scan:
            try:
                content = f.read_text(encoding="utf-8", errors="ignore")
                deps = vibe_engine.extract_dependencies(str(f), content)
                f_rel = f.relative_to(project_root).as_posix()
                dep_graph[f_rel] = deps

                # Index by stem for fuzzy matching
                stem = f.stem
                if stem not in file_stems:
                    file_stems[stem] = []
                file_stems[stem].append(f_rel)
            except Exception:
                continue

        # 3. Fuzzy matching helper
        def matches_target(dep: str, target_stem: str) -> bool:
            if target_stem == dep:
                return True
            if dep.endswith(f".{target_stem}"):
                return True
            if dep.endswith(f"/{target_stem}"):
                return True
            return False

        # 4. Build reverse dependency graph (who imports what)
        # direct_dependents: files that directly import target
        direct_dependents = set()
        for f_rel, deps in dep_graph.items():
            if f_rel == rel_target:
                continue
            for dep in deps:
                if matches_target(dep, target_stem):
                    direct_dependents.add(f_rel)
                    break

        # 5. Multi-level impact tracking (Phase 15 Enhancement)
        all_affected = set(direct_dependents)
        indirect_dependents = set()

        if max_depth >= 2:
            # Level 2: Find files that import direct_dependents
            for direct_dep in direct_dependents:
                direct_stem = Path(direct_dep).stem
                for f_rel, deps in dep_graph.items():
                    if f_rel in all_affected or f_rel == rel_target:
                        continue
                    for dep in deps:
                        if matches_target(dep, direct_stem):
                            indirect_dependents.add(f_rel)
                            all_affected.add(f_rel)
                            break

        # Level 3 (if max_depth >= 3)
        level3_dependents = set()
        if max_depth >= 3:
            for indirect_dep in indirect_dependents:
                indirect_stem = Path(indirect_dep).stem
                for f_rel, deps in dep_graph.items():
                    if f_rel in all_affected or f_rel == rel_target:
                        continue
                    for dep in deps:
                        if matches_target(dep, indirect_stem):
                            level3_dependents.add(f_rel)
                            all_affected.add(f_rel)
                            break

        # 6. è©•ä¼°è¡æ“Šç­‰ç´š
        impact_level = "Low"
        if len(all_affected) > 10:
            impact_level = "Critical"
        elif len(all_affected) > 5:
            impact_level = "High"
        elif len(all_affected) > 0:
            impact_level = "Medium"

        # 7. Mermaid åœ–å½¢è¼¸å‡º
        mermaid_lines = ["graph TD", f'    Target["{rel_target}"]:::target']

        # Direct impacts
        for imp in list(direct_dependents)[:15]:
            sanitized_imp = imp.replace("/", "_").replace(".", "_").replace("-", "_")
            mermaid_lines.append(f'    {sanitized_imp}["{imp}"]:::direct -->|L1| Target')

        # Indirect impacts
        for imp in list(indirect_dependents)[:10]:
            sanitized_imp = imp.replace("/", "_").replace(".", "_").replace("-", "_")
            mermaid_lines.append(f'    {sanitized_imp}["{imp}"]:::indirect -->|L2| ...')

        mermaid_lines.append("    classDef target fill:#f96,stroke:#333")
        mermaid_lines.append("    classDef direct fill:#ff9,stroke:#333")
        mermaid_lines.append("    classDef indirect fill:#9ff,stroke:#333")
        mermaid_graph = "\n".join(mermaid_lines)

        # 8. Fix/Verification Prompt
        verify_prompt = ""
        if all_affected:
            verify_prompt = (
                f"âš ï¸ Impact Warning: Modifying `{rel_target}` affects {len(all_affected)} files.\n\n"
            )

            if direct_dependents:
                verify_prompt += (
                    f"ğŸ”´ **Direct Dependents (L1)** - {len(direct_dependents)} files:\n"
                )
                for aff in list(direct_dependents)[:5]:
                    verify_prompt += f"   - `{aff}`\n"
                if len(direct_dependents) > 5:
                    verify_prompt += f"   - ... and {len(direct_dependents) - 5} more.\n"

            if indirect_dependents:
                verify_prompt += (
                    f"\nğŸŸ¡ **Indirect Dependents (L2)** - {len(indirect_dependents)} files:\n"
                )
                for aff in list(indirect_dependents)[:5]:
                    verify_prompt += f"   - `{aff}`\n"
                if len(indirect_dependents) > 5:
                    verify_prompt += f"   - ... and {len(indirect_dependents) - 5} more.\n"

            # V10.21: åŠ å…¥ RAG èªç¾©ç›¸é—œæª”æ¡ˆ
            if semantic_related:
                verify_prompt += (
                    f"\nğŸ§  **Semantically Related (RAG)** - {len(semantic_related)} files:\n"
                )
                for sem in semantic_related[:3]:
                    verify_prompt += f"   - `{sem}`\n"

            verify_prompt += (
                "\nğŸ“‹ **Action Required**: Run tests for these files after your changes."
            )
        else:
            verify_prompt = f"âœ… Low Impact: `{rel_target}` appears to have no internal dependents."

        rag_status = (
            f"âœ… RAG èªç¾©åˆ†æ ({len(semantic_related)} ç›¸é—œ)"
            if semantic_related
            else "âš ï¸ RAG æœªå•Ÿç”¨"
        )

        return create_success_result(
            message=f"ğŸ“¡ Impact Analysis: {rel_target}\nImpact Level: {impact_level}\nDirect Dependent Count: {len(direct_dependents)}\nIndirect Dependent Count: {len(indirect_dependents)}\n{rag_status}\n\n{verify_prompt}",
            data={
                "impact_level": impact_level,
                "affected_count": len(all_affected),
                "direct_count": len(direct_dependents),
                "indirect_count": len(indirect_dependents),
                "semantic_related_count": len(semantic_related),
                "rag_enhanced": bool(semantic_related),
                "affected_files": list(all_affected),
                "direct_dependents": list(direct_dependents),
                "indirect_dependents": list(indirect_dependents),
                "semantic_related": semantic_related,
                "mermaid": mermaid_graph,
                "vibe_summary": f"ğŸ“¡ **Impact Analysis**: `{rel_target}`\n"
                f"âš ï¸ **Impact Level**: {impact_level}\n"
                f"ğŸ”— **Direct (L1)**: {len(direct_dependents)}\n"
                f"ğŸ”— **Indirect (L2+)**: {len(indirect_dependents)}\n"
                f"ğŸ§  **Semantic (RAG)**: {len(semantic_related)}\n"
                f"ğŸ”— {rag_status}",
                "suggested_fix_prompt": verify_prompt,
            },
        )

    # =========================================================================
    # V10.22: Intelligence Tools
    # =========================================================================

    @mcp.tool(
        description="é æ¸¬å¯èƒ½çš„éŒ¯èª¤ (Predict likely errors before running). "
        "èªª: 'é æ¸¬é€™å€‹æª”æ¡ˆæœƒæœ‰ä»€éº¼éŒ¯èª¤', 'predict errors for auth.py'. "
        "æˆ‘æœƒåˆ†ææ­·å²æ¨¡å¼ï¼Œé æ¸¬æœ€å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ä¸¦æä¾›é é˜²å»ºè­°ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_predict_errors(
        file_path: Annotated[str, Field(description="è¦é æ¸¬éŒ¯èª¤çš„æª”æ¡ˆè·¯å¾‘")],
        limit: Annotated[int, Field(description="æœ€å¤šè¿”å›å¹¾å€‹é æ¸¬")] = 5,
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„")] = None,
    ) -> BoringResult:
        """
        ğŸ”® é æ¸¬éŒ¯èª¤ - æ ¹æ“šæ­·å²æ¨¡å¼é æ¸¬å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ã€‚


        V10.22 Intelligence:
        - åˆ†ææª”æ¡ˆé¡å‹èˆ‡éå»éŒ¯èª¤çš„é—œè¯
        - æä¾›ä¿¡å¿ƒåˆ†æ•¸å’Œé é˜²å»ºè­°
        - å­¸ç¿’å°ˆæ¡ˆç‰¹å®šçš„éŒ¯èª¤æ¨¡å¼
        """
        return run_predict_errors(file_path, limit, project_path)

    @mcp.tool(
        description="ğŸ“Š å°ˆæ¡ˆå¥åº·è©•åˆ† (Project health score). "
        "èªª: 'å°ˆæ¡ˆå¥åº·ç‹€æ³', 'çµ¦æˆ‘å¥åº·å ±å‘Š', 'project health score'. "
        "æˆ‘æœƒåˆ†ææˆåŠŸç‡ã€éŒ¯èª¤è¶¨å‹¢ã€è§£æ±ºç‡ï¼Œçµ¦å‡ºç¶œåˆå¥åº·è©•åˆ†ï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_health_score(
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„")] = None,
    ) -> BoringResult:
        """
        ğŸ“Š å°ˆæ¡ˆå¥åº·è©•åˆ† - ç¶œåˆåˆ†æå°ˆæ¡ˆç‹€æ…‹ã€‚

        V10.22 Intelligence:
        - æˆåŠŸç‡åˆ†æ (40% æ¬Šé‡)
        - éŒ¯èª¤è§£æ±ºç‡ (30% æ¬Šé‡)
        - åŸ·è¡Œæ•ˆç‡ (30% æ¬Šé‡)
        - è¶¨å‹¢åˆ†æå’Œå»ºè­°
        """
        root_str, error = _get_project_root_or_error(project_path)
        if error:
            return create_error_result(error.get("message", "Unknown error"))
        project_root = Path(root_str)

        storage = _get_storage(project_root)
        if not storage:
            return create_error_result("Storage æœªåˆå§‹åŒ–")

        # Get health score
        health = storage.get_health_score()

        # Get error trend
        trend = storage.get_error_trend(days=7)

        # Build detailed report
        score = health["score"]
        grade = health["grade"]

        # Emoji for grade
        grade_emoji = {
            "A+": "ğŸ†",
            "A": "ğŸŒŸ",
            "B": "âœ…",
            "C": "ğŸ‘",
            "D": "âš ï¸",
            "F": "ğŸš¨",
            "N/A": "ğŸ“Š",
        }.get(grade, "ğŸ“Š")

        breakdown = health.get("breakdown", {})

        summary = f"""# {grade_emoji} å°ˆæ¡ˆå¥åº·å ±å‘Š

## ç¶œåˆè©•åˆ†: **{score}/100** (ç­‰ç´š: {grade})

{health["message"]}

## ğŸ“ˆ æŒ‡æ¨™åˆ†è§£
- æˆåŠŸç‡: **{breakdown.get("success_rate", "N/A")}%**
- éŒ¯èª¤è§£æ±ºç‡: **{breakdown.get("resolution_rate", "N/A")}%**
- å¹³å‡åŸ·è¡Œæ™‚é–“: **{breakdown.get("avg_loop_duration", "N/A")}s**

## ğŸ“Š éŒ¯èª¤è¶¨å‹¢ (7å¤©)
- è¶¨å‹¢æ–¹å‘: {trend.get("emoji", "â¡ï¸")} {trend.get("trend", "N/A")}
- è®ŠåŒ–å¹…åº¦: {trend.get("change_percent", 0)}%
- {trend.get("recommendation", "")}
"""

        return create_success_result(
            message=summary,
            data={
                "score": score,
                "grade": grade,
                "breakdown": breakdown,
                "trend": trend,
                "vibe_summary": summary,
            },
        )

    @mcp.tool(
        description="ğŸ§  å„ªåŒ–ä¸Šä¸‹æ–‡ (Optimize context for LLM). "
        "èªª: 'å¹«æˆ‘å£“ç¸®é€™äº›ç¨‹å¼ç¢¼', 'optimize context'. "
        "æˆ‘æœƒæ™ºèƒ½å£“ç¸®ç¨‹å¼ç¢¼ä¸Šä¸‹æ–‡ï¼Œæ¸›å°‘ token ä½¿ç”¨åŒæ™‚ä¿ç•™é—œéµè³‡è¨Šï¼",
        annotations={"readOnlyHint": True, "openWorldHint": False, "idempotentHint": True},
    )
    @audited
    def boring_optimize_context(
        file_paths: Annotated[list[str], Field(description="è¦å„ªåŒ–çš„æª”æ¡ˆè·¯å¾‘åˆ—è¡¨")],
        max_tokens: Annotated[int, Field(description="æœ€å¤§ token é™åˆ¶")] = 8000,
        error_message: Annotated[str | None, Field(description="ç›¸é—œéŒ¯èª¤è¨Šæ¯ (æœ€é«˜å„ªå…ˆç´š)")] = None,
        project_path: Annotated[str | None, Field(description="å°ˆæ¡ˆæ ¹ç›®éŒ„")] = None,
    ) -> BoringResult:
        """
        ğŸ§  ä¸Šä¸‹æ–‡å„ªåŒ– - æ™ºèƒ½å£“ç¸®ç¨‹å¼ç¢¼ä»¥æ¸›å°‘ token ä½¿ç”¨ã€‚

        V10.22 Intelligence:
        - å»é‡è¤‡å…§å®¹
        - å„ªå…ˆä¿ç•™é—œéµç¨‹å¼ç¢¼
        - å£“ç¸®æ–‡æª”å’Œè¨»é‡‹
        - ä¿æŒèªç¾©å®Œæ•´æ€§
        """
        root_str, error = _get_project_root_or_error(project_path)
        if error:
            return create_error_result(error.get("message", "Unknown error"))
        project_root = Path(root_str)

        try:
            from ..intelligence import SmartContextBuilder

            builder = SmartContextBuilder(max_tokens=max_tokens, project_root=project_root)
        except ImportError:
            return create_error_result("Intelligence æ¨¡çµ„æœªå®‰è£")

        # Add error context (highest priority)
        if error_message:
            builder.with_error(error_message, priority=1.0)

        # Add code files
        for fp in file_paths:
            try:
                path = Path(project_root) / fp if not Path(fp).is_absolute() else Path(fp)
                if path.exists():
                    content = path.read_text(encoding="utf-8", errors="ignore")
                    rel_path = (
                        str(path.relative_to(project_root))
                        if path.is_relative_to(project_root)
                        else str(path)
                    )
                    builder.with_code_file(rel_path, content, priority=0.8)
            except Exception:
                continue

        # Build optimized context
        optimized = builder.build()
        report = builder.get_compression_report()
        stats = builder.stats

        return create_success_result(
            message=report,
            data={
                "optimized_context": optimized,
                "stats": {
                    "original_tokens": stats.original_tokens if stats else 0,
                    "optimized_tokens": stats.optimized_tokens if stats else 0,
                    "compression_ratio": stats.compression_ratio if stats else 1.0,
                    "sections_removed": stats.sections_removed if stats else 0,
                    "duplicates_merged": stats.duplicates_merged if stats else 0,
                },
                "vibe_summary": report,
            },
        )

    # === boring_done (BoringDone Notification) ===
    @mcp.tool(
        description="ğŸ”” å®Œæˆé€šçŸ¥ (Completion Notification). "
        "èªª: 'ä»»å‹™å®Œæˆé€šçŸ¥æˆ‘', 'Notify me when done', 'å¥½äº†å«æˆ‘'. "
        "æˆ‘æœƒç™¼é€æ¡Œé¢é€šçŸ¥ã€éŸ³æ•ˆæé†’ï¼Œè®“ä½ ä¸ç”¨ç›¯è‘—è¢å¹•ï¼",
        annotations={"readOnlyHint": False, "openWorldHint": False, "idempotentHint": False},
    )
    @audited
    def boring_done(
        task_name: Annotated[str, Field(description="ä»»å‹™åç¨±")] = "AI Task",
        success: Annotated[bool, Field(description="ä»»å‹™æ˜¯å¦æˆåŠŸ")] = True,
        details: Annotated[str, Field(description="é¡å¤–è©³æƒ…")] = "",
    ) -> BoringResult:
        """
        ğŸ”” BoringDone - å®Œæˆé€šçŸ¥ç³»çµ±ã€‚

        ç•¶ AI ä»»å‹™å®Œæˆæ™‚ç™¼é€é€šçŸ¥:
        - æ¡Œé¢å½ˆçª— (Windows Toast / macOS / Linux)
        - éŸ³æ•ˆæé†’
        - Terminal Bell

        è®“ä½¿ç”¨è€…å¯ä»¥æ”¾å¿ƒåšå…¶ä»–äº‹ï¼Œå®Œæˆå¾Œæœƒæ”¶åˆ°é€šçŸ¥ï¼
        """
        try:
            from ...services.notifier import done as notify_done

            result = notify_done(task_name=task_name, success=success, details=details)
            return create_success_result(
                message=f"ğŸ”” å·²ç™¼é€é€šçŸ¥: {result['title']}",
                data=result,
            )
        except ImportError:
            # Fallback: simple terminal bell
            print("\a", end="", flush=True)
            return create_success_result(
                message=f"ğŸ”” Terminal Bell: {task_name} {'âœ… Complete' if success else 'âŒ Failed'}",
                data={"fallback": True},
            )
        except Exception as e:
            return create_error_result(f"âŒ é€šçŸ¥å¤±æ•—: {str(e)}")

    return {
        "boring_test_gen": boring_test_gen,
        "boring_code_review": boring_code_review,
        "boring_perf_tips": boring_perf_tips,
        "boring_arch_check": boring_arch_check,
        "boring_doc_gen": boring_doc_gen,
        "boring_vibe_check": boring_vibe_check,
        "boring_impact_check": boring_impact_check,
        # V10.22 Intelligence Tools
        "boring_predict_errors": boring_predict_errors,
        "boring_health_score": boring_health_score,
        "boring_optimize_context": boring_optimize_context,
        # V12.2 BoringDone
        "boring_done": boring_done,
    }
