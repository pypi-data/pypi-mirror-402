# å¤šé—»(Duowen) - ä¼ä¸šçº§AI Agentå¼€å‘æ¡†æ¶

å¤šé—»(Duowen)æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ä¼ä¸šçº§AI Agentå¼€å‘æ¡†æ¶ï¼Œæä¾›äº†å®Œæ•´çš„å¤§è¯­è¨€æ¨¡å‹(LLM)é›†æˆã€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ã€æ™ºèƒ½ä½“(Agent)æ„å»ºå’Œå·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚

## ç›®å½•

- [âœ¨ æ ¸å¿ƒç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§)
- [ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
  - [å®‰è£…](#å®‰è£…)
  - [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [ğŸ“Š é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [ğŸ“– ä½¿ç”¨æŒ‡å—](#-ä½¿ç”¨æŒ‡å—)
  - [è¯­è¨€æ¨¡å‹](#1-è¯­è¨€æ¨¡å‹)
  - [åµŒå…¥æ¨¡å‹](#2-åµŒå…¥æ¨¡å‹)
  - [å¤šæ¨¡æ€åµŒå…¥](#3-å¤šæ¨¡æ€åµŒå…¥)
  - [é‡æ’åºæ¨¡å‹](#4-é‡æ’åºæ¨¡å‹)
- [ğŸ” RAGç³»ç»Ÿ](#-ragç³»ç»Ÿ)
  - [æ–‡æ¡£è§£æ](#æ–‡æ¡£è§£æ)
  - [æ–‡æœ¬åˆ‡å‰²](#æ–‡æœ¬åˆ‡å‰²)
  - [å‘é‡æ•°æ®åº“](#å‘é‡æ•°æ®åº“)
- [ğŸ¤– Agentæ¡†æ¶](#-agentæ¡†æ¶)
  - [ReAct Agent](#react-agent)
  - [è®°å¿†ç³»ç»Ÿ](#è®°å¿†ç³»ç»Ÿ)
- [ğŸ”§ å·¥å…·ç”Ÿæ€](#-å·¥å…·ç”Ÿæ€)
  - [å†…ç½®å·¥å…·](#å†…ç½®å·¥å…·)
  - [è‡ªå®šä¹‰å·¥å…·](#è‡ªå®šä¹‰å·¥å…·)
- [ğŸŒ MCPåè®®æ”¯æŒ](#-mcpåè®®æ”¯æŒ)
- [ğŸš€ é«˜çº§ç‰¹æ€§](#-é«˜çº§ç‰¹æ€§)
  - [æ‰¹é‡å¤„ç†](#æ‰¹é‡å¤„ç†)
  - [éŸ³é¢‘å¤„ç†](#éŸ³é¢‘å¤„ç†)
- [çŸ¥è¯†å›¾è°± (Graph)](#çŸ¥è¯†å›¾è°±-graph)

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¤– **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒOpenAIåè®®çš„å¤§è¯­è¨€æ¨¡å‹
- ğŸ§  **æ™ºèƒ½æ¨ç†**: å†…ç½®æ¨ç†æ¨¡å‹æ”¯æŒï¼Œæä¾›æ€ç»´é“¾æ¨ç†èƒ½åŠ›
- ğŸ“š **RAGç³»ç»Ÿ**: å®Œæ•´çš„æ–‡æ¡£è§£æã€æ–‡æœ¬åˆ‡å‰²ã€å‘é‡æ£€ç´¢å’Œé‡æ’åºåŠŸèƒ½
- ğŸ”§ **å·¥å…·ç”Ÿæ€**: ä¸°å¯Œçš„å†…ç½®å·¥å…·å’Œè‡ªå®šä¹‰å·¥å…·æ”¯æŒ
- ğŸ¯ **Agentæ¡†æ¶**: åŸºäºReActæ¨¡å¼çš„æ™ºèƒ½ä½“æ„å»ºèƒ½åŠ›
- ğŸ’¾ **è®°å¿†ç³»ç»Ÿ**: å¯¹è¯è®°å¿†å’Œé•¿æœŸè®°å¿†ç®¡ç†
- ğŸŒ **MCPåè®®**: æ”¯æŒModel Context Protocolå®¢æˆ·ç«¯
- ğŸ“Š **å¤šæ¨¡æ€**: æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€å¤„ç†

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install duowen-agent
```


### ç¯å¢ƒé…ç½®

> **æ³¨æ„**: ä»¥ä¸‹ç¯å¢ƒé…ç½®ä¸»è¦ç”¨äºè¿è¡Œæµ‹è¯•ç”¨ä¾‹ï¼ŒSDKæœ¬èº«ä¸å¼ºåˆ¶ä¾èµ–è¿™äº›é…ç½®ã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦çµæ´»é…ç½®ç›¸åº”çš„APIå¯†é’¥å’ŒæœåŠ¡åœ°å€ã€‚

å¦‚éœ€è¿è¡Œé¡¹ç›®æµ‹è¯•ç”¨ä¾‹ï¼Œè¯·åˆ›å»º `.env` æ–‡ä»¶å¹¶é…ç½®ç›¸å…³APIå¯†é’¥:

```env
SILICONFLOW_API_KEY=your_api_key_here
TAVILY_API_KEY=your_tavily_key_here
REDIS_ADDR=127.0.0.1:6379
REDIS_PASSWORD=your_redis_password
```

## ğŸ“Š é¡¹ç›®ç»“æ„

```
duowen-agent/
â”œâ”€â”€ duowen_agent/              # æ ¸å¿ƒåŒ…
â”‚   â”œâ”€â”€ agents/                # Agentå®ç°
â”‚   â”‚   â”œâ”€â”€ react.py          # ReAct Agent
â”‚   â”‚   â”œâ”€â”€ memories/         # è®°å¿†ç³»ç»Ÿ
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ llm/                  # å¤§è¯­è¨€æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ chat_model.py     # å¯¹è¯æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ embedding_model.py # åµŒå…¥æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ rerank_model.py   # é‡æ’åºæ¨¡å‹
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ rag/                  # RAGç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ extractor/        # æ–‡æ¡£è§£æ
â”‚   â”‚   â”œâ”€â”€ splitter/         # æ–‡æœ¬åˆ‡å‰²
â”‚   â”‚   â”œâ”€â”€ retrieval/        # å‘é‡æ£€ç´¢
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ tools/                # å·¥å…·ç”Ÿæ€
â”‚   â”‚   â”œâ”€â”€ base.py          # å·¥å…·åŸºç±»
â”‚   â”‚   â”œâ”€â”€ tavily_search.py # æœç´¢å·¥å…·
â”‚   â”‚   â”œâ”€â”€ python_repl.py   # Pythonæ‰§è¡Œå™¨
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ mcp/                  # MCPåè®®
â”‚   â”œâ”€â”€ prompt/               # æç¤ºè¯ç®¡ç†
â”‚   â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”œâ”€â”€ test/                     # æµ‹è¯•ç”¨ä¾‹
â”œâ”€â”€ pyproject.toml           # é¡¹ç›®é…ç½®
â””â”€â”€ README.md               # é¡¹ç›®æ–‡æ¡£
```

## ğŸ“– ä½¿ç”¨æŒ‡å—

### 1. è¯­è¨€æ¨¡å‹

#### åŸºç¡€å¯¹è¯æ¨¡å‹

```python
from duowen_agent.llm import OpenAIChat
from os import getenv

llm_cfg = {
    "model": "THUDM/glm-4-9b-chat", 
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY")
}

llm = OpenAIChat(**llm_cfg)

# åŒæ­¥è°ƒç”¨
response = llm.chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
print(response)

# æµå¼è°ƒç”¨
for chunk in llm.chat_for_stream("è®²ä¸€ä¸ªæœ‰è¶£çš„æ•…äº‹"):
    print(chunk, end="")
```

#### æ¨ç†æ¨¡å‹

```python
from duowen_agent.llm import OpenAIChat
from duowen_agent.utils.core_utils import separate_reasoning_and_response

llm_cfg = {
    "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY"),
    "is_reasoning": True,
}

llm = OpenAIChat(**llm_cfg)
content = llm.chat('9.9å’Œ9.11å“ªä¸ªæ•°å­—æ›´å¤§ï¼Ÿ')

# åˆ†ç¦»æ¨ç†è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆ
reasoning, response = separate_reasoning_and_response(content)
print(f"æ¨ç†è¿‡ç¨‹: {reasoning}")
print(f"æœ€ç»ˆç­”æ¡ˆ: {response}")
```

### 2. åµŒå…¥æ¨¡å‹

#### åŸºç¡€ä½¿ç”¨

```python
from duowen_agent.llm import OpenAIEmbedding
from os import getenv

emb_cfg = {
    "model": "BAAI/bge-large-zh-v1.5", 
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY")
}

emb = OpenAIEmbedding(**emb_cfg)

# å•ä¸ªæ–‡æœ¬åµŒå…¥
vector = emb.get_embedding('è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬')
print(f"å‘é‡ç»´åº¦: {len(vector)}")

# æ‰¹é‡æ–‡æœ¬åµŒå…¥
vectors = emb.get_embedding(['æ–‡æœ¬1', 'æ–‡æœ¬2', 'æ–‡æœ¬3'])
print(f"æ‰¹é‡åµŒå…¥ç»“æœ: {len(vectors)} ä¸ªå‘é‡")
```

#### åµŒå…¥ç¼“å­˜

```python
from duowen_agent.llm import OpenAIEmbedding, EmbeddingCache
from duowen_agent.utils.cache import InMemoryCache
from os import getenv

# é…ç½®åµŒå…¥æ¨¡å‹
emb_cfg = {
    "model": "BAAI/bge-large-zh-v1.5", 
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY")
}
emb = OpenAIEmbedding(**emb_cfg)

# ä½¿ç”¨å†…å­˜ç¼“å­˜
cache = InMemoryCache()
embedding_cache = EmbeddingCache(cache, emb)

# é¦–æ¬¡è°ƒç”¨ä¼šè®¡ç®—åµŒå…¥
vector1 = embedding_cache.get_embedding('æµ‹è¯•æ–‡æœ¬')
# ç¬¬äºŒæ¬¡è°ƒç”¨ä¼šä»ç¼“å­˜è·å–
vector2 = embedding_cache.get_embedding('æµ‹è¯•æ–‡æœ¬')

print(f"ä¸¤æ¬¡ç»“æœç›¸åŒ: {vector1 == vector2}")
```

### 3. å¤šæ¨¡æ€åµŒå…¥

#### å›¾æ–‡å‘é‡æ¨¡å‹

```python
from duowen_agent.llm.embedding_vl_model import JinaClipV2Embedding, EmbeddingVLCache
from duowen_agent.utils.cache import InMemoryCache
from os import getenv

# é…ç½®å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹
embedding_vl_model = JinaClipV2Embedding(
    base_url='http://127.0.0.1:8000',
    model_name='jina-clip-v2',
    api_key=getenv('JINA_API_KEY'),
    dimension=512
)

# æ··åˆè¾“å…¥ï¼šæ–‡æœ¬å’Œå›¾åƒ
input_data = [
    {'text': 'ä¸€åªå¯çˆ±çš„å°çŒ«'}, 
    {'text': 'ç¾ä¸½çš„é£æ™¯ç…§ç‰‡'}, 
    {'image': 'https://example.com/cat.jpg'}
]

# è·å–å¤šæ¨¡æ€åµŒå…¥
embedding_data = embedding_vl_model.get_embedding(input_data)
print(f"ç”Ÿæˆäº† {len(embedding_data)} ä¸ªåµŒå…¥å‘é‡")

# ä½¿ç”¨ç¼“å­˜æå‡æ€§èƒ½
embedding_cache = EmbeddingVLCache(InMemoryCache(), embedding_vl_model)
cached_embeddings = embedding_cache.get_embedding(input_data)
```

### 4. é‡æ’åºæ¨¡å‹

```python
from duowen_agent.llm import GeneralRerank
from duowen_agent.llm.tokenizer import tokenizer
from os import getenv

# é…ç½®é‡æ’åºæ¨¡å‹
rerank_cfg = {
    "model": "BAAI/bge-reranker-v2-m3",
    "base_url": "https://api.siliconflow.cn/v1/rerank",
    "api_key": getenv("SILICONFLOW_API_KEY")
}

rerank = GeneralRerank(
    model=rerank_cfg["model"],
    api_key=rerank_cfg["api_key"],
    base_url=rerank_cfg["base_url"],
    encoding=tokenizer.chat_encoder
)

# é‡æ’åºç¤ºä¾‹
query = 'è‹¹æœå…¬å¸çš„æœ€æ–°äº§å“'
documents = [
    "è‹¹æœå…¬å¸å‘å¸ƒäº†æ–°æ¬¾iPhone",
    "é¦™è•‰æ˜¯ä¸€ç§çƒ­å¸¦æ°´æœ", 
    "è‹¹æœæ‰‹æœºé”€é‡åˆ›æ–°é«˜",
    "æ°´æœå¸‚åœºä»·æ ¼æ³¢åŠ¨"
]

# è·å–é‡æ’åºç»“æœ
results = rerank.rerank(query=query, documents=documents, top_n=3)
for result in results:
    print(f"ç›¸å…³åº¦: {result['relevance_score']}, æ–‡æ¡£: {result['document']}")
```

## ğŸ” RAGç³»ç»Ÿ

å¤šé—»æä¾›äº†å®Œæ•´çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ–‡æ¡£è§£æã€æ–‡æœ¬åˆ‡å‰²å’Œå‘é‡æ£€ç´¢ç­‰åŠŸèƒ½ã€‚

### æ–‡æ¡£è§£æ

å¤šé—»æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„è§£æï¼Œå°†å„ç§æ ¼å¼è½¬æ¢ä¸ºMarkdownæ ¼å¼ä¾¿äºåç»­å¤„ç†ã€‚

#### Wordæ–‡æ¡£è§£æ

```python
from duowen_agent.rag.extractor.simple import word2md

# è§£æWordæ–‡æ¡£
markdown_content = word2md("./documents/report.docx")
print(markdown_content)
```

#### PDFæ–‡æ¡£è§£æ

```python
from duowen_agent.rag.extractor.simple import pdf2md

# è§£æPDFæ–‡æ¡£
markdown_content = pdf2md("./documents/whitepaper.pdf")
print(markdown_content)
```

#### PowerPointè§£æ

```python
from duowen_agent.rag.extractor.simple import ppt2md

# è§£æPPTæ–‡æ¡£
markdown_content = ppt2md("./documents/presentation.pptx")
print(markdown_content)
```

#### HTMLç½‘é¡µè§£æ

```python
from duowen_agent.rag.extractor.simple import html2md
import requests

# è·å–ç½‘é¡µå†…å®¹
url = "https://example.com/article"
response = requests.get(url)
response.raise_for_status()

# è½¬æ¢ä¸ºMarkdown
markdown_content = html2md(response.text)
print(markdown_content)
```

#### Excelè¡¨æ ¼è§£æ

```python
from duowen_agent.rag.extractor.simple import excel_parser

# è§£æExcelæ–‡ä»¶ï¼Œæ”¯æŒ.xlsxå’Œ.xlsæ ¼å¼
for sheet_content in excel_parser("./documents/data.xlsx"):
    print(f"å·¥ä½œè¡¨å†…å®¹: {sheet_content}")
    print("---")
```

### æ–‡æœ¬åˆ‡å‰²

å¤šé—»æä¾›äº†å¤šç§æ–‡æœ¬åˆ‡å‰²ç­–ç•¥ï¼Œé€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯å’Œæ–‡æ¡£ç±»å‹ã€‚

#### Tokenåˆ‡å‰²

åŸºäºè¯­è¨€æ¨¡å‹çš„tokenè¿›è¡Œåˆ‡å‰²ï¼Œç¡®ä¿æ¯ä¸ªå—ä¸è¶…è¿‡æ¨¡å‹çš„è¾“å…¥é™åˆ¶ã€‚

```python
from duowen_agent.rag.splitter import TokenChunker

# é…ç½®tokenåˆ‡å‰²å™¨
chunker = TokenChunker(
    chunk_size=512,      # æ¯å—æœ€å¤§tokenæ•°
    chunk_overlap=50     # å—ä¹‹é—´çš„é‡å tokenæ•°
)

text = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬å†…å®¹..."
for chunk in chunker.chunk(text):
    print(f"å—å¤§å°: {len(chunk.page_content)} å­—ç¬¦")
    print(f"å†…å®¹: {chunk.page_content[:100]}...")
    print("---")
```

#### åˆ†éš”ç¬¦åˆ‡å‰²

æ ¹æ®æŒ‡å®šçš„åˆ†éš”ç¬¦è¿›è¡Œæ–‡æœ¬åˆ†å‰²ï¼Œé€‚åˆç»“æ„åŒ–æ–‡æ¡£ã€‚

```python
from duowen_agent.rag.splitter import SeparatorChunker

# æŒ‰æ®µè½åˆ†å‰²
chunker = SeparatorChunker(
    separator="\n\n",     # åˆ†éš”ç¬¦
    chunk_size=1000,     # æœ€å¤§å—å¤§å°
    chunk_overlap=100    # é‡å å¤§å°
)

text = "æ®µè½1\n\næ®µè½2\n\næ®µè½3..."
for chunk in chunker.chunk(text):
    print(chunk.page_content)
    print("---")
```

#### é€’å½’åˆ‡å‰²

æ™ºèƒ½åœ°å°è¯•å¤šç§åˆ†éš”ç¬¦ï¼Œä¼˜å…ˆä½¿ç”¨è¯­ä¹‰è¾¹ç•Œè¿›è¡Œåˆ‡å‰²ã€‚

```python
from duowen_agent.rag.splitter import RecursiveChunker

# é…ç½®é€’å½’åˆ‡å‰²å™¨
chunker = RecursiveChunker(
    splitter_breaks=["\n\n", "ã€‚", "ï¼Ÿ", "ï¼", ".", "?", "!"],
    chunk_size=800,
    chunk_overlap=80
)

text = "é•¿ç¯‡æ–‡æ¡£å†…å®¹..."
for chunk in chunker.chunk(text):
    print(f"å—å†…å®¹: {chunk.page_content}")
    print("---")
```

#### è¯­ä¹‰åˆ‡å‰²

åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§è¿›è¡Œæ™ºèƒ½åˆ‡å‰²ï¼Œä¿æŒå†…å®¹çš„è¯­ä¹‰è¿è´¯æ€§ã€‚

```python
from duowen_agent.llm import OpenAIEmbedding
from duowen_agent.rag.splitter import SemanticChunker
from os import getenv

# é…ç½®åµŒå…¥æ¨¡å‹
emb_cfg = {
    "model": "BAAI/bge-large-zh-v1.5", 
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY")
}
emb = OpenAIEmbedding(**emb_cfg)

# è¯­ä¹‰åˆ‡å‰²å™¨
chunker = SemanticChunker(
    llm_embeddings_instance=emb,
    buffer_size=1,           # ç¼“å†²åŒºå¤§å°
    breakpoint_threshold_type="percentile",  # é˜ˆå€¼ç±»å‹
    breakpoint_threshold_amount=95          # é˜ˆå€¼ç™¾åˆ†ä½
)

text = "åŒ…å«å¤šä¸ªä¸»é¢˜çš„é•¿æ–‡æ¡£..."
for chunk in chunker.chunk(text):
    print(f"è¯­ä¹‰å—: {chunk.page_content}")
    print("---")
```

#### å¿«é€Ÿæ··åˆåˆ‡å‰²

é›†æˆå¤šç§åˆ‡å‰²ç­–ç•¥çš„é«˜æ•ˆåˆ‡å‰²å™¨ï¼Œé€‚åˆå¤§å¤šæ•°åº”ç”¨åœºæ™¯ã€‚

```python
from duowen_agent.rag.splitter import FastMixinChunker

# å¿«é€Ÿæ··åˆåˆ‡å‰²å™¨
chunker = FastMixinChunker(
    chunk_size=1000,
    chunk_overlap=100
)

text = "åŒ…å«æ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ç­‰å¤šç§å…ƒç´ çš„æ–‡æ¡£..."
for chunk in chunker.chunk(text):
    print(f"æ··åˆåˆ‡å‰²å—: {chunk.page_content}")
    print("---")
```

### å‘é‡æ•°æ®åº“

å¤šé—»å†…ç½®äº†è½»é‡çº§çš„å†…å­˜å‘é‡æ•°æ®åº“`KDTreeVector`ï¼Œé€‚ç”¨äºå°å‹åº”ç”¨çš„å¿«é€ŸåŸå‹å¼€å‘å’Œæµ‹è¯•ã€‚å¯¹äºå¤§å‹ç”Ÿäº§ç¯å¢ƒï¼Œå»ºè®®åŸºäº`BaseVector`æŠ½è±¡ç±»å¼€å‘è‡ªå®šä¹‰çš„å‘é‡æ•°æ®åº“æ‰©å±•ã€‚

#### å†…ç½®å‘é‡åº“ä½¿ç”¨

```python
from duowen_agent.rag.retrieval.kdtree import KDTreeVector
from duowen_agent.llm import OpenAIEmbedding
from duowen_agent.rag.nlp_bak import LexSynth
from duowen_agent.rag.models import Document
from os import getenv

# é…ç½®åµŒå…¥æ¨¡å‹
emb_cfg = {
    "model": "BAAI/bge-large-zh-v1.5",
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY"),
}
emb = OpenAIEmbedding(**emb_cfg)
lex_synth = LexSynth()

# åˆ›å»ºå‘é‡æ•°æ®åº“
vdb = KDTreeVector(
    llm_embeddings_instance=emb,
    lex_synth=lex_synth,
    db_file="./knowledge_base.svdb"
)

# æ·»åŠ æ–‡æ¡£
documents = [
    "è‹¹æœå…¬å¸äº2023å¹´9æœˆå‘å¸ƒiPhone 15 Proï¼Œæ–°å¢é’›åˆé‡‘æœºèº«ã€A17 ProèŠ¯ç‰‡å’ŒUSB-Cæ¥å£ã€‚",
    "iPhone 15 Proæ”¯æŒ4K ProResè§†é¢‘å½•åˆ¶ï¼Œé…å¤‡48MPä¸»æ‘„åƒå¤´ã€‚",
    "æ–°æ¬¾iPhoneé‡‡ç”¨Action Buttonæ›¿ä»£é™éŸ³å¼€å…³ï¼Œæä¾›æ›´å¤šè‡ªå®šä¹‰åŠŸèƒ½ã€‚"
]

for doc_text in documents:
    vdb.add_document(Document(page_content=doc_text))

# ä¿å­˜åˆ°ç£ç›˜
vdb.save_to_disk()

# æŸ¥è¯¢ç¤ºä¾‹
query = "iPhone 15 Proæœ‰ä»€ä¹ˆæ–°åŠŸèƒ½ï¼Ÿ"

print("=== è¯­ä¹‰æ£€ç´¢ ===")
for result in vdb.semantic_search(query, top_k=3):
    print(f"ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
    print(f"å†…å®¹: {result.result.page_content}")
    print("---")

print("\n=== å…¨æ–‡æ£€ç´¢ ===")
for result in vdb.full_text_search(query, top_k=3):
    print(f"ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
    print(f"å†…å®¹: {result.result.page_content}")
    print("---")

print("\n=== æ··åˆæ£€ç´¢ ===")
for result in vdb.hybrid_search(query, top_k=3):
    print(f"ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
    print(f"å†…å®¹: {result.result.page_content}")
    print("---")
```

#### è‡ªå®šä¹‰å‘é‡æ•°æ®åº“æ‰©å±•

å¯¹äºå¤§å‹ç”Ÿäº§ç¯å¢ƒï¼Œæ‚¨å¯ä»¥åŸºäº`BaseVector`æŠ½è±¡ç±»å¼€å‘è‡ªå®šä¹‰çš„å‘é‡æ•°æ®åº“å®ç°ï¼š

```python
from duowen_agent.rag.retrieval.base import BaseVector
from duowen_agent.rag.models import Document, SearchResult
from typing import List

class CustomVectorDB(BaseVector):
    """è‡ªå®šä¹‰å‘é‡æ•°æ®åº“å®ç°"""
    
    def __init__(self, connection_string: str):
        # åˆå§‹åŒ–æ‚¨çš„å‘é‡æ•°æ®åº“è¿æ¥
        self.connection = self._connect(connection_string)
    
    def add_document(self, document: Document) -> None:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“"""
        # å®ç°æ–‡æ¡£æ·»åŠ é€»è¾‘
        pass
    
    def semantic_search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """è¯­ä¹‰æ£€ç´¢å®ç°"""
        # å®ç°è¯­ä¹‰æ£€ç´¢é€»è¾‘
        pass
    
    def hybrid_search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """æ··åˆæ£€ç´¢å®ç°"""
        # å®ç°æ··åˆæ£€ç´¢é€»è¾‘
        pass

# ä½¿ç”¨è‡ªå®šä¹‰å‘é‡æ•°æ®åº“
custom_vdb = CustomVectorDB("your_connection_string")
```

## ğŸ¤– Agentæ¡†æ¶

å¤šé—»æä¾›äº†å¼ºå¤§çš„æ™ºèƒ½ä½“(Agent)æ¡†æ¶ï¼Œæ”¯æŒåŸºäºReActæ¨¡å¼çš„æ¨ç†å’Œè¡ŒåŠ¨èƒ½åŠ›ï¼Œä»¥åŠå®Œå–„çš„è®°å¿†ç³»ç»Ÿã€‚

### ReAct Agent

åŸºäºReActï¼ˆReasoning and Actingï¼‰æ¨¡å¼çš„æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿè¿›è¡Œæ¨ç†å’Œè¡ŒåŠ¨ã€‚

```python
from duowen_agent.agents.react import ReactAgent
from duowen_agent.llm import OpenAIChat
from duowen_agent.tools.base import BaseTool
from pydantic import BaseModel, Field
from os import getenv

# é…ç½®è¯­è¨€æ¨¡å‹
llm_cfg = {
    "model": "THUDM/glm-4-9b-chat",
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY"),
}
llm = OpenAIChat(**llm_cfg)

# å®šä¹‰è‡ªå®šä¹‰å·¥å…·
class CalculatorParameters(BaseModel):
    expression: str = Field(description="æ•°å­¦è¡¨è¾¾å¼")

class Calculator(BaseTool):
    name: str = "è®¡ç®—å™¨"
    description: str = "æ‰§è¡Œæ•°å­¦è®¡ç®—"
    parameters = CalculatorParameters
    
    def _run(self, expression: str) -> str:
        try:
            result = eval(expression)
            return f"è®¡ç®—ç»“æœ: {result}"
        except Exception as e:
            return f"è®¡ç®—é”™è¯¯: {str(e)}"

# åˆ›å»ºAgent
agent = ReactAgent(
    llm=llm,
    tools=[Calculator()],
    max_iterations=5
)

# è¿è¡ŒAgent
result = agent.run("è¯·å¸®æˆ‘è®¡ç®— (25 + 75) * 3 çš„ç»“æœ")
print(result)
```

### è®°å¿†ç³»ç»Ÿ

```python
from duowen_agent.agents.memories.conversation import ConversationMemory
from duowen_agent.llm import OpenAIChat, OpenAIEmbedding
from duowen_agent.rag.nlp_bak import LexSynth
from os import getenv

# é…ç½®æ¨¡å‹
llm_cfg = {
    "model": "THUDM/glm-4-9b-chat",
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY"),
}
llm = OpenAIChat(**llm_cfg)

emb_cfg = {
    "model": "BAAI/bge-large-zh-v1.5",
    "base_url": "https://api.siliconflow.cn/v1",
    "api_key": getenv("SILICONFLOW_API_KEY"),
}
emb = OpenAIEmbedding(**emb_cfg)

# åˆ›å»ºå¯¹è¯è®°å¿†
memory = ConversationMemory(
    llm=llm,
    emb=emb,
    lex_synth=LexSynth(),
    summarize_threshold=1000  # è¶…è¿‡1000å­—ç¬¦æ—¶è¿›è¡Œæ€»ç»“
)

# æ·»åŠ å¯¹è¯å†å²
memory.add_system_message("ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹")
memory.add_user_message("æˆ‘å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ")
memory.add_assistant_message("ä½ å¥½å¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ è¿™ä½è½¯ä»¶å·¥ç¨‹å¸ˆã€‚")
memory.add_user_message("æˆ‘æœ€è¿‘åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ ")

# è·å–ç›¸å…³è®°å¿†
relevant_memories = memory.get_relevant_memories("æˆ‘çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ")
for memory_item in relevant_memories:
    print(memory_item)
```

## ğŸ”§ å·¥å…·ç”Ÿæ€

å¤šé—»æä¾›äº†ä¸°å¯Œçš„å·¥å…·ç”Ÿæ€ç³»ç»Ÿï¼ŒåŒ…æ‹¬å†…ç½®å·¥å…·å’Œè‡ªå®šä¹‰å·¥å…·æ”¯æŒï¼Œæ–¹ä¾¿å¼€å‘è€…æ‰©å±•Agentçš„èƒ½åŠ›ã€‚

### å†…ç½®å·¥å…·

#### ç½‘ç»œæœç´¢å·¥å…·

```python
from duowen_agent.tools.tavily_search import Tavily
from duowen_agent.tools.bocha_search import Bocha

# Tavilyæœç´¢
tavily = Tavily()
result, view = tavily._run(query="2024å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿")
print(f"æœç´¢ç»“æœ: {result}")
print(f"è¯¦ç»†ä¿¡æ¯: {view}")

# Bochaæœç´¢
bocha = Bocha()
result, view = bocha._run(query="æœ€æ–°çš„AIæŠ€æœ¯çªç ´")
print(f"æœç´¢ç»“æœ: {result}")
```

#### æ–‡ä»¶å¤„ç†å·¥å…·

```python
from duowen_agent.tools.file import FileManager

# æ–‡ä»¶ç®¡ç†å·¥å…·
file_manager = FileManager()

# è¯»å–æ–‡ä»¶
content = file_manager.read_file("./documents/report.txt")
print(content)

# å†™å…¥æ–‡ä»¶
file_manager.write_file("./output/summary.txt", "è¿™æ˜¯æ€»ç»“å†…å®¹")
```

#### Pythonä»£ç æ‰§è¡Œ

```python
from duowen_agent.tools.python_repl import PythonREPL

# Pythonä»£ç æ‰§è¡Œå™¨
repl = PythonREPL()

# æ‰§è¡ŒPythonä»£ç 
code = """
import numpy as np
data = np.array([1, 2, 3, 4, 5])
result = np.mean(data)
print(f"å¹³å‡å€¼: {result}")
"""

output = repl._run(code)
print(output)
```

### è‡ªå®šä¹‰å·¥å…·

```python
from duowen_agent.tools.base import BaseTool
from pydantic import BaseModel, Field
import requests

class WeatherParameters(BaseModel):
    city: str = Field(description="åŸå¸‚åç§°")

class WeatherTool(BaseTool):
    name: str = "å¤©æ°”æŸ¥è¯¢"
    description: str = "æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"
    parameters = WeatherParameters
    
    def _run(self, city: str) -> str:
        # è¿™é‡Œå¯ä»¥è°ƒç”¨çœŸå®çš„å¤©æ°”API
        return f"{city}ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦25Â°C"

# ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·
weather_tool = WeatherTool()
result = weather_tool._run("åŒ—äº¬")
print(result)
```

## ğŸŒ MCPåè®®æ”¯æŒ

å¤šé—»æ”¯æŒModel Context Protocol(MCP)åè®®ï¼Œå¯ä»¥æ–¹ä¾¿åœ°ä¸æ”¯æŒè¯¥åè®®çš„æœåŠ¡è¿›è¡Œäº¤äº’ã€‚

```python
from duowen_agent.mcp.mcp_client import MCPClient

# è¿æ¥MCPæœåŠ¡
with MCPClient("https://mcp.example.com/sse", authed=False) as client:
    # åˆ—å‡ºå¯ç”¨å·¥å…·
    tools = client.list_tools()
    print(f"å¯ç”¨å·¥å…·: {tools}")
    
    # è°ƒç”¨å·¥å…·
    result = client.invoke_tool(
        tool_name="search", 
        tool_args={"query": "äººå·¥æ™ºèƒ½"}
    )
    print(f"å·¥å…·æ‰§è¡Œç»“æœ: {result}")
```


## ğŸš€ é«˜çº§ç‰¹æ€§

å¤šé—»æä¾›äº†ä¸€ç³»åˆ—é«˜çº§ç‰¹æ€§ï¼ŒåŒ…æ‹¬æ‰¹é‡å¤„ç†å’ŒéŸ³é¢‘å¤„ç†ç­‰åŠŸèƒ½ï¼Œæ»¡è¶³æ›´å¤æ‚çš„åº”ç”¨åœºæ™¯éœ€æ±‚ã€‚

### æ‰¹é‡å¤„ç†

```python
from duowen_agent.llm.batch import BatchProcessor
from duowen_agent.llm import OpenAIChat

# æ‰¹é‡å¤„ç†å¤§é‡æ–‡æœ¬
batch_processor = BatchProcessor(llm=OpenAIChat(**llm_cfg))

texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
results = batch_processor.process_batch(texts, "è¯·æ€»ç»“è¿™æ®µæ–‡æœ¬")

for i, result in enumerate(results):
    print(f"æ–‡æœ¬{i+1}æ€»ç»“: {result}")
```

### éŸ³é¢‘å¤„ç†

```python
from duowen_agent.llm.audio import AudioProcessor

# éŸ³é¢‘è½¬æ–‡å­—
audio_processor = AudioProcessor()
transcript = audio_processor.transcribe("./audio/speech.mp3")
print(f"è½¬å½•ç»“æœ: {transcript}")

# æ–‡å­—è½¬éŸ³é¢‘
audio_data = audio_processor.text_to_speech("ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨å¤šé—»æ¡†æ¶")
```

## çŸ¥è¯†å›¾è°± (Graph)

Duowen Graph æ˜¯ Duowen Agent æ¡†æ¶ä¸­çš„çŸ¥è¯†å›¾è°±æ¨¡å—ï¼Œç”¨äºä»æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ï¼Œå¹¶æ”¯æŒåŸºäºå›¾è°±çš„æŸ¥è¯¢å’Œå¯è§†åŒ–ã€‚

### åŠŸèƒ½æ¦‚è¿°

- **çŸ¥è¯†æå–**ï¼šä»æ–‡æœ¬ä¸­è‡ªåŠ¨æå–å®ä½“å’Œå…³ç³»
- **å›¾è°±æ„å»º**ï¼šåŸºäºæå–çš„å®ä½“å’Œå…³ç³»æ„å»ºçŸ¥è¯†å›¾è°±
- **ç¤¾åŒºå‘ç°**ï¼šå¯¹å›¾è°±è¿›è¡Œç¤¾åŒºåˆ’åˆ†ï¼Œç”Ÿæˆç¤¾åŒºæŠ¥å‘Š
- **è¯­ä¹‰æŸ¥è¯¢**ï¼šæ”¯æŒåŸºäºè¯­ä¹‰çš„å›¾è°±æŸ¥è¯¢ï¼ŒåŒ…æ‹¬å±€éƒ¨æŸ¥è¯¢å’Œå…¨å±€æŸ¥è¯¢
- **å¯è§†åŒ–**ï¼šæ”¯æŒçŸ¥è¯†å›¾è°±çš„å¯è§†åŒ–å±•ç¤º

### åˆå§‹åŒ–å›¾è°±

```python
from duowen_agent.llm import OpenAIChat, OpenAIEmbedding
from duowen_agent.rag.graph import Graph, QueryParam
from duowen_agent.rag.graph.storage.vdb_kdtree import KdTreeVectorStorage
from duowen_agent.rag.nlp_bak import LexSynth
from duowen_agent.rag.splitter import RecursiveChunker

# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = OpenAIChat(
    model="your_model_name",
    base_url="your_api_base_url",
    api_key="your_api_key",
    token_limit=1024 * 128,
    max_tokens=1024 * 4,
)

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
emb = OpenAIEmbedding(
    model="your_embedding_model",
    base_url="your_api_base_url",
    api_key="your_api_key",
    dimension=1024,
    max_token=32 * 1024,
)

# åˆå§‹åŒ–è¯æ³•åˆ†æå™¨
lex_synth = LexSynth()

# åˆå§‹åŒ–å›¾è°±
graph = Graph(
    llm_instance=llm,
    chunk_func=RecursiveChunker(),
    extractor_concurrent_num=36,  # å®ä½“æå–å¹¶å‘æ•°
    community_concurrent_num=36,  # ç¤¾åŒºå‘ç°å¹¶å‘æ•°
    entity_vdb=KdTreeVectorStorage(
        namespace="entity", embedding=emb, lex_synth=lex_synth
    ),
    community_vdb=KdTreeVectorStorage(
        namespace="community", embedding=emb, lex_synth=lex_synth
    ),
)
```

### æ’å…¥æ–‡æ¡£

```python
# æ’å…¥æ–‡æ¡£
docs = {
    "doc_id_1": "æ–‡æ¡£å†…å®¹1",
    "doc_id_2": "æ–‡æ¡£å†…å®¹2",
    # æ›´å¤šæ–‡æ¡£...
}
graph.insert(docs)
```

### æ„å»ºç¤¾åŒº

```python
# æ„å»ºç¤¾åŒº
graph.build_community()
```

### æŸ¥è¯¢å›¾è°±

```python
# å±€éƒ¨æŸ¥è¯¢
local_result = graph.query(
    "ä½ çš„æŸ¥è¯¢é—®é¢˜", 
    QueryParam(mode="local")
)

# å…¨å±€æŸ¥è¯¢
global_result = graph.query(
    "ä½ çš„æŸ¥è¯¢é—®é¢˜", 
    QueryParam(mode="global")
)

# åªè·å–ä¸Šä¸‹æ–‡ï¼Œä¸ç”Ÿæˆå›ç­”
context_only = graph.query(
    "ä½ çš„æŸ¥è¯¢é—®é¢˜", 
    QueryParam(mode="global", only_need_context=True)
)
```

### è·å–å’Œä¿å­˜å›¾è°±

```python
from duowen_agent.rag.graph import dump_graph

# è·å–å›¾è°±
graph_data = graph.get_graph()

# ä¿å­˜å›¾è°±åˆ°æ–‡ä»¶
with open("graph.json", "w") as f:
    f.write(dump_graph(graph_data))
```

### å›¾è°±å¯è§†åŒ–

```python
from duowen_agent.rag.graph.utils import create_styled_graph

# ç”ŸæˆHTMLå¯è§†åŒ–
with open("graph.html", "w") as f:
    f.write(create_styled_graph(graph.get_graph()))
```

### é«˜çº§é…ç½®

QueryParam ç±»æä¾›äº†ä¸°å¯Œçš„æŸ¥è¯¢å‚æ•°é…ç½®ï¼š

```python
from duowen_agent.rag.graph import QueryParam

# å±€éƒ¨æŸ¥è¯¢å‚æ•°
local_param = QueryParam(
    mode="local",                        # æŸ¥è¯¢æ¨¡å¼ï¼šlocal/global/naive
    only_need_context=False,           # æ˜¯å¦åªè¿”å›ä¸Šä¸‹æ–‡
    response_type="Multiple Paragraphs", # å›ç­”ç±»å‹
    level=2,                           # ç¤¾åŒºå±‚çº§
    top_k=20,                          # æ£€ç´¢æ•°é‡
    local_max_token_for_text_unit=4000, # æ–‡æœ¬å•å…ƒæœ€å¤§tokenæ•°
    local_max_token_for_local_context=4800, # å±€éƒ¨ä¸Šä¸‹æ–‡æœ€å¤§tokenæ•°
    local_max_token_for_community_report=3200, # ç¤¾åŒºæŠ¥å‘Šæœ€å¤§tokenæ•°
    local_community_single_one=False,   # æ˜¯å¦åªä½¿ç”¨ä¸€ä¸ªç¤¾åŒº
)

# å…¨å±€æŸ¥è¯¢å‚æ•°
global_param = QueryParam(
    mode="global",
    global_concurrent_num=4,           # å…¨å±€æŸ¥è¯¢å¹¶å‘æ•°
    global_min_community_rating=0,     # ç¤¾åŒºæœ€ä½è¯„åˆ†
    global_max_consider_community=512, # æœ€å¤§è€ƒè™‘ç¤¾åŒºæ•°
    global_max_token_for_community_report=16384, # ç¤¾åŒºæŠ¥å‘Šæœ€å¤§tokenæ•°
)
```

### å›¾è°±å·¥å…·ç±»

```python
from duowen_agent.rag.graph.utils import NetworkXUtils, similarity_node

# è·å–é‚»å±…å›¾
neighbors_graph = NetworkXUtils(graph_data).get_neighbors_graph(
    "å®ä½“åç§°",
    4,  # æ·±åº¦
    top_k_neighbors=5,
    top_k_node=5,
)

# åˆ†æèŠ‚ç‚¹ç›¸ä¼¼æ€§
similar_nodes = similarity_node(
    node_names,  # èŠ‚ç‚¹åç§°åˆ—è¡¨
    node_vectors,  # èŠ‚ç‚¹å‘é‡åˆ—è¡¨
    sim_threshold=0.9  # ç›¸ä¼¼åº¦é˜ˆå€¼
)
```
