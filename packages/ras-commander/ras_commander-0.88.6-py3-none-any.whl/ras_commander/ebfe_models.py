"""
eBFE Model Organization Functions

Organization functions for specific FEMA eBFE/BLE models used in example notebooks.

These functions provide tested, deterministic organization for:
- Spring Creek (12040102) - Pattern 3a: Single 2D model with nested zip
- North Galveston Bay (12040203) - Pattern 4: Compound HMS + RAS
- Upper Guadalupe (12100201) - Pattern 3b: Cascaded watershed models

For organizing other eBFE models, use the organizing-ebfe-models agent skill which
handles all patterns dynamically and generates new functions as needed.

Generated by: organizing-ebfe-models agent skill
Last Updated: 2025-12-26
"""

from pathlib import Path
from typing import Optional, Dict, List
import shutil
import zipfile
from datetime import datetime
import requests
from tqdm import tqdm

from ras_commander.Decorators import log_call


class RasEbfeModels:
    """
    Organization functions for specific eBFE/BLE models.

    Static class providing deterministic organization for eBFE models used in
    example notebooks. Each function was generated by the organizing-ebfe-models
    agent skill after analyzing the model's specific archive structure.

    Example:
        >>> from ras_commander.ebfe_models import RasEbfeModels
        >>> from pathlib import Path
        >>>
        >>> # Organize Spring Creek
        >>> organized = RasEbfeModels.organize_spring_creek(
        ...     Path(r"D:/downloads/12040102_Spring_Models_extracted")
        ... )
        >>>
        >>> # Use with ras-commander
        >>> from ras_commander import init_ras_project
        >>> init_ras_project(organized / "RAS Model", "5.0.7")
    """

    @staticmethod
    @log_call
    def organize_spring_creek(
        downloaded_folder: Path,
        output_folder: Optional[Path] = None,
        validate_dss: bool = True
    ) -> Path:
        """
        Organize Spring Creek (12040102) eBFE model with automatic download.

        Pattern 3a: Single 2D model in nested zip with self-contained terrain.

        **Automatic Download**: If source data not found, automatically downloads 9.7 GB
        from eBFE S3 bucket. Download includes progress tracking and is resume-safe.

        Model characteristics:
        - Single HEC-RAS 2D unsteady flow model
        - Nested _Final.zip (9.67 GB) requires two-level extraction
        - Terrain self-contained in Terrain/ subfolder
        - 8 plans with pre-computed results (~1.2 GB per plan)
        - HEC-RAS version 5.0.7

        Args:
            downloaded_folder: Path where data should be (will auto-download if missing)
            output_folder: Output location (default: ./ebfe_organized/SpringCreek_12040102/)
            validate_dss: Run DSS validation checks (default: True)

        Returns:
            Path to organized model with structure:
                SpringCreek_12040102/
                ├── HMS Model/        (empty - no HMS for Pattern 3a)
                ├── RAS Model/        (Spring 2D model + terrain)
                ├── Spatial Data/     (terrain + shapefiles)
                ├── Documentation/    (inventory spreadsheet)
                └── agent/model_log.md

        Example:
            >>> from ras_commander.ebfe_models import RasEbfeModels
            >>> from pathlib import Path
            >>>
            >>> # Data will auto-download if not present (9.7 GB)
            >>> organized = RasEbfeModels.organize_spring_creek(
            ...     downloaded_folder=Path(r"D:/eBFE/12040102_Models_extracted"),
            ...     validate_dss=True
            ... )
            >>>
            >>> # Use with ras-commander
            >>> from ras_commander import init_ras_project
            >>> init_ras_project(organized / "RAS Model", "5.0.7")
        """
        downloaded_folder = Path(downloaded_folder)
        if output_folder is None:
            output_folder = Path("./ebfe_organized/SpringCreek_12040102")
        else:
            output_folder = Path(output_folder)

        # Create 4-folder structure + agent folder
        folders = {
            'hms': output_folder / "HMS Model",
            'ras': output_folder / "RAS Model",
            'spatial': output_folder / "Spatial Data",
            'docs': output_folder / "Documentation",
            'agent': output_folder / "agent"
        }

        for folder in folders.values():
            folder.mkdir(parents=True, exist_ok=True)

        print(f"Organizing Spring Creek (12040102) - Pattern 3a")
        print(f"Source: {downloaded_folder}")
        print(f"Output: {output_folder}\n")

        # Download source data if not present
        if not downloaded_folder.exists():
            print("Source data not found - downloading from eBFE S3...")
            url = "https://ebfedata.s3.amazonaws.com/12040102_Spring/12040102_Models.zip"

            # Download and extract to parent folder
            downloaded_folder = RasEbfeModels._download_and_extract(
                url=url,
                output_folder=downloaded_folder.parent,
                description="Spring Creek Models (9.7 GB)"
            )

        # Pattern 3a specific paths
        models_folder = downloaded_folder / "12040102_Models_202207"
        final_zip = models_folder / "_Final.zip"
        inventory = models_folder / "2D_Model_Inventory_Spring.xlsx"

        # Validate nested structure exists
        if not models_folder.exists():
            raise FileNotFoundError(
                f"Models folder not found: {models_folder}\n\n"
                f"Expected structure: {downloaded_folder}/12040102_Models_202207/_Final.zip\n"
                f"Downloaded archive may have unexpected structure."
            )

        if not final_zip.exists():
            raise FileNotFoundError(
                f"Nested zip not found: {final_zip}\n\n"
                f"Expected file: {models_folder}/_Final.zip\n"
                f"Downloaded archive may be incomplete."
            )

        # Extract nested _Final.zip
        print("[1/5] Extracting nested _Final.zip...")
        final_extracted = models_folder / "_Final_extracted"
        if not final_extracted.exists():
            print(f"  Extracting 9.67 GB nested zip (may take 5-10 minutes)...")
            with zipfile.ZipFile(final_zip, 'r') as zip_ref:
                zip_ref.extractall(final_extracted)
            print(f"  ✓ Extracted")
        else:
            print(f"  ✓ Already extracted")

        # Locate Spring model folder
        spring_folder = final_extracted / "_Final" / "HECRAS_507"
        if not spring_folder.exists():
            raise FileNotFoundError(f"Spring model not found at {spring_folder}")

        # Organize RAS Model files
        print("\n[2/5] Organizing RAS Model...")
        files_copied = 0
        for file in spring_folder.rglob('*'):
            if file.is_file():
                # Skip shapefile .prj files
                if file.suffix == '.prj' and file.parent.name in ['Features', 'Shp']:
                    continue

                rel_path = file.relative_to(spring_folder)
                dest = folders['ras'] / rel_path
                dest.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file, dest)
                files_copied += 1

        print(f"  ✓ Organized {files_copied} files")

        # Organize Spatial Data
        print("\n[3/5] Organizing Spatial Data...")
        terrain_source = spring_folder / "Terrain"
        if terrain_source.exists():
            shutil.copytree(terrain_source, folders['spatial'] / "Terrain", dirs_exist_ok=True)
            print(f"  ✓ Copied Terrain/")

        for shp_folder in ['Features', 'Shp']:
            shp_source = spring_folder / shp_folder
            if shp_source.exists():
                shutil.copytree(shp_source, folders['spatial'] / shp_folder, dirs_exist_ok=True)
                print(f"  ✓ Copied {shp_folder}/")

        # Organize Documentation
        print("\n[4/6] Organizing Documentation...")
        if inventory.exists():
            shutil.copy2(inventory, folders['docs'] / inventory.name)
            print(f"  ✓ Copied inventory")

        # CRITICAL: Correct ALL file paths in HEC-RAS files
        print("\n[5/6] Correcting all file paths to relative references...")
        dss_corrections = RasEbfeModels._correct_dss_paths(folders['ras'])
        rasmap_corrections = RasEbfeModels._correct_rasmap_terrain_paths(folders['ras'])
        print(f"  ✓ Corrected {dss_corrections} DSS path(s)")
        print(f"  ✓ Corrected {rasmap_corrections} terrain path(s)")

        # Validate DSS files
        dss_results = []
        if validate_dss:
            print("\n[6/6] Validating DSS files...")
            dss_results = RasEbfeModels._validate_dss_files(folders['ras'])

        # Create agent model log
        RasEbfeModels._create_spring_creek_log(
            folders['agent'],
            downloaded_folder,
            output_folder,
            files_copied,
            dss_results
        )

        print(f"\n✓ Spring Creek organized to: {output_folder}")
        print(f"\nSee {output_folder / 'agent' / 'model_log.md'} for details")

        return output_folder

    @staticmethod
    @log_call
    def organize_north_galveston_bay(
        downloaded_folder: Path,
        output_folder: Optional[Path] = None,
        extract_ras_nested: bool = False,
        validate_dss: bool = True
    ) -> Path:
        """
        Organize North Galveston Bay (12040203) eBFE model with automatic download.

        Pattern 4: Compound archive with HMS hydrologic + RAS hydraulic models.

        **Automatic Download**: If source data not found, automatically downloads 8.2 GB
        from eBFE S3 bucket. Download includes progress tracking and is resume-safe.

        Model characteristics:
        - Contains both HMS (NorthGalvestonBay.hms) and RAS models
        - HMS: 7 storm frequencies (10yr through 500yr) + sensitivity variants
        - RAS: 2D coastal model in nested 6.1 GB zip (may require manual extraction)
        - Total size: 8.2 GB

        Args:
            downloaded_folder: Path where data should be (will auto-download if missing)
            output_folder: Output location (default: ./ebfe_organized/NorthGalvestonBay_12040203/)
            extract_ras_nested: Attempt auto-extraction of RAS_Submittal.zip (may fail, default: False)
            validate_dss: Run DSS validation checks (default: True)

        Returns:
            Path to organized model with structure:
                NorthGalvestonBay_12040203/
                ├── HMS Model/        (NorthGalvestonBay HMS project)
                ├── RAS Model/        (2D coastal model, may need manual extraction)
                ├── Spatial Data/     (pending RAS extraction)
                ├── Documentation/    (BLE reports + metadata)
                └── agent/model_log.md

        Note:
            RAS_Submittal.zip (6.1 GB) often requires manual extraction via Windows Explorer
            due to file locking issues with command-line tools.

        Example:
            >>> from ras_commander.ebfe_models import RasEbfeModels
            >>> from pathlib import Path
            >>>
            >>> # Data will auto-download if not present (8.2 GB)
            >>> organized = RasEbfeModels.organize_north_galveston_bay(
            ...     downloaded_folder=Path(r"D:/eBFE/12040203_Models_extracted"),
            ...     extract_ras_nested=False  # Manual extraction recommended
            ... )
            >>>
            >>> # HMS model ready immediately
            >>> hms = organized / "HMS Model/NorthGalvestonBay/NorthGalvestonBay.hms"
        """
        downloaded_folder = Path(downloaded_folder)
        if output_folder is None:
            output_folder = Path("./ebfe_organized/NorthGalvestonBay_12040203")
        else:
            output_folder = Path(output_folder)

        # Create 4-folder structure
        folders = {
            'hms': output_folder / "HMS Model",
            'ras': output_folder / "RAS Model",
            'spatial': output_folder / "Spatial Data",
            'docs': output_folder / "Documentation",
            'agent': output_folder / "agent"
        }

        for folder in folders.values():
            folder.mkdir(parents=True, exist_ok=True)

        print(f"Organizing North Galveston Bay (12040203) - Pattern 4")
        print(f"Source: {downloaded_folder}")
        print(f"Output: {output_folder}\n")

        # Download source data if not present
        if not downloaded_folder.exists():
            print("Source data not found - downloading from eBFE S3...")
            url = "https://ebfedata.s3.amazonaws.com/12040203_NorthGalvestonBay/12040203_Models.zip"

            # Download and extract to parent folder
            downloaded_folder = RasEbfeModels._download_and_extract(
                url=url,
                output_folder=downloaded_folder.parent,
                description="North Galveston Bay Models (8.2 GB)"
            )

        # Pattern 4 specific paths
        hms_source = downloaded_folder / "Hydrology" / "Hydrology" / "HMS" / "NorthGalvestonBay"
        ras_nested_zip = downloaded_folder / "Hydraulic_Models" / "RAS_Submittal.zip"
        metadata_xml = downloaded_folder / "480119_Hydraulics_metadata.xml"
        inventory = downloaded_folder / "Hydraulic_Models" / "2D_Model_Inventory.xlsx"

        # Check for separate Documents.zip extraction
        docs_source = downloaded_folder.parent / "12040203_NorthGalvestonBay_Documents_extracted"

        # Organize HMS Model
        print("[1/4] Organizing HMS Model...")
        hms_files = 0
        if hms_source.exists():
            hms_dest = folders['hms'] / "NorthGalvestonBay"
            shutil.copytree(hms_source, hms_dest, dirs_exist_ok=True)
            hms_files = len(list(hms_dest.rglob('*')))
            print(f"  ✓ Organized HMS project ({hms_files} files)")
        else:
            print(f"  ⚠️ HMS folder not found")

        # Organize Documentation
        print("\n[2/4] Organizing Documentation...")
        docs_copied = 0

        for doc_file in [metadata_xml, inventory]:
            if doc_file.exists():
                shutil.copy2(doc_file, folders['docs'] / doc_file.name)
                docs_copied += 1

        if docs_source.exists():
            for doc in docs_source.rglob('*'):
                if doc.is_file() and doc.suffix in ['.pdf', '.docx']:
                    shutil.copy2(doc, folders['docs'] / doc.name)
                    docs_copied += 1

        print(f"  ✓ Organized {docs_copied} document(s)")

        # Handle RAS Model (nested zip)
        print("\n[3/4] Organizing RAS Model...")
        ras_extracted = False

        if ras_nested_zip.exists():
            size_gb = ras_nested_zip.stat().st_size / 1e9
            print(f"  Found RAS_Submittal.zip ({size_gb:.1f} GB)")

            if extract_ras_nested:
                print(f"  Attempting extraction...")
                try:
                    with zipfile.ZipFile(ras_nested_zip, 'r') as zip_ref:
                        zip_ref.extractall(folders['ras'])
                    print(f"  ✓ RAS model extracted")
                    ras_extracted = True
                    RasEbfeModels._organize_spatial_from_ras(folders['ras'], folders['spatial'])
                except Exception as e:
                    print(f"  ✗ Extraction failed: {e}")
                    print(f"  Creating manual extraction instructions...")
                    RasEbfeModels._create_extraction_readme(folders['ras'], ras_nested_zip, output_folder)
            else:
                print(f"  Skipping auto-extraction (extract_ras_nested=False)")
                RasEbfeModels._create_extraction_readme(folders['ras'], ras_nested_zip, output_folder)

        # Validate DSS
        dss_results = []
        if validate_dss and ras_extracted:
            print("\n[4/4] Validating DSS files...")
            dss_results = RasEbfeModels._validate_dss_files(folders['ras'])
        else:
            print("\n[4/4] DSS validation skipped")

        # Create model log
        RasEbfeModels._create_north_galveston_log(
            folders['agent'],
            downloaded_folder,
            output_folder,
            hms_files,
            ras_extracted,
            docs_copied,
            dss_results
        )

        print(f"\n✓ North Galveston Bay organized to: {output_folder}")
        print(f"\nOrganized:")
        print(f"  - HMS Model: ✓ ({hms_files} files)")
        print(f"  - Documentation: ✓ ({docs_copied} files)")
        print(f"  - RAS Model: {'✓' if ras_extracted else '⚠️ Requires manual extraction'}")

        return output_folder

    @staticmethod
    @log_call
    def organize_upper_guadalupe(
        downloaded_folder: Path,
        output_folder: Optional[Path] = None,
        validate_dss: bool = True
    ) -> Path:
        """
        Organize Upper Guadalupe (12100201) eBFE model with automatic download.

        Pattern 3b: Multiple cascaded 2D watershed models with DSS flow transfer.

        **Automatic Download**: If source data not found, automatically downloads 54.6 GB
        from eBFE S3 bucket. This is a VERY LARGE download - ensure sufficient disk space
        and time for download/extraction. Download includes progress tracking and is resume-safe.

        Model characteristics:
        - 4 cascaded watershed models (UPGU1 → UPGU2 → UPGU3 → UPGU4)
        - 28 total plans (7 AEP frequencies × 4 models)
        - 55 GB total size
        - 15 GB terrain data (1m resolution, 2.8-4.9 GB per model)
        - 10 DSS files with 10,248 pathnames (gridded precip + boundaries)
        - HEC-RAS version 6.3.1

        Args:
            downloaded_folder: Path where data should be (will auto-download if missing)
            output_folder: Output location (default: ./ebfe_organized/UpperGuadalupe_12100201/)
            validate_dss: Run DSS validation checks (default: True, validates 10,248 pathnames)

        Returns:
            Path to organized model with structure:
                UpperGuadalupe_12100201/
                ├── HMS Model/        (README - no HMS, RAS 6.3.1 handles precip)
                ├── RAS Model/        (4 cascaded models: UPGU1-4)
                ├── Spatial Data/     (empty - terrain in model folders)
                ├── Documentation/    (BLE report + inventory)
                └── agent/
                    ├── model_log.md
                    └── dss_validation_output.txt

        Note:
            Models must be executed sequentially (UPGU1 → UPGU2 → UPGU3 → UPGU4)
            as upstream models provide downstream boundary conditions via DSS.

        Example:
            >>> from ras_commander.ebfe_models import RasEbfeModels
            >>> from ras_commander import init_ras_project, RasCmdr, RasPrj
            >>> from pathlib import Path
            >>>
            >>> # Data will auto-download if not present (54.6 GB - LARGE!)
            >>> organized = RasEbfeModels.organize_upper_guadalupe(
            ...     downloaded_folder=Path(r"D:/eBFE/12100201_Models_extracted"),
            ...     validate_dss=True
            ... )
            >>>
            >>> # Execute cascade (upstream to downstream)
            >>> for model in ['UPGU1', 'UPGU2', 'UPGU3', 'UPGU4']:
            ...     folder = organized / "RAS Model" / model / "Input"
            ...     ras_obj = RasPrj()
            ...     init_ras_project(folder, "6.5", ras_object=ras_obj)
            ...     RasCmdr.compute_plan("01", ras_object=ras_obj, num_cores=4)
        """
        downloaded_folder = Path(downloaded_folder)
        if output_folder is None:
            output_folder = Path("./ebfe_organized/UpperGuadalupe_12100201")
        else:
            output_folder = Path(output_folder)

        # Create 4-folder structure
        folders = {
            'hms': output_folder / "HMS Model",
            'ras': output_folder / "RAS Model",
            'spatial': output_folder / "Spatial Data",
            'docs': output_folder / "Documentation",
            'agent': output_folder / "agent"
        }

        for folder in folders.values():
            folder.mkdir(parents=True, exist_ok=True)

        print(f"Organizing Upper Guadalupe (12100201) - Pattern 3b")
        print(f"Source: {downloaded_folder}")
        print(f"Output: {output_folder}\n")

        # Download source data if not present
        if not downloaded_folder.exists():
            print("Source data not found - downloading from eBFE S3...")
            print("⚠️  WARNING: This is a VERY LARGE download (54.6 GB)")
            print("⚠️  Download time will vary based on connection speed")
            print("⚠️  Ensure you have sufficient disk space available\n")

            url = "https://ebfedata.s3.amazonaws.com/12100201_UpperGuadalupe/12100201_Models.zip"

            # Download and extract to parent folder
            downloaded_folder = RasEbfeModels._download_and_extract(
                url=url,
                output_folder=downloaded_folder.parent,
                description="Upper Guadalupe Models (54.6 GB)"
            )

        # Pattern 3b specific paths (discovered by agent)
        models_source = downloaded_folder / "Engineering Models" / "HEC-RAS Models"
        inventory = models_source / "2D_Model_Inventory_UpperGuadalupe.xlsx"

        # Validate nested structure exists
        if not models_source.exists():
            raise FileNotFoundError(
                f"Models folder not found: {models_source}\n\n"
                f"Expected structure: {downloaded_folder}/Engineering Models/HEC-RAS Models/\n"
                f"Check that you extracted the correct archive and it has the expected structure."
            )

        # Check for separate Documents.zip
        docs_source = downloaded_folder.parent / "12100201_UpperGuadalupe_Documents_extracted"

        # Organize RAS Model (4 cascaded watersheds)
        print("[1/4] Organizing RAS Model (4 cascaded watersheds)...")
        ras_files = 0
        for model_name in ['UPGU1', 'UPGU2', 'UPGU3', 'UPGU4']:
            model_source = models_source / model_name
            if model_source.exists():
                # Copy Input/ folder
                input_source = model_source / "Input"
                input_dest = folders['ras'] / model_name

                if input_source.exists():
                    shutil.copytree(input_source, input_dest, dirs_exist_ok=True)
                    print(f"  ✓ {model_name}/Input/ copied")

                    # CRITICAL: Move Output/ HDF files INTO Input/ folder (where HEC-RAS expects them)
                    output_source = model_source / "Output"
                    if output_source.exists():
                        print(f"    Moving Output/ HDF files into {model_name}/ folder...")
                        for output_file in output_source.rglob('*'):
                            if output_file.is_file():
                                # Move HDF and other output files to Input/ (HEC-RAS project folder)
                                dest_file = input_dest / output_file.name
                                shutil.copy2(output_file, dest_file)
                        print(f"    ✓ Pre-run HDF files moved to project folder")

                    # CRITICAL: Move Terrain/ INTO project folder (where HEC-RAS expects it)
                    terrain_source = model_source / "Terrain"
                    if terrain_source.exists():
                        terrain_dest = input_dest / "Terrain"
                        shutil.copytree(terrain_source, terrain_dest, dirs_exist_ok=True)
                        print(f"    ✓ Terrain/ moved to project folder")

                    model_files = len(list(input_dest.rglob('*')))
                    ras_files += model_files
                else:
                    print(f"  ⚠️ {model_name}/Input/ not found")

        if inventory.exists():
            shutil.copy2(inventory, folders['ras'] / inventory.name)

        # Organize Documentation
        print("\n[2/4] Organizing Documentation...")
        docs_copied = 0

        if docs_source.exists():
            for doc in docs_source.rglob('*'):
                if doc.is_file():
                    shutil.copy2(doc, folders['docs'] / doc.name)
                    docs_copied += 1

        print(f"  ✓ Organized {docs_copied} document(s)")

        # Create HMS Model README (no HMS for this pattern)
        hms_readme = folders['hms'] / "README.md"
        hms_readme.write_text("""# No HMS Model

Upper Guadalupe uses HEC-RAS 6.3.1 which handles precipitation and losses
internally. No separate HEC-HMS hydrologic model is included.

Meteorology is configured within the HEC-RAS unsteady flow files (.u##).
""", encoding='utf-8')

        # CRITICAL: Correct ALL file paths in HEC-RAS files
        print("\n[3/4] Correcting all file paths to relative references...")
        dss_corrections = RasEbfeModels._correct_dss_paths(folders['ras'])
        rasmap_corrections = RasEbfeModels._correct_rasmap_terrain_paths(folders['ras'])
        print(f"  ✓ Corrected {dss_corrections} DSS path(s)")
        print(f"  ✓ Corrected {rasmap_corrections} terrain path(s)")

        # Validate DSS files
        print("\n[4/4] Validating DSS files...")
        dss_results = []
        if validate_dss:
            dss_results = RasEbfeModels._validate_dss_files(folders['ras'])

        # Create model log
        RasEbfeModels._create_upper_guadalupe_log(
            folders['agent'],
            downloaded_folder,
            output_folder,
            ras_files,
            docs_copied,
            dss_results
        )

        print(f"\n✓ Upper Guadalupe organized to: {output_folder}")
        print(f"\nCascade: UPGU1 → UPGU2 → UPGU3 → UPGU4 (sequential execution required)")

        return output_folder

    # =========================================================================
    # Helper Methods
    # =========================================================================

    @staticmethod
    def _download_and_extract(
        url: str,
        output_folder: Path,
        description: str = "file"
    ) -> Path:
        """
        Download and extract a zip file from S3.

        Args:
            url: S3 download URL
            output_folder: Where to extract the contents
            description: Description for progress bar

        Returns:
            Path to extracted folder
        """
        output_folder = Path(output_folder)
        output_folder.mkdir(parents=True, exist_ok=True)

        # Determine zip filename from URL
        zip_filename = url.split('/')[-1]
        zip_path = output_folder / zip_filename

        # Download if not already present
        download_needed = False

        if zip_path.exists():
            # Validate existing zip file
            try:
                with zipfile.ZipFile(zip_path, 'r') as zf:
                    # Quick test - just open, don't extract
                    pass
                print(f"\n✓ {description} already downloaded: {zip_path}")
            except zipfile.BadZipFile:
                print(f"\n⚠️ Existing file is corrupted, re-downloading...")
                zip_path.unlink()  # Delete corrupted file
                download_needed = True
        else:
            download_needed = True

        if download_needed:
            print(f"\nDownloading {description}...")
            print(f"  URL: {url}")
            print(f"  Destination: {zip_path}")

            response = requests.get(url, stream=True)
            response.raise_for_status()

            total_size = int(response.headers.get('content-length', 0))
            block_size = 8192

            with open(zip_path, 'wb') as f:
                with tqdm(total=total_size, unit='B', unit_scale=True, desc=f"  {description}") as pbar:
                    for chunk in response.iter_content(block_size):
                        f.write(chunk)
                        pbar.update(len(chunk))

            print(f"  ✓ Downloaded {total_size / 1e9:.1f} GB")

        # Extract if not already extracted
        extracted_folder_name = zip_filename.replace('.zip', '_extracted')
        extracted_folder = output_folder / extracted_folder_name

        if not extracted_folder.exists():
            print(f"\nExtracting {description}...")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # Get total uncompressed size for progress bar
                total_size = sum(info.file_size for info in zip_ref.filelist)

                with tqdm(total=total_size, unit='B', unit_scale=True, desc=f"  Extracting") as pbar:
                    for member in zip_ref.filelist:
                        zip_ref.extract(member, extracted_folder)
                        pbar.update(member.file_size)

            print(f"  ✓ Extracted to: {extracted_folder}")
        else:
            print(f"✓ {description} already extracted: {extracted_folder}")

        return extracted_folder

    @staticmethod
    def _validate_dss_files(ras_model_folder: Path) -> List[Dict]:
        """Validate DSS files using ras-commander."""
        try:
            from ras_commander.dss import RasDss
        except ImportError:
            print("  ⚠️ ras-commander.dss not available - skipping validation")
            return []

        dss_files = list(ras_model_folder.glob('**/*.dss'))
        if not dss_files:
            print("  No DSS files found")
            return []

        print(f"  Found {len(dss_files)} DSS file(s)")
        validation_results = []

        for dss_file in dss_files:
            print(f"\n  Validating: {dss_file.name}")
            try:
                catalog = RasDss.get_catalog(dss_file)
                pathnames = catalog["pathname"].astype(str).tolist()
                pathname_count = len(pathnames)
                print(f"    Pathnames: {pathname_count}")

                # NOTE:
                # Many DSS files contain mixed record types (time series, paired data,
                # grids, etc.). A "read_timeseries" check on arbitrary catalog entries
                # can produce false negatives even when the DSS file is perfectly fine
                # for HEC-RAS (which only needs specific referenced records).
                #
                # So our "organize" validation is intentionally lightweight:
                # - File is readable (catalog can be fetched)
                # - Pathname formats look structurally correct
                format_errors = 0
                format_warnings = 0

                try:
                    from ras_commander.validation_base import ValidationSeverity
                except Exception:
                    ValidationSeverity = None

                for pn in pathnames:
                    r = RasDss.check_pathname_format(pn)
                    passed = (
                        r.get("passed", False)
                        if isinstance(r, dict)
                        else getattr(r, "passed", False)
                    )
                    if not passed:
                        format_errors += 1
                        continue
                    if ValidationSeverity is not None:
                        severity = getattr(r, "severity", None)
                        if severity == ValidationSeverity.WARNING:
                            format_warnings += 1

                ok = format_errors == 0
                validation_results.append({
                    "file": dss_file.name,
                    "total_pathnames": pathname_count,
                    "format_errors": format_errors,
                    "format_warnings": format_warnings,
                    "valid": ok,
                })

                if ok:
                    print(f"    ✓ Format OK ({format_warnings} warnings)")
                else:
                    print(f"    ⚠️ Format errors: {format_errors} ({format_warnings} warnings)")

            except Exception as e:
                print(f"    ✗ Error: {e}")
                validation_results.append({
                    'file': dss_file.name,
                    'total_pathnames': 0,
                    'valid': False,
                    'error': str(e)
                })

        return validation_results

    @staticmethod
    def _organize_spatial_from_ras(ras_folder: Path, spatial_folder: Path):
        """Copy spatial data from RAS Model to Spatial Data folder."""
        # Copy Terrain/ if present
        terrain = ras_folder / "Terrain"
        if terrain.exists():
            shutil.copytree(terrain, spatial_folder / "Terrain", dirs_exist_ok=True)

        # Copy shapefile folders
        for shp_folder in ['Features', 'Shp', 'gis']:
            shp_source = ras_folder / shp_folder
            if shp_source.exists():
                shutil.copytree(shp_source, spatial_folder / shp_folder, dirs_exist_ok=True)

    @staticmethod
    def _create_extraction_readme(ras_folder: Path, ras_zip: Path, output_folder: Path):
        """Create README for manual RAS extraction."""
        readme = f"""# RAS Model Manual Extraction Required

The RAS_Submittal.zip file (6.1 GB) requires manual extraction.

## Extraction Steps

1. Navigate to: {ras_zip.parent}
2. Right-click: RAS_Submittal.zip
3. Select: "Extract All..."
4. Extract to: {output_folder / 'RAS Model'}

## Why Manual?

Command-line extraction tools (Python zipfile, PowerShell) encountered file
locking errors with this large nested archive. Windows Explorer handles
large zips more reliably.

---
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        (ras_folder / "README_EXTRACTION_NEEDED.txt").write_text(readme, encoding='utf-8')

    @staticmethod
    def _correct_dss_paths(ras_model_folder: Path) -> int:
        """
        Correct DSS file path references in HEC-RAS files.

        eBFE models have incorrect DSS paths (absolute paths or wrong relative paths).
        This finds where DSS files actually exist and corrects all references.

        Handles:
        - Absolute paths: C:\eBFE\... → relative path to actual file
        - Wrong relative paths: DSS\Input\file.dss → file.dss (if file is in same folder)

        Args:
            ras_model_folder: Path to RAS Model/ folder

        Returns:
            Number of DSS path references corrected
        """
        import re
        corrections_made = 0

        # Find all DSS files in the organized structure
        dss_files = list(ras_model_folder.glob('**/*.dss'))
        if not dss_files:
            print("    No DSS files found")
            return 0

        print(f"    Found {len(dss_files)} DSS file(s)")
        for dss in dss_files:
            print(f"      - {dss.relative_to(ras_model_folder)}")

        # Build DSS file lookup by name (for matching)
        dss_lookup = {}
        for dss_path in dss_files:
            dss_lookup[dss_path.name] = dss_path

        # Find all HEC-RAS files that might reference DSS
        hecras_files = []
        hecras_files.extend(ras_model_folder.glob('**/*.u[0-9]*'))  # Unsteady flow files
        hecras_files.extend(ras_model_folder.glob('**/*.p[0-9][0-9]'))  # Plan files
        hecras_files.extend(ras_model_folder.glob('**/*.prj'))  # Project files

        for hecras_file in hecras_files:
            if not hecras_file.is_file():
                continue

            # Skip shapefile .prj
            if hecras_file.suffix == '.prj' and hecras_file.parent.name in ['Features', 'Shp', 'gis']:
                continue

            try:
                content = hecras_file.read_text(encoding='utf-8', errors='ignore')
                modified = False

                # Find all DSS references (multiple formats):
                # - DSS File= (boundary conditions, unsteady flow)
                # - DSS Filename= (gridded meteorology)
                dss_file_pattern = re.compile(r'DSS (?:File|Filename)=(.+?)(?:\n|$)', re.IGNORECASE)

                for match in dss_file_pattern.finditer(content):
                    old_path = match.group(1).strip()

                    # Extract DSS filename from the path
                    dss_filename = Path(old_path).name

                    # Check if this DSS file exists in our organized structure
                    if dss_filename in dss_lookup:
                        actual_dss_path = dss_lookup[dss_filename]

                        # Verify the DSS file actually exists
                        if actual_dss_path.exists():
                            # Calculate correct relative path from HEC-RAS file to DSS file
                            try:
                                rel_path = actual_dss_path.relative_to(hecras_file.parent)
                                rel_path_str = str(rel_path).replace('\\', '/')

                                # Only replace if the path is wrong
                                if old_path != rel_path_str:
                                    # Replace both "DSS File=" and "DSS Filename=" patterns
                                    # Preserve the original keyword
                                    for keyword in ['DSS File', 'DSS Filename']:
                                        old_full = f"{keyword}={old_path}"
                                        new_full = f"{keyword}={rel_path_str}"
                                        if old_full in content:
                                            content = content.replace(old_full, new_full)
                                            modified = True
                                            print(f"    Corrected: {hecras_file.name}")
                                            print(f"      Old: {keyword}={old_path}")
                                            print(f"      New: {keyword}={rel_path_str}")
                                            print(f"      Verified: File exists at {actual_dss_path}")

                            except ValueError:
                                # Can't make relative path (different drives)
                                print(f"    ⚠️ Can't create relative path for {dss_filename} (different drives?)")
                        else:
                            print(f"    ⚠️ DSS file not found: {actual_dss_path}")
                    else:
                        print(f"    ⚠️ DSS file not in organized structure: {dss_filename}")

                if modified:
                    hecras_file.write_text(content, encoding='utf-8')
                    corrections_made += 1

            except Exception as e:
                print(f"    ⚠️ Error processing {hecras_file.name}: {e}")

        return corrections_made

    @staticmethod
    def _correct_rasmap_terrain_paths(ras_model_folder: Path) -> int:
        """
        Correct terrain HDF path references in .rasmap files.

        eBFE .rasmap files often reference Terrain\RAS_Terrain\Terrain.hdf but the
        actual file is at Terrain\Terrain.hdf. This finds the actual terrain file
        and corrects the .rasmap reference.

        Args:
            ras_model_folder: Path to RAS Model/ folder

        Returns:
            Number of .rasmap files corrected
        """
        import re
        corrections = 0

        # Find all .rasmap files
        rasmap_files = list(ras_model_folder.glob('**/*.rasmap'))

        for rasmap_file in rasmap_files:
            # Find actual terrain HDF files in this project
            project_folder = rasmap_file.parent
            terrain_hdf_files = list(project_folder.glob('Terrain/**/*.hdf'))

            if not terrain_hdf_files:
                continue  # No terrain for this model

            actual_terrain_hdf = terrain_hdf_files[0]

            try:
                content = rasmap_file.read_text(encoding='utf-8')
                modified = False

                # Fix terrain layer Filename attribute
                terrain_pattern = re.compile(
                    r'(<Layer[^>]*Type="TerrainLayer"[^>]*Filename=")([^"]+)(")',
                    re.IGNORECASE
                )

                for match in terrain_pattern.finditer(content):
                    old_path = match.group(2)

                    # Calculate correct relative path
                    rel_path = actual_terrain_hdf.relative_to(project_folder)
                    rel_path_str = '.\\' + str(rel_path).replace('/', '\\')

                    if old_path != rel_path_str:
                        content = content.replace(
                            f'{match.group(1)}{old_path}{match.group(3)}',
                            f'{match.group(1)}{rel_path_str}{match.group(3)}'
                        )
                        modified = True
                        print(f"      {rasmap_file.name}: {old_path} → {rel_path_str}")

                # Fix TerrainDestinationFolder
                dest_pattern = re.compile(
                    r'(<TerrainDestinationFolder>)([^<]+)(</TerrainDestinationFolder>)',
                    re.IGNORECASE
                )

                for match in dest_pattern.finditer(content):
                    old_folder = match.group(2)

                    # Check if RAS_Terrain subfolder exists, otherwise use Terrain
                    if (project_folder / 'Terrain' / 'RAS_Terrain').exists():
                        new_folder = '.\\Terrain\\RAS_Terrain'
                    else:
                        new_folder = '.\\Terrain'

                    if old_folder != new_folder:
                        content = content.replace(
                            f'{match.group(1)}{old_folder}{match.group(3)}',
                            f'{match.group(1)}{new_folder}{match.group(3)}'
                        )
                        modified = True

                if modified:
                    rasmap_file.write_text(content, encoding='utf-8')
                    corrections += 1

            except Exception as e:
                print(f"      Error: {e}")

        return corrections

    @staticmethod
    def _create_spring_creek_log(
        agent_folder: Path,
        source: Path,
        dest: Path,
        files_count: int,
        dss_results: List[Dict]
    ):
        """Create agent/model_log.md for Spring Creek."""
        dss_section = ""
        if dss_results:
            # Backwards-compatible formatting across validation versions
            def _fmt_dss_result(r: Dict) -> str:
                if "format_errors" in r:
                    errs = r.get("format_errors", 0)
                    warns = r.get("format_warnings", 0)
                    return f"{r['file']}: format_errors={errs}, warnings={warns}"
                return f"{r['file']}: {r.get('sample_valid', 'N/A')}"

            dss_section = f"""
### DSS Validation
**Files**: {len(dss_results)}
**Results**: {', '.join(_fmt_dss_result(r) for r in dss_results)}
"""

        log_content = f"""# Agent Work Log - Spring Creek

**Model**: Spring Creek (12040102)
**Pattern**: 3a - Single 2D model, nested zip
**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Generated Function**: RasEbfeModels.organize_spring_creek()

## Organization Summary

**Source**: {source}
**Output**: {dest}
**Files Organized**: {files_count}

### Structure Created
- HMS Model/ (empty - no HMS for Pattern 3a)
- RAS Model/ ({files_count} files, ~9.3 GB)
- Spatial Data/ (terrain + shapefiles, ~515 MB)
- Documentation/ (1 file, 58 KB)
- agent/model_log.md (this file)

### Critical Fixes Applied

**DSS Path Corrections**:
- eBFE models have incorrect absolute DSS paths from original system
- **Fix**: Updated all "DSS File=" references to relative paths from project folder
- **Result**: Model opens in HEC-RAS without "DSS path needs correction" errors
- **Benefit**: Automation-friendly, no GUI popups during automated workflows

**Terrain Integration**:
- Terrain/ folder already in correct location for Pattern 3a (Spring Creek)
- Verified .rasmap terrain references are valid
- No manual path corrections needed
{dss_section}
## Model Details

**Type**: 2D unsteady flow
**Plans**: 8 (p01-p08, pre-computed results)
**Terrain**: Self-contained in Terrain/ subfolder
**Version**: HEC-RAS 5.0.7

## Usage

```python
from ras_commander import init_ras_project
from pathlib import Path

project = Path(r"{dest / 'RAS Model'}")
init_ras_project(project, "5.0.7")
```

**Organization Status**: ✓ Complete
**See Also**: examples/950_ebfe_spring_creek.ipynb
"""
        (agent_folder / "model_log.md").write_text(log_content, encoding='utf-8')

    @staticmethod
    def _create_north_galveston_log(
        agent_folder: Path,
        source: Path,
        dest: Path,
        hms_files: int,
        ras_extracted: bool,
        docs_count: int,
        dss_results: List[Dict]
    ):
        """Create agent/model_log.md for North Galveston Bay."""
        log_content = f"""# Agent Work Log - North Galveston Bay

**Model**: North Galveston Bay (12040203)
**Pattern**: 4 - Compound HMS + RAS
**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Generated Function**: RasEbfeModels.organize_north_galveston_bay()

## Organization Summary

**Source**: {source}
**Output**: {dest}

### Structure Created
- HMS Model/ ({hms_files} files, ~1.3 MB) ✓
- RAS Model/ ({'extracted' if ras_extracted else 'pending manual extraction'})
- Spatial Data/ (pending RAS extraction)
- Documentation/ ({docs_count} files, ~21 MB) ✓
- agent/model_log.md (this file)

## Model Details

**HMS**: 7 storm frequencies (10yr-500yr) + sensitivity analysis
**RAS**: 2D coastal model (in nested 6.1 GB zip)
**Type**: Compound HMS + RAS

## Status

- HMS Model: ✓ Ready for HEC-HMS
- Documentation: ✓ Complete (BLE reports + metadata)
- RAS Model: {'✓ Extracted' if ras_extracted else '⚠️ See RAS Model/README_EXTRACTION_NEEDED.txt'}

**Organization Status**: {'✓ Complete' if ras_extracted else '⚠️ Partial'}
**See Also**: examples/951_ebfe_north_galveston_bay.ipynb
"""
        (agent_folder / "model_log.md").write_text(log_content, encoding='utf-8')

    @staticmethod
    def _create_upper_guadalupe_log(
        agent_folder: Path,
        source: Path,
        dest: Path,
        ras_files: int,
        docs_count: int,
        dss_results: List[Dict]
    ):
        """Create agent/model_log.md for Upper Guadalupe."""
        dss_section = ""
        if dss_results:
            total_pathnames = sum(r.get('total_pathnames', 0) for r in dss_results)
            dss_section = f"""
### DSS Validation
**Files**: {len(dss_results)}
**Total Pathnames**: {total_pathnames:,}
**Validation**: {'✓ All valid' if all(r.get('valid', False) for r in dss_results) else '⚠️ Some invalid'}

**Files Validated**:
{chr(10).join(f"- {r['file']}: {r['total_pathnames']:,} pathnames" for r in dss_results)}

### DSS Path Corrections
**Purpose**: eBFE models have incorrect absolute DSS paths from original system.
**Action**: All DSS File= references updated to relative paths from project folder.
**Result**: Model will open in HEC-RAS without "DSS path needs correction" errors.
"""

        log_content = f"""# Agent Work Log - Upper Guadalupe

**Model**: Upper Guadalupe (12100201)
**Pattern**: 3b - Cascaded watershed models
**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Generated Function**: RasEbfeModels.organize_upper_guadalupe()

## Organization Summary

**Source**: {source}
**Output**: {dest}
**Files Organized**: {ras_files}

### Structure Created
- RAS Model/ (4 cascaded models: UPGU1-4, {ras_files} files, ~56 GB)
- Spatial Data/ (empty - terrain in model folders)
- Documentation/ ({docs_count} files)
- HMS Model/ (README - no HMS for this pattern)
- agent/model_log.md (this file)

### Critical Fixes Applied

**1. Output/ Folder Integration**:
- eBFE separates Output/ (pre-run HDF files) from Input/ (project files)
- **Fix**: Moved all Output/*.hdf files INTO Input/ folder (project folder)
- **Result**: Pre-computed results now accessible in HEC-RAS project
- **Benefit**: Can view expected runtime from pre-run results

**2. Terrain/ Integration**:
- eBFE places Terrain/ as sibling to Input/ (breaks model references)
- **Fix**: Moved Terrain/ INTO Input/ folder (project folder)
- **Result**: HEC-RAS can find terrain files, model runs without errors
- **Benefit**: .rasmap terrain references now valid

**3. DSS Path Corrections**:
- eBFE has absolute DSS paths from original system (C:\eBFE\...)
- **Fix**: Updated all "DSS File=" references to relative paths
- **Result**: No "DSS path needs correction" GUI popups
- **Benefit**: Automation-friendly, no manual GUI fixes needed
{dss_section}
## Cascade Structure

**Watersheds**: UPGU1 → UPGU2 → UPGU3 → UPGU4
**Execution**: Sequential (upstream to downstream)
**Flow Transfer**: Via DSS boundary conditions

**Each Model**:
- 7 plans (0.1%, 0.2%, 1%, 2%, 4%, 10%, special)
- Large terrain (2.8-4.9 GB per model)
- Input/ and Output/ folders

## Usage

```python
from ras_commander import init_ras_project, RasCmdr, RasPrj
from pathlib import Path

# Execute cascade
for model in ['UPGU1', 'UPGU2', 'UPGU3', 'UPGU4']:
    folder = Path(r"{dest / 'RAS Model'}") / model / "Input"
    ras_obj = RasPrj()
    init_ras_project(folder, "6.5", ras_object=ras_obj)
    RasCmdr.compute_plan("01", ras_object=ras_obj, num_cores=4)
```

**Organization Status**: ✓ Complete
**See Also**: examples/952_ebfe_upper_guadalupe_cascade.ipynb
"""
        (agent_folder / "model_log.md").write_text(log_content, encoding='utf-8')
