Metadata-Version: 2.4
Name: microimpute
Version: 1.13.0
Summary: Benchmarking imputation methods for microdata
Author-email: Mar√≠a Juaristi <juaristi@uni.minerva.edu>, Nikhil Woodruff <nikhil.woodruff@outlook.com>
Requires-Python: <3.14,>=3.12
Description-Content-Type: text/markdown
Requires-Dist: numpy<3.0.0,>=2.0.0
Requires-Dist: pandas<3.0.0,>=2.2.0
Requires-Dist: plotly<6.0.0,>=5.24.0
Requires-Dist: scikit-learn<2.0.0,>=1.7.0
Requires-Dist: scipy<1.17.0,>=1.16.0
Requires-Dist: requests<3.0.0,>=2.32.0
Requires-Dist: tqdm<5.0.0,>=4.65.0
Requires-Dist: statsmodels<0.16.0,>=0.14.5
Requires-Dist: quantile-forest<1.5.0,>=1.4.1
Requires-Dist: pydantic<3.0.0,>=2.8.0
Requires-Dist: optuna<5.0.0,>=4.3.0
Requires-Dist: joblib<2.0.0,>=1.5.0
Requires-Dist: psutil
Provides-Extra: dev
Requires-Dist: pytest<9.0.0,>=8.0.0; extra == "dev"
Requires-Dist: pytest-cov<7.0.0,>=6.0.0; extra == "dev"
Requires-Dist: flake8<8.0.0,>=7.0.0; extra == "dev"
Requires-Dist: black>=24.0.0; extra == "dev"
Requires-Dist: isort<6.0.0,>=5.13.0; extra == "dev"
Requires-Dist: mypy<2.0.0,>=1.2.3; extra == "dev"
Requires-Dist: build<2.0.0,>=1.2.0; extra == "dev"
Requires-Dist: linecheck<0.3.0,>=0.1.0; extra == "dev"
Provides-Extra: matching
Requires-Dist: rpy2<4.0.0,>=3.5.0; extra == "matching"
Provides-Extra: mdn
Requires-Dist: pytorch-tabular>=1.1.0; extra == "mdn"
Requires-Dist: torch>=2.0.0; extra == "mdn"
Provides-Extra: docs
Requires-Dist: jupyter-book; extra == "docs"
Requires-Dist: furo>=2024.0.0; extra == "docs"
Requires-Dist: ipywidgets<9.0.0,>=8.0.0; extra == "docs"
Requires-Dist: plotly<6.0.0,>=5.24.0; extra == "docs"
Requires-Dist: h5py<4.0.0,>=3.1.0; extra == "docs"
Provides-Extra: images
Requires-Dist: kaleido<0.3.0,>=0.2.1; extra == "images"

# Microimpute

Microimpute enables variable imputation through a variety of statistical methods. By providing a consistent interface across different imputation techniques, it allows researchers and data scientists to easily compare and benchmark different approaches using quantile loss and log loss calculations to determine the method providing most accurate results.

## Features

### Multiple imputation methods
- **Statistical Matching**: Distance-based matching for finding similar observations
- **Ordinary Least Squares (OLS)**: Linear regression-based imputation
- **Quantile Regression**: Distribution-aware regression imputation
- **Quantile Random Forests (QRF)**: Non-parametric forest-based approach
- **Mixture Density Networks (MDN)**: Neural network with Gaussian mixture approximation head

### Automated method selection
- **AutoImpute**: Automatically compares and selects the best imputation method for your data
- **Cross-validation**: Built-in evaluation using quantile loss (numerical) and log loss (categorical)
- **Variable type support**: Handles numerical, categorical, and boolean variables

### Developer-friendly design
- **Consistent API**: Standardized `fit()` and `predict()` interface across all models
- **Extensible architecture**: Easy to implement custom imputation methods
- **Weighted data handling**: Preserve data distributions with sample weights
- **Input validation**: Automatic parameter and data validation

### Interactive dashboard
- **Visual exploration**: Analyze imputation results through interactive charts at https://microimpute-dashboard.vercel.app/
- **GitHub integration**: Load artifacts directly from CI/CD workflows
- **Multiple data sources**: File upload, URL loading and sample data

## Installation

```bash
pip install microimpute
```

For image export functionality (PNG/JPG), install with:

```bash
pip install microimpute[images]
```

## Examples and documentation

For detailed examples and interactive notebooks, see the [documentation](https://policyengine.github.io/microimpute/).

## Contributing

Contributions are welcome to the project. Please feel free to submit a Pull Request with your improvements.
