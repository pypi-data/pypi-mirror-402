"""
PDF Tools MCP Server
æä¾› PDF è™•ç†åŠŸèƒ½ (åŸºæ–¼ FastMCP)
"""
import os
import io
import json
import shutil
import threading
import http.server
import socketserver
from typing import Optional, List
from fastmcp import FastMCP
from pydantic import BaseModel, Field

# å˜—è©¦åŒ¯å…¥ PDF Utils
try:
    from pdf_utils import (
        get_pdf_info as _get_pdf_info,
        split_pdf_by_pages as _split_pdf_by_pages,
        split_pdf_by_range as _split_pdf_by_range,
        split_pdf_by_pages_list as _split_pdf_by_pages_list,
        merge_pdfs as _merge_pdfs,
        create_zip_archive as _create_zip_archive,
    )
except ImportError:
    # Fallback for docker environment where path might differ
    import sys
    sys.path.append(os.path.dirname(__file__))
    from pdf_utils import (
        get_pdf_info as _get_pdf_info,
        split_pdf_by_pages as _split_pdf_by_pages,
        split_pdf_by_range as _split_pdf_by_range,
        split_pdf_by_pages_list as _split_pdf_by_pages_list,
        merge_pdfs as _merge_pdfs,
        create_zip_archive as _create_zip_archive,
    )

# å»ºç«‹ FastMCP ä¼ºæœå™¨
mcp = FastMCP("PDF Tools ğŸ“„")

# è¼¸å‡ºç›®éŒ„è¨­å®š
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), "outputs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# -------------------------------------------------------------
# [2026-01-16] è³‡å®‰å¼·åŒ–ï¼šåœç”¨ç›®éŒ„åˆ—è¡¨ + è‡ªå‹•æ¸…ç†
# åŠŸèƒ½ï¼š
#   1. SecureHandler - ç¦æ­¢ç€è¦½ç›®éŒ„ï¼Œåªå…è¨±ä¸‹è¼‰æŒ‡å®šæª”å
#   2. cleanup_old_files - åˆªé™¤è¶…é 5 åˆ†é˜çš„èˆŠæª”æ¡ˆ
#   3. UUID æª”å - å¢åŠ éš¨æ©Ÿæ€§ï¼Œé˜²æ­¢çŒœæ¸¬
# -------------------------------------------------------------
HTTP_PORT = 8090
CLEANUP_INTERVAL_SECONDS = 60  # æ¯ 60 ç§’åŸ·è¡Œä¸€æ¬¡æ¸…ç†
CLEANUP_MAX_AGE_MINUTES = 5    # åˆªé™¤å»ºç«‹è¶…é 5 åˆ†é˜çš„æª”æ¡ˆ

import time
import uuid

def cleanup_old_files():
    """[2026-01-16] è‡ªå‹•æ¸…ç†èˆŠæª”æ¡ˆçš„èƒŒæ™¯åŸ·è¡Œç·’"""
    while True:
        try:
            now = time.time()
            for filename in os.listdir(OUTPUT_DIR):
                filepath = os.path.join(OUTPUT_DIR, filename)
                if os.path.isfile(filepath):
                    file_age_minutes = (now - os.path.getmtime(filepath)) / 60
                    if file_age_minutes > CLEANUP_MAX_AGE_MINUTES:
                        os.remove(filepath)
                        print(f"ğŸ—‘ï¸ å·²æ¸…ç†éæœŸæª”æ¡ˆ: {filename}")
        except Exception as e:
            print(f"æ¸…ç†éŒ¯èª¤: {e}")
        time.sleep(CLEANUP_INTERVAL_SECONDS)

# å•Ÿå‹•æ¸…ç†åŸ·è¡Œç·’
cleanup_thread = threading.Thread(target=cleanup_old_files, daemon=True)
cleanup_thread.start()

def serve_files():
    """åœ¨èƒŒæ™¯å•Ÿå‹• HTTP Server æä¾›æª”æ¡ˆä¸‹è¼‰"""
    # [2026-01-16] è³‡å®‰å¼·åŒ–ï¼šè‡ªè¨‚ Handler ç¦ç”¨ç›®éŒ„åˆ—è¡¨
    class SecureHandler(http.server.SimpleHTTPRequestHandler):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, directory=OUTPUT_DIR, **kwargs)
        
        def list_directory(self, path):
            """[2026-01-16] ç¦æ­¢ç›®éŒ„åˆ—è¡¨ï¼Œå›å‚³ 403 Forbidden"""
            self.send_error(403, "Forbidden: Directory listing is disabled")
            return None

    socketserver.TCPServer.allow_reuse_address = True
    
    with socketserver.ThreadingTCPServer(("", HTTP_PORT), SecureHandler) as httpd:
        print(f"ğŸ“‚ File Server serving at port {HTTP_PORT} (secure mode)")
        httpd.serve_forever()

# å•Ÿå‹•æª”æ¡ˆä¼ºæœå™¨åŸ·è¡Œç·’
file_server_thread = threading.Thread(target=serve_files, daemon=True)
file_server_thread.start()

def generate_secure_filename(base_name: str, suffix: str) -> str:
    """[2026-01-16] ç”¢ç”Ÿå¸¶æœ‰ UUID çš„å®‰å…¨æª”å"""
    short_uuid = str(uuid.uuid4())[:8]
    return f"{short_uuid}_{base_name}{suffix}"

def get_download_url(filename: str) -> str:
    """ç”¢ç”Ÿæª”æ¡ˆä¸‹è¼‰ URL"""
    return f"http://localhost:9090/{filename}"
 


@mcp.prompt()
def pdf_tools_guide() -> str:
    return f"""
    é€™å€‹Toolsæä¾›ä»¥ä¸‹åŠŸèƒ½ï¼Œç•¶ä½¿ç”¨è€…è¦é€²è¡Œåˆ†å‰²æˆ–åˆä½µPDFçš„æ™‚å€™ä½¿ç”¨ä¸éœ€è¦é€²è¡ŒRAGï¼š
    1. åˆ†å‰² PDF (å…¨é é¢)ï¼š{split_pdf_all}
    2. åˆ†å‰² PDF (æŒ‡å®šç¯„åœ)ï¼š{split_pdf_range}
    3. åˆä½µ PDFï¼š{merge_pdfs}
    4. åˆ†å‰² PDF (æŒ‡å®šé é¢)ï¼š{split_pdf_pages}
    
    ä½¿ç”¨é ˆçŸ¥ï¼š
    - å¾å°è©±ä¸­å°‹æ‰¾æª”æ¡ˆç›¸é—œè³‡è¨Šæˆ–attached_filesä¸­çš„æª”æ¡ˆ
    - ä¸éœ€è¦è§£è®€PDFä¸­çš„æ–‡å­—å…§å®¹ï¼Œé€™å€‹å·¥å…·çš„ä½¿ç”¨åªæ˜¯åˆ†å‰²èˆ‡åˆä½µPDFæª”æ¡ˆã€‚
    - è·³éRAGï¼Œåªéœ€è¦å°æª”æ¡ˆé€²è¡Œå‹•ä½œã€‚
    - å¦‚æœéœ€è¦åˆ†å‰²ã€Œæœ€å¾Œä¸€é ã€æˆ–ã€Œç‰¹å®šç¯„åœã€ä½†ä¸çŸ¥é“ç¸½é æ•¸ï¼Œè«‹ç›´æ¥å‘¼å« {split_pdf_range} ä¸¦å¡«å¯«é ä¼°çš„çµæŸé ç¢¼ (ä¾‹å¦‚ 9999)ï¼Œç³»çµ±æœƒè‡ªå‹•ä¿®æ­£ç‚ºå¯¦éš›çš„æœ€å¾Œä¸€é ã€‚
    - æ‰€æœ‰æ“ä½œå®Œæˆå¾Œï¼Œéƒ½æœƒæä¾› ZIP å£“ç¸®æª”çš„ä¸‹è¼‰é€£çµä¸¦ç”¨Markdownèªæ³•åŒ…è¦†é€£çµã€‚
    """

@mcp.tool(name="split_pdf_all")
def split_pdf_all(
    filename: str = None,
    file_id: str = None,
    file_path: str = None,
    __files__: list[dict] = None
) -> str:
    """
    å°‡ PDF åˆ†å‰²æˆæ¯é ä¸€å€‹ç¨ç«‹çš„æª”æ¡ˆï¼Œä¸¦æ‰“åŒ…æˆ ZIP ä¸‹è¼‰
    """
    # Inline resolve_file_path logic
    real_path = None
    # [2026-01-19] å„ªå…ˆæª¢æŸ¥ /tmp/{filename}
    if not file_path and filename:
        potential_path = os.path.join("/tmp", filename)
        if os.path.exists(potential_path):
            file_path = potential_path

    if file_path and os.path.exists(file_path):
        real_path = file_path
    else:
        search_dir = "/tmp"
        if os.path.exists(search_dir):
            try:
                for f in os.listdir(search_dir):
                    if (filename and filename in f) or (file_id and file_id in f):
                        real_path = os.path.join(search_dir, f)
                        break
            except:
                pass

    if not real_path:
        return f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}"

    try:
        output_files = _split_pdf_by_pages(real_path, OUTPUT_DIR)
        
        # [2026-01-16] ä½¿ç”¨ UUID å®‰å…¨æª”å
        base_name = os.path.splitext(os.path.basename(real_path))[0]
        zip_filename = generate_secure_filename(base_name, "_split.zip")
        zip_path = os.path.join(OUTPUT_DIR, zip_filename)
        _create_zip_archive(output_files, zip_path)
        
        results = [os.path.basename(f) for f in output_files]
        return f"æˆåŠŸåˆ†å‰²æˆ {len(results)} å€‹æª”æ¡ˆï¼Œä¸¦å·²æ‰“åŒ…ä¸‹è¼‰ã€‚\næª”æ¡ˆåˆ—è¡¨:\n" + "\n".join(results[:5]) + ("\n..." if len(results) > 5 else "") + f"\n\nâ¬‡ï¸ ä¸‹è¼‰ ZIP: {get_download_url(zip_filename)}"
    except Exception as e:
        return f"Error splitting PDF: {str(e)}"

@mcp.tool(name="split_pdf_range")
def split_pdf_range(
    start_page: int,
    end_page: int,
    filename: str = None,
    file_id: str = None,
    file_path: str = None,
    __files__: list[dict] = None
) -> str:
    """
    æ“·å– PDF çš„æŒ‡å®šé é¢ç¯„åœå­˜ç‚ºæ–°æª”æ¡ˆï¼Œä¸¦æä¾› ZIP ä¸‹è¼‰ã€‚
    å¦‚æœ end_page è¶…éå¯¦éš›é æ•¸ï¼Œæœƒè‡ªå‹•ä¿®æ­£ç‚ºæœ€å¾Œä¸€é ã€‚
    """
    # Inline resolve_file_path logic
    real_path = None
    # [2026-01-19] å„ªå…ˆæª¢æŸ¥ /tmp/{filename}
    if not file_path and filename:
        potential_path = os.path.join("/tmp", filename)
        if os.path.exists(potential_path):
            file_path = potential_path

    if file_path and os.path.exists(file_path):
        real_path = file_path
    else:
        search_dir = "/tmp"
        if os.path.exists(search_dir):
            try:
                for f in os.listdir(search_dir):
                    if (filename and filename in f) or (file_id and file_id in f):
                        real_path = os.path.join(search_dir, f)
                        break
            except:
                pass

    if not real_path:
        return f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}"

    try:
        # å–å¾—å¯¦éš›é æ•¸ä»¥é€²è¡Œå› æ‡‰
        info = _get_pdf_info(real_path)
        total_pages = info.get('page_count', 0)
        
        # è‡ªå‹•ä¿®æ­£é ç¢¼ç¯„åœ
        original_end_page = end_page
        if end_page > total_pages:
            end_page = total_pages
            
        if start_page > total_pages:
             return f"éŒ¯èª¤ï¼šèµ·å§‹é ç¢¼ ({start_page}) è¶…éæª”æ¡ˆç¸½é æ•¸ ({total_pages})ã€‚"

        base_name = os.path.splitext(os.path.basename(real_path))[0]
        output_filename = f"{base_name}_pages_{start_page}-{end_page}.pdf"
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        
        result_path = _split_pdf_by_range(real_path, start_page, end_page, output_path)
        
        # [2026-01-16] ä½¿ç”¨ UUID å®‰å…¨æª”å
        zip_filename = generate_secure_filename(base_name, f"_pages_{start_page}-{end_page}.zip")
        zip_path = os.path.join(OUTPUT_DIR, zip_filename)
        _create_zip_archive([result_path], zip_path)

        msg = f"æˆåŠŸæ“·å–é é¢ {start_page}-{end_page} (ç¸½é æ•¸: {total_pages})ã€‚\næª”æ¡ˆ: {os.path.basename(result_path)}\n\nâ¬‡ï¸ ä¸‹è¼‰ ZIP: {get_download_url(zip_filename)}"
        if original_end_page > total_pages:
            msg += f"\n(å‚™è¨»: æ‚¨è¼¸å…¥çš„çµæŸé ç¢¼ {original_end_page} è¶…éç¸½é æ•¸ï¼Œå·²è‡ªå‹•ä¿®æ­£ç‚º {total_pages})"
            
        return msg
    except Exception as e:
        return f"Error splitting PDF range: {str(e)}"

@mcp.tool(name="split_pdf_pages")
def split_pdf_pages(
    pages: list[int],
    filename: str = None,
    file_id: str = None,
    file_path: str = None,
    __files__: list[dict] = None
) -> str:
    """
    æ“·å–æŒ‡å®šçš„ç‰¹å®šé é¢ (æ”¯æ´ä¸é€£çºŒé é¢ï¼Œå¦‚ 1, 3, 5)
    """
    # Inline resolve_file_path logic
    real_path = None
    # [2026-01-19] å„ªå…ˆæª¢æŸ¥ /tmp/{filename}
    if not file_path and filename:
        potential_path = os.path.join("/tmp", filename)
        if os.path.exists(potential_path):
            file_path = potential_path

    if file_path and os.path.exists(file_path):
        real_path = file_path
    else:
        search_dir = "/tmp"
        if os.path.exists(search_dir):
            try:
                for f in os.listdir(search_dir):
                    if (filename and filename in f) or (file_id and file_id in f):
                        real_path = os.path.join(search_dir, f)
                        break
            except:
                pass

    if not real_path:
        return f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}"

    try:
        # å–å¾—ç¸½é æ•¸
        info = _get_pdf_info(real_path)
        total_pages = info.get('page_count', 0)
        
        # éæ¿¾æœ‰æ•ˆé ç¢¼
        valid_pages = sorted(set(p for p in pages if 1 <= p <= total_pages))
        invalid_pages = [p for p in pages if p < 1 or p > total_pages]
        
        if not valid_pages:
            return f"éŒ¯èª¤ï¼šæ²’æœ‰æœ‰æ•ˆçš„é ç¢¼ã€‚ç¸½é æ•¸: {total_pages}ï¼Œè¼¸å…¥: {pages}"

        base_name = os.path.splitext(os.path.basename(real_path))[0]
        pages_str = "_".join(str(p) for p in valid_pages[:5])  # é™åˆ¶æª”åé•·åº¦
        if len(valid_pages) > 5:
            pages_str += "_etc"
        output_filename = f"{base_name}_pages_{pages_str}.pdf"
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        
        result_path = _split_pdf_by_pages_list(real_path, valid_pages, output_path)
        
        # [2026-01-16] ä½¿ç”¨ UUID å®‰å…¨æª”å
        zip_filename = generate_secure_filename(base_name, f"_pages_{pages_str}.zip")
        zip_path = os.path.join(OUTPUT_DIR, zip_filename)
        _create_zip_archive([result_path], zip_path)

        msg = f"æˆåŠŸæ“·å–é é¢ {valid_pages} (ç¸½é æ•¸: {total_pages})ã€‚\næª”æ¡ˆ: {os.path.basename(result_path)}\n\nâ¬‡ï¸ ä¸‹è¼‰ ZIP: {get_download_url(zip_filename)}"
        if invalid_pages:
            msg += f"\n(å‚™è¨»: ä»¥ä¸‹é ç¢¼ç„¡æ•ˆå·²è¢«å¿½ç•¥: {invalid_pages})"
            
        return msg
    except Exception as e:
        return f"Error splitting PDF pages: {str(e)}"

@mcp.tool(name="merge_pdfs")
def merge_pdfs(
    filenames: list[str],
    output_filename: str = "merged.pdf",
    __files__: list[dict] = None
) -> str:
    """
    åˆä½µå¤šå€‹ PDF æª”æ¡ˆï¼Œä¸¦æä¾› ZIP ä¸‹è¼‰
    """
    real_paths = []
    missing_files = []
    
    for fname in filenames:
        # Inline resolve_file_path logic
        path = None
        # Check direct path (unlikely for filename input but good to have)
        if os.path.exists(fname):
            path = fname
        # [2026-01-19] å„ªå…ˆæª¢æŸ¥ /tmp/{filename}
        elif os.path.exists(os.path.join("/tmp", fname)):
            path = os.path.join("/tmp", fname)
        else:
             # Search in /tmp
            search_dir = "/tmp"
            if os.path.exists(search_dir):
                try:
                    for f in os.listdir(search_dir):
                        if fname in f: # Match filename
                            path = os.path.join(search_dir, f)
                            break
                except:
                    pass
        
        if path:
            real_paths.append(path)
        else:
            missing_files.append(fname)
            
    if missing_files:
        return f"ç„¡æ³•æ‰¾åˆ°ä»¥ä¸‹æª”æ¡ˆï¼Œè«‹ç¢ºèªæ˜¯å¦å·²ä¸Šå‚³:\n" + "\n".join(missing_files)
        
    try:
        if not output_filename.endswith(".pdf"):
            output_filename += ".pdf"
            
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        result_path = _merge_pdfs(real_paths, output_path)
        
        # [2026-01-16] ä½¿ç”¨ UUID å®‰å…¨æª”å
        base_name = os.path.splitext(output_filename)[0]
        zip_filename = generate_secure_filename(base_name, "_merged.zip")
        zip_path = os.path.join(OUTPUT_DIR, zip_filename)
        _create_zip_archive([result_path], zip_path)
        
        return f"æˆåŠŸåˆä½µ {len(real_paths)} å€‹æª”æ¡ˆã€‚\nè¼¸å‡ºæª”æ¡ˆ: {os.path.basename(result_path)}\n\n ä¸‹è¼‰ ZIP: {get_download_url(zip_filename)}"
    except Exception as e:
        return f"Error merging PDFs: {str(e)}"

def main():
    """Entry point for PDF Tools MCP Server."""
    mcp.run()

if __name__ == "__main__":
    main()
