"""
Tests for bundle resource YAML Jinja2 template functionality.

This module contains tests for the conversion from f-string templates
to Jinja2 templates for bundle resource file generation.
"""

import pytest
import tempfile
import shutil
import yaml
from pathlib import Path
from unittest.mock import Mock, patch

from lhp.bundle.manager import BundleManager
from lhp.bundle.exceptions import BundleResourceError


class TestBundleJinja2Templates:
    """Test suite for bundle Jinja2 template functionality."""

    def setup_method(self):
        """Set up test environment for each test."""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.project_root = self.temp_dir / "project"
        self.project_root.mkdir()
        self.generated_dir = self.project_root / "generated"
        self.generated_dir.mkdir()
        self.resources_dir = self.project_root / "resources" / "lhp"
        
        self.manager = BundleManager(self.project_root)

    def teardown_method(self):
        """Clean up test environment after each test."""
        shutil.rmtree(self.temp_dir)

    # Template Rendering Tests (Scenarios 1-5)
    
    def test_basic_jinja2_template_rendering(self):
        """Should render basic template with standard pipeline name."""
        # Test with realistic pipeline name
        pipeline_name = "raw_ingestion"
        
        # Generate content using template
        content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
        
        # Verify basic structure
        assert content is not None
        assert isinstance(content, str)
        assert len(content) > 0
        
        # Verify LHP header
        assert "Generated by LakehousePlumber" in content
        assert f"Bundle Resource for {pipeline_name}" in content
        
        # Verify YAML structure basics
        assert "resources:" in content
        assert "pipelines:" in content
        assert f"{pipeline_name}_pipeline:" in content
    
    def test_template_variable_substitution(self):
        """Should properly substitute {{ pipeline_name }} variable."""
        # Test with multiple realistic pipeline names
        pipeline_names = ["bronze_load", "silver_transformations", "gold_aggregations"]
        
        for pipeline_name in pipeline_names:
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            
            # Verify pipeline_name is substituted in all expected locations
            assert f"Bundle Resource for {pipeline_name}" in content  # Header
            assert f"{pipeline_name}_pipeline:" in content  # Pipeline key
            assert f"name: {pipeline_name}_pipeline" in content  # Pipeline name
            assert f"include: ${{workspace.file_path}}/generated/${{bundle.target}}/{pipeline_name}/**" in content  # Glob pattern
            assert f"${{workspace.file_path}}/generated/${{bundle.target}}/{pipeline_name}" in content  # Root path
            
            # Verify no template syntax remains
            assert "{{ pipeline_name }}" not in content
            assert "{{pipeline_name}}" not in content
    
    def test_empty_pipeline_directory_template(self):
        """Should render template even with no Python files."""
        # Test template rendering is independent of actual files
        pipeline_name = "data_quality_checks"
        
        # Template rendering should work regardless of file existence
        content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
        
        # Verify template renders successfully
        assert content is not None
        assert isinstance(content, str)
        assert len(content) > 0
        
        # Verify glob pattern is still present (will capture any future files)
        assert f"include: ${{workspace.file_path}}/generated/${{bundle.target}}/{pipeline_name}/**" in content
        assert f"root_path: ${{workspace.file_path}}/generated/${{bundle.target}}/{pipeline_name}" in content
        
        # Verify basic structure
        assert f"{pipeline_name}_pipeline:" in content
        assert "- glob:" in content
    
    def test_very_long_pipeline_names(self):
        """Should handle very long pipeline names without truncation."""
        # Test with pipeline name approaching 200 character limit
        long_pipeline_name = "bronze_raw_data_ingestion_from_external_systems_including_legacy_databases_and_api_endpoints_with_comprehensive_data_validation_and_quality_checks_for_enterprise_data_warehouse_bronze_layer_processing"
        
        # Verify name is approximately 200 chars
        assert len(long_pipeline_name) >= 190
        assert len(long_pipeline_name) <= 200
        
        # Template should handle long names without issues
        content = self.manager.generate_resource_file_content(long_pipeline_name, self.generated_dir, "dev")
        
        # Verify no truncation occurred
        assert f"Bundle Resource for {long_pipeline_name}" in content
        assert f"{long_pipeline_name}_pipeline:" in content
        assert f"name: {long_pipeline_name}_pipeline" in content
        assert f"include: ${{workspace.file_path}}/generated/${{bundle.target}}/{long_pipeline_name}/**" in content
        assert f"${{workspace.file_path}}/generated/${{bundle.target}}/{long_pipeline_name}" in content
        
        # Verify template still produces valid structure
        assert "resources:" in content
        assert "- glob:" in content
    
    def test_invalid_pipeline_names_error_handling(self):
        """Should handle null/empty pipeline names gracefully."""
        # Test various invalid pipeline names
        invalid_names = ["", "   ", None]
        
        for invalid_name in invalid_names:
            try:
                # Should handle gracefully without crashing
                content = self.manager.generate_resource_file_content(invalid_name, self.generated_dir, "dev")
                
                # If it succeeds, verify reasonable behavior
                if content:
                    assert isinstance(content, str)
                    # Basic structure should still be present
                    assert "resources:" in content
                    
            except (TypeError, ValueError, AttributeError) as e:
                # Graceful error handling is acceptable
                assert invalid_name in [None, "", "   "]
                # Error should be informative
                assert len(str(e)) > 0
            
        # Test with special characters that might cause issues
        special_chars_name = "test@#$%^&*()"
        content = self.manager.generate_resource_file_content(special_chars_name, self.generated_dir, "dev")
        
        # Should handle special characters
        assert content is not None
        assert special_chars_name in content

    # Content Validation Tests (Scenarios 6-9)
    
    def test_generated_yaml_syntax_validation(self):
        """Should generate syntactically valid YAML output."""
        import yaml
        
        # Test with multiple realistic pipeline names
        pipeline_names = ["raw_ingestion", "bronze_load", "silver_transforms", "gold_aggregations"]
        
        for pipeline_name in pipeline_names:
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            
            # Should parse as valid YAML without errors
            try:
                parsed_yaml = yaml.safe_load(content)
                
                # Verify it parsed successfully
                assert parsed_yaml is not None
                assert isinstance(parsed_yaml, dict)
                
                # Verify basic YAML structure
                assert "resources" in parsed_yaml
                assert "pipelines" in parsed_yaml["resources"]
                
                # Verify pipeline structure
                pipeline_key = f"{pipeline_name}_pipeline"
                assert pipeline_key in parsed_yaml["resources"]["pipelines"]
                
                pipeline_config = parsed_yaml["resources"]["pipelines"][pipeline_key]
                assert "name" in pipeline_config
                assert "libraries" in pipeline_config
                assert "root_path" in pipeline_config
                
            except yaml.YAMLError as e:
                pytest.fail(f"Generated YAML is invalid for pipeline '{pipeline_name}': {e}")
    
    def test_glob_pattern_format_correctness(self):
        """Should generate correct glob pattern: ../../generated/{{ pipeline_name }}/**"""
        import yaml
        
        # Test with realistic pipeline names
        pipeline_names = ["raw_ingestion", "bronze_processing", "silver_analytics"]
        
        for pipeline_name in pipeline_names:
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            parsed_yaml = yaml.safe_load(content)
            
            # Navigate to libraries section
            pipeline_key = f"{pipeline_name}_pipeline"
            libraries = parsed_yaml["resources"]["pipelines"][pipeline_key]["libraries"]
            
            # Should have exactly one library entry with glob
            assert len(libraries) == 1
            assert "glob" in libraries[0]
            
            # Verify exact glob pattern format
            glob_config = libraries[0]["glob"]
            assert "include" in glob_config
            
            expected_pattern = f"${{workspace.file_path}}/generated/${{bundle.target}}/{pipeline_name}/**"
            actual_pattern = glob_config["include"]
            
            assert actual_pattern == expected_pattern, f"Expected '{expected_pattern}', got '{actual_pattern}'"
            
            # Verify no individual notebook entries exist
            for library in libraries:
                assert "notebook" not in library, "Should not contain individual notebook entries"
    
    def test_root_path_format_correctness(self):
        """Should generate correct root_path: ${workspace.file_path}/generated/{{ pipeline_name }}"""
        import yaml
        
        # Test with realistic pipeline names
        pipeline_names = ["bronze_load", "silver_transforms", "gold_metrics"]
        
        for pipeline_name in pipeline_names:
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            parsed_yaml = yaml.safe_load(content)
            
            # Navigate to pipeline configuration
            pipeline_key = f"{pipeline_name}_pipeline"
            pipeline_config = parsed_yaml["resources"]["pipelines"][pipeline_key]
            
            # Verify root_path exists and has correct format
            assert "root_path" in pipeline_config
            
            expected_root_path = f"${{workspace.file_path}}/generated/${{bundle.target}}/{pipeline_name}"
            actual_root_path = pipeline_config["root_path"]
            
            assert actual_root_path == expected_root_path, f"Expected '{expected_root_path}', got '{actual_root_path}'"
            
            # Verify the path contains workspace variable substitution
            assert "${workspace.file_path}" in actual_root_path
            assert f"/generated/${{bundle.target}}/{pipeline_name}" in actual_root_path
    
    def test_yaml_structure_completeness(self):
        """Should include all required YAML fields (libraries, root_path, etc.)"""
        import yaml
        
        # Test with realistic pipeline name
        pipeline_name = "bronze_data_processing"
        content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
        parsed_yaml = yaml.safe_load(content)
        
        # Verify top-level structure
        assert "resources" in parsed_yaml
        assert "pipelines" in parsed_yaml["resources"]
        
        # Verify pipeline structure
        pipeline_key = f"{pipeline_name}_pipeline"
        assert pipeline_key in parsed_yaml["resources"]["pipelines"]
        
        pipeline_config = parsed_yaml["resources"]["pipelines"][pipeline_key]
        
        # Verify all required fields are present
        required_fields = ["name", "catalog", "schema", "libraries", "root_path", "configuration"]
        for field in required_fields:
            assert field in pipeline_config, f"Missing required field: {field}"
        
        # Verify field values are properly set
        assert pipeline_config["name"] == f"{pipeline_name}_pipeline"
        assert pipeline_config["catalog"] == "${var.default_pipeline_catalog}"
        assert pipeline_config["schema"] == "${var.default_pipeline_schema}"
        
        # Verify libraries structure
        libraries = pipeline_config["libraries"]
        assert isinstance(libraries, list)
        assert len(libraries) == 1
        assert "glob" in libraries[0]
        
        # Verify configuration structure
        configuration = pipeline_config["configuration"]
        assert isinstance(configuration, dict)
        assert "bundle.sourcePath" in configuration

    # Jinja2 Integration Tests (Scenarios 10-13)
    
    def test_template_engine_integration(self):
        """Should integrate properly with bundle manager's Jinja2 environment via composition."""
        # Verify BundleManager uses composition with TemplateRenderer
        from lhp.utils.template_renderer import TemplateRenderer
        assert hasattr(self.manager, 'template_renderer')
        assert isinstance(self.manager.template_renderer, TemplateRenderer)
        
        # Verify Jinja2 environment is available through template_renderer
        assert hasattr(self.manager.template_renderer, 'env')
        assert self.manager.template_renderer.env is not None
        
        # Verify render_template method is available on template_renderer
        assert hasattr(self.manager.template_renderer, 'render_template')
        assert callable(self.manager.template_renderer.render_template)
        
        # Test template rendering with direct call (updated for pipeline config feature)
        context = {
            "pipeline_name": "integration_test",
            "pipeline_config": {"serverless": True, "edition": "ADVANCED", "channel": "CURRENT", "continuous": False}
        }
        content = self.manager.template_renderer.render_template("bundle/pipeline_resource.yml.j2", context)
        
        # Verify content was rendered
        assert content is not None
        assert isinstance(content, str)
        assert "integration_test" in content
        assert "integration_test_pipeline:" in content
        
        # Verify Jinja2 environment filters are available
        assert 'tojson' in self.manager.template_renderer.env.filters
        assert 'toyaml' in self.manager.template_renderer.env.filters
        
        # Verify template directory is correctly set
        template_paths = self.manager.template_renderer.env.loader.searchpath
        assert any("templates" in path for path in template_paths)
    
    def test_template_loading_from_package(self):
        """Should load .j2 template file from package resources."""
        # Test that the specific template file can be loaded
        template_name = "bundle/pipeline_resource.yml.j2"
        
        # Should be able to get template without errors
        try:
            template = self.manager.template_renderer.env.get_template(template_name)
            assert template is not None
            
            # Template should have correct name
            assert template.name == template_name
            
            # Template should be renderable (updated for pipeline config feature)
            context = {
                "pipeline_name": "package_test",
                "pipeline_config": {"serverless": True, "edition": "ADVANCED", "channel": "CURRENT", "continuous": False}
            }
            rendered = template.render(**context)
            
            assert rendered is not None
            assert isinstance(rendered, str)
            assert "package_test" in rendered
            
        except Exception as e:
            pytest.fail(f"Failed to load template '{template_name}': {e}")
        
        # Verify template file physically exists in expected location
        from pathlib import Path
        import lhp
        
        # Find the lhp package path
        lhp_path = Path(lhp.__file__).parent
        template_path = lhp_path / "templates" / "bundle" / "pipeline_resource.yml.j2"
        
        assert template_path.exists(), f"Template file not found at {template_path}"
        assert template_path.is_file(), f"Template path is not a file: {template_path}"
    
    def test_template_context_building(self):
        """Should build proper context with required variables."""
        # Test context building by mocking the render_template method
        from unittest.mock import Mock
        
        # Store original method
        original_render = self.manager.template_renderer.render_template
        
        # Mock to capture context
        captured_contexts = []
        def mock_render(template_name, context):
            captured_contexts.append((template_name, context))
            return original_render(template_name, context)
        
        self.manager.template_renderer.render_template = mock_render
        
        try:
            # Test with various pipeline names
            pipeline_names = ["context_test", "bronze_processing", "silver_analytics"]
            
            for pipeline_name in pipeline_names:
                self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            
            # Verify contexts were captured
            assert len(captured_contexts) == len(pipeline_names)
            
            for i, (template_name, context) in enumerate(captured_contexts):
                # Verify correct template was used
                assert template_name == "bundle/pipeline_resource.yml.j2"
                
                # Verify context structure (updated for catalog/schema config feature)
                assert isinstance(context, dict)
                assert "pipeline_name" in context
                assert "pipeline_config" in context
                assert "catalog" in context  # Now included (may be None)
                assert "schema" in context   # Now included (may be None)
                
                # Verify correct pipeline_name value
                expected_name = pipeline_names[i]
                assert context["pipeline_name"] == expected_name
                
                # Context should contain pipeline_name, pipeline_config, catalog, and schema
                assert len(context) == 4, f"Context should contain 4 keys, got: {context.keys()}"
                
        finally:
            # Restore original method
            self.manager.template_renderer.render_template = original_render
    
    def test_template_context_has_resolved_values(self):
        """Should pass resolved (substituted) config values to template."""
        # Setup: Create pipeline config with tokens and substitution file
        config_file = self.project_root / "config" / "pipeline_config.yaml"
        config_file.parent.mkdir(parents=True, exist_ok=True)
        config_file.write_text("""
---
pipeline: token_test
catalog: "{catalog}"
schema: "{bronze_schema}"
serverless: false
clusters:
  - label: default
    node_type_id: "{node_type}"
    policy_id: "{policy_id}"
""")
        
        sub_file = self.project_root / "substitutions" / "dev.yaml"
        sub_file.parent.mkdir(parents=True, exist_ok=True)
        sub_file.write_text("""
dev:
  catalog: resolved_catalog
  bronze_schema: resolved_schema
  node_type: Standard_D8ds_v5
  policy_id: resolved-policy-123
""")
        
        # Recreate manager with new config
        manager_with_config = BundleManager(self.project_root, str(config_file))
        
        # Capture context
        captured_context = None
        original_render = manager_with_config.template_renderer.render_template
        
        def mock_render(template_name, context):
            nonlocal captured_context
            captured_context = context
            return original_render(template_name, context)
        
        manager_with_config.template_renderer.render_template = mock_render
        
        try:
            # Act
            manager_with_config.generate_resource_file_content("token_test", self.generated_dir, "dev")
            
            # Assert - verify tokens were resolved in context
            assert captured_context is not None
            
            # Check catalog/schema in top-level context (for conditional)
            assert captured_context["catalog"] == "resolved_catalog"
            assert captured_context["schema"] == "resolved_schema"
            
            # Check that pipeline_config has ALL fields resolved
            config = captured_context["pipeline_config"]
            assert config["catalog"] == "resolved_catalog"
            assert config["schema"] == "resolved_schema"
            assert config["clusters"][0]["node_type_id"] == "Standard_D8ds_v5"
            assert config["clusters"][0]["policy_id"] == "resolved-policy-123"
            
        finally:
            # Restore original method
            manager_with_config.template_renderer.render_template = original_render
    
    def test_template_rendering_error_handling(self):
        """Should handle Jinja2 errors gracefully (missing variables, etc.)"""
        from unittest.mock import patch
        from jinja2 import TemplateNotFound, UndefinedError
        
        # Test 1: Missing template file
        with patch.object(self.manager.template_renderer.env, 'get_template') as mock_get_template:
            mock_get_template.side_effect = TemplateNotFound("bundle/missing_template.yml.j2")
            
            # Should handle template not found gracefully
            try:
                self.manager.template_renderer.render_template("bundle/missing_template.yml.j2", {"pipeline_name": "test"})
                pytest.fail("Expected TemplateNotFound error")
            except TemplateNotFound:
                pass  # Expected behavior
                
        # Test 2: Test with missing context variables
        # Create a template that requires more variables than provided
        with patch.object(self.manager.template_renderer.env, 'get_template') as mock_get_template:
            mock_template = mock_get_template.return_value
            mock_template.render.side_effect = UndefinedError("'missing_var' is undefined")
            
            # Should handle undefined variables gracefully
            try:
                self.manager.template_renderer.render_template("bundle/pipeline_resource.yml.j2", {})
                pytest.fail("Expected UndefinedError")
            except UndefinedError:
                pass  # Expected behavior
                
        # Test 3: Verify normal operation still works
        # This confirms our error handling doesn't break normal functionality
        pipeline_name = "error_handling_test"
        content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
        
        assert content is not None
        assert pipeline_name in content
        assert "resources:" in content

    # Migration Verification Tests (Scenarios 14-16)
    

    def test_no_template_syntax_in_output(self):
        """Should ensure all {{ }} template syntax is resolved in final output."""
        # Test with various pipeline names to ensure comprehensive coverage
        pipeline_names = [
            "simple_test", 
            "complex_pipeline_with_long_name", 
            "test-with-dashes",
            "test_with_underscores",
            "123numeric_start"
        ]
        
        jinja2_patterns = [
            "{{",      # Variable start
            "}}",      # Variable end  
            "{%",      # Statement start
            "%}",      # Statement end
            "{#",      # Comment start
            "#}",      # Comment end
            "{% for",  # Common loop syntax
            "{% if",   # Common conditional syntax
            "{% set",  # Common assignment syntax
            "{{ pipeline_name }}",  # Specific variable we use
        ]
        
        for pipeline_name in pipeline_names:
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            
            # Check for any Jinja2 syntax patterns
            for pattern in jinja2_patterns:
                assert pattern not in content, f"Found Jinja2 syntax '{pattern}' in output for pipeline '{pipeline_name}'"
            
            # Additional verification - ensure pipeline_name was actually substituted
            assert pipeline_name in content, f"Pipeline name '{pipeline_name}' not found in output - template may not have rendered properly"
            
            # Verify basic YAML structure exists (confirms template rendered)
            assert "resources:" in content
            assert "pipelines:" in content
    
    def test_lhp_header_preservation(self):
        """Should preserve correct LHP generated header comment."""
        # Test with various pipeline names
        pipeline_names = ["header_test", "bronze_processing", "complex_data_transformation"]
        
        for pipeline_name in pipeline_names:
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            
            # Split content into lines for easier analysis
            lines = content.split('\n')
            
            # First line should be the LHP header comment
            assert len(lines) > 0, "Generated content should not be empty"
            first_line = lines[0].strip()
            
            # Verify LHP header format (environment-agnostic)
            expected_header = f"# Generated by LakehousePlumber - Bundle Resource for {pipeline_name}"
            assert first_line == expected_header, f"Expected header '{expected_header}', got '{first_line}'"
            
            # Verify header contains key components
            assert "Generated by LakehousePlumber" in first_line
            assert "Bundle Resource for" in first_line
            assert pipeline_name in first_line
            
            # Verify header is a comment (starts with #)
            assert first_line.startswith("#"), "Header should be a YAML comment"
            
            # Verify content after header is proper YAML (not starting with #)
            yaml_lines = [line for line in lines[1:] if line.strip() and not line.strip().startswith("#")]
            assert len(yaml_lines) > 0, "Should have YAML content after header"
            assert yaml_lines[0].startswith("resources:"), "First YAML line should be 'resources:'"

    # Glob Pattern Tests (Scenarios 17-19)
    
    def test_replace_individual_notebooks_with_glob(self):
        """Should replace individual notebook format with glob pattern."""
        import yaml
        
        # Test with realistic pipeline names
        pipeline_names = ["glob_test", "bronze_ingestion", "silver_transformation"] 
        
        for pipeline_name in pipeline_names:
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            parsed_yaml = yaml.safe_load(content)
            
            # Navigate to libraries section
            pipeline_key = f"{pipeline_name}_pipeline"
            libraries = parsed_yaml["resources"]["pipelines"][pipeline_key]["libraries"]
            
            # Verify glob pattern structure
            assert len(libraries) == 1, "Should have exactly one library entry"
            library_entry = libraries[0]
            
            # Should use glob, not individual paths
            assert "glob" in library_entry, "Library entry should use 'glob' key"
            assert "notebook" not in library_entry, "Should not have individual 'notebook' entries"
            assert "file" not in library_entry, "Should not have individual 'file' entries"
            assert "jar" not in library_entry, "Should not have individual 'jar' entries"
            
            # Verify glob pattern format
            glob_config = library_entry["glob"]
            assert "include" in glob_config, "Glob should have 'include' pattern"
            
            expected_pattern = f"${{workspace.file_path}}/generated/${{bundle.target}}/{pipeline_name}/**"
            actual_pattern = glob_config["include"]
            assert actual_pattern == expected_pattern, f"Expected pattern '{expected_pattern}', got '{actual_pattern}'"
            
            # Verify no legacy library path patterns in content
            # (Note: root_path legitimately contains the path, so we check for specific library patterns)
            legacy_library_patterns = [
                f"notebook: ../../generated/dev/{pipeline_name}/",  # Individual notebook entries
                f"path: ../../generated/dev/{pipeline_name}/",  # Path entries
                f"- notebook:",  # Individual library entries
                f"- file:",      # File library entries  
                f"- jar:",       # JAR library entries
            ]
            
            for pattern in legacy_library_patterns:
                assert pattern not in content, f"Found legacy library pattern '{pattern}' in output"
                
            # Verify the path only appears in expected contexts (root_path and glob include)
            expected_contexts = [
                f"root_path: ${{workspace.file_path}}/generated/dev/{pipeline_name}",  # Root path (no trailing slash)
                f"include: ../../generated/dev/{pipeline_name}/**",  # Glob pattern
            ]
            
            # Count how many times the path appears in expected vs unexpected contexts
            path_pattern = f"generated/dev/{pipeline_name}"
            total_occurrences = content.count(path_pattern)
            expected_occurrences = sum(1 for context in expected_contexts if context in content)
            
            assert total_occurrences == expected_occurrences, f"Path pattern appears {total_occurrences} times but only {expected_occurrences} are in expected contexts"
    

    def test_no_notebook_path_iteration(self):
        """Should not require iteration through individual notebook paths."""
        from unittest.mock import patch, MagicMock
        import os
        
        # Test that bundle manager no longer needs to scan for files
        with patch('os.listdir') as mock_listdir, \
             patch('os.path.exists') as mock_exists, \
             patch('pathlib.Path.glob') as mock_glob:
            
            # Set up mocks to track if they're called
            mock_listdir.return_value = []
            mock_exists.return_value = True
            mock_glob.return_value = []
            
            # Generate content without any file system scanning
            pipeline_name = "no_iteration_test"
            content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
            
            # Verify content was generated successfully
            assert content is not None
            assert isinstance(content, str)
            assert pipeline_name in content
            assert "resources:" in content
            
            # Verify no file system operations were needed
            # (These should not be called since we use glob patterns)
            mock_listdir.assert_not_called()
            mock_glob.assert_not_called()
            
        # Verify the method signature includes pipeline_name and env parameters
        import inspect
        method_sig = inspect.signature(self.manager.generate_resource_file_content)
        param_names = list(method_sig.parameters.keys())
        
        # Should have pipeline_name, output_dir, and env parameters
        assert param_names == ['pipeline_name', 'output_dir', 'env'], f"Expected 'pipeline_name', 'output_dir', and 'env' parameters, got {param_names}"
        
        # Verify no methods exist for path iteration (removed in migration)
        removed_methods = [
            '_get_notebook_paths_for_pipeline',
            '_scan_pipeline_directory', 
            '_list_notebook_files'
        ]
        
        for method_name in removed_methods:
            assert not hasattr(self.manager, method_name), f"Method '{method_name}' should have been removed during migration"

    # Error Handling Tests (Scenarios 20-21)
    
    def test_corrupted_resource_file_handling(self):
        """Should handle corrupted existing resource files gracefully."""
        # Test graceful handling when template rendering encounters issues
        from unittest.mock import patch
        
        # Test 1: Verify normal operation works
        pipeline_name = "corruption_test"
        content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
        
        assert content is not None
        assert isinstance(content, str)
        assert pipeline_name in content
        
        # Test 2: Template corruption scenario (missing template file)
        with patch.object(self.manager.template_renderer.env, 'get_template') as mock_get_template:
            from jinja2 import TemplateNotFound
            mock_get_template.side_effect = TemplateNotFound("bundle/pipeline_resource.yml.j2")
            
            # Should handle missing template gracefully
            try:
                self.manager.generate_resource_file_content("test_pipeline", self.generated_dir, "dev")
                pytest.fail("Expected TemplateNotFound to be raised")
            except TemplateNotFound:
                pass  # Expected behavior - let caller handle the error
                
        # Test 3: Template rendering corruption (context issues)
        with patch.object(self.manager.template_renderer, 'render_template') as mock_render:
            mock_render.side_effect = Exception("Template rendering failed")
            
            # Should propagate template rendering errors
            try:
                self.manager.generate_resource_file_content("test_pipeline", self.generated_dir, "dev")
                pytest.fail("Expected template rendering error to be raised")
            except Exception as e:
                assert "Template rendering failed" in str(e)
                
        # Test 4: Verify system can recover after errors
        # (Normal operation should work again after patches are removed)
        recovery_content = self.manager.generate_resource_file_content("recovery_test", self.generated_dir, "dev")
        assert recovery_content is not None
        assert "recovery_test" in recovery_content
    
    def test_invalid_template_output_detection(self):
        """Should detect when template produces invalid YAML."""
        import yaml
        from unittest.mock import patch
        
        # Test 1: Verify normal template produces valid YAML
        pipeline_name = "validation_test"
        content = self.manager.generate_resource_file_content(pipeline_name, self.generated_dir, "dev")
        
        # Should parse without errors
        try:
            parsed = yaml.safe_load(content)
            assert parsed is not None
            assert isinstance(parsed, dict)
        except yaml.YAMLError:
            pytest.fail("Normal template output should produce valid YAML")
            
        # Test 2: Test detection of invalid YAML output
        with patch.object(self.manager.template_renderer, 'render_template') as mock_render:
            # Mock template that produces invalid YAML
            invalid_yaml_outputs = [
                "resources:\n  pipelines:\n    - invalid: [unclosed",  # Syntax error
                "resources: {\n  pipelines: {\n    test:",  # Incomplete YAML
                "resources:\n  pipelines:\n    @invalid_key: value",  # Invalid key
                "{{unclosed_template",  # Template syntax not resolved
            ]
            
            for invalid_output in invalid_yaml_outputs:
                mock_render.return_value = invalid_output
                
                # Get the generated content
                result = self.manager.generate_resource_file_content("test", self.generated_dir, "dev")
                
                # Verify it returns the invalid content (detection happens at parse time)
                assert result == invalid_output
                
                # Verify it would fail YAML parsing
                try:
                    yaml.safe_load(result)
                    pytest.fail(f"Invalid YAML should have failed parsing: {invalid_output[:50]}...")
                except yaml.YAMLError:
                    pass  # Expected - invalid YAML should fail parsing
                    
        # Test 3: Verify recovery after invalid output
        # (Should work normally again when template is fixed)
        recovery_content = self.manager.generate_resource_file_content("recovery_test", self.generated_dir, "dev")
        assert recovery_content is not None
        
        # Should produce valid YAML again
        try:
            yaml.safe_load(recovery_content)
        except yaml.YAMLError:
            pytest.fail("Recovery content should produce valid YAML")


class TestBundleJinja2TemplateHelpers:
    """Helper test class for template-specific utilities."""

    def setup_method(self):
        """Set up test environment for each test."""
        self.temp_dir = Path(tempfile.mkdtemp())

    def teardown_method(self):
        """Clean up test environment after each test."""
        shutil.rmtree(self.temp_dir)

    def test_template_file_discovery(self):
        """Should find and load bundle template files."""
        from pathlib import Path
        import lhp
        from lhp.bundle.manager import BundleManager
        
        # Create a bundle manager for testing
        manager = BundleManager(self.temp_dir)
        
        # Verify template file exists in expected location
        lhp_path = Path(lhp.__file__).parent
        bundle_template_dir = lhp_path / "templates" / "bundle"
        template_file = bundle_template_dir / "pipeline_resource.yml.j2"
        
        # File should exist
        assert bundle_template_dir.exists(), f"Bundle template directory not found: {bundle_template_dir}"
        assert bundle_template_dir.is_dir(), f"Bundle template path is not a directory: {bundle_template_dir}"
        assert template_file.exists(), f"Template file not found: {template_file}"
        assert template_file.is_file(), f"Template path is not a file: {template_file}"
        
        # File should be readable
        try:
            content = template_file.read_text()
            assert len(content) > 0, "Template file should not be empty"
            
            # Should contain expected Jinja2 syntax
            assert "{{ pipeline_name }}" in content, "Template should contain pipeline_name variable"
            assert "resources:" in content, "Template should contain YAML structure"
            assert "pipelines:" in content, "Template should contain pipelines section"
            
        except Exception as e:
            pytest.fail(f"Could not read template file: {e}")
            
        # Verify Jinja2 environment can load the template
        try:
            template = manager.template_renderer.env.get_template("bundle/pipeline_resource.yml.j2")
            assert template is not None, "Template should be loadable by Jinja2 environment"
            
        except Exception as e:
            pytest.fail(f"Template could not be loaded by Jinja2: {e}")
    
    def test_template_variable_validation(self):
        """Should validate required template variables are present."""
        from pathlib import Path
        import lhp
        from lhp.bundle.manager import BundleManager
        
        # Create a bundle manager for testing
        manager = BundleManager(self.temp_dir)
        
        # Test 1: Verify template contains all required variables
        template = manager.template_renderer.env.get_template("bundle/pipeline_resource.yml.j2")
        
        # Get template source by reading the file directly
        lhp_path = Path(lhp.__file__).parent
        template_file = lhp_path / "templates" / "bundle" / "pipeline_resource.yml.j2"
        template_source = template_file.read_text()
        
        # Required variables that must be present in template
        required_variables = [
            "pipeline_name",  # Primary template variable
        ]
        
        for var in required_variables:
            var_pattern = f"{{{{ {var} }}}}"
            assert var_pattern in template_source, f"Template missing required variable: {var}"
            
        # Test 2: Verify template validation with valid context (updated for pipeline config feature)
        default_pipeline_config = {"serverless": True, "edition": "ADVANCED", "channel": "CURRENT", "continuous": False}
        valid_contexts = [
            {"pipeline_name": "test_pipeline", "pipeline_config": default_pipeline_config},
            {"pipeline_name": "bronze_ingestion", "pipeline_config": default_pipeline_config}, 
            {"pipeline_name": "complex_data_transformation", "pipeline_config": default_pipeline_config},
        ]
        
        for context in valid_contexts:
            try:
                result = template.render(**context)
                assert result is not None
                assert len(result) > 0
                assert context["pipeline_name"] in result
                
            except Exception as e:
                pytest.fail(f"Template failed with valid context {context}: {e}")
                
        # Test 3: Verify template validation with missing required variables
        invalid_contexts = [
            {},  # Missing pipeline_name
            {"wrong_variable": "test"},  # Wrong variable name
            {"pipeline_name": None},  # Null value
        ]
        
        for context in invalid_contexts:
            try:
                result = template.render(**context)
                # If it succeeds, verify pipeline_name substitution actually happened
                if "pipeline_name" not in context or context["pipeline_name"] is None:
                    # Should contain the literal string or be malformed
                    assert "{{ pipeline_name }}" in result or "None" in result
                    
            except Exception:
                pass  # Expected for invalid contexts
                
        # Test 4: Verify template variables are properly escaped/safe (updated for pipeline config feature)
        special_contexts = [
            {"pipeline_name": "test<script>alert('xss')</script>", "pipeline_config": default_pipeline_config},
            {"pipeline_name": "test&special&chars", "pipeline_config": default_pipeline_config},
            {"pipeline_name": "test\"quotes\"", "pipeline_config": default_pipeline_config},
        ]

        for context in special_contexts:
            try:
                result = template.render(**context)
                # Should render without errors and include the content
                assert context["pipeline_name"] in result

            except Exception as e:
                pytest.fail(f"Template failed with special characters context {context}: {e}")