Metadata-Version: 2.4
Name: luna2
Version: 0.1.3
Summary: Real-Time VLAs via Future-state-aware Asynchronous Inference.
Author: Jin Fagang
License: MIT
Project-URL: Homepage, https://github.com/jinfagang/luna
Project-URL: Repository, https://github.com/jinfagang/luna
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: lerobot[feetech,smolvla]==0.4.1
Requires-Dist: transformers
Requires-Dist: peft>=0.18.0
Requires-Dist: bitsandbytes>=0.48.2
Requires-Dist: flask>=3.1.2
Requires-Dist: flask-cors>=4.0.0
Requires-Dist: requests>=2.31.0
Requires-Dist: reachy2_sdk
Requires-Dist: superbot2
Dynamic: license-file

# LUNA: Real-Time VLAs via Future-state-aware Asynchronous Inference

LUNA is an efficient and easy-to-use framework for VLAs inference.

## Features

LUNA is efficient through:
- **Asynchronous Inference**: Overlaps action prediction with execution to achieve real-time performance
- **Future-state Awareness**: Uses predicted future states for more accurate action planning

LUNA is easy to use with:
- **Simple CLI**: Clean command-line interface for inference and serving
- **Flexible Configuration**: YAML-based configuration for easy customization

## Installation

```bash
# Create conda environment
conda create -n "luna" python=3.10
conda activate luna

# Install dependencies
pip install -e .
```

## Usage

```bash
# Run inference with a trained policy
luna run examples/inference/async.yaml

# Start model server for remote inference
luna server examples/inference/async.yaml

# Run inference with custom parameters
luna run examples/inference/async.yaml --action_quant_ratio=2
```

LUNA is designed to be flexible and extensible, allowing users to easily integrate new policies and customize existing ones.

