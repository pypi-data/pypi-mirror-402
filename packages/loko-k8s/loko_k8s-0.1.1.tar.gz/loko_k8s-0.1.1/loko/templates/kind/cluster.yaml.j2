# KinD configuration for {{ env_name }} environment
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: {{ env_name }}

# Cluster-wide configuration
# Networking
networking:
  apiServerAddress: "127.0.0.1"  # Always use localhost for API server
  apiServerPort: {{ api_port }}
  # Pod subnet configuration
  podSubnet: "10.10.0.0/16"
  # Service subnet configuration
  serviceSubnet: "10.11.0.0/16"
  disableDefaultCNI: false

# Containerd configuration patches
# Remove legacy mirrors config to avoid conflict with new-style certs.d/hosts.toml
containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry]
    config_path = "/etc/containerd/certs.d"

# Node-specific configuration
nodes:
# Control plane nodes
{% for i in range(nodes.servers) %}
- role: control-plane
  image: {{ kubernetes_full_image }}
  {% if loop.first %}
  # Configure port mappings on the first control plane node
  extraPortMappings:
    {% for port in ingress_ports %}
    - containerPort: {{ port }}
      hostPort: {{ port }}
      protocol: TCP
    {% endfor %}
    # Also expose service ports on control-plane when no workers
    {% for service in services if service.enabled %}
    {% for port in service.ports %}
    - containerPort: {{ port }}
      hostPort: {{ port }}
      protocol: TCP
    {% endfor %}
    {% endfor %}
  {% endif %}
  # Configure mounts for logs, storage, and certificates
  extraMounts:
  {% for mount in mounts %}
  - hostPath: {{ mount.hostPath }}/control-{{ i }}
    containerPath: {{ mount.node_path }}
  {% endfor %}
  - hostPath: {{ root_ca_path }}
    containerPath: {{ cacert_file }}
  - hostPath: {{ k8s_dir }}/config/containerd
    containerPath: /etc/containerd/certs.d
  kubeadmConfigPatches:
  - |
    apiVersion: kubeadm.k8s.io/v1beta4
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        # Node taints
        {% set should_taint = True %}
        {% if nodes.workers == 0 or not scheduling.control_plane.isolate_internal_components %}
          {% if scheduling.control_plane.allow_workloads %}
            {% set should_taint = False %}
          {% endif %}
        {% endif %}
        {% if should_taint %}
        register-with-taints: "node-role=control-plane:NoSchedule,node-role=master:NoSchedule"
        {% else %}
        register-with-taints: ""
        {% endif %}
{% endfor %}

{% if nodes.workers > 0 %}
# Worker nodes
{% for i in range(nodes.workers) %}
- role: worker
  image: {{ kubernetes_full_image }}
  # Simple worker node configuration
  extraMounts:
  {% for mount in mounts %}
  - hostPath: {{ mount.hostPath }}/worker-{{ i }}
    containerPath: {{ mount.node_path }}
  {% endfor %}
  - hostPath: {{ root_ca_path }}
    containerPath: {{ cacert_file }}
  - hostPath: {{ k8s_dir }}/config/containerd
    containerPath: /etc/containerd/certs.d
{% if nodes.get('labels') or scheduling.workers.isolate_workloads %}
  kubeadmConfigPatches:
  - |
    apiVersion: kubeadm.k8s.io/v1beta4
    kind: JoinConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "kubernetes.io/hostname=worker-{{ i }},node-role=worker
        {%- if nodes.get('labels', {}).get('individual', {}).get('worker-' + i|string) -%}
          {%- for key, value in nodes.labels.individual['worker-' + i|string].items() -%}
            ,{{ key }}={{ value }}
          {%- endfor -%}
        {%- elif nodes.get('labels', {}).get('worker') -%}
          {%- for key, value in nodes.labels.worker.items() -%}
            ,{{ key }}={{ value }}
          {%- endfor -%}
        {%- endif -%}
        "
        {% if scheduling.workers.isolate_workloads %}
        register-with-taints: "node-role=worker:NoSchedule"  # Taint worker nodes when isolate_workloads is true
        {% endif %}
{% endif %}
{% if not loop.last %}

{% endif %}
{% endfor %}
{% endif %}
