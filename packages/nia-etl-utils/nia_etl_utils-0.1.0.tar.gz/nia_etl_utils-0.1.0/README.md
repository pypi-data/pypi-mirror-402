# nia-etl-utils

## âœ¨ VisÃ£o Geral

Biblioteca Python centralizada contendo **utilitÃ¡rios compartilhados** para pipelines ETL do NIA/MPRJ. Consolida funÃ§Ãµes reutilizÃ¡veis para configuraÃ§Ã£o de ambiente, notificaÃ§Ãµes por email, conexÃµes de banco de dados, logging padronizado e processamento de dados.

Desenvolvida para **eliminar duplicaÃ§Ã£o de cÃ³digo**, **padronizar boas prÃ¡ticas** e **facilitar manutenÃ§Ã£o** em todos os projetos de engenharia de dados do NIA.

---

## ğŸ“‚ Estrutura do Projeto

```plaintext
.
â”œâ”€â”€ src/
â”‚   â””â”€â”€ nia_etl_utils/                          # Pacote principal
â”‚       â”œâ”€â”€ __init__.py                         # Exporta funÃ§Ãµes principais
â”‚       â”œâ”€â”€ env_config.py                       # Gerenciamento de variÃ¡veis de ambiente
â”‚       â”œâ”€â”€ email_smtp.py                       # Envio de emails via SMTP
â”‚       â”œâ”€â”€ database.py                         # ConexÃµes PostgreSQL e Oracle
â”‚       â”œâ”€â”€ logger_config.py                    # ConfiguraÃ§Ã£o de logging com Loguru
â”‚       â”œâ”€â”€ processa_csv.py                     # Processamento e exportaÃ§Ã£o de CSV
â”‚       â”œâ”€â”€ processa_csv_paralelo.py            # Processamento paralelo de CSV grandes
â”‚       â””â”€â”€ limpeza_pastas.py                   # ManipulaÃ§Ã£o de arquivos e diretÃ³rios
â”‚
â”œâ”€â”€ tests/                                      # Testes unitÃ¡rios (~60+ testes)
â”‚   â”œâ”€â”€ conftest.py                             # Fixtures compartilhadas
â”‚   â”œâ”€â”€ test_env_config.py                      # Testes de variÃ¡veis de ambiente
â”‚   â”œâ”€â”€ test_email_smtp.py                      # Testes de email (com mocks)
â”‚   â”œâ”€â”€ test_database.py                        # Testes de conexÃµes (com mocks)
â”‚   â”œâ”€â”€ test_logger_config.py                   # Testes de logging
â”‚   â”œâ”€â”€ test_processa_csv.py                    # Testes de processamento CSV
â”‚   â”œâ”€â”€ test_processa_csv_paralelo.py           # Testes de processamento paralelo
â”‚   â”œâ”€â”€ test_limpeza_pastas.py                  # Testes de manipulaÃ§Ã£o de arquivos
â”‚   â””â”€â”€ README.md                               # DocumentaÃ§Ã£o dos testes
â”‚
â”œâ”€â”€ .env.example                                # Template de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                                  # Arquivos ignorados pelo Git
â”œâ”€â”€ .gitlab-ci.yml                              # Pipeline CI/CD (testes + cobertura)
â”œâ”€â”€ .python-version                             # VersÃ£o Python do projeto (3.13.3)
â”œâ”€â”€ pyproject.toml                              # ConfiguraÃ§Ã£o do pacote Python
â”œâ”€â”€ requirements.txt                            # DependÃªncias do projeto
â”œâ”€â”€ run_tests.sh                                # Script helper para executar testes
â””â”€â”€ README.md
```

---

## ğŸ”§ MÃ³dulos DisponÃ­veis

### 1ï¸âƒ£ ConfiguraÃ§Ã£o de Ambiente (`env_config.py`)

Gerenciamento robusto de variÃ¡veis de ambiente com validaÃ§Ã£o e falha explÃ­cita.

```python
from nia_etl_utils import obter_variavel_env

# VariÃ¡vel obrigatÃ³ria (falha com sys.exit(1) se nÃ£o existir)
db_host = obter_variavel_env('DB_POSTGRESQL_HOST')

# VariÃ¡vel opcional com fallback
porta = obter_variavel_env('DB_PORT', default='5432')
```

**CaracterÃ­sticas:**
- âœ… Falha rÃ¡pida com `sys.exit(1)` quando variÃ¡vel obrigatÃ³ria nÃ£o existe
- âœ… Suporte a valores padrÃ£o opcionais
- âœ… Logs descritivos de erro

---

### 2ï¸âƒ£ Email SMTP (`email_smtp.py`)

Envio de emails com ou sem anexo, suportando destinatÃ¡rios configurÃ¡veis via env var.

```python
from nia_etl_utils import enviar_email_smtp

# Uso padrÃ£o (destinatÃ¡rios da env var EMAIL_DESTINATARIOS)
enviar_email_smtp(
    corpo_do_email="Pipeline concluÃ­do com sucesso",
    assunto="[PROD] ETL Finalizado"
)

# Com destinatÃ¡rios especÃ­ficos e anexo
enviar_email_smtp(
    destinatarios=["diretor@mprj.mp.br"],
    corpo_do_email="RelatÃ³rio executivo anexo",
    assunto="RelatÃ³rio Mensal",
    anexo="/tmp/relatorio.pdf"
)
```

**CaracterÃ­sticas:**
- âœ… DestinatÃ¡rios configurÃ¡veis via `EMAIL_DESTINATARIOS`
- âœ… Suporte a anexos
- âœ… Falha explÃ­cita com `sys.exit(1)` em erros SMTP
- âœ… ValidaÃ§Ã£o de arquivos anexos

---

### 3ï¸âƒ£ ConexÃµes de Banco (`database.py`)

ConexÃµes padronizadas para PostgreSQL (psycopg2 + SQLAlchemy) e Oracle (cx_Oracle).

#### PostgreSQL

```python
from nia_etl_utils import conectar_postgresql_nia, fechar_conexao

# Conecta no PostgreSQL do NIA
cur, conn = conectar_postgresql_nia()
cur.execute("SELECT * FROM tabela")
resultados = cur.fetchall()
fechar_conexao(cur, conn)

# Engine SQLAlchemy (para pandas)
from nia_etl_utils import obter_engine_postgresql_nia
import pandas as pd

engine = obter_engine_postgresql_nia()
df = pd.read_sql("SELECT * FROM tabela", engine)
```

#### Oracle

```python
from nia_etl_utils import conectar_oracle, fechar_conexao

# Conecta no Oracle
cur, conn = conectar_oracle()
cur.execute("SELECT * FROM tabela WHERE ROWNUM <= 10")
resultados = cur.fetchall()
fechar_conexao(cur, conn)
```

#### Bancos Adicionais (GenÃ©rico)

```python
from nia_etl_utils import conectar_postgresql

# Conecta em qualquer PostgreSQL configurado com sufixo customizado
# Requer: DB_POSTGRESQL_HOST_SUFIXO, DB_POSTGRESQL_PORT_SUFIXO, etc
cur, conn = conectar_postgresql("_SUFIXO")
```

**CaracterÃ­sticas:**
- âœ… FunÃ§Ãµes genÃ©ricas + wrappers de conveniÃªncia
- âœ… Suporte a mÃºltiplos bancos PostgreSQL (via sufixos)
- âœ… Logs informativos de conexÃ£o
- âœ… Falha explÃ­cita com `sys.exit(1)` em erros de conexÃ£o
- âœ… `fechar_conexao()` segura (nÃ£o falha se erro ao fechar)

---

### 4ï¸âƒ£ Logging (`logger_config.py`)

ConfiguraÃ§Ã£o padronizada do Loguru com rotaÃ§Ã£o, retenÃ§Ã£o e nÃ­veis customizÃ¡veis.

```python
from nia_etl_utils import configurar_logger_padrao_nia
from loguru import logger

# ConfiguraÃ§Ã£o rÃ¡pida com padrÃµes do NIA
caminho_log = configurar_logger_padrao_nia("ouvidorias_etl")
logger.info("Pipeline iniciado")

# ConfiguraÃ§Ã£o customizada
from nia_etl_utils import configurar_logger

caminho_log = configurar_logger(
    prefixo="meu_pipeline",
    data_extracao="2025_01_19",
    pasta_logs="/var/logs/nia",
    rotation="50 MB",
    retention="30 days",
    level="INFO"
)
```

**CaracterÃ­sticas:**
- âœ… RotaÃ§Ã£o automÃ¡tica de arquivos por tamanho
- âœ… RetenÃ§Ã£o configurÃ¡vel (padrÃ£o: 7 dias em DEV, 30 dias em PROD)
- âœ… Formato padronizado com timestamp, nÃ­vel, mÃ³dulo, funÃ§Ã£o e linha
- âœ… Logs organizados por pipeline e data

---

### 5ï¸âƒ£ Processamento CSV (`processa_csv.py`)

ExportaÃ§Ã£o de DataFrames para CSV com nomenclatura padronizada e validaÃ§Ãµes.

```python
from nia_etl_utils import exportar_para_csv, extrair_e_exportar_csv
import pandas as pd

# ExportaÃ§Ã£o simples
df = pd.DataFrame({"col1": [1, 2], "col2": [3, 4]})
caminho = exportar_para_csv(
    df=df,
    nome_arquivo="dados_clientes",
    data_extracao="2025_01_19",
    diretorio_base="/tmp/dados"
)

# ExtraÃ§Ã£o + ExportaÃ§Ã£o
def extrair_dados():
    # ... lÃ³gica de extraÃ§Ã£o ...
    return pd.DataFrame({"dados": [1, 2, 3]})

caminho = extrair_e_exportar_csv(
    nome_extracao="dados_vendas",
    funcao_extracao=extrair_dados,
    data_extracao="2025_01_19",
    diretorio_base="/tmp/dados",
    falhar_se_vazio=True  # sys.exit(1) se DataFrame vazio
)

# MÃºltiplas extraÃ§Ãµes em lote
from nia_etl_utils import exportar_multiplos_csv

extractions = [
    {"nome": "clientes", "funcao": extrair_clientes},
    {"nome": "vendas", "funcao": extrair_vendas}
]

resultados = exportar_multiplos_csv(
    extractions=extractions,
    data_extracao="2025_01_19",
    diretorio_base="/tmp/dados"
)
```

**CaracterÃ­sticas:**
- âœ… Nomenclatura padronizada: `{nome}_{data}.csv`
- âœ… CriaÃ§Ã£o automÃ¡tica de diretÃ³rios
- âœ… Logs com informaÃ§Ãµes Ãºteis (linhas, colunas, tamanho)
- âœ… Controle de falha em DataFrames vazios

---

### 6ï¸âƒ£ ManipulaÃ§Ã£o de Arquivos (`limpeza_pastas.py`)

UtilitÃ¡rios para limpeza e criaÃ§Ã£o de diretÃ³rios.

```python
from nia_etl_utils import limpar_pasta, remover_pasta_recursivamente, criar_pasta_se_nao_existir

# Limpa pasta (remove arquivos, mantÃ©m subdiretÃ³rios)
limpar_pasta("/tmp/dados")

# Remove pasta completa (arquivos + subdiretÃ³rios)
remover_pasta_recursivamente("/tmp/temporario")

# Cria pasta se nÃ£o existir (incluindo pais)
criar_pasta_se_nao_existir("/dados/processados/2025/01")
```

**CaracterÃ­sticas:**
- âœ… Uso de `pathlib.Path` (moderno e seguro)
- âœ… ValidaÃ§Ãµes de permissÃ£o
- âœ… Falha explÃ­cita com `sys.exit(1)` em erros

---

### 7ï¸âƒ£ Processamento Paralelo de CSV (`processa_csv_paralelo.py`)

Processa arquivos CSV grandes em paralelo usando multiprocessing com chunks otimizados.

```python
from nia_etl_utils import processar_csv_paralelo

# FunÃ§Ã£o de transformaÃ§Ã£o customizada
def limpar_texto(texto):
    return texto.strip().upper()

# Processa CSV grande em paralelo
processar_csv_paralelo(
    caminho_entrada="dados_brutos.csv",
    caminho_saida="dados_limpos.csv",
    colunas_para_tratar=["nome", "descricao", "observacao"],
    funcao_transformacao=limpar_texto,
    remover_entrada=True  # Remove arquivo original apÃ³s processar
)

# Com configuraÃ§Ãµes customizadas
processar_csv_paralelo(
    caminho_entrada="dados_gigantes.csv",
    caminho_saida="dados_processados.csv",
    colunas_para_tratar=["texto"],
    funcao_transformacao=limpar_texto,
    chunksize=5000,              # Tamanho customizado de chunk
    num_processos=4,             # NÃºmero de processos paralelos
    normalizar_colunas=False,    # MantÃ©m case original das colunas
    remover_entrada=False        # Preserva arquivo de entrada
)
```

**CaracterÃ­sticas:**
- âœ… Processamento paralelo automÃ¡tico usando `multiprocessing.Pool`
- âœ… Chunksize calculado automaticamente baseado no tamanho do arquivo
- âœ… HeurÃ­stica inteligente:
  - Arquivos < 500MB: chunks de 10.000 linhas
  - Arquivos 500MB-2GB: chunks de 5.000 linhas
  - Arquivos 2-5GB: chunks de 2.000 linhas
  - Arquivos > 5GB: chunks de 1.000 linhas
- âœ… NormalizaÃ§Ã£o opcional de nomes de colunas (lowercase)
- âœ… RemoÃ§Ã£o opcional do arquivo de entrada
- âœ… Logs informativos de progresso
- âœ… Suporta qualquer funÃ§Ã£o de transformaÃ§Ã£o customizada

**Quando usar:**
- ğŸ“Š Arquivos CSV com milhÃµes de linhas
- ğŸ”„ TransformaÃ§Ãµes pesadas em texto (limpeza, normalizaÃ§Ã£o)
- âš¡ Necessidade de processar mÃºltiplas colunas rapidamente
- ğŸ’¾ Arquivos que nÃ£o cabem confortavelmente na memÃ³ria

---

## ğŸ“¦ InstalaÃ§Ã£o

### Via GitLab (Recomendado)

```bash
# Instalar versÃ£o especÃ­fica
pip install git+https://gitlab-dti.mprj.mp.br/nia/etl-nia/nia-etl-utils.git@v0.1.0

# Ou no requirements.txt
nia-etl-utils @ git+https://gitlab-dti.mprj.mp.br/nia/etl-nia/nia-etl-utils.git@v0.1.0
```

### Modo Desenvolvimento

```bash
git clone https://gitlab-dti.mprj.mp.br/nia/etl-nia/nia-etl-utils.git
cd nia-etl-utils
pip install -e ".[dev]"
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. Criar arquivo `.env`

```bash
cp .env.example .env
```

### 2. Configurar variÃ¡veis de ambiente

```env
# Email SMTP
MAIL_SMTP_SERVER=smtp.mprj.mp.br
MAIL_SMTP_PORT=587
MAIL_SENDER=etl@mprj.mp.br
EMAIL_DESTINATARIOS=equipe@mprj.mp.br,gestor@mprj.mp.br

# PostgreSQL - NIA
DB_POSTGRESQL_HOST=postgres-nia.mprj.mp.br
DB_POSTGRESQL_PORT=5432
DB_POSTGRESQL_DATABASE=nia_database
DB_POSTGRESQL_USER=usuario
DB_POSTGRESQL_PASSWORD=senha

# PostgreSQL - OpenGeo
DB_POSTGRESQL_HOST_OPENGEO=postgres-opengeo.mprj.mp.br
DB_POSTGRESQL_PORT_OPENGEO=5432
DB_POSTGRESQL_DATABASE_OPENGEO=opengeo_database
DB_POSTGRESQL_USER_OPENGEO=usuario
DB_POSTGRESQL_PASSWORD_OPENGEO=senha

# Oracle
DB_ORACLE_HOST=oracle.mprj.mp.br
DB_ORACLE_PORT=1521
DB_ORACLE_SERVICE_NAME=ORCL
DB_ORACLE_USER=usuario
DB_ORACLE_PASSWORD=senha
```

---

## ğŸ§ª Testes

### Executar Testes

```bash
# Todos os testes
pytest

# Com cobertura
pytest --cov=src/nia_etl_utils --cov-report=term-missing

# Ou usar o script helper
./run_tests.sh --coverage --verbose
```

### Cobertura Atual

- **~70 testes unitÃ¡rios** (incluindo testes de processamento paralelo)
- **~90% de cobertura** de cÃ³digo
- Testes com mocks (sem dependÃªncia de banco/SMTP real)

Veja `tests/README.md` para documentaÃ§Ã£o completa dos testes.

---

## ğŸš€ Exemplo de Uso Completo

```python
from nia_etl_utils import (
    configurar_logger_padrao_nia,
    obter_variavel_env,
    conectar_postgresql_nia,
    exportar_para_csv,
    processar_csv_paralelo,
    fechar_conexao
)
from loguru import logger
import pandas as pd

# 1. Configura logging
configurar_logger_padrao_nia("meu_pipeline")

# 2. Conecta no banco
logger.info("Iniciando conexÃ£o com banco de dados...")
cur, conn = conectar_postgresql_nia()

# 3. Extrai dados
logger.info("Extraindo dados...")
cur.execute("SELECT * FROM tabela WHERE data >= CURRENT_DATE - 7")
resultados = cur.fetchall()
colunas = [desc[0] for desc in cur.description]
df = pd.DataFrame(resultados, columns=colunas)

# 4. Fecha conexÃ£o
fechar_conexao(cur, conn)
logger.info(f"ExtraÃ§Ã£o concluÃ­da: {len(df)} registros")

# 5. Exporta CSV
from datetime import datetime
data_hoje = datetime.now().strftime("%Y_%m_%d")

caminho = exportar_para_csv(
    df=df,
    nome_arquivo="dados_extraidos",
    data_extracao=data_hoje,
    diretorio_base="/dados/processados"
)

# 6. Processa CSV em paralelo (se necessÃ¡rio)
if len(df) > 100000:  # SÃ³ paraleliza arquivos grandes
    def limpar_descricao(texto):
        return texto.strip().upper() if texto else ""

    processar_csv_paralelo(
        caminho_entrada=caminho,
        caminho_saida=f"/dados/processados/dados_limpos_{data_hoje}.csv",
        colunas_para_tratar=["descricao", "observacao"],
        funcao_transformacao=limpar_descricao,
        remover_entrada=True
    )
    logger.success("Processamento paralelo concluÃ­do!")

logger.success(f"Pipeline concluÃ­do! Arquivo: {caminho}")
```

---

## â˜ï¸ IntegraÃ§Ã£o com Airflow

### Usando em KubernetesPodOperator

```python
from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import KubernetesPodOperator

task = KubernetesPodOperator(
    task_id="meu_etl",
    name="meu-etl-pod",
    namespace="airflow-nia-stage",
    image="python:3.13.3",
    cmds=[
        "sh", "-c",
        "pip install git+https://gitlab-dti.mprj.mp.br/nia/etl-nia/nia-etl-utils.git@v0.1.0 && "
        "python src/extract.py"
    ],
    env_vars={
        "DB_POSTGRESQL_HOST": "...",
        "EMAIL_DESTINATARIOS": "equipe@mprj.mp.br"
    },
    # ... outras configs
)
```

---

## âš™ï¸ Tecnologias Utilizadas

- Python 3.13.3
- Loguru (logging)
- python-dotenv (env vars)
- cx_Oracle (Oracle)
- psycopg2 (PostgreSQL)
- SQLAlchemy (engines)
- pandas (processamento de dados)
- pytest + pytest-cov (testes)
- ruff (linting)

---

## ğŸ“‹ Versionamento

Este projeto usa [Semantic Versioning](https://semver.org/):

- **MAJOR**: MudanÃ§as incompatÃ­veis na API
- **MINOR**: Novas funcionalidades (retrocompatÃ­veis)
- **PATCH**: CorreÃ§Ãµes de bugs

**VersÃ£o atual:** `v0.1.0`

---

## ğŸ”” Monitoramento e Logs

- Logging estruturado via Loguru
- Logs organizados por pipeline e data em `/logs`
- Scripts retornam `sys.exit(1)` em falhas para integraÃ§Ã£o com Airflow
- NotificaÃ§Ãµes via email em pipelines de produÃ§Ã£o

---

## ğŸ”§ CI/CD

Pipeline automatizado no GitLab com:

- âœ… Testes unitÃ¡rios (pytest)
- âœ… Cobertura de cÃ³digo (>= 80%)
- âœ… Linting (ruff)
- âœ… RelatÃ³rios de cobertura (HTML + XML)
- âœ… ExecuÃ§Ã£o em branches e merge requests

---

## âœï¸ ContribuiÃ§Ã£o

Merge requests sÃ£o bem-vindos. Sempre crie uma branch a partir de `main`.

### Checklist para Contribuir:

- [ ] Testes passam: `pytest`
- [ ] Cobertura >= 70%: `pytest --cov=src/nia_etl_utils --cov-fail-under=80`
- [ ] Lint OK: `ruff check src/ tests/`
- [ ] Commits semÃ¢nticos: `feat:`, `fix:`, `refactor:`, etc.
- [ ] DocumentaÃ§Ã£o atualizada

---

## ğŸ” LicenÃ§a

Projeto de uso interno do MPRJ. Sem licenÃ§a pÃºblica.

---

## âœ¨ ResponsÃ¡vel TÃ©cnico

**NÃ­colas Galdino Esmael** | Engenheiro de Dados - NIA | MPRJ

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [DocumentaÃ§Ã£o de Testes](tests/README.md)
- [Template de VariÃ¡veis de Ambiente](.env.example)
- [ConfiguraÃ§Ã£o do Projeto](pyproject.toml)
