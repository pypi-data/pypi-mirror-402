"""Tests for CombinatorialPurgedCV splitter."""

import math

import numpy as np
import pandas as pd
import polars as pl
import pytest
from pydantic import ValidationError

from ml4t.diagnostic.splitters.combinatorial import CombinatorialPurgedCV


class TestCombinatorialPurgedCV:
    """Test suite for CombinatorialPurgedCV."""

    def test_basic_combinatorial_split(self):
        """Test basic combinatorial splitting without purging/embargo."""
        X = np.arange(240).reshape(240, 1)  # 240 samples
        cv = CombinatorialPurgedCV(
            n_groups=6,
            n_test_groups=2,
            label_horizon=0,
            embargo_size=0,
        )

        splits = list(cv.split(X))

        # C(6,2) = 15 combinations
        expected_combinations = math.comb(6, 2)
        assert len(splits) == expected_combinations

        # Each split should have non-empty train and test sets
        for train_idx, test_idx in splits:
            assert len(train_idx) > 0
            assert len(test_idx) > 0

            # No overlap between train and test
            assert len(set(train_idx) & set(test_idx)) == 0

            # Test indices should be from exactly 2 groups
            # (may be contiguous if groups are adjacent)
            test_ranges = self._get_contiguous_ranges(test_idx)
            assert 1 <= len(test_ranges) <= 2  # 1 if adjacent groups, 2 if separate

    def test_group_boundaries(self):
        """Test that groups are correctly partitioned."""
        n_samples = 120
        np.arange(n_samples).reshape(n_samples, 1)
        cv = CombinatorialPurgedCV(n_groups=5, n_test_groups=1)

        # Test group boundary creation
        boundaries = cv._create_group_boundaries(n_samples)

        assert len(boundaries) == 5

        # Check boundaries are contiguous and cover all data
        assert boundaries[0][0] == 0
        assert boundaries[-1][1] == n_samples

        for i in range(len(boundaries) - 1):
            assert boundaries[i][1] == boundaries[i + 1][0]

    def test_group_size_distribution(self):
        """Test that groups have approximately equal sizes."""
        n_samples = 100
        cv = CombinatorialPurgedCV(n_groups=7)
        boundaries = cv._create_group_boundaries(n_samples)

        group_sizes = [end - start for start, end in boundaries]

        # With 100 samples and 7 groups: 6 groups of size 14, 1 group of size 16
        assert min(group_sizes) >= 14
        assert max(group_sizes) <= 15
        assert sum(group_sizes) == n_samples

    def test_combinatorial_math(self):
        """Test that correct number of combinations are generated."""
        X = np.arange(200).reshape(200, 1)

        test_cases = [
            (5, 2, 10),  # C(5,2) = 10
            (6, 2, 15),  # C(6,2) = 15
            (8, 3, 56),  # C(8,3) = 56
        ]

        for n_groups, n_test_groups, expected in test_cases:
            cv = CombinatorialPurgedCV(n_groups=n_groups, n_test_groups=n_test_groups)
            assert cv.get_n_splits() == expected

            splits = list(cv.split(X))
            assert len(splits) == expected

    def test_max_combinations_limit(self):
        """Test limiting the number of combinations."""
        X = np.arange(200).reshape(200, 1)
        cv = CombinatorialPurgedCV(
            n_groups=8,
            n_test_groups=3,
            max_combinations=10,
            random_state=42,
        )

        # Should limit to 10 instead of C(8,3) = 56
        assert cv.get_n_splits() == 10

        splits = list(cv.split(X))
        assert len(splits) == 10

    def test_with_purging(self):
        """Test combinatorial CV with purging."""
        n_samples = 200
        X = np.arange(n_samples).reshape(n_samples, 1)
        label_horizon = 10

        cv = CombinatorialPurgedCV(
            n_groups=5,
            n_test_groups=2,
            label_horizon=label_horizon,
        )

        for train_idx, test_idx in cv.split(X):
            # Verify purging: no training sample within label_horizon of any test group start
            test_starts = self._get_group_starts(test_idx)

            for test_start in test_starts:
                # Check that no training samples are within purging window
                purge_start = max(0, test_start - label_horizon)
                purged_samples = set(range(purge_start, test_start))

                # Training set should not contain purged samples
                assert len(set(train_idx) & purged_samples) == 0

    def test_with_embargo(self):
        """Test combinatorial CV with embargo."""
        n_samples = 300
        X = np.arange(n_samples).reshape(n_samples, 1)
        embargo_size = 8

        cv = CombinatorialPurgedCV(
            n_groups=6,
            n_test_groups=2,
            embargo_size=embargo_size,
        )

        for train_idx, test_idx in cv.split(X):
            # Verify embargo: no training sample within embargo_size after any test group end
            test_ends = self._get_group_ends(test_idx, n_samples)

            for test_end in test_ends:
                # Check that no training samples are within embargo window
                embargo_end = min(n_samples, test_end + embargo_size)
                embargoed_samples = set(range(test_end, embargo_end))

                # Training set should not contain embargoed samples
                assert len(set(train_idx) & embargoed_samples) == 0

    def test_with_pandas_timestamps(self):
        """Test with pandas DataFrame having DatetimeIndex."""
        n_samples = 120
        dates = pd.date_range("2020-01-01", periods=n_samples, freq="D", tz="UTC")
        X = pd.DataFrame({"feature": np.arange(n_samples)}, index=dates)

        cv = CombinatorialPurgedCV(
            n_groups=4,
            n_test_groups=1,
            label_horizon=pd.Timedelta("10D"),
            embargo_size=pd.Timedelta("5D"),
        )

        splits = list(cv.split(X))
        assert len(splits) == 4  # C(4,1) = 4

        for train_idx, test_idx in splits:
            # Verify temporal ordering within groups
            X.index[train_idx]
            test_times = X.index[test_idx]

            # Test times should be contiguous
            test_time_diffs = test_times[1:] - test_times[:-1]
            assert all(diff == pd.Timedelta("1D") for diff in test_time_diffs)

    def test_with_polars_dataframe(self):
        """Test with Polars DataFrame."""
        X = pl.DataFrame({"feature": np.arange(150)})
        cv = CombinatorialPurgedCV(n_groups=5, n_test_groups=2)

        splits = list(cv.split(X))
        assert len(splits) == 10  # C(5,2) = 10

        for train_idx, test_idx in splits:
            assert len(train_idx) > 0
            assert len(test_idx) > 0

    def test_insufficient_data_per_group(self):
        """Test error when insufficient data per group."""
        X = np.arange(5).reshape(5, 1)  # Only 5 samples
        cv = CombinatorialPurgedCV(n_groups=8)  # Want 8 groups

        with pytest.raises(ValueError, match="Not enough samples"):
            list(cv.split(X))

    def test_invalid_parameters(self):
        """Test validation of invalid parameters."""
        # n_test_groups >= n_groups - validated by Pydantic config
        with pytest.raises(ValidationError, match="cannot exceed"):
            CombinatorialPurgedCV(n_groups=4, n_test_groups=4)

        # Both embargo specifications - validated by Pydantic config model_validator
        with pytest.raises(ValidationError, match="Cannot specify both"):
            CombinatorialPurgedCV(embargo_size=5, embargo_pct=0.1)

        # Invalid embargo percentage - validated by Pydantic config Field(lt=1.0)
        with pytest.raises(ValidationError, match="less than 1"):
            CombinatorialPurgedCV(embargo_pct=1.2)

        # Negative parameters - validated by Pydantic config
        with pytest.raises(ValidationError, match="greater than 1"):
            CombinatorialPurgedCV(n_groups=-1)

    def test_reproducible_sampling(self):
        """Test that random sampling is reproducible."""
        X = np.arange(200).reshape(200, 1)

        cv1 = CombinatorialPurgedCV(
            n_groups=10,
            n_test_groups=3,
            max_combinations=5,
            random_state=42,
        )
        cv2 = CombinatorialPurgedCV(
            n_groups=10,
            n_test_groups=3,
            max_combinations=5,
            random_state=42,
        )

        splits1 = list(cv1.split(X))
        splits2 = list(cv2.split(X))

        # Should produce identical splits
        assert len(splits1) == len(splits2) == 5

        for (train1, test1), (train2, test2) in zip(splits1, splits2, strict=False):
            np.testing.assert_array_equal(train1, train2)
            np.testing.assert_array_equal(test1, test2)

    def test_all_combinations_covered(self):
        """Test that all possible combinations are generated when max_combinations is None."""
        X = np.arange(100).reshape(100, 1)
        cv = CombinatorialPurgedCV(n_groups=5, n_test_groups=2)

        splits = list(cv.split(X))
        test_group_combinations = []

        # Extract which groups were used for testing in each split
        for _, test_idx in splits:
            # Identify which groups these indices belong to
            group_boundaries = cv._create_group_boundaries(100)
            test_groups = []

            for group_idx, (start, end) in enumerate(group_boundaries):
                if any(start <= idx < end for idx in test_idx):
                    test_groups.append(group_idx)

            test_group_combinations.append(tuple(sorted(test_groups)))

        # Should have all C(5,2) = 10 combinations
        unique_combinations = set(test_group_combinations)
        assert len(unique_combinations) == 10

        # Verify it matches the expected combinations
        import itertools

        expected_combinations = set(itertools.combinations(range(5), 2))
        assert unique_combinations == expected_combinations

    def test_edge_case_single_test_group(self):
        """Test with single test group (leave-one-group-out style)."""
        X = np.arange(80).reshape(80, 1)
        cv = CombinatorialPurgedCV(n_groups=4, n_test_groups=1)

        splits = list(cv.split(X))
        assert len(splits) == 4  # C(4,1) = 4

        # Each test set should be approximately 1/4 of the data
        for train_idx, test_idx in splits:
            assert 15 <= len(test_idx) <= 25  # Approximately 20 samples per group
            assert 50 <= len(train_idx) <= 70  # Remaining after purging/embargo

    def test_performance_with_large_dataset(self):
        """Test performance characteristics with larger dataset."""
        # This is more of a smoke test to ensure it works with realistic sizes
        n_samples = 2000
        X = np.random.randn(n_samples, 5)

        cv = CombinatorialPurgedCV(
            n_groups=8,
            n_test_groups=2,
            max_combinations=10,  # Limit combinations for speed
            random_state=42,
        )

        splits = list(cv.split(X))
        assert len(splits) == 10

        for train_idx, test_idx in splits:
            # Verify basic properties
            assert len(train_idx) > 0
            assert len(test_idx) > 0
            assert len(set(train_idx) & set(test_idx)) == 0

    def _get_contiguous_ranges(self, indices):
        """Helper to identify contiguous ranges in indices."""
        if len(indices) == 0:
            return []

        indices = sorted(indices)
        ranges = []
        start = indices[0]
        end = indices[0]

        for i in indices[1:]:
            if i == end + 1:
                end = i
            else:
                ranges.append((start, end))
                start = end = i

        ranges.append((start, end))
        return ranges

    def _get_group_starts(self, test_indices):
        """Helper to get start indices of test groups."""
        ranges = self._get_contiguous_ranges(test_indices)
        return [start for start, _ in ranges]

    def _get_group_ends(self, test_indices, n_samples):
        """Helper to get end indices of test groups."""
        ranges = self._get_contiguous_ranges(test_indices)
        return [min(end + 1, n_samples) for _, end in ranges]

    # =====================================================================
    # TASK-005: Additional tests for edge cases, multi-asset, sessions
    # =====================================================================

    def test_empty_data_raises_error(self):
        """Test that empty data raises appropriate error."""
        X = np.array([]).reshape(0, 1)
        cv = CombinatorialPurgedCV(n_groups=4, n_test_groups=1)

        with pytest.raises(ValueError, match="Not enough samples"):
            list(cv.split(X))

    def test_single_group_raises_error(self):
        """Test that single group configuration raises error."""
        np.arange(100).reshape(100, 1)

        # n_test_groups must be < n_groups
        with pytest.raises(ValidationError):
            CombinatorialPurgedCV(n_groups=1, n_test_groups=1)

    def test_zero_samples_per_group_raises_error(self):
        """Test that insufficient samples per group raises error."""
        X = np.arange(3).reshape(3, 1)  # Only 3 samples
        cv = CombinatorialPurgedCV(n_groups=10, n_test_groups=2)

        with pytest.raises(ValueError, match="Not enough samples"):
            list(cv.split(X))

    def test_config_based_initialization(self):
        """Test initialization using CombinatorialPurgedConfig."""
        from ml4t.diagnostic.splitters.config import CombinatorialPurgedConfig

        config = CombinatorialPurgedConfig(
            n_groups=6,
            n_test_groups=2,
            label_horizon=5,
            embargo_td=3,
            max_combinations=10,
        )

        cv = CombinatorialPurgedCV(config=config)

        assert cv.config.n_groups == 6
        assert cv.config.n_test_groups == 2
        assert cv.config.label_horizon == 5
        assert cv.config.embargo_td == 3
        assert cv.config.max_combinations == 10

        X = np.arange(240).reshape(240, 1)
        splits = list(cv.split(X))
        assert len(splits) == 10

    def test_config_conflicts_raise_error(self):
        """Test that providing both config and params raises error."""
        from ml4t.diagnostic.splitters.config import CombinatorialPurgedConfig

        config = CombinatorialPurgedConfig(n_groups=5, n_test_groups=2)

        # Should raise error if non-default params provided with config
        with pytest.raises(ValueError, match="Cannot specify both"):
            CombinatorialPurgedCV(config=config, n_groups=6)

    def test_session_aligned_splitting(self):
        """Test session-aligned splitting (multi-day strategies)."""
        n_days = 20
        samples_per_day = 10
        n_samples = n_days * samples_per_day

        # Create data with session_date column
        dates = pd.date_range("2020-01-01", periods=n_days, freq="D", tz="UTC")
        session_dates = np.repeat(dates, samples_per_day)

        X = pd.DataFrame(
            {
                "feature": np.arange(n_samples),
                "session_date": session_dates,
            }
        )

        cv = CombinatorialPurgedCV(
            n_groups=4,
            n_test_groups=1,
            align_to_sessions=True,
            session_col="session_date",
        )

        splits = list(cv.split(X))
        assert len(splits) == 4  # C(4,1) = 4

        for _train_idx, test_idx in splits:
            # Verify session integrity - all samples from same session stay together
            test_sessions = X.loc[test_idx, "session_date"].unique()

            # Count how many sessions in test set
            assert len(test_sessions) >= 4  # At least 4 days (20/4 groups â‰ˆ 5 days)

            # Verify no partial sessions (all samples from test session are in test)
            for session in test_sessions:
                session_indices = X[X["session_date"] == session].index
                # All indices for this session should be in test set
                assert all(idx in test_idx for idx in session_indices)

    def test_session_aligned_with_polars(self):
        """Test session alignment with Polars DataFrame."""
        n_days = 15
        samples_per_day = 8
        n_samples = n_days * samples_per_day

        # Create Polars DataFrame with session column
        dates = pd.date_range("2020-01-01", periods=n_days, freq="D", tz="UTC")
        session_dates = np.repeat(dates, samples_per_day)

        X = pl.DataFrame(
            {
                "feature": np.arange(n_samples),
                "session_date": session_dates,
            }
        )

        cv = CombinatorialPurgedCV(
            n_groups=3,
            n_test_groups=1,
            align_to_sessions=True,
            session_col="session_date",
        )

        splits = list(cv.split(X))
        assert len(splits) == 3  # C(3,1) = 3

        for train_idx, test_idx in splits:
            assert len(train_idx) > 0
            assert len(test_idx) > 0
            assert len(set(train_idx) & set(test_idx)) == 0

    def test_insufficient_sessions_raises_error(self):
        """Test error when too few sessions for number of groups."""
        X = pd.DataFrame(
            {
                "feature": np.arange(30),
                "session_date": pd.date_range("2020-01-01", periods=30, freq="h", tz="UTC"),
            }
        )

        # Only 30 unique sessions (hours), but want 50 groups
        cv = CombinatorialPurgedCV(
            n_groups=50,
            n_test_groups=5,
            align_to_sessions=True,
            session_col="session_date",
        )

        # Should raise error (either not enough sessions or not enough samples)
        with pytest.raises(ValueError, match="Not enough"):
            list(cv.split(X))

    # Note: Multi-asset purging (asset_col) not yet implemented
    # Tests removed pending TASK-006+ implementation

    def test_performance_benchmark_10k_samples(self):
        """Test performance with 10K samples (should complete in <1 second)."""
        import time

        n_samples = 10000
        X = np.random.randn(n_samples, 10)

        cv = CombinatorialPurgedCV(
            n_groups=8,
            n_test_groups=2,
            max_combinations=5,  # Limit for speed
            random_state=42,
        )

        start_time = time.time()
        splits = list(cv.split(X))
        elapsed = time.time() - start_time

        assert len(splits) == 5
        assert elapsed < 1.0, f"Performance benchmark failed: {elapsed:.3f}s > 1.0s"

    def test_integration_with_real_world_data_shape(self):
        """Test integration with realistic single-asset trading data."""
        # Simulate realistic quant trading data:
        # - Single asset (simplified)
        # - Daily frequency (1 year = 252 trading days)
        # - Multiple features (20 technical indicators)

        n_days = 252
        n_features = 20

        dates = pd.date_range("2020-01-01", periods=n_days, freq="D", tz="UTC")

        # Create dataframe with DatetimeIndex (required for Timedelta purging)
        data_rows = {}
        for i in range(n_features):
            data_rows[f"feature_{i}"] = np.random.randn(n_days)

        X = pd.DataFrame(data_rows, index=dates)

        # Apply realistic CPCV setup
        cv = CombinatorialPurgedCV(
            n_groups=6,
            n_test_groups=2,
            label_horizon=pd.Timedelta("5D"),  # 5-day prediction horizon
            embargo_size=pd.Timedelta("2D"),  # 2-day embargo for serial correlation
            max_combinations=10,
            random_state=42,
        )

        splits = list(cv.split(X))
        assert len(splits) == 10

        # Verify realistic properties
        for train_idx, test_idx in splits:
            # Reasonable train/test split ratios
            train_ratio = len(train_idx) / len(X)
            test_ratio = len(test_idx) / len(X)

            assert 0.15 <= train_ratio <= 0.90  # Broader range for realistic data
            assert 0.05 <= test_ratio <= 0.50  # Broader range

            # No overlap
            assert len(set(train_idx) & set(test_idx)) == 0

    def test_embargo_pct_parameter(self):
        """Test embargo_pct (percentage-based embargo) parameter."""
        X = np.arange(400).reshape(400, 1)

        cv = CombinatorialPurgedCV(
            n_groups=5,
            n_test_groups=2,
            embargo_pct=0.05,  # 5% embargo
        )

        splits = list(cv.split(X))

        for train_idx, test_idx in splits:
            # Calculate expected embargo size (5% of group size)
            group_size = 400 / 5  # = 80 samples per group
            expected_embargo = int(0.05 * group_size)  # = 4 samples

            # Verify embargo is applied
            test_ends = self._get_group_ends(test_idx, 400)

            for test_end in test_ends:
                embargo_end = min(400, test_end + expected_embargo)
                embargoed_samples = set(range(test_end, embargo_end))

                # Training set should not contain embargoed samples
                assert len(set(train_idx) & embargoed_samples) == 0

    def test_coverage_90_percent(self):
        """Meta-test to verify we achieve 90%+ coverage target."""
        # This test doesn't actually test functionality,
        # but serves as a reminder to run coverage checks

        # To verify coverage, run:
        # pytest tests/test_splitters/test_combinatorial.py \
        #     --cov=src/ml4t/evaluation/splitters/combinatorial \
        #     --cov-report=term-missing

        # Expected: Coverage >= 90%
        assert True  # Placeholder - actual coverage verified by pytest-cov


class TestBaseSplitterRegressions:
    """Regression tests for bugs found in code review (Jan 2026).

    These tests verify fixes for bugs identified in:
    - .claude/code_review/260109/combinatorial_review.md
    - .claude/code_review/260109/combinatorial_review_02.md
    """

    def test_validate_data_polars_series_no_type_error(self):
        """Bug: isinstance(y, pl.Series | pd.Series) raises TypeError on Python <3.10.

        The | operator creates a UnionType which is invalid for isinstance() in Python 3.9.
        Python 3.10+ supports this syntax, but for compatibility we must use tuple form:
        isinstance(y, (pl.Series, pd.Series)).
        """
        from ml4t.diagnostic.splitters.base import BaseSplitter

        # Create a concrete splitter for testing
        class TestSplitter(BaseSplitter):
            def split(self, X, y=None, groups=None):
                yield np.array([0]), np.array([1])

            def get_n_splits(self, X=None, y=None, groups=None):
                return 1

        splitter = TestSplitter()

        # Test with Polars Series - should NOT raise TypeError
        X = pl.DataFrame({"a": [1, 2, 3]})
        y_polars = pl.Series("y", [0, 1, 0])
        groups_polars = pl.Series("g", ["A", "A", "B"])

        # This should not raise TypeError
        n_samples = splitter._validate_data(X, y=y_polars, groups=groups_polars)
        assert n_samples == 3

        # Test with Pandas Series
        y_pandas = pd.Series([0, 1, 0])
        groups_pandas = pd.Series(["A", "A", "B"])

        n_samples = splitter._validate_data(X, y=y_pandas, groups=groups_pandas)
        assert n_samples == 3

    def test_session_to_indices_exact_indices(self):
        """Verify _session_to_indices returns exact indices, not ranges."""
        from ml4t.diagnostic.splitters.base import BaseSplitter

        class TestSplitter(BaseSplitter):
            def split(self, X, y=None, groups=None):
                yield np.array([0]), np.array([1])

            def get_n_splits(self, X=None, y=None, groups=None):
                return 1

        splitter = TestSplitter()

        # Interleaved data where sessions are NOT contiguous
        X = pl.DataFrame(
            {
                "session": ["A", "A", "B", "A", "B"],
                "asset": ["X", "Y", "X", "X", "Y"],
            }
        )

        ordered_sessions, session_indices = splitter._session_to_indices(X, "session")

        # Check order
        assert ordered_sessions == ["A", "B"], "Sessions should be in appearance order"

        # Check EXACT indices (not ranges!)
        np.testing.assert_array_equal(session_indices["A"], np.array([0, 1, 3]))
        np.testing.assert_array_equal(session_indices["B"], np.array([2, 4]))

        # Test with Pandas too
        X_pd = pd.DataFrame(
            {
                "session": ["A", "A", "B", "A", "B"],
                "asset": ["X", "Y", "X", "X", "Y"],
            }
        )

        ordered_sessions_pd, session_indices_pd = splitter._session_to_indices(X_pd, "session")

        assert ordered_sessions_pd == ["A", "B"]
        np.testing.assert_array_equal(session_indices_pd["A"], np.array([0, 1, 3]))
        np.testing.assert_array_equal(session_indices_pd["B"], np.array([2, 4]))

    def test_session_order_preserved_not_sorted(self):
        """Bug: _get_unique_sessions sorts by session ID instead of appearance order.

        For session alignment, we need chronological order (order of first appearance),
        not alphabetical/numerical sort of session IDs.
        """
        from ml4t.diagnostic.splitters.base import BaseSplitter

        class TestSplitter(BaseSplitter):
            def split(self, X, y=None, groups=None):
                yield np.array([0]), np.array([1])

            def get_n_splits(self, X=None, y=None, groups=None):
                return 1

        splitter = TestSplitter()

        # Create data where session order differs from sort order
        # Appearance order: C, A, B (first seen at rows 0, 2, 4)
        # Sort order would be: A, B, C
        X = pl.DataFrame(
            {
                "feature": [1, 2, 3, 4, 5, 6],
                "session": ["C", "C", "A", "A", "B", "B"],
            }
        )

        sessions = splitter._get_unique_sessions(X, "session")

        # Should be in appearance order: C, A, B
        expected_order = ["C", "A", "B"]
        actual_order = sessions.to_list()
        assert actual_order == expected_order, (
            f"Sessions should be in appearance order {expected_order}, "
            f"got {actual_order} (likely sorted)"
        )

        # Test with pandas too
        X_pd = pd.DataFrame(
            {
                "feature": [1, 2, 3, 4, 5, 6],
                "session": ["C", "C", "A", "A", "B", "B"],
            }
        )

        sessions_pd = splitter._get_unique_sessions(X_pd, "session")
        actual_order_pd = sessions_pd.to_list()
        assert actual_order_pd == expected_order


class TestSessionAlignmentRegressions:
    """Regression tests for session alignment bugs."""

    def test_interleaved_assets_exact_indices(self):
        """Bug: Session alignment converts indices to (start, end) ranges.

        When assets are interleaved within sessions, range(start, end) includes
        rows from other assets. Must use exact index arrays.
        """
        # Create interleaved data:
        # Row 0: Session 1, Asset A
        # Row 1: Session 1, Asset B
        # Row 2: Session 1, Asset A
        # Row 3: Session 1, Asset B
        # Row 4: Session 2, Asset A
        # Row 5: Session 2, Asset B
        # etc.
        n_sessions = 4
        n_assets = 2
        rows_per_session_per_asset = 3  # Each asset has 3 rows per session

        data = []
        for session_idx in range(n_sessions):
            session_name = f"session_{session_idx}"
            for row_in_session in range(rows_per_session_per_asset * n_assets):
                asset = "A" if row_in_session % 2 == 0 else "B"
                data.append(
                    {
                        "feature": len(data),
                        "session_date": session_name,
                        "asset": asset,
                    }
                )

        X = pd.DataFrame(data)
        # Total: 4 sessions * 6 rows = 24 rows

        cv = CombinatorialPurgedCV(
            n_groups=2,
            n_test_groups=1,
            align_to_sessions=True,
            session_col="session_date",
        )

        for _train_idx, test_idx in cv.split(X):
            # Get the sessions that should be in test set
            test_sessions = X.iloc[test_idx]["session_date"].unique()

            # For each test session, verify ALL rows are included
            for session in test_sessions:
                session_rows = X[X["session_date"] == session].index.tolist()
                missing_rows = set(session_rows) - set(test_idx)

                assert len(missing_rows) == 0, (
                    f"Session {session} has rows {session_rows} but test_idx only "
                    f"contains {sorted(set(session_rows) & set(test_idx))}. "
                    f"Missing: {missing_rows}. "
                    "This bug occurs when indices are converted to range(min, max) "
                    "instead of using exact indices."
                )

            # Also verify NO extra rows from other sessions crept in
            for idx in test_idx:
                row_session = X.iloc[idx]["session_date"]
                assert row_session in test_sessions, (
                    f"Row {idx} has session {row_session} but test set should only "
                    f"contain sessions {list(test_sessions)}. "
                    "This bug occurs when range(start, end) includes rows from "
                    "other sessions that happen to have indices in that range."
                )

    def test_interleaved_assets_polars(self):
        """Same as above but with Polars DataFrame."""
        n_sessions = 4
        n_assets = 2
        rows_per_session_per_asset = 3

        data = {
            "feature": [],
            "session_date": [],
            "asset": [],
        }
        row_count = 0
        for session_idx in range(n_sessions):
            session_name = f"session_{session_idx}"
            for row_in_session in range(rows_per_session_per_asset * n_assets):
                asset = "A" if row_in_session % 2 == 0 else "B"
                data["feature"].append(row_count)
                data["session_date"].append(session_name)
                data["asset"].append(asset)
                row_count += 1

        X = pl.DataFrame(data)

        cv = CombinatorialPurgedCV(
            n_groups=2,
            n_test_groups=1,
            align_to_sessions=True,
            session_col="session_date",
        )

        for _train_idx, test_idx in cv.split(X):
            # Convert to pandas-like access for verification
            test_sessions = X[test_idx]["session_date"].unique().to_list()

            for session in test_sessions:
                session_mask = X["session_date"] == session
                session_rows = [i for i, m in enumerate(session_mask) if m]
                missing_rows = set(session_rows) - set(test_idx)

                assert len(missing_rows) == 0, (
                    f"Session {session} missing rows {missing_rows} in test_idx"
                )


class TestCPCVInvariants:
    """Pre-refactor tests that lock in expected behavior.

    These tests verify invariants that must hold before and after any
    refactoring of the CPCV implementation. Based on code review
    recommendations from .claude/code_review/260112/combinatorial-01.md
    """

    def test_contiguous_single_asset_purging(self):
        """Test purging correctness for contiguous single-asset data.

        Verifies exact indices are removed with known purging parameters.
        """
        n_samples = 100
        n_groups = 5
        n_test_groups = 2
        label_horizon = 2
        embargo_size = 1

        X = pd.DataFrame({"feature": np.arange(n_samples)})
        X["timestamp"] = pd.date_range("2020-01-01", periods=n_samples, freq="D", tz="UTC")

        cv = CombinatorialPurgedCV(
            n_groups=n_groups,
            n_test_groups=n_test_groups,
            label_horizon=label_horizon,
            embargo_size=embargo_size,
            timestamp_col="timestamp",
        )

        for train_idx, test_idx in cv.split(X):
            # Invariant 1: Train and test are disjoint
            overlap = set(train_idx) & set(test_idx)
            assert len(overlap) == 0, f"Train/test overlap: {overlap}"

            # Invariant 2: Union covers less than full dataset (purging removed some)
            all_indices = set(train_idx) | set(test_idx)
            assert len(all_indices) < n_samples, "No indices were purged"

            # Invariant 3: Indices are sorted
            assert np.all(np.diff(train_idx) >= 0), "Train indices not sorted"
            assert np.all(np.diff(test_idx) >= 0), "Test indices not sorted"

            # Invariant 4: Purged region is around test boundaries
            test_min, test_max = test_idx.min(), test_idx.max()
            purged_indices = set(range(n_samples)) - all_indices

            # Each purged index should be within purge window of test set
            for purged_idx in purged_indices:
                near_test = (
                    purged_idx >= test_min - label_horizon - embargo_size
                    and purged_idx <= test_max + embargo_size
                )
                assert near_test, (
                    f"Purged index {purged_idx} not near test range [{test_min}, {test_max}]"
                )

    def test_multi_asset_disjoint_test_groups(self):
        """Test multi-asset purging with disjoint test groups.

        When using isolate_groups=True, assets appearing in test should not
        appear in train. Test uses many assets to ensure isolation is feasible.
        """
        n_samples = 100
        # Use many assets (10) so group isolation doesn't exhaust training data

        # Create multi-asset data with timestamps
        X = pd.DataFrame(
            {
                "feature": np.arange(n_samples),
                "timestamp": pd.date_range("2020-01-01", periods=n_samples, freq="D", tz="UTC"),
            }
        )
        # Each asset appears in 10 consecutive rows (asset_0 in 0-9, asset_1 in 10-19, etc.)
        groups = np.array([f"asset_{i // 10}" for i in range(n_samples)])

        cv = CombinatorialPurgedCV(
            n_groups=5,
            n_test_groups=2,
            label_horizon=1,
            embargo_size=1,
            timestamp_col="timestamp",
            isolate_groups=True,
        )

        for train_idx, test_idx in cv.split(X, groups=groups):
            # Invariant: Each asset in test should not appear in train
            test_assets = set(groups[test_idx])
            train_assets = set(groups[train_idx])

            # With isolate_groups=True, no overlap in assets
            assert test_assets.isdisjoint(train_assets), (
                f"Assets in both train and test: {test_assets & train_assets}"
            )

            # Indices should be sorted
            assert np.all(np.diff(train_idx) >= 0), "Train indices not sorted"
            assert np.all(np.diff(test_idx) >= 0), "Test indices not sorted"

    def test_reproducible_sampling(self):
        """Test that max_combinations with random_state produces stable sequence."""
        X = np.arange(200).reshape(200, 1)

        cv1 = CombinatorialPurgedCV(
            n_groups=8,
            n_test_groups=3,
            max_combinations=10,
            random_state=42,
        )
        cv2 = CombinatorialPurgedCV(
            n_groups=8,
            n_test_groups=3,
            max_combinations=10,
            random_state=42,
        )

        splits1 = list(cv1.split(X))
        splits2 = list(cv2.split(X))

        assert len(splits1) == len(splits2) == 10

        for (train1, test1), (train2, test2) in zip(splits1, splits2):
            np.testing.assert_array_equal(train1, train2)
            np.testing.assert_array_equal(test1, test2)

    def test_different_random_state_different_splits(self):
        """Test that different random_state produces different splits."""
        X = np.arange(200).reshape(200, 1)

        cv1 = CombinatorialPurgedCV(
            n_groups=8,
            n_test_groups=3,
            max_combinations=10,
            random_state=42,
        )
        cv2 = CombinatorialPurgedCV(
            n_groups=8,
            n_test_groups=3,
            max_combinations=10,
            random_state=123,
        )

        splits1 = list(cv1.split(X))
        splits2 = list(cv2.split(X))

        # At least one split should be different
        any_different = False
        for (_train1, test1), (_train2, test2) in zip(splits1, splits2):
            if not np.array_equal(test1, test2):
                any_different = True
                break

        assert any_different, "Different random states produced identical splits"

    def test_deterministic_output_order(self):
        """Test that outputs are deterministic across multiple calls."""
        X = pd.DataFrame(
            {
                "feature": np.arange(100),
                "timestamp": pd.date_range("2020-01-01", periods=100, freq="D", tz="UTC"),
            }
        )

        cv = CombinatorialPurgedCV(
            n_groups=5,
            n_test_groups=2,
            label_horizon=2,
            embargo_size=1,
            timestamp_col="timestamp",
        )

        # Run split twice
        splits1 = list(cv.split(X))
        splits2 = list(cv.split(X))

        assert len(splits1) == len(splits2)

        for (train1, test1), (train2, test2) in zip(splits1, splits2):
            np.testing.assert_array_equal(train1, train2)
            np.testing.assert_array_equal(test1, test2)

            # Verify sorted (deterministic order)
            assert np.all(np.diff(train1) >= 0), "Train not sorted"
            assert np.all(np.diff(test1) >= 0), "Test not sorted"

    def test_session_aligned_exact_indices(self):
        """Test session-aligned mode uses exact indices, not range approximations.

        This verifies that interleaved data within sessions is handled correctly.
        """
        # Create interleaved data: 4 sessions, 2 assets, alternating rows
        data = []
        for session_idx in range(4):
            session_name = f"2020-01-{session_idx + 1:02d}"
            for row in range(6):  # 6 rows per session, alternating A/B
                asset = "A" if row % 2 == 0 else "B"
                data.append(
                    {
                        "feature": len(data),
                        "session_date": session_name,
                        "asset": asset,
                        "timestamp": pd.Timestamp(session_name, tz="UTC") + pd.Timedelta(hours=row),
                    }
                )

        X = pd.DataFrame(data)

        cv = CombinatorialPurgedCV(
            n_groups=2,  # 2 sessions per group
            n_test_groups=1,
            align_to_sessions=True,
            session_col="session_date",
            timestamp_col="timestamp",
            label_horizon=0,
            embargo_size=0,
        )

        for train_idx, test_idx in cv.split(X):
            # Get sessions in test set
            test_sessions = set(X.iloc[test_idx]["session_date"].unique())

            # CRITICAL INVARIANT: Every row from test sessions must be in test_idx
            for session in test_sessions:
                session_rows = X[X["session_date"] == session].index.tolist()
                missing = set(session_rows) - set(test_idx)
                assert len(missing) == 0, (
                    f"Session {session} has rows {session_rows} but "
                    f"test_idx missing {missing}. This indicates range-based "
                    f"indexing instead of exact indices."
                )

            # Verify no test session rows in train
            for session in test_sessions:
                session_rows = X[X["session_date"] == session].index.tolist()
                in_train = set(session_rows) & set(train_idx)
                assert len(in_train) == 0, f"Session {session} rows {in_train} incorrectly in train"

    def test_config_with_random_state(self):
        """Test that random_state can be set via config (Issue: config/random_state API).

        Previously, random_state was not part of config, so users who used config
        could not control sampling reproducibility. This test verifies the fix.
        """
        from ml4t.diagnostic.splitters.config import CombinatorialPurgedConfig

        X = np.arange(200).reshape(200, 1)

        # Create config with random_state
        config = CombinatorialPurgedConfig(
            n_groups=8,
            n_test_groups=3,
            max_combinations=10,
            random_state=42,  # This should now work
        )

        cv1 = CombinatorialPurgedCV(config=config)
        cv2 = CombinatorialPurgedCV(config=config)

        splits1 = list(cv1.split(X))
        splits2 = list(cv2.split(X))

        assert len(splits1) == len(splits2) == 10

        for (train1, test1), (train2, test2) in zip(splits1, splits2):
            np.testing.assert_array_equal(train1, train2)
            np.testing.assert_array_equal(test1, test2)

    def test_random_state_param_overrides_config(self):
        """Test that random_state parameter overrides config.random_state."""
        from ml4t.diagnostic.splitters.config import CombinatorialPurgedConfig

        config = CombinatorialPurgedConfig(
            n_groups=8,
            n_test_groups=3,
            max_combinations=10,
            random_state=42,
        )

        # Parameter should override config
        cv = CombinatorialPurgedCV(config=config, random_state=123)
        assert cv.random_state == 123

    def test_heterogeneous_type_defaults(self):
        """Test that semantically equivalent defaults don't trigger conflicts.

        Issue 2.5: pd.Timedelta(0) should be treated as equivalent to 0 for
        label_horizon, and np.int64(0) should equal 0.
        """
        from ml4t.diagnostic.splitters.config import CombinatorialPurgedConfig

        config = CombinatorialPurgedConfig(n_groups=5, n_test_groups=2)

        # These should NOT raise - they're semantically equivalent to defaults
        cv1 = CombinatorialPurgedCV(config=config, label_horizon=pd.Timedelta(0))
        assert cv1.label_horizon == 0  # Config value

        cv2 = CombinatorialPurgedCV(config=config, label_horizon=np.int64(0))
        assert cv2.label_horizon == 0  # Config value

        # Verify that non-zero values still trigger conflict
        with pytest.raises(ValueError, match="Cannot specify both 'config'"):
            CombinatorialPurgedCV(config=config, label_horizon=5)
