#!/usr/bin/env python3
"""
Tests de casos complejos para probar los l√≠mites del sistema de roles y la validaci√≥n de mensajes.
"""
import os
from dotenv import load_dotenv

# Cargar variables de entorno desde .env
load_dotenv()

try:
    import colmena
    print("‚úì M√≥dulo colmena importado correctamente")
except ImportError as e:
    print(f"‚úó Error importando colmena: {e}")
    exit(1)

# --- Test Configuration ---
# Usamos un modelo r√°pido y econ√≥mico para las pruebas.
GEMINI_PROVIDER = "gemini"
GEMINI_MODEL = "gemini-2.5-flash"
OPENAI_PROVIDER = "openai"
OPENAI_MODEL = "gpt-4o-mini"
ANTHROPIC_PROVIDER = "anthropic"
ANTHROPIC_MODEL = "claude-3-haiku-20240307"


# --- Role & Message Validation Tests ---

def test_valid_alternating_conversation_succeeds():
    """Test a valid conversation with alternating user/assistant roles succeeds."""
    llm = colmena.ColmenaLlm()
    messages = [
        {"role": "system", "content": "eres un asistente que responde conciso"},
        {"role": "user", "content": "Hola"},
        {"role": "assistant", "content": "Hola, ¬øc√≥mo puedo ayudarte?"},
        {"role": "user", "content": "¬øQu√© es Rust?"},
    ]
    try:
        options = colmena.LlmConfigOptions()
        options.model = GEMINI_MODEL
        options.max_tokens = 400
        response = llm.call(messages=messages, provider=GEMINI_PROVIDER, options=options)
        print(f"‚úÖ PASSED: Valid alternating conversation succeeded. Response: '{response[:50]}...'")
        return True
    except Exception as e:
        print(f"‚ùå FAILED: Valid conversation failed unexpectedly with: {e}")
        return False

def test_consecutive_user_messages_fails():
    """Test that consecutive user messages fail validation."""
    llm = colmena.ColmenaLlm()
    messages = [
        {"role": "user", "content": "Expl√≠came qu√© es una funci√≥n matem√°tica"},
        {"role": "user", "content": "Dame un ejemplo simple"}
    ]
    try:
        options = colmena.LlmConfigOptions()
        options.model = GEMINI_MODEL
        options.max_tokens = 400
        llm.call(messages=messages, provider=GEMINI_PROVIDER, options=options)
        print("‚ùå FAILED: Consecutive user messages did not raise an exception.")
        return False
    except colmena.LlmException as e:
        assert "Consecutive messages" in str(e)
        print(f"‚úÖ PASSED: Consecutive user messages correctly failed with: {e}")
        return True
    except Exception as e:
        print(f"‚ùå FAILED: An unexpected error occurred: {e}")
        return False

def test_consecutive_assistant_messages_fails():
    """Test that consecutive assistant messages fail validation."""
    llm = colmena.ColmenaLlm()
    messages = [
        {"role": "user", "content": "Hola"},
        {"role": "assistant", "content": "Hola, ¬øc√≥mo puedo ayudarte?"},
        {"role": "assistant", "content": "Estoy aqu√≠ para servirte."}
    ]
    try:
        options = colmena.LlmConfigOptions()
        options.model = GEMINI_MODEL
        options.max_tokens = 400
        llm.call(messages=messages, provider=GEMINI_PROVIDER, options=options)
        print("‚ùå FAILED: Consecutive assistant messages did not raise an exception.")
        return False
    except colmena.LlmException as e:
        assert "Consecutive messages" in str(e)
        print(f"‚úÖ PASSED: Consecutive assistant messages correctly failed with: {e}")
        return True
    except Exception as e:
        print(f"‚ùå FAILED: An unexpected error occurred: {e}")
        return False

def test_multiple_system_messages_succeeds():
    """Test that multiple consecutive system messages are allowed and ignored by validation."""
    llm = colmena.ColmenaLlm()
    messages = [
        {"role": "system", "content": "Siempre responde en ingles."},
        {"role": "system", "content": "Explica conceptos de forma simple."},
        {"role": "user", "content": "¬øQu√© es una variable en programaci√≥n?"},
    ]
    try:
        options = colmena.LlmConfigOptions()
        options.model = GEMINI_MODEL
        options.max_tokens = 400
        llm.call(messages=messages, provider=GEMINI_PROVIDER, options=options)
        return False
    except Exception as e:
        print(f"‚úÖ PASSED: Consecutive system messages correctly failed with: {e}")
        return True

def test_missing_role_key_fails():
    """Test that a message with a missing 'role' key fails validation."""
    llm = colmena.ColmenaLlm()
    messages = [{"content": "hola"}]
    try:
        options = colmena.LlmConfigOptions()
        options.model = GEMINI_MODEL
        options.max_tokens = 400
        llm.call(messages=messages, provider=GEMINI_PROVIDER, options=options)
        print("‚ùå FAILED: Missing 'role' key did not raise an exception.")
        return False
    except colmena.LlmException as e:
        assert "Missing 'role' key" in str(e)
        print(f"‚úÖ PASSED: Missing 'role' key correctly failed with: {e}")
        return True
    except Exception as e:
        print(f"‚ùå FAILED: An unexpected error occurred: {e}")
        return False

def test_missing_content_key_fails():
    """Test that a message with a missing 'content' key fails validation."""
    llm = colmena.ColmenaLlm()
    messages = [{"role": "user"}]
    try:
        options = colmena.LlmConfigOptions()
        options.model = GEMINI_MODEL
        options.max_tokens = 400
        llm.call(messages=messages, provider=GEMINI_PROVIDER, options=options)
        print("‚ùå FAILED: Missing 'content' key did not raise an exception.")
        return False
    except colmena.LlmException as e:
        assert "Missing 'content' key" in str(e)
        print(f"‚úÖ PASSED: Missing 'content' key correctly failed with: {e}")
        return True
    except Exception as e:
        print(f"‚ùå FAILED: An unexpected error occurred: {e}")
        return False

def test_openai_valid_call_succeeds():
    """Test a valid call to OpenAI succeeds."""
    if not os.getenv("OPENAI_API_KEY"):
        print("\n‚ö†Ô∏è SKIPPED: OPENAI_API_KEY not set. Skipping OpenAI test.")
        return True  # Skip test if key is not set

    llm = colmena.ColmenaLlm()
    messages = [
        {"role": "system", "content": "You are an assistant that provides short answers."},
        {"role": "user", "content": "What is the capital of France?"},
    ]
    try:
        options = colmena.LlmConfigOptions()
        options.model = OPENAI_MODEL
        options.max_tokens = 4000
        response = llm.call(messages=messages, provider=OPENAI_PROVIDER, options=options)
        assert response.strip(), "Response content should not be empty."
        print(f"‚úÖ PASSED: OpenAI valid call succeeded. Response: '{response}'")
        return True
    except Exception as e:
        print(f"‚ùå FAILED: OpenAI valid call failed unexpectedly with: {e}")
        return False

def test_anthropic_valid_call_succeeds():
    """Test a valid call to Anthropic succeeds."""
    if not os.getenv("ANTHROPIC_API_KEY"):
        print("\n‚ö†Ô∏è SKIPPED: ANTHROPIC_API_KEY not set. Skipping Anthropic test.")
        return True

    llm = colmena.ColmenaLlm()
    messages = [
        {"role": "user", "content": "What are the primary colors?"},
    ]
    try:
        options = colmena.LlmConfigOptions()
        options.model = ANTHROPIC_MODEL
        options.max_tokens = 100
        response = llm.call(messages=messages, provider=ANTHROPIC_PROVIDER, options=options)
        assert response.strip(), "Response content should not be empty."
        print(f"‚úÖ PASSED: Anthropic valid call succeeded. Response: '{response}'")
        return True
    except Exception as e:
        print(f"‚ùå FAILED: Anthropic valid call failed unexpectedly with: {e}")
        return False

if __name__ == "__main__":
    # Check for API key to provide a better error message
    if not os.getenv("GEMINI_API_KEY"):
        print("\n‚ÄºÔ∏è  WARNING: GEMINI_API_KEY environment variable not set.")
        print("\n    The Gemini tests will likely fail. Please create a .env file with your key.")
        print("-" * 60)
    
    if not os.getenv("OPENAI_API_KEY"):
        print("\n‚ÄºÔ∏è  WARNING: OPENAI_API_KEY environment variable not set.")
        print("\n    The OpenAI tests will be skipped. Please create a .env file with your key.")
        print("-" * 60)

    if not os.getenv("ANTHROPIC_API_KEY"):
        print("\n‚ÄºÔ∏è  WARNING: ANTHROPIC_API_KEY environment variable not set.")
        print("\n    The Anthropic tests will be skipped. Please create a .env file with your key.")
        print("-" * 60)

    print("üß™ Role and Message Validation Testing")
    print("="*60)

    tests = [
        test_valid_alternating_conversation_succeeds,
        test_consecutive_user_messages_fails,
        test_consecutive_assistant_messages_fails,
        test_missing_role_key_fails,
        test_multiple_system_messages_succeeds,
        test_missing_content_key_fails,
        test_openai_valid_call_succeeds,
        test_anthropic_valid_call_succeeds,
    ]

    passed = 0
    total = len(tests)

    for test_func in tests:
        print(f"\nüìã Running {test_func.__name__}")
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"‚ùå Test {test_func.__name__} crashed: {e}")

    print(f"\nüéØ Results: {passed}/{total} tests passed")
    print("="*60)

    if passed != total:
        exit(1)
