# üîß Gu√≠a de Soluci√≥n de Problemas - Colmena

Esta gu√≠a te ayudar√° a resolver los problemas m√°s comunes al compilar, instalar y usar Colmena.

## üìã Tabla de Contenidos

- [Problemas de Instalaci√≥n](#problemas-de-instalaci√≥n)
- [Problemas de Compilaci√≥n](#problemas-de-compilaci√≥n)
- [Problemas de Ejecuci√≥n](#problemas-de-ejecuci√≥n)
- [Problemas con API Keys](#problemas-con-api-keys)
- [Problemas de Performance](#problemas-de-performance)
- [Diagn√≥stico Avanzado](#diagn√≥stico-avanzado)
- [Obtener Ayuda](#obtener-ayuda)

## üö® Diagn√≥stico R√°pido

Antes de buscar soluciones espec√≠ficas, ejecuta este script de diagn√≥stico:

```python
# quick_diagnosis.py
import sys
import subprocess
import platform

def run_cmd(cmd):
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.returncode == 0, result.stdout.strip(), result.stderr.strip()
    except:
        return False, "", "Command failed"

def quick_diagnosis():
    print("üîç DIAGN√ìSTICO R√ÅPIDO DE COLMENA")
    print("=" * 50)

    # Informaci√≥n del sistema
    print(f"üñ•Ô∏è  Sistema: {platform.system()} {platform.release()}")
    print(f"üêç Python: {sys.version}")

    # Verificar componentes clave
    checks = [
        ("Rust", "rustc --version"),
        ("Cargo", "cargo --version"),
        ("Maturin", "maturin --version"),
        ("Git", "git --version")
    ]

    for name, cmd in checks:
        success, output, error = run_cmd(cmd)
        status = "‚úÖ" if success else "‚ùå"
        print(f"{status} {name}: {output if success else 'NO ENCONTRADO'}")

    # Verificar Colmena
    try:
        import colmena
        print(f"‚úÖ Colmena: Importado correctamente desde {colmena.__file__}")

        llm = colmena.ColmenaLlm()
        print(f"‚úÖ ColmenaLlm: Inicializado correctamente")
    except Exception as e:
        print(f"‚ùå Colmena: Error - {e}")

    print("\n" + "=" * 50)

quick_diagnosis()
```

## üõ†Ô∏è Problemas de Instalaci√≥n

### Error: "Command 'rustc' not found"

**S√≠ntomas:**
```bash
bash: rustc: command not found
```

**Soluci√≥n:**

```bash
# 1. Instalar Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# 2. Reinicializar shell
source ~/.bashrc
# o
source ~/.zshrc

# 3. Verificar instalaci√≥n
rustc --version
```

**Soluci√≥n alternativa (Windows):**
1. Descargar Rust desde https://rustup.rs/
2. Ejecutar instalador como administrador
3. Reiniciar terminal

### Error: "Microsoft Visual C++ 14.0 is required" (Windows)

**S√≠ntomas:**
```
error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual Studio Build Tools"
```

**Soluci√≥n M√©todo 1 (Recomendado):**
```powershell
# Instalar con chocolatey
Set-ExecutionPolicy Bypass -Scope Process -Force
iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))
choco install visualstudio2022buildtools --package-parameters "--add Microsoft.VisualStudio.Workload.VCTools" -y
```

**Soluci√≥n M√©todo 2 (Manual):**
1. Ir a https://visualstudio.microsoft.com/visual-cpp-build-tools/
2. Descargar "Build Tools for Visual Studio 2022"
3. Ejecutar instalador
4. Seleccionar "C++ build tools" y "Windows 10 SDK"
5. Instalar y reiniciar

### Error: "python3-dev not found" (Linux)

**S√≠ntomas:**
```bash
Package python3-dev is not available
```

**Soluci√≥n Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install python3-dev python3-pip build-essential
```

**Soluci√≥n CentOS/RHEL/Fedora:**
```bash
# CentOS/RHEL
sudo dnf install python3-devel python3-pip gcc gcc-c++

# Fedora
sudo dnf install python3-devel python3-pip @development-tools
```

### Error: "maturin: command not found"

**S√≠ntomas:**
```bash
bash: maturin: command not found
```

**Soluci√≥n:**
```bash
# Verificar que el entorno virtual est√° activado
source venv/bin/activate

# Instalar maturin
pip install --upgrade pip
pip install maturin

# Verificar instalaci√≥n
maturin --version
```

## ‚öôÔ∏è Problemas de Compilaci√≥n

### Error: "failed to compile `colmena`"

**S√≠ntomas:**
```
error[E0433]: failed to resolve: use of undeclared crate or module `tokio`
```

**Soluci√≥n:**
```bash
# 1. Limpiar cach√© de compilaci√≥n
cargo clean
rm -rf target/

# 2. Actualizar dependencias
cargo update

# 3. Verificar Cargo.toml
cat Cargo.toml  # Verificar que todas las dependencias est√°n presentes

# 4. Recompilar
cargo build --release
```

### Error: "PyO3 compilation failed"

**S√≠ntomas:**
```
error: failed to run custom build command for `pyo3-ffi`
```

**Soluci√≥n:**
```bash
# 1. Verificar versi√≥n de Python (debe ser 3.8+)
python --version

# 2. Reinstalar PyO3 dependencies
pip uninstall maturin
pip install --upgrade pip setuptools wheel
pip install maturin

# 3. Limpiar y recompilar
cargo clean
maturin develop --release
```

### Error: "linking with `cc` failed"

**S√≠ntomas:**
```
error: linking with `cc` failed: exit status: 1
...
Undefined symbols for architecture arm64:
  "_PyBaseObject_Type", referenced from:
```

**Causa:**
Este error ocurre cuando se intenta compilar el proyecto con `cargo build` directamente. `cargo` no sabe d√≥nde encontrar las librer√≠as de Python para enlazarlas, por lo que falla.

**Soluci√≥n:**
Usa `maturin` para compilar el proyecto. `maturin` se encarga de pasar las banderas correctas al compilador de Rust.

```bash
# Para desarrollo
maturin develop

# Para producci√≥n
maturin build --release
```

### Error: "cargo: permission denied"

**S√≠ntomas:**
```bash
cargo: permission denied
```

**Soluci√≥n:**
```bash
# Cambiar ownership del directorio
sudo chown -R $USER:$USER ~/.cargo
sudo chown -R $USER:$USER ./target

# O cambiar a directorio con permisos
cd ~/
git clone <repo-url> colmena_nuevo
cd colmena_nuevo
```

## üèÉ Problemas de Ejecuci√≥n

### Error: "No module named 'colmena'"

**S√≠ntomas:**
```python
ModuleNotFoundError: No module named 'colmena'
```

**Diagn√≥stico:**
```python
# Verificar instalaci√≥n
import sys
print("Python path:")
for path in sys.path:
    print(f"  {path}")

# Verificar entorno virtual
import os
print(f"Virtual env: {os.environ.get('VIRTUAL_ENV', 'NONE')}")
```

**Soluci√≥n:**
```bash
# 1. Verificar que el entorno virtual est√° activado
source venv/bin/activate

# 2. Verificar que maturin fue ejecutado
maturin develop --release

# 3. Verificar instalaci√≥n
python -c "import colmena; print('OK')"

# 4. Si falla, reinstalar
pip uninstall colmena
maturin develop --release
```

### Error: "LlmException: Network error"

**S√≠ntomas:**
```python
colmena.LlmException: Network error: connection failed
```

**Diagn√≥stico:**
```python
# Test de conectividad
import requests

apis = {
    "OpenAI": "https://api.openai.com/v1/models",
    "Gemini": "https://generativelanguage.googleapis.com/v1beta/models",
    "Anthropic": "https://api.anthropic.com/v1/messages"
}

for name, url in apis.items():
    try:
        response = requests.get(url, timeout=10)
        print(f"‚úÖ {name}: Conectividad OK ({response.status_code})")
    except Exception as e:
        print(f"‚ùå {name}: Error - {e}")
```

**Soluci√≥n:**
```bash
# 1. Verificar conexi√≥n a internet
ping google.com

# 2. Verificar proxy/firewall
curl -I https://api.openai.com/v1/models

# 3. Configurar proxy si es necesario
export HTTP_PROXY=http://proxy:port
export HTTPS_PROXY=http://proxy:port

# 4. Verificar DNS
nslookup api.openai.com
```

### Error: "Segmentation fault" al importar

**S√≠ntomas:**
```bash
Segmentation fault (core dumped)
```

**Soluci√≥n:**
```bash
# 1. Verificar arquitectura
uname -m
python -c "import platform; print(platform.machine())"

# 2. Recompilar para arquitectura espec√≠fica
rustup target add x86_64-unknown-linux-gnu
cargo build --target x86_64-unknown-linux-gnu --release

# 3. Verificar versiones compatibles
python --version
rustc --version

# 4. Reinstalar desde cero
rm -rf venv/ target/
python3 -m venv venv
source venv/bin/activate
pip install maturin
cargo clean
maturin develop --release
```

## üîë Problemas con API Keys

### Error: "Invalid API key"

**S√≠ntomas:**
```python
colmena.LlmException: Request failed: Invalid API key
```

**Diagn√≥stico:**
```python
# test_api_keys.py
import os
import requests

def test_openai_key(api_key):
    headers = {"Authorization": f"Bearer {api_key}"}
    response = requests.get("https://api.openai.com/v1/models", headers=headers)
    return response.status_code == 200

def test_gemini_key(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    response = requests.get(url)
    return response.status_code == 200

def test_anthropic_key(api_key):
    headers = {
        "x-api-key": api_key,
        "Content-Type": "application/json",
        "anthropic-version": "2023-06-01"
    }
    # Test con request m√≠nimo
    data = {
        "model": "claude-3-sonnet-20240229",
        "max_tokens": 1,
        "messages": [{"role": "user", "content": "Hi"}]
    }
    response = requests.post("https://api.anthropic.com/v1/messages",
                           headers=headers, json=data)
    return response.status_code in [200, 400]  # 400 es OK (formato del request)

# Probar keys
keys = {
    "OpenAI": os.getenv("OPENAI_API_KEY", "tu-openai-key"),
    "Gemini": os.getenv("GEMINI_API_KEY", "tu-gemini-key"),
    "Anthropic": os.getenv("ANTHROPIC_API_KEY", "tu-anthropic-key")
}

tests = {
    "OpenAI": test_openai_key,
    "Gemini": test_gemini_key,
    "Anthropic": test_anthropic_key
}

for provider, key in keys.items():
    if key and key != f"tu-{provider.lower()}-key":
        result = tests[provider](key)
        status = "‚úÖ" if result else "‚ùå"
        print(f"{status} {provider}: {'V√°lida' if result else 'Inv√°lida'}")
    else:
        print(f"‚ö†Ô∏è  {provider}: No configurada")
```

**Soluci√≥n:**
1. **Verificar formato de API key:**
   - OpenAI: `sk-...` (comienza con sk-)
   - Gemini: `AIza...` (comienza con AIza)
   - Anthropic: `sk-ant-...` (comienza con sk-ant-)

2. **Regenerar API key:**
   - OpenAI: https://platform.openai.com/api-keys
   - Gemini: https://makersuite.google.com/app/apikey
   - Anthropic: https://console.anthropic.com/

3. **Verificar permisos y l√≠mites:**
   - Cuenta activa y con cr√©ditos
   - API key con permisos correctos
   - No exceder rate limits

### Error: "Rate limit exceeded"

**S√≠ntomas:**
```python
colmena.LlmException: Request failed: Rate limit exceeded
```

**Soluci√≥n con Retry Autom√°tico:**
```python
import time
import random

def call_with_retry(llm, messages, provider, api_key, max_retries=5):
    """Llamada con retry autom√°tico para rate limits"""

    for attempt in range(max_retries):
        try:
            return llm.call(messages=messages, provider=provider, api_key=api_key)

        except colmena.LlmException as e:
            if "rate limit" in str(e).lower() and attempt < max_retries - 1:
                # Backoff exponencial con jitter
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"‚è≥ Rate limit alcanzado, esperando {wait_time:.1f}s...")
                time.sleep(wait_time)
                continue
            else:
                raise

# Uso
llm = colmena.ColmenaLlm()
response = call_with_retry(llm, ["Test"], "openai", "tu-api-key")
```

## üêå Problemas de Performance

### Llamadas muy lentas

**Diagn√≥stico:**
```python
import time
import colmena

def benchmark_call():
    llm = colmena.ColmenaLlm()

    # Test simple
    start = time.time()
    response = llm.call(
        messages=["Hi"],
        provider="gemini",
        api_key="tu-api-key"
    )
    total_time = time.time() - start

    print(f"‚è±Ô∏è  Tiempo total: {total_time:.2f}s")
    print(f"üìä Caracteres/segundo: {len(response) / total_time:.1f}")

    if total_time > 10:
        print("‚ö†Ô∏è  Llamada muy lenta (>10s)")
    elif total_time > 5:
        print("‚ö†Ô∏è  Llamada lenta (>5s)")
    else:
        print("‚úÖ Velocidad normal")

benchmark_call()
```

**Soluciones:**
1. **Optimizar par√°metros:**
   ```python
   # Reducir max_tokens para respuestas m√°s r√°pidas
   response = llm.call(
       messages=["Respuesta corta por favor"],
       provider="gemini",
       max_tokens=100,  # L√≠mite bajo
       api_key="tu-api-key"
   )
   ```

2. **Usar modelos m√°s r√°pidos:**
   ```python
   # Modelos m√°s r√°pidos por proveedor
   fast_models = {
       "openai": "gpt-3.5-turbo",      # M√°s r√°pido que gpt-4
       "gemini": "gemini-1.5-flash",   # M√°s r√°pido que gemini-pro
       "anthropic": "claude-3-haiku-20240307"  # M√°s r√°pido que sonnet
   }
   ```

3. **Implementar timeout:**
   ```python
   import signal

   def call_with_timeout(llm, messages, provider, api_key, timeout=30):
       def timeout_handler(signum, frame):
           raise TimeoutError("Llamada excedi√≥ el timeout")

       signal.signal(signal.SIGALRM, timeout_handler)
       signal.alarm(timeout)

       try:
           response = llm.call(messages=messages, provider=provider, api_key=api_key)
           signal.alarm(0)  # Cancelar timeout
           return response
       except TimeoutError:
           print(f"‚è∞ Timeout despu√©s de {timeout}s")
           raise
   ```

### Memoria excesiva

**Diagn√≥stico:**
```python
import psutil
import os

def monitor_memory():
    process = psutil.Process(os.getpid())

    # Memoria antes
    mem_before = process.memory_info().rss / 1024 / 1024  # MB
    print(f"üß† Memoria antes: {mem_before:.1f} MB")

    # Crear m√∫ltiples instancias (test de leak)
    llms = []
    for i in range(10):
        llm = colmena.ColmenaLlm()
        llms.append(llm)

    # Memoria despu√©s
    mem_after = process.memory_info().rss / 1024 / 1024  # MB
    print(f"üß† Memoria despu√©s: {mem_after:.1f} MB")
    print(f"üìà Incremento: {mem_after - mem_before:.1f} MB")

    # Limpiar
    del llms

monitor_memory()
```

**Soluciones:**
1. **Reutilizar instancias:**
   ```python
   # ‚ùå Malo: crear nueva instancia cada vez
   def bad_usage():
       llm = colmena.ColmenaLlm()  # Nueva instancia
       return llm.call(...)

   # ‚úÖ Bueno: reutilizar instancia
   class MyApp:
       def __init__(self):
           self.llm = colmena.ColmenaLlm()  # Una sola instancia

       def process(self, messages):
           return self.llm.call(...)
   ```

2. **Implementar pool de conexiones:**
   ```python
   class LlmPool:
       def __init__(self, size=3):
           self.llms = [colmena.ColmenaLlm() for _ in range(size)]
           self.index = 0

       def get_llm(self):
           llm = self.llms[self.index]
           self.index = (self.index + 1) % len(self.llms)
           return llm

   # Uso
   pool = LlmPool()
   response = pool.get_llm().call(...)
   ```

## üîç Diagn√≥stico Avanzado

### Habilitar Debug Logging

```python
import logging
import colmena

# Configurar logging detallado
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Activar logs de requests HTTP
import urllib3
urllib3.disable_warnings()
logging.getLogger("urllib3").setLevel(logging.DEBUG)

# Ahora las llamadas mostrar√°n informaci√≥n detallada
llm = colmena.ColmenaLlm()
response = llm.call(["Debug test"], "gemini", api_key="tu-api-key")
```

### Verificar Bindings Nativos

```python
import inspect
import colmena

def verify_native_bindings():
    """Verificar que estamos usando c√≥digo Rust nativo"""

    llm = colmena.ColmenaLlm()

    # Verificar tipo de m√©todos
    print(f"Tipo de ColmenaLlm: {type(llm)}")
    print(f"Tipo de m√©todo call: {type(llm.call)}")
    print(f"Tipo de m√©todo stream: {type(llm.stream)}")

    # Intentar obtener c√≥digo fuente (deber√≠a fallar para c√≥digo nativo)
    try:
        source = inspect.getsource(llm.call)
        print("‚ùå WARNING: M√©todo call() tiene c√≥digo Python visible")
        print(source)
    except (OSError, TypeError) as e:
        print(f"‚úÖ M√©todo call() es nativo: {type(e).__name__}")

    # Verificar m√≥dulo compilado
    print(f"Archivo del m√≥dulo: {colmena.__file__}")
    if colmena.__file__.endswith('.so') or colmena.__file__.endswith('.pyd'):
        print("‚úÖ M√≥dulo compilado detectado")
    else:
        print("‚ö†Ô∏è  M√≥dulo no parece estar compilado")

verify_native_bindings()
```

### Test de Stress

```python
import threading
import time
import colmena

def stress_test():
    """Test de stress para detectar problemas de concurrencia"""

    llm = colmena.ColmenaLlm()
    errors = []
    responses = []

    def worker(thread_id):
        try:
            response = llm.call(
                messages=[f"Thread {thread_id} test"],
                provider="gemini",
                api_key="tu-api-key"
            )
            responses.append(f"Thread {thread_id}: OK")
        except Exception as e:
            errors.append(f"Thread {thread_id}: {e}")

    # Crear m√∫ltiples threads
    threads = []
    for i in range(5):
        thread = threading.Thread(target=worker, args=(i,))
        threads.append(thread)

    # Ejecutar en paralelo
    start_time = time.time()
    for thread in threads:
        thread.start()

    for thread in threads:
        thread.join()

    total_time = time.time() - start_time

    print(f"‚è±Ô∏è  Tiempo total: {total_time:.2f}s")
    print(f"‚úÖ √âxitos: {len(responses)}")
    print(f"‚ùå Errores: {len(errors)}")

    if errors:
        print("\nErrores encontrados:")
        for error in errors:
            print(f"  {error}")

# stress_test()  # Descomenta para ejecutar
```

## üìû Obtener Ayuda

### Informaci√≥n para Reportar Bugs

Cuando reportes un problema, incluye:

```python
# bug_report.py
import sys
import platform
import colmena

def generate_bug_report():
    """Generar reporte completo para debugging"""

    print("üêõ REPORTE DE BUG - COLMENA")
    print("=" * 50)

    # Informaci√≥n del sistema
    print("üñ•Ô∏è  SISTEMA:")
    print(f"   OS: {platform.system()} {platform.release()}")
    print(f"   Arquitectura: {platform.machine()}")
    print(f"   Python: {sys.version}")

    # Informaci√≥n de Colmena
    print("\nüêù COLMENA:")
    try:
        print(f"   Archivo: {colmena.__file__}")
        print(f"   Tipo: {type(colmena.ColmenaLlm())}")

        # M√©todos disponibles
        llm = colmena.ColmenaLlm()
        methods = [m for m in dir(llm) if not m.startswith('_')]
        print(f"   M√©todos: {methods}")

    except Exception as e:
        print(f"   Error: {e}")

    # Dependencias
    print("\nüì¶ DEPENDENCIAS:")
    deps = ["maturin", "requests", "setuptools"]
    for dep in deps:
        try:
            module = __import__(dep)
            version = getattr(module, '__version__', 'unknown')
            print(f"   {dep}: {version}")
        except ImportError:
            print(f"   {dep}: NO INSTALADO")

    print("\n" + "=" * 50)
    print("üìß Incluye esta informaci√≥n al reportar el bug")

generate_bug_report()
```

### Canales de Soporte

1. **Documentaci√≥n**: Lee primero esta gu√≠a completa
2. **Issues GitHub**: Reporta bugs espec√≠ficos con informaci√≥n completa
3. **Discusiones**: Para preguntas generales y casos de uso
4. **Email**: Solo para problemas cr√≠ticos de seguridad

### Template para Issues

```markdown
## üêõ Descripci√≥n del Problema

Descripci√≥n clara del problema...

## üîÑ Pasos para Reproducir

1. Paso 1...
2. Paso 2...
3. Error aparece...

## üíª Informaci√≥n del Sistema

- OS: [Ubuntu 20.04 / macOS 12 / Windows 11]
- Python: [3.9.7]
- Rust: [1.75.0]
- Colmena: [versi√≥n]

## üìã C√≥digo que Falla

```python
# C√≥digo m√≠nimo que reproduce el error
import colmena
llm = colmena.ColmenaLlm()
# ... resto del c√≥digo
```

## üìÑ Output/Error Completo

```
Error completo aqu√≠...
```

## üîç Informaci√≥n Adicional

Cualquier informaci√≥n adicional relevante...
```

---

**üêù Colmena** - *Solucionando problemas juntos*

> üí° **Tip**: La mayor√≠a de problemas se resuelven limpiando cach√© (`cargo clean`) y recompilando (`maturin develop --release`)