# ðŸš€ GuÃ­a de Desarrollo: `dag_engine`

Este documento describe la arquitectura y el proceso de desarrollo para el `dag_engine`, un motor de ejecuciÃ³n de Grafos AcÃ­clicos Dirigidos (DAG) extensible, implementado en Rust y basado en una arquitectura hexagonal limpia.

## ðŸš€ Conceptos Clave

El motor estÃ¡ diseÃ±ado para ejecutar un DAG definido en un fichero JSON.

### El Fichero `graph.json`

Este fichero JSON es el "cÃ³digo fuente" para el motor. Define tres elementos clave:

1.  **`nodes`**: Un mapa de todas las operaciones en el grafo. Cada nodo tiene un ID Ãºnico (ej. `"start_data"`, `"add_step"`) y define:
    *   **`type`**: Un string (ej. `"add"`, `"log"`, `"http_request"`, `"llm_call"`) que se mapea a una implementaciÃ³n especÃ­fica en Rust.
    *   **`config`**: Un objeto JSON para valores estÃ¡ticos que el nodo necesita (ej. un exponente, un prompt, una URL, un API key).

2.  **`edges`**: Una lista de conexiones que definen el flujo de datos.
    *   **`from`**: El origen de los datos, usando una sintaxis similar a JSON-pointer (ej. `"node_id.field_a"` o `"node_id.output"`).
    *   **`to`**: El destino de los datos (ej. `"other_node.input_b"`).

### Flujo de Datos

- El motor ejecuta los nodos en un orden determinado por un **ordenamiento topolÃ³gico**.
- La salida de un nodo se pasa a la entrada del siguiente, segÃºn lo definido en los `edges`.
- Todos los nodos estÃ¡ndar (matemÃ¡ticos, de log, etc.) deben devolver su resultado envuelto en una clave `output`, por ejemplo: `{ "output": 75.0 }`.
- Los nodos raÃ­z (como `mock_input` o `trigger_webhook`) son especiales y emiten su objeto de datos como salida.

### ConfiguraciÃ³n DinÃ¡mica

**Novedad**: Todos los nodos ahora soportan **configuraciÃ³n dinÃ¡mica**, donde los valores de `inputs` tienen prioridad sobre los valores de `config`. Esto permite que los nodos se configuren dinÃ¡micamente en tiempo de ejecuciÃ³n basÃ¡ndose en las salidas de nodos anteriores.

**Ejemplo**: El `HttpNode` puede recibir el `endpoint` desde el nodo trigger en lugar de tenerlo codificado en la configuraciÃ³n.

## ðŸ›ï¸ Arquitectura: Hexagonal (Puertos y Adaptadores)

El motor sigue una estricta arquitectura hexagonal, separando la lÃ³gica en tres capas distintas. Esto hace que el sistema sea altamente modular y fÃ¡cil de testear y extender.

### 1. `domain` (El NÃºcleo)

Es el corazÃ³n de la aplicaciÃ³n. Es Rust puro y no tiene dependencias del "mundo exterior" (como bases de datos, APIs o nuestro `main.rs`).

-   **`domain/graph.rs`**: Define las estructuras de datos puras (`Graph`, `NodeConfig`, `Edge`).
-   **`domain/node.rs`**: Define el "Puerto" principal (el trait `ExecutableNode`). Este es el contrato central que todos los nodos deben firmar. BÃ¡sicamente dice: "Debes ser capaz de ejecutar".
-   **`domain/error.rs`**: Define los errores puros del dominio (`DagError`, ej. `CycleDetected`).

### 2. `application` (El Orquestador)

Esta capa contiene la "lÃ³gica de negocio" de cÃ³mo ejecutar un grafo. Depende del `domain` pero no sabe nada sobre cÃ³mo se implementan los nodos.

-   **`application/ports.rs`**: Define los "Puertos" que la aplicaciÃ³n necesita del mundo exterior (ej. el trait `NodeRegistryPort`, que dice "Necesito una forma de encontrar un nodo a partir de su `type` string").
-   **`application/run_use_case.rs`**: Es el cerebro del motor.
    -   Recibe el `NodeRegistryPort` mediante inyecciÃ³n de dependencias.
    -   Realiza el ordenamiento topolÃ³gico para obtener el orden de ejecuciÃ³n.
    -   Itera a travÃ©s de los nodos.
    -   Construye los `NodeInputs` para cada nodo parseando los `edges`.
    -   Usa el `NodeRegistryPort` para obtener la implementaciÃ³n correcta del nodo.
    -   Llama a `node.execute()`.

### 3. `infrastructure` (El Mundo "Real")

Esta capa implementa todos los "Puertos" definidos en las capas `domain` y `application`. AquÃ­ es donde ocurre todo el trabajo "sucio".

-   **`infrastructure/nodes/`**: Contiene todas nuestras implementaciones de nodos (ej. `AddNode`, `LogNode`, `HttpNode`, `LlmNode`). Cada uno de estos es un "Adaptador" que implementa el trait `ExecutableNode`.
-   **`infrastructure/registry.rs`**: Es el "Adaptador" que implementa el `NodeRegistryPort`. `HashMapNodeRegistry` usa un simple `HashMap` para conectar strings (ej. `"add"`, `"http_request"`) con la estructura concreta del nodo.
-   **`main.rs`**: Es el "Adaptador Primario" o "Ensamblador". Inicializa el `HashMapNodeRegistry`, lo inyecta en el `DagRunUseCase`, y luego le indica al caso de uso que se ejecute.

## ðŸ“¦ Tipos de Nodos Disponibles

### Nodos MatemÃ¡ticos
- `add`, `subtract`, `multiply`, `divide`: Operaciones bÃ¡sicas
- `exponential`: Eleva un nÃºmero a una potencia

### Nodos de DepuraciÃ³n
- `log`: Imprime valores a la consola
- `mock_input`: Proporciona datos de entrada para testing

### Nodos de Trigger
- `trigger_webhook`: Recibe peticiones HTTP en modo `serve` o usa `test_payload` en modo `run`

### Nodos HTTP
- `http_request`: Realiza peticiones HTTP a APIs externas

### Nodos LLM
- `llm_call`: Llama a modelos de lenguaje (OpenAI, Gemini, Anthropic). Soporta **Memoria** y **Function Calling** (prÃ³ximamente).

## ðŸ§  Memoria y Persistencia

El `dag_engine` soporta **persistencia de conversaciones** para los nodos LLM mediante selecciÃ³n dinÃ¡mica de backend de base de datos. Esto permite mantener el contexto entre mÃºltiples ejecuciones y crear agentes con memoria a largo plazo.

### ðŸŽ¯ CaracterÃ­sticas

- **SelecciÃ³n DinÃ¡mica de Backend**: Elige entre SQLite y PostgreSQL por nodo
- **Variables de Entorno**: Usa `${VAR_NAME}` para configuraciÃ³n segura
- **Connection Pooling**: ReutilizaciÃ³n automÃ¡tica de conexiones
- **Migraciones AutomÃ¡ticas**: Las tablas se crean automÃ¡ticamente
- **Thread-Safe**: Soporte para ejecuciÃ³n concurrente

### ðŸ”§ ConfiguraciÃ³n

#### OpciÃ³n 1: SQLite (Desarrollo/Local)

Ideal para desarrollo, testing y aplicaciones single-user.

**Archivo `.env`:**
```bash
# No es necesario configurar DATABASE_URL para SQLite
# Puedes especificar la ruta directamente en el DAG
```

**En tu DAG:**
```json
{
  "type": "llm_call",
  "config": {
    "provider": "openai",
    "api_key": "${OPENAI_API_KEY}",
    "thread_id": "user_session_123",
    "connection_url": "sqlite://colmena_memory.db",
    "prompt": "Hello!"
  }
}
```

#### OpciÃ³n 2: PostgreSQL (ProducciÃ³n)

Ideal para producciÃ³n, aplicaciones multi-user y escalabilidad.

**Archivo `.env`:**
```bash
# PostgreSQL estÃ¡ndar
DATABASE_URL="postgresql://user:password@localhost:5432/database_name"

# O con el protocolo alternativo
DATABASE_URL="postgres://user:password@localhost:5432/database_name"

# Ejemplo con Supabase
DATABASE_URL="postgresql://postgres:password@db.xxxxx.supabase.co:5432/postgres"
```

**En tu DAG:**
```json
{
  "type": "llm_call",
  "config": {
    "provider": "openai",
    "api_key": "${OPENAI_API_KEY}",
    "thread_id": "user_session_123",
    "connection_url": "${DATABASE_URL}",
    "prompt": "Hello!"
  }
}
```

### ðŸ“ Formatos de Connection URL Soportados

| Base de Datos | Formato | Ejemplo |
|---------------|---------|---------|
| SQLite (relativo) | `sqlite://path/to/file.db` | `sqlite://memory.db` |
| SQLite (absoluto) | `sqlite:///absolute/path/to/file.db` | `sqlite:///var/data/memory.db` |
| SQLite (memoria) | `sqlite::memory:` | `sqlite::memory:` |
| PostgreSQL | `postgresql://user:pass@host:port/db` | `postgresql://postgres:pwd@localhost:5432/mydb` |
| PostgreSQL (alternativo) | `postgres://user:pass@host:port/db` | `postgres://postgres:pwd@localhost:5432/mydb` |

### ðŸŽ¯ Uso en Nodos `llm_call`

Para habilitar memoria en un nodo LLM, necesitas dos campos:

1. **`thread_id`**: Identificador Ãºnico de la conversaciÃ³n
2. **`connection_url`**: URL de conexiÃ³n a la base de datos

Ambos pueden estar en `config` (estÃ¡tico) o en `inputs` (dinÃ¡mico).

#### Ejemplo BÃ¡sico

```json
{
  "nodes": {
    "chat": {
      "type": "llm_call",
      "config": {
        "provider": "openai",
        "api_key": "${OPENAI_API_KEY}",
        "model": "gpt-3.5-turbo",
        "thread_id": "conversation_001",
        "connection_url": "sqlite://chat.db",
        "prompt": "Remember: my name is Alice"
      }
    }
  }
}
```

### ðŸ“š Ejemplos Completos

#### Ejemplo 1: Memoria con SQLite

Este ejemplo demuestra cÃ³mo usar SQLite para persistencia local.

**Archivo:** `tests/memory_sqlite_example.json`

```json
{
    "nodes": {
        "step_1": {
            "type": "llm_call",
            "config": {
                "provider": "openai",
                "api_key": "${OPENAI_API_KEY}",
                "model": "gpt-3.5-turbo",
                "system_message": "You are a helpful assistant with perfect memory.",
                "thread_id": "sqlite_test_thread_001",
                "connection_url": "sqlite://colmena_memory.db",
                "prompt": "My name is Alice and I love programming in Rust."
            }
        },
        "step_2": {
            "type": "llm_call",
            "config": {
                "provider": "openai",
                "api_key": "${OPENAI_API_KEY}",
                "model": "gpt-3.5-turbo",
                "thread_id": "sqlite_test_thread_001",
                "connection_url": "sqlite://colmena_memory.db",
                "prompt": "What is my name and what do I love?"
            }
        },
        "log_result": {
            "type": "log"
        }
    },
    "edges": [
        {
            "from": "step_1.output",
            "to": "step_2.dummy_input"
        },
        {
            "from": "step_2.output",
            "to": "log_result.input"
        }
    ]
}
```

**Ejecutar:**
```bash
cargo run --bin dag_engine -- run tests/memory_sqlite_example.json
```

**Resultado esperado:**
- `step_1` guarda "My name is Alice..." en la base de datos
- `step_2` recupera el historial y responde correctamente con el nombre

#### Ejemplo 2: Memoria con PostgreSQL

Este ejemplo usa PostgreSQL para producciÃ³n con variables de entorno.

**Archivo `.env`:**
```bash
DATABASE_URL="postgresql://postgres:password@localhost:5432/colmena_memory"
OPENAI_API_KEY="sk-..."
```

**Archivo:** `tests/memory_postgres_example.json`

```json
{
    "nodes": {
        "step_1": {
            "type": "llm_call",
            "config": {
                "provider": "openai",
                "api_key": "${OPENAI_API_KEY}",
                "model": "gpt-3.5-turbo",
                "system_message": "You are a helpful assistant with perfect memory.",
                "thread_id": "postgres_test_thread_001",
                "connection_url": "${DATABASE_URL}",
                "prompt": "My favorite color is blue and I work as a software engineer."
            }
        },
        "step_2": {
            "type": "llm_call",
            "config": {
                "provider": "openai",
                "api_key": "${OPENAI_API_KEY}",
                "model": "gpt-3.5-turbo",
                "thread_id": "postgres_test_thread_001",
                "connection_url": "${DATABASE_URL}",
                "prompt": "What is my favorite color and what do I do for work?"
            }
        },
        "log_result": {
            "type": "log"
        }
    },
    "edges": [
        {
            "from": "step_1.output",
            "to": "step_2.dummy_input"
        },
        {
            "from": "step_2.output",
            "to": "log_result.input"
        }
    ]
}
```

**Ejecutar:**
```bash
cargo run --bin dag_engine -- run tests/memory_postgres_example.json
```

#### Ejemplo 3: Memoria DinÃ¡mica (Thread ID desde Webhook)

Este ejemplo muestra cÃ³mo usar diferentes threads por usuario en un servidor.

```json
{
  "nodes": {
    "webhook": {
      "type": "trigger_webhook",
      "config": {
        "path": "/chat",
        "method": "POST",
        "test_payload": {
          "user_id": "user_123",
          "message": "What's my name?"
        }
      }
    },
    "chat": {
      "type": "llm_call",
      "config": {
        "provider": "openai",
        "api_key": "${OPENAI_API_KEY}",
        "model": "gpt-3.5-turbo",
        "connection_url": "${DATABASE_URL}"
      }
    },
    "log_response": {
      "type": "log"
    }
  },
  "edges": [
    {
      "from": "webhook.output.user_id",
      "to": "chat.thread_id"
    },
    {
      "from": "webhook.output.message",
      "to": "chat.prompt"
    },
    {
      "from": "chat.output",
      "to": "log_response.input"
    }
  ]
}
```

**Modo Serve:**
```bash
cargo run --bin dag_engine -- serve tests/dynamic_memory.json
```

**PeticiÃ³n HTTP:**
```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"user_id": "alice_001", "message": "My name is Alice"}'

curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"user_id": "alice_001", "message": "What is my name?"}'
```

### ðŸ” CÃ³mo Funciona Internamente

1. **Primera ejecuciÃ³n con un `thread_id`:**
   - Se conecta a la base de datos especificada en `connection_url`
   - Ejecuta migraciones automÃ¡ticamente (crea tablas si no existen)
   - Crea un nuevo thread en la base de datos
   - Guarda el mensaje del usuario y la respuesta del LLM

2. **Ejecuciones subsecuentes con el mismo `thread_id`:**
   - Reutiliza la conexiÃ³n del pool (mÃ¡s rÃ¡pido)
   - Carga todo el historial de mensajes del thread
   - EnvÃ­a el historial completo al LLM para mantener contexto
   - Guarda el nuevo mensaje y respuesta

3. **Connection Pooling:**
   - Las conexiones se cachean por `connection_url`
   - MÃºltiples nodos pueden compartir la misma conexiÃ³n
   - PostgreSQL: hasta 5 conexiones concurrentes
   - SQLite: 1 conexiÃ³n (limitaciÃ³n de SQLite)

### âš ï¸ Consideraciones Importantes

- **Thread IDs Ãºnicos**: Usa IDs Ãºnicos por conversaciÃ³n (ej: `user_id`, `session_id`)
- **Seguridad**: Nunca hardcodees credenciales, usa variables de entorno
- **SQLite Limitations**: SQLite no soporta escrituras concurrentes, usa PostgreSQL para producciÃ³n
- **Migraciones**: Se ejecutan automÃ¡ticamente en la primera conexiÃ³n
- **Costos de LLM**: El historial completo se envÃ­a en cada llamada, considera el costo de tokens

### ðŸ› Troubleshooting

**Error: "Unsupported database protocol"**
- Verifica que uses `sqlite://`, `postgres://` o `postgresql://`
- Revisa que la variable de entorno estÃ© correctamente configurada

**Error: "Failed to connect to Postgres: pool timed out"**
- Verifica que la base de datos estÃ© accesible
- Revisa las credenciales en el connection URL
- AsegÃºrate de que el firewall permita la conexiÃ³n

**Error: "Environment variable X not found"**
- Verifica que el archivo `.env` exista en la raÃ­z del proyecto
- AsegÃºrate de que la variable estÃ© definida sin espacios: `VAR=value`
- El archivo `.env` se carga automÃ¡ticamente al iniciar el DAG engine

## ðŸ” Variables de Entorno en ConfiguraciÃ³n

Puedes usar variables de entorno directamente en la configuraciÃ³n de tus nodos usando la sintaxis `${VAR_NAME}`. Esto es ideal para no hardcodear API Keys.

```json
"config": {
  "api_key": "${OPENAI_API_KEY}",
  "model": "gpt-4"
}
```
El motor resolverÃ¡ `${OPENAI_API_KEY}` buscando en las variables de entorno del sistema (o archivo `.env`).

## ðŸ”§ CÃ³mo Crear un Nuevo Nodo

Crear un nuevo nodo es la forma principal de extender el motor. Es un proceso simple de dos pasos.

### Paso 1: Implementar el Trait `ExecutableNode`

Primero, crea la estructura de tu nodo e implementa el trait `ExecutableNode`.

-   **Leer de `inputs`**: Usa `inputs.get("input_name")` para obtener datos de los `edges` entrantes.
-   **Leer de `config`**: Usa `config.get("config_key")` para obtener configuraciÃ³n estÃ¡tica.
-   **ConfiguraciÃ³n DinÃ¡mica**: Implementa la precedencia `inputs > config` para soportar configuraciÃ³n dinÃ¡mica.
-   **Devolver Salida**: Devuelve tu resultado envuelto en `json!({ "output": ... })`.

```rust
// Ejemplo: HttpNode con configuraciÃ³n dinÃ¡mica
use crate::domain::node::{ExecutableNode, NodeInputs};
use serde_json::{json, Value};
use std::error::Error as StdError;

pub struct HttpNode;

#[async_trait::async_trait]
impl ExecutableNode for HttpNode {
    async fn execute(
        &self,
        inputs: &NodeInputs,
        config: &Value,
        _state: &mut Value,
    ) -> Result<Value, Box<dyn StdError>> {
        // ConfiguraciÃ³n dinÃ¡mica: inputs > config
        let base_url = inputs.get("base_url").and_then(|v| v.as_str())
            .or_else(|| config.get("base_url").and_then(|v| v.as_str()))
            .unwrap_or("");
            
        let endpoint = inputs.get("endpoint").and_then(|v| v.as_str())
            .or_else(|| config.get("endpoint").and_then(|v| v.as_str()))
            .unwrap_or("");
        
        // ... realizar peticiÃ³n HTTP ...
        
        Ok(json!({
            "output": {
                "status": 200,
                "body": response_body
            }
        }))
    }

    fn schema(&self) -> Value {
        json!({
            "type": "http_request",
            "config": {
                "base_url": "string",
                "endpoint": "string",
                "method": "string"
            },
            "inputs": {
                "base_url": "string (optional)",
                "endpoint": "string (optional)",
                "method": "string (optional)",
                "body": "any (optional)"
            },
            "outputs": {
                "status": "integer",
                "body": "any"
            }
        })
    }
}
```

### Paso 2: Registrar el Nodo

Segundo, "inyecta" tu nuevo nodo en la aplicaciÃ³n aÃ±adiÃ©ndolo al registro.

Abre `src/dag_engine/infrastructure/registry.rs` y aÃ±ade tu nodo en la funciÃ³n `HashMapNodeRegistry::new()`.

```rust
// en: src/dag_engine/infrastructure/registry.rs

// ... (otros registros de nodos) ...
nodes.insert("http_request".to_string(), Arc::new(HttpNode));
nodes.insert("llm_call".to_string(), Arc::new(LlmNode));
        
Self { nodes }
```

## ðŸ§ª Testing Local con `test_payload`

Para facilitar el desarrollo y testing, el nodo `trigger_webhook` soporta la opciÃ³n `test_payload` que permite ejecutar grafos localmente sin levantar un servidor.

### Modo Run (Testing Local)

```json
{
  "nodes": {
    "my_webhook": {
      "type": "trigger_webhook",
      "config": {
        "path": "/test",
        "method": "POST",
        "test_payload": {
          "message": "Hello from local test!"
        }
      }
    },
    "log_step": {
      "type": "log"
    }
  },
  "edges": [
    {
      "from": "my_webhook.output.message",
      "to": "log_step.input"
    }
  ]
}
```

Ejecutar:
```bash
cargo run --bin dag_engine -- run tests/my_graph.json
```

### Modo Serve (ProducciÃ³n)

En modo `serve`, el `test_payload` es ignorado y se usa el payload real de las peticiones HTTP:

```bash
cargo run --bin dag_engine -- serve tests/my_graph.json
```

Luego hacer peticiones:
```bash
curl -X POST http://localhost:3000/test \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello from HTTP!"}'
```

## ðŸ“Š Ejemplos Completos

### Ejemplo 1: Llamada HTTP DinÃ¡mica

```json
{
  "nodes": {
    "webhook": {
      "type": "trigger_webhook",
      "config": {
        "path": "/fetch-joke",
        "method": "POST",
        "test_payload": {
          "endpoint": "/random_joke"
        }
      }
    },
    "http_call": {
      "type": "http_request",
      "config": {
        "base_url": "https://official-joke-api.appspot.com",
        "method": "GET"
      }
    },
    "log_result": {
      "type": "log"
    }
  },
  "edges": [
    {
      "from": "webhook.output.endpoint",
      "to": "http_call.endpoint"
    },
    {
      "from": "http_call.output",
      "to": "log_result.input"
    }
  ]
}
```

### Ejemplo 2: Llamada a LLM

```json
{
  "nodes": {
    "webhook": {
      "type": "trigger_webhook",
      "config": {
        "path": "/ask-llm",
        "method": "POST",
        "test_payload": {
          "question": "What is Rust?"
        }
      }
    },
    "llm_step": {
      "type": "llm_call",
      "config": {
        "provider": "openai",
        "api_key": "sk-...",
        "model": "gpt-3.5-turbo",
        "system_message": "You are a helpful programming assistant.",
        "max_tokens": 100
      }
    },
    "log_answer": {
      "type": "log"
    }
  },
  "edges": [
    {
      "from": "webhook.output.question",
      "to": "llm_step.prompt"
    },
    {
      "from": "llm_step.output",
      "to": "log_answer.input"
    }
  ]
}
```

### Ejemplo 3: Pipeline HTTP â†’ LLM

```json
{
  "nodes": {
    "webhook": {
      "type": "trigger_webhook",
      "config": {
        "path": "/analyze-joke",
        "method": "POST",
        "test_payload": {}
      }
    },
    "get_joke": {
      "type": "http_request",
      "config": {
        "base_url": "https://official-joke-api.appspot.com",
        "endpoint": "/random_joke",
        "method": "GET"
      }
    },
    "analyze_joke": {
      "type": "llm_call",
      "config": {
        "provider": "openai",
        "api_key": "sk-...",
        "model": "gpt-3.5-turbo",
        "system_message": "You are a comedy expert. Analyze jokes.",
        "max_tokens": 150
      }
    },
    "log_analysis": {
      "type": "log"
    }
  },
  "edges": [
    {
      "from": "get_joke.output.body.setup",
      "to": "analyze_joke.prompt"
    },
    {
      "from": "analyze_joke.output",
      "to": "log_analysis.input"
    }
  ]
}
```

## ðŸš€ Comandos de EjecuciÃ³n

### Run Mode (Local Testing)
```bash
# Ejecutar un grafo con test_payload
cargo run --bin dag_engine -- run tests/my_graph.json

# Ver el output completo
cargo run --bin dag_engine -- run tests/my_graph.json | jq
```

### Serve Mode (Production)
```bash
# Iniciar servidor en puerto 3000 (default)
cargo run --bin dag_engine -- serve tests/my_graph.json

# Iniciar servidor en puerto custom
cargo run --bin dag_engine -- serve tests/my_graph.json --port 8080
```

## ðŸ” Best Practices

1. **Usa `test_payload` para desarrollo**: Acelera el ciclo de desarrollo evitando levantar servidores.
2. **ConfiguraciÃ³n dinÃ¡mica**: Aprovecha `inputs > config` para crear grafos mÃ¡s flexibles.
3. **Modularidad**: Crea nodos pequeÃ±os y reutilizables.
4. **Error handling**: Siempre maneja errores apropiadamente en tus nodos.
5. **Testing**: Prueba con `run` antes de usar `serve`.

## ðŸ“š MÃ¡s InformaciÃ³n

- Ver [USAGE_EXAMPLES.md](../examples/USAGE_EXAMPLES.md) para mÃ¡s ejemplos completos
- Ver [DAG_ENGINE_DISEÃ‘O.md](../dds/DAG_ENGINE_DISEÃ‘O.md) para detalles de arquitectura
- Ver [MODULO_LLM_DISEÃ‘O.md](../dds/MODULO_LLM_DISEÃ‘O.md) para integraciÃ³n con LLMs
