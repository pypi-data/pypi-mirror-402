Metadata-Version: 2.4
Name: langchain-timbr
Version: 2.2.0
Summary: LangChain & LangGraph extensions that parse LLM prompts into Timbr semantic SQL and execute them.
Project-URL: Homepage, https://github.com/WPSemantix/langchain-timbr
Project-URL: Documentation, https://docs.timbr.ai/doc/docs/integration/langchain-sdk/
Project-URL: Source, https://github.com/WPSemantix/langchain-timbr
Project-URL: Issues, https://github.com/WPSemantix/langchain-timbr/issues
Author-email: "Timbr.ai" <contact@timbr.ai>
License: MIT
License-File: LICENSE
Keywords: Agents,Knowledge Graph,LLM,LangChain,LangGraph,SQL,Semantic Layer,Timbr
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: <3.13,>=3.10
Requires-Dist: cryptography==45.0.7; python_version >= '3.11'
Requires-Dist: cryptography>=44.0.3; python_version == '3.10'
Requires-Dist: langchain-community==0.3.30; python_version >= '3.11'
Requires-Dist: langchain-community>=0.3.27; python_version == '3.10'
Requires-Dist: langchain-core>=0.3.81
Requires-Dist: langchain==0.3.27; python_version >= '3.11'
Requires-Dist: langchain>=0.3.25; python_version == '3.10'
Requires-Dist: langgraph-checkpoint==3.0.0
Requires-Dist: langgraph==1.0.1; python_version >= '3.11'
Requires-Dist: langgraph>=0.3.20; python_version == '3.10'
Requires-Dist: pydantic==2.10.4
Requires-Dist: pytimbr-api>=2.1.0
Requires-Dist: tiktoken==0.8.0
Requires-Dist: transformers==4.57.0; python_version >= '3.11'
Requires-Dist: transformers>=4.53; python_version == '3.10'
Requires-Dist: uvicorn==0.34.0
Provides-Extra: all
Requires-Dist: anthropic==0.42.0; extra == 'all'
Requires-Dist: azure-identity==1.25.0; (python_version >= '3.11') and extra == 'all'
Requires-Dist: azure-identity>=1.16.1; (python_version == '3.10') and extra == 'all'
Requires-Dist: databricks-langchain==0.7.1; extra == 'all'
Requires-Dist: databricks-sdk==0.64.0; extra == 'all'
Requires-Dist: google-generativeai==0.8.4; extra == 'all'
Requires-Dist: langchain-anthropic==0.3.5; (python_version >= '3.11') and extra == 'all'
Requires-Dist: langchain-anthropic>=0.3.1; (python_version == '3.10') and extra == 'all'
Requires-Dist: langchain-aws<1,>=0.2.35; extra == 'all'
Requires-Dist: langchain-google-genai==2.0.10; (python_version >= '3.11') and extra == 'all'
Requires-Dist: langchain-google-genai>=2.0.9; (python_version == '3.10') and extra == 'all'
Requires-Dist: langchain-google-vertexai==2.1.2; (python_version >= '3.11') and extra == 'all'
Requires-Dist: langchain-google-vertexai>=2.0.28; (python_version == '3.10') and extra == 'all'
Requires-Dist: langchain-openai==0.3.34; (python_version >= '3.11') and extra == 'all'
Requires-Dist: langchain-openai>=0.3.16; (python_version == '3.10') and extra == 'all'
Requires-Dist: langchain-tests==0.3.22; (python_version >= '3.11') and extra == 'all'
Requires-Dist: langchain-tests>=0.3.20; (python_version == '3.10') and extra == 'all'
Requires-Dist: openai==2.1.0; (python_version >= '3.11') and extra == 'all'
Requires-Dist: openai>=1.77.0; (python_version == '3.10') and extra == 'all'
Requires-Dist: pytest==8.3.4; extra == 'all'
Requires-Dist: snowflake-snowpark-python==1.39.1; (python_version >= '3.11') and extra == 'all'
Requires-Dist: snowflake-snowpark-python>=1.39.1; (python_version == '3.10') and extra == 'all'
Requires-Dist: snowflake==1.8.0; (python_version >= '3.11') and extra == 'all'
Requires-Dist: snowflake>=1.8.0; (python_version == '3.10') and extra == 'all'
Requires-Dist: uvicorn==0.34.0; extra == 'all'
Provides-Extra: anthropic
Requires-Dist: anthropic==0.42.0; extra == 'anthropic'
Requires-Dist: langchain-anthropic==0.3.5; (python_version >= '3.11') and extra == 'anthropic'
Requires-Dist: langchain-anthropic>=0.3.1; (python_version == '3.10') and extra == 'anthropic'
Provides-Extra: azure-openai
Requires-Dist: azure-identity==1.25.0; (python_version >= '3.11') and extra == 'azure-openai'
Requires-Dist: azure-identity>=1.16.1; (python_version == '3.10') and extra == 'azure-openai'
Requires-Dist: langchain-openai==0.3.34; (python_version >= '3.11') and extra == 'azure-openai'
Requires-Dist: langchain-openai>=0.3.16; (python_version == '3.10') and extra == 'azure-openai'
Requires-Dist: openai==2.1.0; (python_version >= '3.11') and extra == 'azure-openai'
Requires-Dist: openai>=1.77.0; (python_version == '3.10') and extra == 'azure-openai'
Provides-Extra: bedrock
Requires-Dist: langchain-aws==0.2.35; extra == 'bedrock'
Provides-Extra: databricks
Requires-Dist: databricks-langchain==0.7.1; extra == 'databricks'
Requires-Dist: databricks-sdk==0.64.0; extra == 'databricks'
Provides-Extra: dev
Requires-Dist: langchain-tests==0.3.22; (python_version >= '3.11') and extra == 'dev'
Requires-Dist: langchain-tests>=0.3.20; (python_version == '3.10') and extra == 'dev'
Requires-Dist: pytest==8.3.4; extra == 'dev'
Requires-Dist: uvicorn==0.34.0; extra == 'dev'
Provides-Extra: google
Requires-Dist: google-generativeai==0.8.4; extra == 'google'
Requires-Dist: langchain-google-genai==2.0.10; (python_version >= '3.11') and extra == 'google'
Requires-Dist: langchain-google-genai>=2.0.9; (python_version == '3.10') and extra == 'google'
Provides-Extra: openai
Requires-Dist: langchain-openai==0.3.34; (python_version >= '3.11') and extra == 'openai'
Requires-Dist: langchain-openai>=0.3.16; (python_version == '3.10') and extra == 'openai'
Requires-Dist: openai==2.1.0; (python_version >= '3.11') and extra == 'openai'
Requires-Dist: openai>=1.77.0; (python_version == '3.10') and extra == 'openai'
Provides-Extra: snowflake
Requires-Dist: opentelemetry-api==1.38.0; (python_version < '3.12') and extra == 'snowflake'
Requires-Dist: opentelemetry-sdk==1.38.0; (python_version < '3.12') and extra == 'snowflake'
Requires-Dist: snowflake-snowpark-python==1.39.1; (python_version >= '3.11') and extra == 'snowflake'
Requires-Dist: snowflake-snowpark-python>=1.39.1; (python_version == '3.10') and extra == 'snowflake'
Requires-Dist: snowflake==1.8.0; (python_version >= '3.11') and extra == 'snowflake'
Requires-Dist: snowflake>=1.8.0; (python_version == '3.10') and extra == 'snowflake'
Provides-Extra: vertex-ai
Requires-Dist: google-generativeai==0.8.4; extra == 'vertex-ai'
Requires-Dist: langchain-google-vertexai==2.1.2; (python_version >= '3.11') and extra == 'vertex-ai'
Requires-Dist: langchain-google-vertexai>=2.0.28; (python_version == '3.10') and extra == 'vertex-ai'
Description-Content-Type: text/markdown

![Timbr logo description](https://timbr.ai/wp-content/uploads/2025/01/logotimbrai230125.png)

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FWPSemantix%2Flangchain-timbr.svg?type=shield&issueType=security)](https://app.fossa.com/projects/git%2Bgithub.com%2FWPSemantix%2Flangchain-timbr?ref=badge_shield&issueType=security)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FWPSemantix%2Flangchain-timbr.svg?type=shield&issueType=license)](https://app.fossa.com/projects/git%2Bgithub.com%2FWPSemantix%2Flangchain-timbr?ref=badge_shield&issueType=license)


[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/release/python-31017/)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-31112/)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3129/)

# Timbr LangChain LLM SDK

Timbr LangChain LLM SDK is a Python SDK that extends LangChain and LangGraph with custom agents, chains, and nodes for seamless integration with the Timbr semantic layer. It enables converting natural language prompts into optimized semantic-SQL queries and executing them directly against your data.

![Timbr LangGraph pipeline](https://docs.timbr.ai/doc/assets/images/timbr-langgraph-fcf8e2eb7e26dc9dfa8b56b62937281e.png)

## Dependencies

- Access to a timbr-server
- Python 3.10 or newer

## Installation

### Using pip

```bash
python -m pip install langchain-timbr
```

### Install with selected LLM providers

#### One of: openai, anthropic, google, azure_openai, snowflake, databricks, vertex_ai, bedrock (or 'all')

```bash
python -m pip install 'langchain-timbr[<your selected providers, separated by comma w/o space>]'
```

### Using pip from github

```bash
pip install git+https://github.com/WPSemantix/langchain-timbr
```

## Documentation

For comprehensive documentation and usage examples, please visit:

- [Timbr LangChain Documentation](https://docs.timbr.ai/doc/docs/integration/langchain-sdk)
- [Timbr LangGraph Documentation](https://docs.timbr.ai/doc/docs/integration/langgraph-sdk)

## Configuration

The SDK uses environment variables for configuration. All configurations are optional - when set, they serve as default values for `langchain-timbr` provided tools. Below are all available configuration options:

### Configuration Options

#### Timbr Connection Settings

- **`TIMBR_URL`** - The URL of your Timbr server
- **`TIMBR_TOKEN`** - Authentication token for accessing the Timbr server
- **`TIMBR_ONTOLOGY`** - The ontology to use (also accepts `ONTOLOGY` as an alias)
- **`IS_JWT`** - Whether the token is a JWT token (true/false)
- **`JWT_TENANT_ID`** - Tenant ID for JWT authentication

#### Cache and Data Processing

- **`CACHE_TIMEOUT`** - Timeout for caching operations in seconds
- **`IGNORE_TAGS`** - Comma-separated list of tags to ignore during processing
- **`IGNORE_TAGS_PREFIX`** - Comma-separated list of tag prefixes to ignore during processing

#### LLM Configuration

- **`LLM_TYPE`** - The type of LLM provider to use
- **`LLM_MODEL`** - The specific model to use with the LLM provider
- **`LLM_API_KEY`** - API key or client secret for the LLM provider
- **`LLM_TEMPERATURE`** - Temperature setting for LLM responses (controls randomness)
- **`LLM_ADDITIONAL_PARAMS`** - Additional parameters to pass to the LLM
- **`LLM_TIMEOUT`** - Timeout for LLM requests in seconds
- **`LLM_TENANT_ID`** - LLM provider tenant/directory ID (Used for Service Principal authentication)
- **`LLM_CLIENT_ID`** - LLM provider client ID (Used for Service Principal authentication)
- **`LLM_CLIENT_SECRET`** - LLM provider client secret (Used for Service Principal authentication)
- **`LLM_ENDPOINT`** - LLM provider OpenAI endpoint URL
- **`LLM_API_VERSION`** - LLM provider API version
- **`LLM_SCOPE`** - LLM provider authentication scope
