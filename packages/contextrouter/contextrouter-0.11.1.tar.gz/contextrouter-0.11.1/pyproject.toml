[project]
name = "contextrouter"
version = "0.11.1"
description = "Modular LangGraph-powered agentic brain for multi-source knowledge orchestration and RAG"
readme = "README.md"
requires-python = ">=3.13"
authors = [
    { name = "Pylypchuk Oleksii", email = "oleksii.pylypchuk@tuta.com" },
]
license = { file = "LICENSE.md" }
classifiers = [
    "Development Status :: 3 - Alpha",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3 :: Only",
    "Programming Language :: Python :: 3.13",
    "Typing :: Typed",
]
dependencies = [
    "python-dotenv>=1.0.0",
    "langgraph>=0.2.0",
    "langchain-core>=0.3.0",
    "langchain-community>=0.3.0",
    "pydantic>=2.0.0",
    "click>=8.0.0",
    "typer>=0.12.0",
    "rich>=13.0.0",
    "tomli>=2.0.0",
    "joblib>=1.5.3",
]

[project.urls]
Homepage = "https://contextrouter.dev"
Documentation = "https://contextrouter.org"
Repository = "https://github.com/ContextRouter/contextrouter"
Issues = "https://github.com/ContextRouter/contextrouter/issues"

[project.optional-dependencies]
dev = [
    "pre-commit>=3.0.0",
    "ruff>=0.14.0",
    "pytest>=8.0.0",
    "joblib>=1.4.0",
    "alembic>=1.13.0",
    "twine>=5.0.0",
    "build>=1.0.0",
]
# Core providers (most common)
vertex = [
    "langchain-google-vertexai>=2.0.0",
    "langchain-google-genai>=2.0.0",
    "langchain-google-community>=2.0.0",
    "google-cloud-discoveryengine>=0.13.0",
    "google-cloud-aiplatform>=1.0.0",  # For Vertex AI Search
    "google-genai>=1.0.0",  # Modern SDK for native grounding (replaces deprecated vertexai.generative_models)
]
# Extended providers
storage = [
    "google-cloud-storage>=3.0.0",
    "google-cloud-firestore>=2.16.0",
    "psycopg[binary]>=3.1.0",
    "psycopg-pool>=3.2.0",
    "sqlalchemy>=2.0.0",
]
# Transport integrations
integrations = [
    "python-telegram-bot>=21.0",
    "google-api-python-client>=2.100.0,<3.0.0",
    "google-auth>=2.25.0,<3.0.0",
    "google-auth-oauthlib>=1.2.0,<2.0.0",
]
# Ingestion capabilities
ingestion = [
    "networkx>=3.0",
    "trafilatura>=1.6.0",
    "pymupdf4llm>=0.0.10",
    "pymupdf-layout>=0.0.0",
    "beautifulsoup4>=4.12.0",
]
# Observability
observability = [
    "langfuse>=2.0.0",
    "opentelemetry-instrumentation-threading>=0.48b0",
]
# Alternative LLM providers
models-openai = [
    "langchain-openai>=0.1.0",
]
models-anthropic = [
    "langchain-anthropic>=0.1.0",
]
models-hf-hub = [
    "huggingface-hub>=0.20.0",
]
# Convenience bundle (all non-Vertex LLM providers we ship today)
models = [
    "contextrouter[models-openai,models-anthropic,models-hf-hub]",
]
# CPU-only local inference (heavy dependencies, development only)
hf-transformers = [
    "transformers>=4.30.0",
    "torch>=2.0.0",
]
# Local embeddings via sentence-transformers
hf-embeddings = [
    "sentence-transformers>=3.0.0",
]
# Everything (for development/testing)
all = [
    "contextrouter[vertex,storage,integrations,ingestion,observability]"
]

# Experimental / optional bundle (may be unsatisfiable depending on resolver + platform)
all_experimental = [
    "contextrouter[all]"
]

[project.scripts]
contextrouter = "contextrouter.cli.app:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/contextrouter"]

[tool.ruff]
target-version = "py313"
line-length = 100

[tool.ruff.lint]
select = ["E", "F", "W", "I"]
ignore = ["E501"]

[dependency-groups]
dev = [
    "bandit>=1.9.2",
    "pre-commit>=4.5.1",
    "pytest>=8.0.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.0.0",
    "ruff>=0.14.0",
    "alembic>=1.13.0",
]
