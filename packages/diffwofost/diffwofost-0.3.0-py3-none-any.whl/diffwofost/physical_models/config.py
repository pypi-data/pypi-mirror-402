from dataclasses import dataclass
from dataclasses import field
from pathlib import Path
from typing import Self
import pcse
import torch
from pcse.agromanager import AgroManager
from pcse.base import AncillaryObject
from pcse.base import SimulationObject


class ComputeConfig:
    """Central configuration for device and dtype settings.

    This class provides a centralized way to control PyTorch device and dtype
    settings across all simulation objects in diffWOFOST. Instead of setting
    device and dtype individually for each class, use this central configuration
    to apply settings globally.

    **Default Behavior:**

    - **Device**: Automatically defaults to 'cuda' if available, otherwise 'cpu'
    - **Dtype**: Defaults to torch.float64

    **Basic Usage:**

        >>> from diffwofost.physical_models.config import ComputeConfig
        >>> import torch
        >>>
        >>> # Set device to CPU
        >>> ComputeConfig.set_device('cpu')
        >>>
        >>> # Or use a torch.device object
        >>> ComputeConfig.set_device(torch.device('cuda'))
        >>>
        >>> # Set dtype to float32
        >>> ComputeConfig.set_dtype(torch.float32)
        >>>
        >>> # Get current settings
        >>> device = ComputeConfig.get_device()  # Returns: torch.device('cpu')
        >>> dtype = ComputeConfig.get_dtype()    # Returns: torch.float32

    **Using with Simulation Objects:**

    All simulation objects (e.g., WOFOST_Leaf_Dynamics, WOFOST_Phenology)
    automatically use the settings from ComputeConfig. No changes needed to
    instantiation code:

        >>> from diffwofost.physical_models.config import ComputeConfig
        >>> from diffwofost.physical_models.crop.leaf_dynamics import WOFOST_Leaf_Dynamics
        >>>
        >>> # Set global compute settings
        >>> ComputeConfig.set_device('cuda')
        >>> ComputeConfig.set_dtype(torch.float32)
        >>>
        >>> # Instantiate objects - they automatically use global settings
        >>> leaf_dynamics = WOFOST_Leaf_Dynamics()

    **Switching Between Devices:**

    Useful for switching between GPU training and CPU evaluation:

        >>> # Train on GPU
        >>> ComputeConfig.set_device('cuda')
        >>> ComputeConfig.set_dtype(torch.float32)
        >>> # ... run training ...
        >>>
        >>> # Evaluate on CPU
        >>> ComputeConfig.set_device('cpu')
        >>> ComputeConfig.set_dtype(torch.float64)
        >>> # ... run evaluation ...

    **Resetting to Defaults:**

        >>> ComputeConfig.reset_to_defaults()

    """

    _device: torch.device = None
    _dtype: torch.dtype = None

    @classmethod
    def _initialize_defaults(cls):
        """Initialize default device and dtype if not already set."""
        if cls._device is None:
            cls._device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if cls._dtype is None:
            cls._dtype = torch.float64

    @classmethod
    def get_device(cls) -> torch.device:
        """Get the current device setting.

        Returns:
            torch.device: The current device (cuda or cpu)
        """
        cls._initialize_defaults()
        return cls._device

    @classmethod
    def set_device(cls, device: str | torch.device) -> None:
        """Set the device to use for tensor operations.

        Args:
            device (str | torch.device): Device to use ('cuda', 'cpu', or torch.device object)

        Example:
            >>> ComputeConfig.set_device('cuda')
            >>> ComputeConfig.set_device(torch.device('cpu'))
        """
        if isinstance(device, str):
            cls._device = torch.device(device)
        else:
            cls._device = device

    @classmethod
    def get_dtype(cls) -> torch.dtype:
        """Get the current dtype setting.

        Returns:
            torch.dtype: The current dtype (e.g., torch.float32, torch.float64)
        """
        cls._initialize_defaults()
        return cls._dtype

    @classmethod
    def set_dtype(cls, dtype: torch.dtype) -> None:
        """Set the dtype to use for tensor creation.

        Args:
            dtype (torch.dtype): PyTorch dtype (torch.float32, torch.float64, etc.)

        Example:
            >>> ComputeConfig.set_dtype(torch.float32)
        """
        cls._dtype = dtype

    @classmethod
    def reset_to_defaults(cls) -> None:
        """Reset device and dtype to their default values."""
        cls._device = None
        cls._dtype = None
        cls._initialize_defaults()


@dataclass(frozen=True)
class Configuration:
    """Class to store model configuration from a PCSE configuration files."""

    CROP: type[SimulationObject]
    SOIL: type[SimulationObject] | None = None
    AGROMANAGEMENT: type[AncillaryObject] = AgroManager
    OUTPUT_VARS: list = field(default_factory=list)
    SUMMARY_OUTPUT_VARS: list = field(default_factory=list)
    TERMINAL_OUTPUT_VARS: list = field(default_factory=list)
    OUTPUT_INTERVAL: str = "daily"  # "daily"|"dekadal"|"monthly"
    OUTPUT_INTERVAL_DAYS: int = 1
    OUTPUT_WEEKDAY: int = 0
    model_config_file: str | Path | None = None
    description: str | None = None

    @classmethod
    def from_pcse_config_file(cls, filename: str | Path) -> Self:
        """Load the model configuration from a PCSE configuration file.

        Args:
            filename (str | pathlib.Path): Path to the configuraiton file. The path is first
                interpreted with respect to the current working directory and, if not found, it will
                then be interpreted with respect to the `conf` folder in the PCSE package.

        Returns:
            Configuration: Model configuration instance

        Raises:
            FileNotFoundError: if the configuraiton file does not exist
            RuntimeError: if parsing the configuration file fails
        """
        config = {}

        path = Path(filename)
        if path.is_absolute() or path.is_file():
            model_config_file = path
        else:
            pcse_dir = Path(pcse.__path__[0])
            model_config_file = pcse_dir / "conf" / path
        model_config_file = model_config_file.resolve()

        # check that configuration file exists
        if not model_config_file.exists():
            msg = f"PCSE model configuration file does not exist: {model_config_file.name}"
            raise FileNotFoundError(msg)
        # store for later use
        config["model_config_file"] = model_config_file

        # Load file using execfile
        try:
            loc = {}
            bytecode = compile(open(model_config_file).read(), model_config_file, "exec")
            exec(bytecode, {}, loc)
        except Exception as e:
            msg = f"Failed to load configuration from file {model_config_file}"
            raise RuntimeError(msg) from e

        # Add the descriptive header for later use
        if "__doc__" in loc:
            desc = loc.pop("__doc__")
            if len(desc) > 0:
                description = desc
                if description[-1] != "\n":
                    description += "\n"
            config["description"] = description

        # Loop through the attributes in the configuration file
        for key, value in loc.items():
            if key.isupper():
                config[key] = value
        return cls(**config)

    def update_output_variable_lists(
        self,
        output_vars: str | list | tuple | set | None = None,
        summary_vars: str | list | tuple | set | None = None,
        terminal_vars: str | list | tuple | set | None = None,
    ):
        """Updates the lists of output variables that are defined in the configuration file.

        This is useful because sometimes you want the flexibility to get access to an additional
        model variable which is not in the standard list of variables defined in the model
        configuration file. The more elegant way is to define your own configuration file, but this
        adds some flexibility particularly for use in jupyter notebooks and exploratory analysis.

        Note that there is a different behaviour given the type of the variable provided. List and
        string inputs will extend the list of variables, while set/tuple inputs will replace the
        current list.

        Args:
            output_vars: the variable names to add/replace for the OUTPUT_VARS configuration
                variable
            summary_vars: the variable names to add/replace for the SUMMARY_OUTPUT_VARS
                configuration variable
            terminal_vars: the variable names to add/replace for the TERMINAL_OUTPUT_VARS
                configuration variable

        Raises:
            TypeError: if the type of the input arguments is not recognized
        """
        config_varnames = ["OUTPUT_VARS", "SUMMARY_OUTPUT_VARS", "TERMINAL_OUTPUT_VARS"]
        for varitems, config_varname in zip(
            [output_vars, summary_vars, terminal_vars], config_varnames, strict=True
        ):
            if varitems is None:
                continue
            else:
                if isinstance(varitems, str):  # A string: we extend the current list
                    getattr(self, config_varname).extend(varitems.split())
                elif isinstance(varitems, list):  # a list: we extend the current list
                    getattr(self, config_varname).extend(varitems)
                elif isinstance(varitems, tuple | set):  # tuple/set we replace the current list
                    attr = getattr(self, config_varname)
                    attr.clear()
                    attr.extend(list(varitems))
                else:
                    msg = f"Unrecognized input for `output_vars` to engine(): {output_vars}"
                    raise TypeError(msg)
