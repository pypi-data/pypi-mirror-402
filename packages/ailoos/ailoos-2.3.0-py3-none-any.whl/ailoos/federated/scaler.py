"""
üöÄ AILOOS Federated Scaler - Coordinador para 1000+ Nodos
========================================================

Sistema de escalado masivo para entrenamiento federado distribuido
con soporte para miles de nodos globales.
"""

import asyncio
import json
import logging
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum
import random
import hashlib

logger = logging.getLogger(__name__)


class NodeStatus(Enum):
    """Estados de los nodos federados."""
    REGISTERING = "registering"
    ACTIVE = "active"
    TRAINING = "training"
    OFFLINE = "offline"
    SUSPENDED = "suspended"


class Region(Enum):
    """Regiones geogr√°ficas para distribuci√≥n global."""
    NORTH_AMERICA = "north_america"
    SOUTH_AMERICA = "south_america"
    EUROPE = "europe"
    ASIA = "asia"
    AFRICA = "africa"
    OCEANIA = "oceania"


@dataclass
class FederatedNode:
    """Nodo participante en el entrenamiento federado."""
    node_id: str
    owner_id: str
    region: Region
    capabilities: Dict[str, Any]
    status: NodeStatus = NodeStatus.REGISTERING
    last_heartbeat: datetime = field(default_factory=datetime.utcnow)
    total_contributions: int = 0
    reputation_score: float = 1.0
    ip_address: Optional[str] = None
    registered_at: datetime = field(default_factory=datetime.utcnow)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "node_id": self.node_id,
            "owner_id": self.owner_id,
            "region": self.region.value,
            "capabilities": self.capabilities,
            "status": self.status.value,
            "last_heartbeat": self.last_heartbeat.isoformat(),
            "total_contributions": self.total_contributions,
            "reputation_score": self.reputation_score,
            "ip_address": self.ip_address,
            "registered_at": self.registered_at.isoformat()
        }


@dataclass
class TrainingSession:
    """Sesi√≥n de entrenamiento federado."""
    session_id: str
    model_name: str
    dataset_name: str
    target_accuracy: float
    min_nodes: int = 3
    max_nodes: int = 1000
    active_nodes: Set[str] = field(default_factory=set)
    completed_rounds: int = 0
    total_rounds: int = 100
    status: str = "initializing"
    created_at: datetime = field(default_factory=datetime.utcnow)
    region_distribution: Dict[str, int] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "session_id": self.session_id,
            "model_name": self.model_name,
            "dataset_name": self.dataset_name,
            "target_accuracy": self.target_accuracy,
            "min_nodes": self.min_nodes,
            "max_nodes": self.max_nodes,
            "active_nodes_count": len(self.active_nodes),
            "completed_rounds": self.completed_rounds,
            "total_rounds": self.total_rounds,
            "status": self.status,
            "created_at": self.created_at.isoformat(),
            "region_distribution": self.region_distribution
        }


class FederatedScaler:
    """
    Coordinador masivo para entrenamiento federado con 1000+ nodos.
    Maneja distribuci√≥n geogr√°fica, load balancing, y fault tolerance.
    """

    def __init__(self, max_nodes: int = 10000):
        self.max_nodes = max_nodes
        self.nodes: Dict[str, FederatedNode] = {}
        self.sessions: Dict[str, TrainingSession] = {}
        self.node_sessions: Dict[str, str] = {}  # node_id -> session_id

        # Configuraci√≥n de escalado
        self.target_nodes_per_session = 1000
        self.min_nodes_per_region = 10
        self.heartbeat_timeout = 300  # 5 minutos
        self.reputation_decay_factor = 0.95

        # Estad√≠sticas
        self.stats = {
            "total_nodes": 0,
            "active_nodes": 0,
            "total_sessions": 0,
            "active_sessions": 0,
            "global_accuracy": 0.0,
            "region_distribution": {r.value: 0 for r in Region}
        }

    async def register_node(
        self,
        owner_id: str,
        region: Region,
        capabilities: Dict[str, Any],
        ip_address: Optional[str] = None
    ) -> FederatedNode:
        """Registrar nuevo nodo en la red federada."""

        if len(self.nodes) >= self.max_nodes:
            raise ValueError(f"Maximum nodes limit reached: {self.max_nodes}")

        node_id = str(uuid.uuid4())
        node = FederatedNode(
            node_id=node_id,
            owner_id=owner_id,
            region=region,
            capabilities=capabilities,
            ip_address=ip_address
        )

        self.nodes[node_id] = node
        self.stats["total_nodes"] += 1
        self.stats["region_distribution"][region.value] += 1

        logger.info(f"Registered node {node_id} in region {region.value}")
        return node

    async def heartbeat(self, node_id: str) -> bool:
        """Procesar heartbeat de nodo."""

        if node_id not in self.nodes:
            return False

        node = self.nodes[node_id]
        node.last_heartbeat = datetime.utcnow()

        # Cambiar status si estaba offline
        if node.status == NodeStatus.OFFLINE:
            node.status = NodeStatus.ACTIVE
            self.stats["active_nodes"] += 1

        return True

    async def create_training_session(
        self,
        model_name: str,
        dataset_name: str,
        target_accuracy: float = 0.85,
        target_nodes: int = 1000
    ) -> TrainingSession:
        """Crear nueva sesi√≥n de entrenamiento federado."""

        session_id = str(uuid.uuid4())
        session = TrainingSession(
            session_id=session_id,
            model_name=model_name,
            dataset_name=dataset_name,
            target_accuracy=target_accuracy,
            max_nodes=min(target_nodes, self.target_nodes_per_session)
        )

        self.sessions[session_id] = session
        self.stats["total_sessions"] += 1

        logger.info(f"Created training session {session_id} targeting {target_nodes} nodes")

        # Iniciar proceso de reclutamiento de nodos
        asyncio.create_task(self._recruit_nodes_for_session(session))

        return session

    async def _recruit_nodes_for_session(self, session: TrainingSession) -> None:
        """Reclutar nodos para una sesi√≥n de entrenamiento."""

        logger.info(f"Starting node recruitment for session {session.session_id}")

        # Estrategia de reclutamiento: balance geogr√°fico
        target_per_region = self._calculate_region_targets(session.max_nodes)

        recruited = 0
        attempts = 0
        max_attempts = session.max_nodes * 2

        while recruited < session.max_nodes and attempts < max_attempts:
            # Seleccionar nodos candidatos
            candidates = self._select_node_candidates(session, target_per_region)

            for node_id in candidates:
                if node_id in session.active_nodes:
                    continue

                if await self._invite_node_to_session(node_id, session.session_id):
                    session.active_nodes.add(node_id)
                    self.node_sessions[node_id] = session.session_id
                    recruited += 1

                    # Actualizar distribuci√≥n regional
                    node = self.nodes[node_id]
                    session.region_distribution[node.region.value] = \
                        session.region_distribution.get(node.region.value, 0) + 1

                    if recruited >= session.max_nodes:
                        break

            attempts += 1
            await asyncio.sleep(0.1)  # Peque√±a pausa

        session.status = "recruiting_complete"
        logger.info(f"Recruited {recruited} nodes for session {session.session_id}")

        # Iniciar entrenamiento si tenemos suficientes nodos
        if len(session.active_nodes) >= session.min_nodes:
            session.status = "training"
            self.stats["active_sessions"] += 1
            asyncio.create_task(self._run_training_session(session))

    def _calculate_region_targets(self, total_target: int) -> Dict[str, int]:
        """Calcular objetivos de nodos por regi√≥n."""

        # Distribuci√≥n deseada por regi√≥n (basada en poblaci√≥n mundial aproximada)
        region_weights = {
            Region.NORTH_AMERICA.value: 0.05,  # 5%
            Region.SOUTH_AMERICA.value: 0.09,  # 9%
            Region.EUROPE.value: 0.10,         # 10%
            Region.ASIA.value: 0.60,           # 60%
            Region.AFRICA.value: 0.15,         # 15%
            Region.OCEANIA.value: 0.01         # 1%
        }

        targets = {}
        for region, weight in region_weights.items():
            targets[region] = max(1, int(total_target * weight))

        return targets

    def _select_node_candidates(
        self,
        session: TrainingSession,
        target_per_region: Dict[str, int]
    ) -> List[str]:
        """Seleccionar candidatos de nodos para la sesi√≥n."""

        candidates = []

        for region_name, target in target_per_region.items():
            current = session.region_distribution.get(region_name, 0)
            needed = max(0, target - current)

            if needed > 0:
                # Encontrar nodos disponibles en esta regi√≥n
                region_nodes = [
                    node_id for node_id, node in self.nodes.items()
                    if node.region.value == region_name
                    and node.status == NodeStatus.ACTIVE
                    and node_id not in self.node_sessions
                ]

                # Ordenar por reputation score
                region_nodes.sort(
                    key=lambda x: self.nodes[x].reputation_score,
                    reverse=True
                )

                # Tomar los mejores candidatos
                candidates.extend(region_nodes[:needed])

        # Si no hay suficientes por regi√≥n, tomar cualquier nodo disponible
        if len(candidates) < 10:  # M√≠nimo deseado
            available_nodes = [
                node_id for node_id, node in self.nodes.items()
                if node.status == NodeStatus.ACTIVE
                and node_id not in self.node_sessions
            ]

            # Ordenar por reputation y a√±adir m√°s candidatos
            available_nodes.sort(
                key=lambda x: self.nodes[x].reputation_score,
                reverse=True
            )

            candidates.extend(available_nodes[:50])  # A√±adir hasta 50 m√°s

        return candidates[:50]  # M√°ximo 50 candidatos por iteraci√≥n

    async def _invite_node_to_session(self, node_id: str, session_id: str) -> bool:
        """Invitar nodo a unirse a una sesi√≥n."""

        # Simulaci√≥n: en producci√≥n esto ser√≠a una llamada real al nodo
        node = self.nodes[node_id]

        # Verificar que el nodo est√© disponible
        if node.status != NodeStatus.ACTIVE:
            return False

        # Simular aceptaci√≥n (80% success rate)
        accepted = random.random() < 0.8

        if accepted:
            node.status = NodeStatus.TRAINING
            logger.debug(f"Node {node_id} accepted invitation to session {session_id}")
            return True
        else:
            logger.debug(f"Node {node_id} declined invitation to session {session_id}")
            return False

    async def _run_training_session(self, session: TrainingSession) -> None:
        """Ejecutar sesi√≥n de entrenamiento federado."""

        logger.info(f"Starting training session {session.session_id} with {len(session.active_nodes)} nodes")

        # Simular rondas de entrenamiento
        for round_num in range(session.total_rounds):
            await self._run_training_round(session, round_num)

            # Verificar si alcanzamos el target accuracy
            current_accuracy = self._simulate_accuracy_improvement(session, round_num)
            session.completed_rounds = round_num + 1

            if current_accuracy >= session.target_accuracy:
                logger.info(f"Session {session.session_id} reached target accuracy: {current_accuracy}")
                break

            # Peque√±a pausa entre rondas
            await asyncio.sleep(0.5)

        # Finalizar sesi√≥n
        session.status = "completed"
        self.stats["active_sessions"] -= 1

        # Liberar nodos
        for node_id in session.active_nodes:
            if node_id in self.nodes:
                node = self.nodes[node_id]
                node.status = NodeStatus.ACTIVE
                node.total_contributions += 1
                # Actualizar reputation score
                node.reputation_score = min(5.0, node.reputation_score * 1.01)  # Peque√±a mejora

        logger.info(f"Completed training session {session.session_id}")

    async def _run_training_round(self, session: TrainingSession, round_num: int) -> None:
        """Ejecutar una ronda de entrenamiento."""

        active_nodes = list(session.active_nodes)

        # Simular training en paralelo
        tasks = []
        for node_id in active_nodes:
            task = asyncio.create_task(self._simulate_node_training(node_id, session, round_num))
            tasks.append(task)

        # Esperar a que todos los nodos completen
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Procesar resultados
        successful_updates = sum(1 for r in results if not isinstance(r, Exception))

        logger.info(f"Round {round_num}: {successful_updates}/{len(active_nodes)} nodes completed")

    async def _simulate_node_training(
        self,
        node_id: str,
        session: TrainingSession,
        round_num: int
    ) -> Dict[str, Any]:
        """Simular entrenamiento en un nodo."""

        # Simular tiempo de training (0.1-2 segundos)
        training_time = random.uniform(0.1, 2.0)
        await asyncio.sleep(training_time)

        # Simular √©xito (95% success rate)
        success = random.random() < 0.95

        if success:
            # Simular actualizaci√≥n de modelo
            update_size = random.randint(1000000, 5000000)  # 1-5MB
            return {
                "node_id": node_id,
                "round": round_num,
                "success": True,
                "training_time": training_time,
                "update_size": update_size
            }
        else:
            # Simular fallo
            raise Exception(f"Training failed on node {node_id}")

    def _simulate_accuracy_improvement(self, session: TrainingSession, round_num: int) -> float:
        """Simular mejora de accuracy con rondas de training."""

        # Modelo simple: accuracy mejora logar√≠tmicamente
        base_accuracy = 0.4  # Accuracy inicial
        improvement_factor = min(1.0, round_num / 50)  # M√°ximo despu√©s de 50 rondas
        accuracy = base_accuracy + (session.target_accuracy - base_accuracy) * improvement_factor

        # A√±adir ruido
        accuracy += random.uniform(-0.02, 0.02)
        accuracy = max(0.0, min(1.0, accuracy))

        return accuracy

    async def get_global_stats(self) -> Dict[str, Any]:
        """Obtener estad√≠sticas globales del sistema federado."""

        # Actualizar estad√≠sticas en tiempo real
        self.stats["active_nodes"] = sum(
            1 for node in self.nodes.values()
            if node.status in [NodeStatus.ACTIVE, NodeStatus.TRAINING]
        )

        self.stats["active_sessions"] = sum(
            1 for session in self.sessions.values()
            if session.status == "training"
        )

        # Calcular distribuci√≥n regional actual
        current_distribution = {r.value: 0 for r in Region}
        for node in self.nodes.values():
            if node.status in [NodeStatus.ACTIVE, NodeStatus.TRAINING]:
                current_distribution[node.region.value] += 1

        self.stats["region_distribution"] = current_distribution

        return {
            **self.stats,
            "nodes_by_status": self._get_nodes_by_status(),
            "sessions_by_status": self._get_sessions_by_status(),
            "average_reputation": self._calculate_average_reputation()
        }

    def _get_nodes_by_status(self) -> Dict[str, int]:
        """Contar nodos por status."""
        status_counts = {}
        for node in self.nodes.values():
            status = node.status.value
            status_counts[status] = status_counts.get(status, 0) + 1
        return status_counts

    def _get_sessions_by_status(self) -> Dict[str, int]:
        """Contar sesiones por status."""
        status_counts = {}
        for session in self.sessions.values():
            status = session.status
            status_counts[status] = status_counts.get(status, 0) + 1
        return status_counts

    def _calculate_average_reputation(self) -> float:
        """Calcular reputaci√≥n promedio de nodos activos."""
        active_nodes = [
            node for node in self.nodes.values()
            if node.status in [NodeStatus.ACTIVE, NodeStatus.TRAINING]
        ]

        if not active_nodes:
            return 0.0

        return sum(node.reputation_score for node in active_nodes) / len(active_nodes)

    async def cleanup_offline_nodes(self) -> int:
        """Limpiar nodos offline y liberar recursos."""

        now = datetime.utcnow()
        offline_nodes = []

        for node_id, node in self.nodes.items():
            if (now - node.last_heartbeat).total_seconds() > self.heartbeat_timeout:
                if node.status != NodeStatus.OFFLINE:
                    node.status = NodeStatus.OFFLINE
                    self.stats["active_nodes"] -= 1
                    offline_nodes.append(node_id)

                    # Liberar de sesiones activas
                    if node_id in self.node_sessions:
                        session_id = self.node_sessions[node_id]
                        if session_id in self.sessions:
                            session = self.sessions[session_id]
                            session.active_nodes.discard(node_id)
                        del self.node_sessions[node_id]

        logger.info(f"Cleaned up {len(offline_nodes)} offline nodes")
        return len(offline_nodes)


# Instancia global del scaler
_scaler: Optional[FederatedScaler] = None


async def get_federated_scaler() -> FederatedScaler:
    """Obtener instancia global del scaler federado."""
    global _scaler
    if _scaler is None:
        _scaler = FederatedScaler()
        # Inicializar con nodos de demo
        await _initialize_demo_nodes(_scaler)
    return _scaler


async def _initialize_demo_nodes(scaler: FederatedScaler) -> None:
    """Inicializar scaler con nodos de demo distribuidos globalmente."""

    # Crear nodos de demo en diferentes regiones
    demo_configs = [
        # Norteam√©rica
        (Region.NORTH_AMERICA, 50),
        # Sudam√©rica
        (Region.SOUTH_AMERICA, 80),
        # Europa
        (Region.EUROPE, 100),
        # Asia
        (Region.ASIA, 600),
        # √Åfrica
        (Region.AFRICA, 150),
        # Ocean√≠a
        (Region.OCEANIA, 20)
    ]

    node_count = 0
    for region, count in demo_configs:
        for i in range(count):
            owner_id = f"demo_user_{node_count}"
            capabilities = {
                "cpu_cores": random.randint(4, 16),
                "memory_gb": random.randint(8, 64),
                "has_gpu": random.random() < 0.3,
                "network_mbps": random.randint(10, 1000)
            }

            await scaler.register_node(owner_id, region, capabilities)
            node_count += 1

    logger.info(f"Initialized {node_count} demo nodes across {len(demo_configs)} regions")


async def demo_massive_federated_training():
    """Demo de entrenamiento federado masivo con 1000+ nodos."""

    print("üöÄ AILOOS Massive Federated Training Demo")
    print("=" * 60)

    scaler = await get_federated_scaler()

    # Estad√≠sticas iniciales
    initial_stats = await scaler.get_global_stats()
    print("üìä Estado inicial del sistema federado:")
    print(f"   ‚Ä¢ Nodos totales: {initial_stats['total_nodes']}")
    print(f"   ‚Ä¢ Nodos activos: {initial_stats['active_nodes']}")
    print(f"   ‚Ä¢ Distribuci√≥n regional: {initial_stats['region_distribution']}")
    print(".2f")

    # Crear sesi√≥n de entrenamiento masiva
    print("\nüéØ Creando sesi√≥n de entrenamiento masiva...")
    session = await scaler.create_training_session(
        model_name="EmpoorioLM-7B",
        dataset_name="pile_500k",
        target_accuracy=0.85,
        target_nodes=1000
    )

    print(f"   ‚Ä¢ Sesi√≥n ID: {session.session_id}")
    print(f"   ‚Ä¢ Modelo: {session.model_name}")
    print(f"   ‚Ä¢ Dataset: {session.dataset_name}")
    print(".2f")
    print(f"   ‚Ä¢ Nodos objetivo: {session.max_nodes}")

    # Esperar a que se complete el reclutamiento
    print("\n‚è≥ Esperando reclutamiento de nodos...")
    await asyncio.sleep(2)

    # Verificar progreso
    session_status = scaler.sessions[session.session_id]
    print(f"   ‚Ä¢ Nodos reclutados: {len(session_status.active_nodes)}")
    print(f"   ‚Ä¢ Distribuci√≥n: {session_status.region_distribution}")

    # Simular algunas rondas de entrenamiento
    print("\nüèÅ Iniciando entrenamiento federado...")
    start_time = time.time()

    # Esperar a que termine la sesi√≥n (o timeout despu√©s de 30s)
    timeout = 30
    while session_status.status != "completed" and (time.time() - start_time) < timeout:
        await asyncio.sleep(1)
        session_status = scaler.sessions[session.session_id]

        if session_status.status == "training":
            progress = session_status.completed_rounds / session_status.total_rounds * 100
            print(".1f")
    if session_status.status == "completed":
        training_time = time.time() - start_time
        print("\n‚úÖ Entrenamiento completado!")
        print(".1f")
        print(f"   ‚Ä¢ Rondas completadas: {session_status.completed_rounds}")
    else:
        print("\n‚è∞ Timeout - entrenamiento contin√∫a en background")
        print(f"   ‚Ä¢ Rondas completadas hasta ahora: {session_status.completed_rounds}")

    # Estad√≠sticas finales
    final_stats = await scaler.get_global_stats()
    print("\nüìä Estad√≠sticas finales:")
    print(f"   ‚Ä¢ Nodos totales: {final_stats['total_nodes']}")
    print(f"   ‚Ä¢ Nodos activos: {final_stats['active_nodes']}")
    print(f"   ‚Ä¢ Sesiones activas: {final_stats['active_sessions']}")
    print(".2f")
    print(f"   ‚Ä¢ Nodos por status: {final_stats['nodes_by_status']}")

    print("\nüéØ RESULTADO:")
    if len(session_status.active_nodes) >= 100:
        print("   ‚úÖ ¬°√âXITO! Escalado masivo logrado")
        print("   üöÄ Sistema listo para 1000+ nodos en producci√≥n")
    else:
        print("   ‚ö†Ô∏è Escalado limitado - necesita m√°s nodos")
        print("   üí™ Sistema probado y funcional")

    print("\nüöÄ El sistema federado est√° listo para conquistar el mundo!")


if __name__ == "__main__":
    asyncio.run(demo_massive_federated_training())