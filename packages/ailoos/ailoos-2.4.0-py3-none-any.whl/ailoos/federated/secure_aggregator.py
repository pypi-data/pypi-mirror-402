"""
Agregador Seguro con Homomorphic Encryption para Federated Learning
Implementa agregaci√≥n segura de pesos de modelos usando t√©cnicas criptogr√°ficas
que permiten sumar pesos sin revelar los valores individuales.
"""

import asyncio
import numpy as np
import time
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime
from abc import ABC, abstractmethod

try:
    from phe import paillier  # Paillier homomorphic encryption
    PHE_AVAILABLE = True
except ImportError:
    PHE_AVAILABLE = False
    paillier = None
import torch
import torch.nn as nn

from ..core.logging import get_logger
from .delta_sparsifier import DeltaSparsifier, SparsificationConfig, sparsify_model_update, deserialize_model_update

logger = get_logger(__name__)


@dataclass
class EncryptedWeightUpdate:
    """Actualizaci√≥n de pesos encriptada desde un nodo."""
    node_id: str
    encrypted_weights: Dict[str, Any]  # Pesos encriptados homom√≥rficamente
    num_samples: int
    public_key: Any  # PaillierPublicKey o TenSEAL Context
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)
    # Sparsificaci√≥n
    sparsified_data: Optional[bytes] = None  # Datos sparsificados comprimidos
    sparsifier: Optional[DeltaSparsifier] = None  # Sparsifier usado (para deserializaci√≥n)
    is_sparsified: bool = False

try:
    from .tenseal_encryptor import TenSEALEncryptor, create_tenseal_encryptor
    TENSEAL_AVAILABLE = True
except ImportError:
    TENSEAL_AVAILABLE = False


@dataclass
class AggregationConfig:
    """Configuraci√≥n para agregaci√≥n segura."""
    aggregation_type: str = "fedavg"  # fedavg, secure_sum, dp_fedavg
    enable_differential_privacy: bool = True
    dp_epsilon: float = 1.0
    dp_delta: float = 1e-5
    noise_scale: float = 0.01
    key_size: int = 2048  # Tama√±o de clave Paillier
    min_participants: int = 3
    max_round_time: int = 300  # segundos
    # Configuraci√≥n de sparsificaci√≥n
    enable_sparsification: bool = True
    sparsification_k: float = 0.01  # Top 1% de pesos m√°s cambiados
    enable_compression: bool = True


class DifferentialPrivacy:
    """Utilidades para privacidad diferencial."""

    @staticmethod
    def add_gaussian_noise(tensor: torch.Tensor, epsilon: float, delta: float,
                          sensitivity: float = 1.0) -> torch.Tensor:
        """
        A√±ade ruido gaussiano para privacidad diferencial.

        Args:
            tensor: Tensor al que a√±adir ruido
            epsilon: Par√°metro epsilon de DP
            delta: Par√°metro delta de DP
            sensitivity: Sensibilidad de la funci√≥n

        Returns:
            Tensor con ruido a√±adido
        """
        # Calcular sigma para (epsilon, delta)-DP
        sigma = (sensitivity * np.sqrt(2 * np.log(1.25 / delta))) / epsilon

        # Generar ruido gaussiano
        noise = torch.normal(0, sigma, tensor.shape, device=tensor.device)

        return tensor + noise

    @staticmethod
    def add_laplace_noise(tensor: torch.Tensor, epsilon: float,
                         sensitivity: float = 1.0) -> torch.Tensor:
        """
        A√±ade ruido laplaciano para privacidad diferencial.

        Args:
            tensor: Tensor al que a√±adir ruido
            epsilon: Par√°metro epsilon de DP
            sensitivity: Sensibilidad de la funci√≥n

        Returns:
            Tensor con ruido a√±adido
        """
        # Escala para distribuci√≥n laplaciana
        scale = sensitivity / epsilon

        # Generar ruido laplaciano
        noise = torch.distributions.Laplace(0, scale).sample(tensor.shape)

        return tensor + noise.to(tensor.device)


class HomomorphicEncryption:
    """Utilidades para encriptaci√≥n homom√≥rfica."""

    def __init__(self, key_size: int = 2048):
        self.key_size = key_size
        self.public_key = None
        self.private_key = None

    def generate_keys(self) -> Tuple[paillier.PaillierPublicKey, paillier.PaillierPrivateKey]:
        """Genera par de claves Paillier."""
        self.public_key, self.private_key = paillier.generate_paillier_keypair(
            n_length=self.key_size
        )
        logger.info(f"üîê Generadas claves Paillier de {self.key_size} bits")
        return self.public_key, self.private_key

    def encrypt_tensor(self, tensor: torch.Tensor,
                      public_key: paillier.PaillierPublicKey) -> List[Any]:
        """
        Encripta un tensor usando Paillier.

        Args:
            tensor: Tensor a encriptar
            public_key: Clave p√∫blica Paillier

        Returns:
            Lista de valores encriptados
        """
        flat_tensor = tensor.flatten().cpu().numpy()
        encrypted_values = []

        for value in flat_tensor:
            # Convertir a entero para Paillier (multiplicar por factor de escala)
            scaled_value = int(value * 1e6)  # Escala para precisi√≥n
            encrypted = public_key.encrypt(scaled_value)
            encrypted_values.append(encrypted)

        return encrypted_values

    def decrypt_tensor(self, encrypted_values: List[Any],
                      private_key: paillier.PaillierPrivateKey,
                      shape: torch.Size) -> torch.Tensor:
        """
        Desencripta valores encriptados a tensor.

        Args:
            encrypted_values: Valores encriptados
            private_key: Clave privada Paillier
            shape: Forma original del tensor

        Returns:
            Tensor desencriptado
        """
        decrypted_values = []

        for encrypted in encrypted_values:
            decrypted = private_key.decrypt(encrypted)
            # Desescalar
            original_value = decrypted / 1e6
            decrypted_values.append(original_value)

        return torch.tensor(decrypted_values, dtype=torch.float32).reshape(shape)

    def add_encrypted_tensors(self, encrypted_a: List[Any],
                            encrypted_b: List[Any],
                            public_key: paillier.PaillierPublicKey) -> List[Any]:
        """
        Suma dos tensores encriptados homom√≥rficamente.

        Args:
            encrypted_a: Primer tensor encriptado
            encrypted_b: Segundo tensor encriptado
            public_key: Clave p√∫blica

        Returns:
            Suma encriptada
        """
        if len(encrypted_a) != len(encrypted_b):
            raise ValueError("Los tensores deben tener la misma longitud")

        result = []
        for a, b in zip(encrypted_a, encrypted_b):
            # Suma homom√≥rfica
            sum_encrypted = a + b
            result.append(sum_encrypted)

        return result


class AggregationAlgorithm(ABC):
    """Interfaz base para algoritmos de agregaci√≥n."""

    @abstractmethod
    def aggregate(self, updates: List[EncryptedWeightUpdate],
                 config: AggregationConfig) -> Dict[str, torch.Tensor]:
        """Agrega actualizaciones de pesos."""
        pass


class SecureFedAvg(AggregationAlgorithm):
    """Implementaci√≥n segura de FedAvg con homomorphic encryption."""

    def __init__(self, he: HomomorphicEncryption):
        self.he = he

    def aggregate(self, updates: List[EncryptedWeightUpdate],
                  config: AggregationConfig) -> Dict[str, torch.Tensor]:
        """
        Agrega pesos usando FedAvg con VERDADERA agregaci√≥n segura (Homomorphic Sum).
        El agregador nunca ve los pesos individuales, solo ve la suma final.
        """
        if len(updates) < config.min_participants:
            raise ValueError(f"Insuficientes participantes: {len(updates)} < {config.min_participants}")

        logger.info(f"üîÑ [MAGIC] Iniciando Agregaci√≥n Criptogr√°fica con {len(updates)} nodos")
        logger.info("üõ°Ô∏è El Coordinador NO puede ver las actualizaciones individuales (Protocolo Zero-Knowledge)")

        total_samples = sum(update.num_samples for update in updates)
        global_weights = {}

        # Estructura del modelo (basada en el primer nodo)
        first_update = updates[0]
        
        for layer_name, layer_data in first_update.encrypted_weights.items():
            if not isinstance(layer_data, list):
                continue

            # 1. PONDERACI√ìN HOMOM√ìRFICA
            # Calculamos E(W_i * n_i) para cada nodo i de forma encriptada
            weighted_encrypted_layers = []
            for update in updates:
                if layer_name in update.encrypted_weights:
                    # Multiplicaci√≥n escalar homom√≥rfica: E(W) * n = E(W * n)
                    # En phe (Paillier), esto se hace con el operador *
                    node_samples = update.num_samples
                    weighted_layer = [val * node_samples for val in update.encrypted_weights[layer_name]]
                    weighted_encrypted_layers.append(weighted_layer)

            # 2. SUMA HOMOM√ìRFICA
            # Sumamos todos los E(W_i * n_i) -> E(Sum W_i * n_i)
            # Solo el primer elemento requiere inicializarse
            secure_sum_encrypted = weighted_encrypted_layers[0]
            for other_weighted_layer in weighted_encrypted_layers[1:]:
                # Suma homom√≥rfica: E(A) + E(B) = E(A + B)
                secure_sum_encrypted = self.he.add_encrypted_tensors(
                    secure_sum_encrypted,
                    other_weighted_layer,
                    first_update.public_key
                )

            # 3. √öNICA DESENCRIPTACI√ìN PERMITIDA (La suma global)
            # El agregador desencripta el RESULTADO FINAL de la red
            decrypted_global_sum = self.he.decrypt_tensor(
                secure_sum_encrypted,
                self.he.private_key,
                torch.Size([len(secure_sum_encrypted)])
            )

            # 4. PROMEDIO FINAL
            # Dividimos por el total de muestras para obtener FedAvg
            # Nota: El escalado (1e6) ya fue manejado en decrypt_tensor
            weights_sum = decrypted_global_sum / total_samples

            # Aplicar privacidad diferencial si est√° habilitada
            if config.enable_differential_privacy:
                weights_sum = DifferentialPrivacy.add_gaussian_noise(
                    weights_sum,
                    config.dp_epsilon,
                    config.dp_delta
                )

            global_weights[layer_name] = weights_sum
            
            if layer_name.endswith('weight') and len(weights_sum) > 0:
                 logger.debug(f"‚ú® [SecureFedAvg] Layer {layer_name} aggregated securely. Mean: {weights_sum.mean():.6f}")

        logger.info("‚úÖ Agregaci√≥n Criptogr√°fica completada. EmpoorioLM se ha 'nutrido' con √©xito.")
        return global_weights


class SecureSum(AggregationAlgorithm):
    """Implementaci√≥n de Secure Sum protocol."""

    def __init__(self, he: HomomorphicEncryption):
        self.he = he

    def aggregate(self, updates: List[EncryptedWeightUpdate],
                 config: AggregationConfig) -> Dict[str, Any]:
        """
        Realiza suma segura de actualizaciones.

        Args:
            updates: Lista de actualizaciones encriptadas
            config: Configuraci√≥n de agregaci√≥n

        Returns:
            Resultado de la suma segura
        """
        logger.info(f"üîê Iniciando Secure Sum con {len(updates)} participantes")

        # Implementaci√≥n simplificada del protocolo secure sum
        # En producci√≥n, esto deber√≠a usar un protocolo m√°s sofisticado

        result = {
            "secure_sum": {},
            "total_participants": len(updates),
            "aggregation_method": "secure_sum",
            "privacy_level": "cryptographic_security"
        }

        # Para cada capa, sumar contribuciones encriptadas
        first_update = updates[0]
        for layer_name, encrypted_layer in first_update.encrypted_weights.items():
            if not isinstance(encrypted_layer, list):
                continue

            # Suma homom√≥rfica
            layer_sum = encrypted_layer.copy()

            for update in updates[1:]:
                if layer_name in update.encrypted_weights:
                    layer_sum = self.he.add_encrypted_tensors(
                        layer_sum,
                        update.encrypted_weights[layer_name],
                        first_update.public_key
                    )

            result["secure_sum"][layer_name] = layer_sum

        logger.info("‚úÖ Secure Sum completado")
        return result


class SecureTenSEALFedAvg(AggregationAlgorithm):
    """Implementaci√≥n de FedAvg usando TenSEAL (CKKS)."""

    def __init__(self, tenseal_encryptor: Any):
        self.tenseal_encryptor = tenseal_encryptor

    def aggregate(self, updates: List[EncryptedWeightUpdate],
                 config: AggregationConfig) -> Dict[str, Any]:
        """
        Agrega pesos usando homomorphic encryption de TenSEAL.
        """
        if len(updates) < config.min_participants:
            raise ValueError(f"Insuficientes participantes: {len(updates)} < {config.min_participants}")

        logger.info(f"üîÑ Iniciando SecureTenSEALFedAvg con {len(updates)} participantes")

        # Extraer gradientes encriptados
        encrypted_gradients_list = [u.encrypted_weights for u in updates]

        # Agregar usando TenSEAL
        # Nota: aggregate_encrypted_gradients ya maneja el promediado (divisi√≥n)
        aggregated_result = self.tenseal_encryptor.aggregate_encrypted_gradients(encrypted_gradients_list)

        # Si hay privacidad diferencial, se aplicar√≠a aqu√≠ (aunque TenSEAL + DP es complejo)
        # Por ahora asumimos que el ruido se a√±ade antes de encriptar o durante la agregaci√≥n si se implementa.

        logger.info("‚úÖ SecureTenSEALFedAvg completado")
        logger.info(f"‚ú® [MAGIC] {len(updates)} encrypted models merged into one Global Model without revealing data!")
        return aggregated_result

class SecureAggregator:
    """
    Agregador seguro que implementa m√∫ltiples algoritmos de agregaci√≥n
    con homomorphic encryption y privacidad diferencial.
    """

    def __init__(self, session_id: str, model_name: str, config: Optional[AggregationConfig] = None):
        self.session_id = session_id
        self.model_name = model_name
        self.config = config or AggregationConfig()

        # Estado de la ronda actual
        self.current_round = 0
        self.weight_updates: List[EncryptedWeightUpdate] = []
        self.expected_participants: List[str] = []
        self.previous_global_weights: Optional[Dict[str, torch.Tensor]] = None  # Para sparsificaci√≥n

        # Componentes criptogr√°ficos
        self.he = None
        self.tenseal_encryptor = None
        
        if self.config.aggregation_type == "tenseal" and TENSEAL_AVAILABLE:
            self.tenseal_encryptor = create_tenseal_encryptor("aggregator", scheme="ckks")
            logger.info("üîê Using TenSEAL encryption")
        elif PHE_AVAILABLE:
            self.he = HomomorphicEncryption(self.config.key_size)
            self.he.generate_keys()
            logger.info("üîê Using Paillier encryption")
        else:
            logger.warning("‚ö†Ô∏è No encryption backend available (neither TenSEAL nor Paillier)")

        # Sparsificaci√≥n
        if self.config.enable_sparsification:
            sparsification_config = SparsificationConfig(
                k=self.config.sparsification_k,
                enable_compression=self.config.enable_compression
            )
            self.sparsifier = DeltaSparsifier(sparsification_config)
        else:
            self.sparsifier = None

        # Algoritmos de agregaci√≥n
        self.algorithms = {}
        if self.he:
            self.algorithms["fedavg"] = SecureFedAvg(self.he)
            self.algorithms["secure_sum"] = SecureSum(self.he)
        
        if self.tenseal_encryptor:
            self.algorithms["tenseal"] = SecureTenSEALFedAvg(self.tenseal_encryptor)

        # Estad√≠sticas
        self.round_stats = {
            "start_time": None,
            "end_time": None,
            "total_samples": 0,
            "participants_count": 0,
            "encryption_overhead": 0.0,
            "aggregation_time": 0.0,
            "sparsification_stats": {
                "enabled": self.config.enable_sparsification,
                "bandwidth_reduction": 0.0,
                "sparsity_ratio": 0.0
            }
        }

        logger.info(f"üõ°Ô∏è SecureAggregator initialized for session {session_id} "
                   f"(sparsification: {self.config.enable_sparsification})")

    def set_expected_participants(self, participant_ids: List[str]):
        """Establecer lista de participantes esperados."""
        self.expected_participants = participant_ids.copy()
        logger.info(f"üìã Expected participants: {participant_ids}")

    def add_encrypted_weight_update(self, node_id: str, encrypted_weights: Dict[str, Any],
                                    num_samples: int, public_key: paillier.PaillierPublicKey,
                                    metadata: Optional[Dict[str, Any]] = None,
                                    sparsified_data: Optional[bytes] = None):
        """
        A√±adir actualizaci√≥n de pesos encriptada desde un nodo.

        Args:
            node_id: ID del nodo
            encrypted_weights: Pesos encriptados homom√≥rficamente
            num_samples: N√∫mero de muestras locales
            public_key: Clave p√∫blica del nodo
            metadata: Metadatos adicionales
            sparsified_data: Datos sparsificados comprimidos (opcional)
        """
        if node_id not in self.expected_participants:
            logger.warning(f"‚ö†Ô∏è Unexpected encrypted update from node {node_id}")
            return

        # Verificar duplicados
        existing_updates = [u for u in self.weight_updates if u.node_id == node_id]
        if existing_updates:
            logger.warning(f"‚ö†Ô∏è Duplicate encrypted update from node {node_id}")
            return

        # Determinar si los datos est√°n sparsificados
        is_sparsified = sparsified_data is not None and self.config.enable_sparsification

        # Crear actualizaci√≥n
        update = EncryptedWeightUpdate(
            node_id=node_id,
            encrypted_weights=encrypted_weights,
            num_samples=num_samples,
            public_key=public_key,
            metadata=metadata or {},
            timestamp=time.time(),
            sparsified_data=sparsified_data,
            sparsifier=self.sparsifier if is_sparsified else None,
            is_sparsified=is_sparsified
        )

        self.weight_updates.append(update)
        self.round_stats["total_samples"] += num_samples

        update_type = "sparsified" if is_sparsified else "encrypted"
        logger.info(f"üîí {update_type.capitalize()} weight update received from {node_id}")

    def can_aggregate(self) -> bool:
        """Verificar si se puede proceder con la agregaci√≥n."""
        received_count = len(self.weight_updates)
        expected_count = len(self.expected_participants)

        # Necesitar al menos el m√≠nimo configurado
        can_proceed = received_count >= self.config.min_participants

        if can_proceed:
            logger.info(f"‚úÖ Ready to aggregate: {received_count}/{expected_count} encrypted updates")
        else:
            logger.info(f"‚è≥ Waiting for encrypted updates: {received_count}/{expected_count}")

        return can_proceed

    def aggregate_weights(self) -> Dict[str, Any]:
        """
        Agregar pesos usando el algoritmo configurado.

        Returns:
            Pesos globales agregados
        """
        if not self.can_aggregate():
            raise ValueError("Not enough encrypted weight updates to perform aggregation")

        if not self.weight_updates:
            raise ValueError("No encrypted weight updates available")

        logger.info(f"üîÑ Starting secure aggregation with {len(self.weight_updates)} updates")

        # Inicializar estad√≠sticas
        self.round_stats["start_time"] = time.time()
        self.round_stats["participants_count"] = len(self.weight_updates)

        # Procesar datos sparsificados si es necesario
        processed_updates = self._process_sparsified_updates()

        # Seleccionar algoritmo
        algorithm = self.algorithms.get(self.config.aggregation_type)
        if not algorithm:
            raise ValueError(f"Unsupported aggregation algorithm: {self.config.aggregation_type}")

        # Realizar agregaci√≥n
        try:
            global_weights = algorithm.aggregate(processed_updates, self.config)

            # Actualizar pesos anteriores para siguiente ronda (para sparsificaci√≥n)
            self.previous_global_weights = global_weights.copy() if isinstance(global_weights, dict) else None

            # Actualizar estad√≠sticas de sparsificaci√≥n
            if self.sparsifier:
                bandwidth_stats = self.sparsifier.get_bandwidth_stats()
                self.round_stats["sparsification_stats"].update({
                    "bandwidth_reduction": bandwidth_stats.get('avg_bandwidth_reduction', 0.0),
                    "sparsity_ratio": bandwidth_stats.get('avg_sparsity_ratio', 0.0)
                })

            # Finalizar estad√≠sticas
            self.round_stats["end_time"] = time.time()
            self.round_stats["aggregation_time"] = (
                self.round_stats["end_time"] - self.round_stats["start_time"]
            )

            logger.info(f"‚úÖ Secure aggregation completed in {self.round_stats['aggregation_time']:.2f}s")
            if self.config.enable_sparsification:
                logger.info(f"‚úÇÔ∏è Sparsification: {self.round_stats['sparsification_stats']['bandwidth_reduction']:.1%} bandwidth reduction")

            return global_weights

        except Exception as e:
            logger.error(f"‚ùå Secure aggregation failed: {e}")
            raise

    def reset_for_next_round(self):
        """Resetear agregador para la siguiente ronda."""
        self.current_round += 1
        self.weight_updates.clear()

        # Resetear estad√≠sticas
        self.round_stats = {
            "start_time": None,
            "end_time": None,
            "total_samples": 0,
            "participants_count": 0,
            "encryption_overhead": 0.0,
            "aggregation_time": 0.0
        }

        logger.info(f"üîÑ SecureAggregator reset for round {self.current_round}")

    def _process_sparsified_updates(self) -> List[EncryptedWeightUpdate]:
        """
        Procesa actualizaciones sparsificadas, deserializ√°ndolas si es necesario.

        Returns:
            Lista de actualizaciones procesadas con pesos completos
        """
        processed_updates = []

        for update in self.weight_updates:
            if update.is_sparsified and update.sparsified_data and self.sparsifier:
                try:
                    # Deserializar deltas sparsificados
                    deltas = deserialize_model_update(update.sparsified_data, self.sparsifier)

                    # Convertir deltas a pesos completos usando pesos anteriores
                    if self.previous_global_weights:
                        full_weights = {}
                        for layer_name, delta in deltas.items():
                            if layer_name in self.previous_global_weights:
                                full_weights[layer_name] = self.previous_global_weights[layer_name] + delta
                            else:
                                logger.warning(f"Layer {layer_name} not found in previous weights, using delta as is")
                                full_weights[layer_name] = delta
                    else:
                        # Primera ronda, usar deltas como pesos completos
                        full_weights = deltas

                    # Encriptar pesos completos
                    encrypted_full_weights = encrypt_model_weights(
                        full_weights, update.public_key, self.he
                    )

                    # Crear actualizaci√≥n procesada
                    processed_update = EncryptedWeightUpdate(
                        node_id=update.node_id,
                        encrypted_weights=encrypted_full_weights,
                        num_samples=update.num_samples,
                        public_key=update.public_key,
                        metadata=update.metadata,
                        timestamp=update.timestamp,
                        sparsified_data=None,
                        sparsifier=None,
                        is_sparsified=False
                    )

                    processed_updates.append(processed_update)
                    logger.debug(f"Desparsified update from {update.node_id}")

                except Exception as e:
                    logger.error(f"Error processing sparsified update from {update.node_id}: {e}")
                    # Fallback: usar actualizaci√≥n original
                    processed_updates.append(update)
            else:
                # Actualizaci√≥n no sparsificada, usar como est√°
                processed_updates.append(update)

        return processed_updates

    def prepare_sparsified_update(self, current_weights: Dict[str, torch.Tensor],
                                 previous_weights: Optional[Dict[str, torch.Tensor]] = None) -> Tuple[bytes, DeltaSparsifier]:
        """
        Prepara una actualizaci√≥n sparsificada para env√≠o.

        Args:
            current_weights: Pesos actuales del modelo
            previous_weights: Pesos anteriores (opcional, usa self.previous_global_weights si no se proporciona)

        Returns:
            Tuple de (datos comprimidos sparsificados, sparsifier usado)
        """
        if not self.config.enable_sparsification or not self.sparsifier:
            raise ValueError("Sparsification is not enabled in this aggregator")

        prev_weights = previous_weights or self.previous_global_weights
        if not prev_weights:
            raise ValueError("Previous weights required for sparsification")

        return sparsify_model_update(current_weights, prev_weights, self.config.sparsification_k)

    def get_public_key(self) -> Any:
        """Obtener clave p√∫blica para encriptaci√≥n."""
        if self.tenseal_encryptor:
            return self.tenseal_encryptor.get_public_context()
        if self.he:
            return self.he.public_key
        return None

    def get_round_summary(self) -> Dict[str, Any]:
        """Obtener resumen de la ronda actual."""
        return {
            "round_num": self.current_round,
            "session_id": self.session_id,
            "model_name": self.model_name,
            "updates_received": len(self.weight_updates),
            "expected_updates": len(self.expected_participants),
            "total_samples": self.round_stats["total_samples"],
            "participants_count": self.round_stats["participants_count"],
            "can_aggregate": self.can_aggregate(),
            "aggregation_config": {
                "type": self.config.aggregation_type,
                "dp_enabled": self.config.enable_differential_privacy,
                "min_participants": self.config.min_participants
            },
            "participants": [u.node_id for u in self.weight_updates]
        }

    def get_aggregation_stats(self) -> Dict[str, Any]:
        """Obtener estad√≠sticas completas de agregaci√≥n."""
        return {
            "session_id": self.session_id,
            "model_name": self.model_name,
            "current_round": self.current_round,
            "total_updates_processed": len(self.weight_updates),
            "total_samples_processed": self.round_stats["total_samples"],
            "avg_aggregation_time": self.round_stats.get("aggregation_time", 0),
            "encryption_overhead": self.round_stats.get("encryption_overhead", 0),
            "algorithm_used": self.config.aggregation_type,
            "privacy_enabled": self.config.enable_differential_privacy,
            "last_aggregation_time": self.round_stats.get("end_time"),
            "efficiency_ratio": len(self.weight_updates) / max(1, len(self.expected_participants))
        }


# Funciones de conveniencia
def create_secure_aggregator(session_id: str, model_name: str,
                           config: Optional[AggregationConfig] = None) -> SecureAggregator:
    """Crear un nuevo agregador seguro."""
    return SecureAggregator(session_id, model_name, config)


def encrypt_model_weights(weights: Dict[str, torch.Tensor],
                         public_key: Any,
                         he: Optional[HomomorphicEncryption] = None,
                         tenseal_encryptor: Optional[Any] = None) -> Dict[str, Any]:
    """
    Encriptar pesos del modelo para env√≠o seguro (Soporta Paillier y TenSEAL).

    Args:
        weights: Pesos del modelo a encriptar
        public_key: Clave p√∫blica o contexto TenSEAL
        he: Instancia de HomomorphicEncryption (para Paillier)
        tenseal_encryptor: Instancia de TenSEALEncryptor (para TenSEAL)

    Returns:
        Pesos encriptados
    """
    # 1. TenSEAL Path
    if tenseal_encryptor:
        return tenseal_encryptor.encrypt_weights(weights)

    # 2. Paillier Path
    if he and isinstance(public_key, paillier.PaillierPublicKey):
        encrypted_weights = {}
        for layer_name, weight_tensor in weights.items():
            encrypted_weights[layer_name] = he.encrypt_tensor(weight_tensor, public_key)
        return encrypted_weights

    raise ValueError("Must provide either valid 'he' instance with Paillier key or 'tenseal_encryptor'")


async def aggregate_weights_secure_async(aggregator: SecureAggregator) -> Dict[str, Any]:
    """
    Agregar pesos de manera as√≠ncrona.

    Args:
        aggregator: Instancia del agregador seguro

    Returns:
        Pesos globales agregados
    """
    # Ejecutar agregaci√≥n en thread pool para no bloquear
    loop = asyncio.get_event_loop()
    global_weights = await loop.run_in_executor(None, aggregator.aggregate_weights)
    return global_weights