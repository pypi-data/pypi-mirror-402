"""
Implementaci√≥n de sparsificaci√≥n top-k para deltas de pesos en protocolos federados P2P.
Reduce el ancho de banda enviando solo los pesos m√°s cambiados (1% superior) en lugar de deltas completos.
"""

import torch
import numpy as np
import logging
from typing import Dict, List, Any, Tuple, Optional, Set
from dataclasses import dataclass, field
from collections import defaultdict
import pickle
import zlib

logger = logging.getLogger(__name__)


@dataclass
class SparsifiedDelta:
    """Estructura para deltas sparsificados."""
    layer_name: str
    indices: torch.Tensor  # √çndices de los pesos sparsificados
    values: torch.Tensor   # Valores sparsificados
    original_shape: torch.Size
    sparsity_ratio: float  # Ratio de sparsificaci√≥n (0.01 = 1%)
    total_elements: int
    sparsified_elements: int


@dataclass
class SparsificationConfig:
    """Configuraci√≥n para sparsificaci√≥n de deltas."""
    k: float = 0.01  # Fracci√≥n de pesos a mantener (0.01 = 1%)
    enable_compression: bool = True  # Habilitar compresi√≥n adicional
    compression_level: int = 6  # Nivel de compresi√≥n zlib
    min_sparsity_ratio: float = 0.005  # Sparsity m√≠nimo (0.5%)
    max_sparsity_ratio: float = 0.1  # Sparsity m√°ximo (10%)


class DeltaSparsifier:
    """
    Implementa sparsificaci√≥n top-k para deltas de pesos en federated learning.
    Solo env√≠a los pesos m√°s cambiados, reduciendo el ancho de banda en 90-99%.
    """

    def __init__(self, config: Optional[SparsificationConfig] = None):
        self.config = config or SparsificationConfig()
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)

        # Estad√≠sticas de sparsificaci√≥n
        self.stats = {
            'total_deltas_processed': 0,
            'total_bandwidth_saved': 0,
            'avg_sparsity_ratio': 0.0,
            'compression_ratios': []
        }

        self.logger.info(f"üóúÔ∏è DeltaSparsifier initialized with k={self.config.k} (top {self.config.k*100:.1f}%)")

    def sparsify_deltas(self, current_weights: Dict[str, torch.Tensor],
                       previous_weights: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """
        Calcula deltas y aplica sparsificaci√≥n top-k.

        Args:
            current_weights: Pesos actuales del modelo
            previous_weights: Pesos anteriores del modelo

        Returns:
            Diccionario con deltas sparsificados por capa
        """
        try:
            sparsified_deltas = {}
            total_original_elements = 0
            total_sparsified_elements = 0

            for layer_name in current_weights.keys():
                if layer_name not in previous_weights:
                    self.logger.warning(f"Layer {layer_name} not found in previous weights, skipping sparsification")
                    continue

                current_layer = current_weights[layer_name]
                previous_layer = previous_weights[layer_name]

                # Calcular delta
                delta = current_layer - previous_layer

                # Aplicar sparsificaci√≥n top-k
                sparsified_delta = self._sparsify_layer_delta(delta, layer_name)

                if sparsified_delta:
                    sparsified_deltas[layer_name] = sparsified_delta
                    total_original_elements += sparsified_delta.total_elements
                    total_sparsified_elements += sparsified_delta.sparsified_elements

            # Calcular estad√≠sticas globales
            if total_original_elements > 0:
                global_sparsity_ratio = total_sparsified_elements / total_original_elements
                bandwidth_reduction = 1.0 - global_sparsity_ratio

                self.stats['total_deltas_processed'] += 1
                self.stats['avg_sparsity_ratio'] = (
                    (self.stats['avg_sparsity_ratio'] * (self.stats['total_deltas_processed'] - 1)) +
                    global_sparsity_ratio
                ) / self.stats['total_deltas_processed']

                self.logger.info(f"‚úÇÔ∏è Sparsified deltas: {total_sparsified_elements}/{total_original_elements} "
                               f"elements ({global_sparsity_ratio:.3f} ratio, "
                               f"{bandwidth_reduction:.1%} bandwidth reduction)")

            return {
                'sparsified_deltas': sparsified_deltas,
                'metadata': {
                    'sparsity_config': {
                        'k': self.config.k,
                        'compression_enabled': self.config.enable_compression
                    },
                    'stats': {
                        'total_original_elements': total_original_elements,
                        'total_sparsified_elements': total_sparsified_elements,
                        'global_sparsity_ratio': global_sparsity_ratio if total_original_elements > 0 else 0.0
                    }
                }
            }

        except Exception as e:
            self.logger.error(f"Error in sparsify_deltas: {e}")
            raise

    def _sparsify_layer_delta(self, delta: torch.Tensor, layer_name: str) -> Optional[SparsifiedDelta]:
        """
        Aplica sparsificaci√≥n top-k a una capa espec√≠fica.

        Args:
            delta: Tensor de deltas para la capa
            layer_name: Nombre de la capa

        Returns:
            SparsifiedDelta o None si no se puede sparsificar
        """
        try:
            # Aplanar el tensor para trabajar con 1D
            flat_delta = delta.flatten()
            total_elements = flat_delta.numel()

            # Calcular n√∫mero de elementos a mantener
            k_elements = max(1, int(total_elements * self.config.k))

            # Asegurar que k_elements est√© dentro de l√≠mites razonables
            k_elements = min(k_elements, total_elements)
            k_elements = max(k_elements, int(total_elements * self.config.min_sparsity_ratio))

            # Encontrar los √≠ndices de los valores absolutos m√°s grandes
            abs_delta = torch.abs(flat_delta)
            _, topk_indices = torch.topk(abs_delta, k_elements, largest=True)

            # Extraer valores sparsificados
            sparsified_values = flat_delta[topk_indices]

            # Crear objeto SparsifiedDelta
            sparsified_delta = SparsifiedDelta(
                layer_name=layer_name,
                indices=topk_indices,
                values=sparsified_values,
                original_shape=delta.shape,
                sparsity_ratio=k_elements / total_elements,
                total_elements=total_elements,
                sparsified_elements=k_elements
            )

            self.logger.debug(f"Layer {layer_name}: sparsified {k_elements}/{total_elements} elements "
                            f"({sparsified_delta.sparsity_ratio:.3f} ratio)")

            return sparsified_delta

        except Exception as e:
            self.logger.error(f"Error sparsifying layer {layer_name}: {e}")
            return None

    def deserialize_deltas(self, sparsified_data: Dict[str, Any]) -> Dict[str, torch.Tensor]:
        """
        Reconstruye deltas completos desde datos sparsificados.

        Args:
            sparsified_data: Datos sparsificados retornados por sparsify_deltas

        Returns:
            Deltas reconstruidos por capa
        """
        try:
            reconstructed_deltas = {}

            for layer_name, sparsified_delta in sparsified_data['sparsified_deltas'].items():
                # Reconstruir tensor completo inicializado en cero
                reconstructed = torch.zeros(sparsified_delta.total_elements, dtype=sparsified_delta.values.dtype)

                # Colocar valores sparsificados en sus posiciones originales
                reconstructed[sparsified_delta.indices] = sparsified_delta.values

                # Reshape al tama√±o original
                reconstructed = reconstructed.view(sparsified_delta.original_shape)

                reconstructed_deltas[layer_name] = reconstructed

            self.logger.debug(f"Reconstructed {len(reconstructed_deltas)} layer deltas")
            return reconstructed_deltas

        except Exception as e:
            self.logger.error(f"Error deserializing deltas: {e}")
            raise

    def compress_sparsified_data(self, sparsified_data: Dict[str, Any]) -> bytes:
        """
        Comprime datos sparsificados para transmisi√≥n eficiente.

        Args:
            sparsified_data: Datos sparsificados

        Returns:
            Datos comprimidos como bytes
        """
        try:
            if not self.config.enable_compression:
                return pickle.dumps(sparsified_data)

            # Serializar y comprimir
            serialized = pickle.dumps(sparsified_data)
            compressed = zlib.compress(serialized, level=self.config.compression_level)

            compression_ratio = len(compressed) / len(serialized) if serialized else 1.0
            self.stats['compression_ratios'].append(compression_ratio)

            self.logger.debug(f"Compressed sparsified data: {compression_ratio:.3f} compression ratio")
            return compressed

        except Exception as e:
            self.logger.error(f"Error compressing sparsified data: {e}")
            raise

    def decompress_sparsified_data(self, compressed_data: bytes) -> Dict[str, Any]:
        """
        Descomprime datos sparsificados.

        Args:
            compressed_data: Datos comprimidos

        Returns:
            Datos sparsificados descomprimidos
        """
        try:
            if not self.config.enable_compression:
                return pickle.loads(compressed_data)

            # Descomprimir y deserializar
            decompressed = zlib.decompress(compressed_data)
            sparsified_data = pickle.loads(decompressed)

            self.logger.debug("Decompressed sparsified data successfully")
            return sparsified_data

        except Exception as e:
            self.logger.error(f"Error decompressing sparsified data: {e}")
            raise

    def get_bandwidth_stats(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas de reducci√≥n de ancho de banda."""
        return {
            'total_deltas_processed': self.stats['total_deltas_processed'],
            'avg_sparsity_ratio': self.stats['avg_sparsity_ratio'],
            'avg_bandwidth_reduction': 1.0 - self.stats['avg_sparsity_ratio'],
            'compression_stats': {
                'avg_compression_ratio': np.mean(self.stats['compression_ratios']) if self.stats['compression_ratios'] else 1.0,
                'total_compressions': len(self.stats['compression_ratios'])
            }
        }


def create_topk_sparsifier(k: float = 0.01) -> DeltaSparsifier:
    """
    Crea un sparsifier configurado para top-k sparsification.

    Args:
        k: Fracci√≥n de pesos a mantener (0.01 = 1%)

    Returns:
        DeltaSparsifier configurado
    """
    config = SparsificationConfig(k=k)
    return DeltaSparsifier(config)


def sparsify_model_update(current_weights: Dict[str, torch.Tensor],
                         previous_weights: Dict[str, torch.Tensor],
                         k: float = 0.01) -> Tuple[bytes, DeltaSparsifier]:
    """
    Funci√≥n de conveniencia para sparsificar una actualizaci√≥n de modelo completa.

    Args:
        current_weights: Pesos actuales
        previous_weights: Pesos anteriores
        k: Fracci√≥n para sparsification

    Returns:
        Tuple de (datos comprimidos, sparsifier usado)
    """
    sparsifier = create_topk_sparsifier(k)
    sparsified_data = sparsifier.sparsify_deltas(current_weights, previous_weights)
    compressed_data = sparsifier.compress_sparsified_data(sparsified_data)

    return compressed_data, sparsifier


def deserialize_model_update(compressed_data: bytes,
                           sparsifier: DeltaSparsifier) -> Dict[str, torch.Tensor]:
    """
    Funci√≥n de conveniencia para deserializar una actualizaci√≥n sparsificada.

    Args:
        compressed_data: Datos comprimidos
        sparsifier: Sparsifier usado para comprimir

    Returns:
        Deltas reconstruidos
    """
    sparsified_data = sparsifier.decompress_sparsified_data(compressed_data)
    return sparsifier.deserialize_deltas(sparsified_data)