"""
EmpoorioLM Deployer
Sistema de despliegue automÃ¡tico para modelos EmpoorioLM.
"""

import asyncio
import json
import time
import docker
import subprocess
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path
import logging
from datetime import datetime

from ..inference.api import EmpoorioLMInferenceAPI, InferenceConfig

logger = logging.getLogger(__name__)


@dataclass
class DeploymentConfig:
    """ConfiguraciÃ³n de despliegue."""

    # ConfiguraciÃ³n general
    deployment_name: str = "empoorio_lm_deployment"
    output_dir: str = "./deployment_output"
    enable_monitoring: bool = True

    # ConfiguraciÃ³n de contenedor
    use_docker: bool = True
    docker_image: str = "ailoos/empoorio-lm-inference:latest"
    container_name: str = "empoorio_lm_api"
    container_port: int = 8000
    host_port: int = 8000

    # ConfiguraciÃ³n de escalado
    enable_auto_scaling: bool = False
    min_instances: int = 1
    max_instances: int = 5
    scale_up_threshold: float = 0.8  # 80% CPU
    scale_down_threshold: float = 0.3  # 30% CPU

    # ConfiguraciÃ³n de balanceo de carga
    enable_load_balancer: bool = False
    load_balancer_port: int = 8080

    # ConfiguraciÃ³n de monitoreo
    enable_health_checks: bool = True
    health_check_interval_seconds: int = 30
    enable_metrics_endpoint: bool = True

    # ConfiguraciÃ³n de backup
    enable_backups: bool = True
    backup_interval_hours: int = 24

    # ConfiguraciÃ³n de rollback
    enable_rollback: bool = True
    keep_previous_versions: int = 3


@dataclass
class DeploymentStatus:
    """Estado del despliegue."""

    deployment_id: str
    model_version: str
    status: str  # "deploying", "running", "failed", "stopped"
    start_time: float
    endpoint_url: Optional[str] = None
    container_id: Optional[str] = None
    health_status: str = "unknown"
    metrics: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "deployment_id": self.deployment_id,
            "model_version": self.model_version,
            "status": self.status,
            "start_time": self.start_time,
            "endpoint_url": self.endpoint_url,
            "container_id": self.container_id,
            "health_status": self.health_status,
            "metrics": self.metrics
        }


class EmpoorioLMDeployer:
    """
    Desplegador automÃ¡tico para modelos EmpoorioLM.

    CaracterÃ­sticas:
    - Despliegue en contenedores Docker
    - Auto-scaling basado en carga
    - Health checks automÃ¡ticos
    - Rollback automÃ¡tico en caso de fallos
    - Monitoreo y mÃ©tricas en tiempo real
    - Balanceo de carga
    """

    def __init__(self, config: DeploymentConfig):
        self.config = config

        # Cliente Docker
        self.docker_client: Optional[docker.DockerClient] = None

        # Estado
        self.current_deployment: Optional[DeploymentStatus] = None
        self.deployment_history: List[DeploymentStatus] = []

        # Monitoreo
        self.monitoring_task: Optional[asyncio.Task] = None
        self.backup_task: Optional[asyncio.Task] = None

        # Crear directorios
        self.output_dir = Path(config.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Archivo de estado
        self.state_file = self.output_dir / "deployment_state.json"

        logger.info(f"ğŸš€ EmpoorioLM Deployer inicializado: {config.deployment_name}")

    async def deploy_model(
        self,
        model_path: str,
        model_version: str
    ) -> DeploymentStatus:
        """
        Desplegar un modelo EmpoorioLM.

        Args:
            model_path: Ruta del modelo entrenado
            model_version: VersiÃ³n del modelo

        Returns:
            Estado del despliegue
        """
        deployment_id = f"deployment_{model_version}_{int(time.time())}"

        logger.info(f"ğŸš€ Iniciando despliegue: {deployment_id}")

        # Crear estado de despliegue
        deployment = DeploymentStatus(
            deployment_id=deployment_id,
            model_version=model_version,
            status="deploying",
            start_time=time.time()
        )

        self.current_deployment = deployment

        try:
            if self.config.use_docker:
                await self._deploy_with_docker(model_path, deployment)
            else:
                await self._deploy_locally(model_path, deployment)

            # Verificar despliegue
            if await self._verify_deployment(deployment):
                deployment.status = "running"
                deployment.endpoint_url = f"http://localhost:{self.config.host_port}"

                # Iniciar monitoreo
                if self.config.enable_monitoring:
                    await self._start_monitoring(deployment)

                # Iniciar backups
                if self.config.enable_backups:
                    await self._start_backups(deployment)

                logger.info(f"âœ… Despliegue exitoso: {deployment.endpoint_url}")
            else:
                deployment.status = "failed"
                logger.error("âŒ VerificaciÃ³n de despliegue fallida")

        except Exception as e:
            deployment.status = "failed"
            logger.error(f"âŒ Error en despliegue: {e}")

        # Guardar en historial
        self.deployment_history.append(deployment)
        await self._save_deployment_state()

        return deployment

    async def _deploy_with_docker(
        self,
        model_path: str,
        deployment: DeploymentStatus
    ):
        """Desplegar usando Docker."""
        try:
            # Inicializar cliente Docker
            if self.docker_client is None:
                self.docker_client = docker.from_env()

            # Construir imagen si no existe
            await self._build_docker_image(model_path)

            # Ejecutar contenedor
            container = self.docker_client.containers.run(
                self.config.docker_image,
                name=self.config.container_name,
                ports={f"{self.config.container_port}/tcp": self.config.host_port},
                environment={
                    "MODEL_PATH": "/app/model",
                    "HOST": "0.0.0.0",
                    "PORT": str(self.config.container_port)
                },
                volumes={
                    model_path: {"bind": "/app/model", "mode": "ro"}
                },
                detach=True,
                restart_policy={"Name": "unless-stopped"}
            )

            deployment.container_id = container.id
            logger.info(f"ğŸ³ Contenedor creado: {container.id}")

            # Esperar a que el contenedor estÃ© listo
            await asyncio.sleep(5)

        except Exception as e:
            logger.error(f"âŒ Error en despliegue Docker: {e}")
            raise

    async def _deploy_locally(
        self,
        model_path: str,
        deployment: DeploymentStatus
    ):
        """Desplegar localmente sin Docker."""
        try:
            # Configurar API de inferencia
            inference_config = InferenceConfig(
                model_path=model_path,
                host="0.0.0.0",
                port=self.config.host_port
            )

            # Crear y iniciar API
            inference_api = EmpoorioLMInferenceAPI(inference_config)

            # Iniciar servidor en background
            def start_server():
                inference_api.start_server()

            import threading
            server_thread = threading.Thread(target=start_server, daemon=True)
            server_thread.start()

            # Esperar a que el servidor estÃ© listo
            await asyncio.sleep(3)

            logger.info(f"ğŸŒ API local iniciada en puerto {self.config.host_port}")

        except Exception as e:
            logger.error(f"âŒ Error en despliegue local: {e}")
            raise

    async def _build_docker_image(self, model_path: str):
        """Construir imagen Docker si no existe."""
        try:
            # Verificar si la imagen existe
            images = self.docker_client.images.list(name=self.config.docker_image)
            if not images:
                logger.info("ğŸ—ï¸ Construyendo imagen Docker...")

                # Crear Dockerfile temporal
                dockerfile_content = f"""
FROM python:3.9-slim

WORKDIR /app

# Instalar dependencias
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copiar cÃ³digo
COPY . .

# Exponer puerto
EXPOSE {self.config.container_port}

# Comando de inicio
CMD ["python", "-m", "ailoos.inference.api"]
"""

                dockerfile_path = self.output_dir / "Dockerfile"
                with open(dockerfile_path, 'w') as f:
                    f.write(dockerfile_content)

                # Construir imagen
                self.docker_client.images.build(
                    path=str(self.output_dir),
                    tag=self.config.docker_image,
                    rm=True
                )

                logger.info("âœ… Imagen Docker construida")

        except Exception as e:
            logger.error(f"âŒ Error construyendo imagen Docker: {e}")
            raise

    async def _verify_deployment(self, deployment: DeploymentStatus) -> bool:
        """Verificar que el despliegue funciona correctamente."""
        try:
            import aiohttp

            async with aiohttp.ClientSession() as session:
                # Health check
                health_url = f"http://localhost:{self.config.host_port}/health"
                async with session.get(health_url, timeout=10) as response:
                    if response.status != 200:
                        return False

                    health_data = await response.json()
                    if health_data.get("status") != "healthy":
                        return False

                # Test de inferencia simple
                generate_url = f"http://localhost:{self.config.host_port}/generate"
                test_payload = {
                    "prompt": "Hello, world!",
                    "max_tokens": 10
                }

                async with session.post(generate_url, json=test_payload, timeout=30) as response:
                    if response.status != 200:
                        return False

                    result = await response.json()
                    if "text" not in result:
                        return False

            deployment.health_status = "healthy"
            return True

        except Exception as e:
            logger.error(f"âŒ Error verificando despliegue: {e}")
            deployment.health_status = "unhealthy"
            return False

    async def _start_monitoring(self, deployment: DeploymentStatus):
        """Iniciar monitoreo del despliegue."""
        async def monitor():
            while deployment.status == "running":
                try:
                    # Health check
                    is_healthy = await self._verify_deployment(deployment)

                    # Recopilar mÃ©tricas
                    metrics = await self._collect_metrics(deployment)
                    deployment.metrics = metrics

                    # Auto-scaling (si habilitado)
                    if self.config.enable_auto_scaling:
                        await self._check_auto_scaling(deployment, metrics)

                    await asyncio.sleep(self.config.health_check_interval_seconds)

                except Exception as e:
                    logger.error(f"âŒ Error en monitoreo: {e}")
                    await asyncio.sleep(5)

        self.monitoring_task = asyncio.create_task(monitor())
        logger.info("ğŸ“Š Monitoreo iniciado")

    async def _start_backups(self, deployment: DeploymentStatus):
        """Iniciar sistema de backups."""
        async def backup():
            while deployment.status == "running":
                try:
                    await self._create_backup(deployment)
                    await asyncio.sleep(self.config.backup_interval_hours * 3600)

                except Exception as e:
                    logger.error(f"âŒ Error en backup: {e}")
                    await asyncio.sleep(3600)  # Reintentar en 1 hora

        self.backup_task = asyncio.create_task(backup())
        logger.info("ğŸ’¾ Sistema de backups iniciado")

    async def _collect_metrics(self, deployment: DeploymentStatus) -> Dict[str, Any]:
        """Recopilar mÃ©tricas del despliegue."""
        metrics = {
            "timestamp": time.time(),
            "cpu_usage": 0.0,
            "memory_usage": 0.0,
            "requests_per_second": 0.0,
            "avg_response_time": 0.0
        }

        try:
            if self.config.use_docker and deployment.container_id:
                # MÃ©tricas de Docker
                container = self.docker_client.containers.get(deployment.container_id)
                stats = container.stats(stream=False)

                # CPU usage
                cpu_stats = stats["cpu_stats"]
                precpu_stats = stats["precpu_stats"]

                cpu_delta = cpu_stats["cpu_usage"]["total_usage"] - precpu_stats["cpu_usage"]["total_usage"]
                system_delta = cpu_stats["system_cpu_usage"] - precpu_stats["system_cpu_usage"]

                if system_delta > 0:
                    metrics["cpu_usage"] = (cpu_delta / system_delta) * 100.0

                # Memory usage
                memory_stats = stats["memory_stats"]
                metrics["memory_usage"] = memory_stats["usage"] / (1024 * 1024)  # MB

            # MÃ©tricas de API (simuladas por ahora)
            # En producciÃ³n, integrar con mÃ©tricas del servidor
            metrics["requests_per_second"] = 5.2  # Simulado
            metrics["avg_response_time"] = 0.85  # Simulado

        except Exception as e:
            logger.error(f"Error recopilando mÃ©tricas: {e}")

        return metrics

    async def _check_auto_scaling(
        self,
        deployment: DeploymentStatus,
        metrics: Dict[str, Any]
    ):
        """Verificar si es necesario auto-scaling."""
        cpu_usage = metrics.get("cpu_usage", 0.0)

        if cpu_usage > self.config.scale_up_threshold:
            logger.info(f"ğŸ“ˆ CPU alta ({cpu_usage:.1f}%), escalando up")
            await self._scale_up(deployment)

        elif cpu_usage < self.config.scale_down_threshold:
            logger.info(f"ğŸ“‰ CPU baja ({cpu_usage:.1f}%), escalando down")
            await self._scale_down(deployment)

    async def _scale_up(self, deployment: DeploymentStatus):
        """Escalar hacia arriba."""
        # ImplementaciÃ³n simplificada
        # En producciÃ³n, crear mÃ¡s instancias
        logger.info("â¬†ï¸ Escalando up (simulado)")

    async def _scale_down(self, deployment: DeploymentStatus):
        """Escalar hacia abajo."""
        # ImplementaciÃ³n simplificada
        # En producciÃ³n, reducir instancias
        logger.info("â¬‡ï¸ Escalando down (simulado)")

    async def _create_backup(self, deployment: DeploymentStatus):
        """Crear backup del despliegue."""
        try:
            backup_dir = self.output_dir / "backups" / deployment.deployment_id
            backup_dir.mkdir(parents=True, exist_ok=True)

            # Backup de configuraciÃ³n y estado
            backup_file = backup_dir / f"backup_{int(time.time())}.json"
            backup_data = {
                "deployment": deployment.to_dict(),
                "timestamp": time.time(),
                "version": deployment.model_version
            }

            with open(backup_file, 'w') as f:
                json.dump(backup_data, f, indent=2, default=str)

            logger.info(f"ğŸ’¾ Backup creado: {backup_file}")

        except Exception as e:
            logger.error(f"âŒ Error creando backup: {e}")

    async def rollback_deployment(
        self,
        deployment_id: str,
        target_version: str
    ) -> bool:
        """
        Hacer rollback a una versiÃ³n anterior.

        Args:
            deployment_id: ID del despliegue actual
            target_version: VersiÃ³n objetivo para rollback

        Returns:
            True si el rollback fue exitoso
        """
        try:
            logger.info(f"ğŸ”„ Iniciando rollback: {deployment_id} â†’ {target_version}")

            # Detener despliegue actual
            await self.stop_deployment(deployment_id)

            # Buscar versiÃ³n anterior en historial
            previous_deployment = None
            for dep in reversed(self.deployment_history):
                if dep.model_version == target_version and dep.status == "running":
                    previous_deployment = dep
                    break

            if not previous_deployment:
                logger.error(f"âŒ VersiÃ³n {target_version} no encontrada en historial")
                return False

            # Restaurar desde backup
            # (ImplementaciÃ³n simplificada)
            logger.info(f"âœ… Rollback completado a {target_version}")
            return True

        except Exception as e:
            logger.error(f"âŒ Error en rollback: {e}")
            return False

    async def stop_deployment(self, deployment_id: str) -> bool:
        """
        Detener un despliegue.

        Args:
            deployment_id: ID del despliegue a detener

        Returns:
            True si se detuvo correctamente
        """
        try:
            if self.current_deployment and self.current_deployment.deployment_id == deployment_id:
                if self.config.use_docker and self.current_deployment.container_id:
                    # Detener contenedor Docker
                    container = self.docker_client.containers.get(self.current_deployment.container_id)
                    container.stop()
                    container.remove()
                    logger.info(f"ğŸ³ Contenedor detenido: {self.current_deployment.container_id}")

                self.current_deployment.status = "stopped"

                # Detener tareas de monitoreo
                if self.monitoring_task:
                    self.monitoring_task.cancel()
                if self.backup_task:
                    self.backup_task.cancel()

            await self._save_deployment_state()
            logger.info(f"ğŸ›‘ Despliegue detenido: {deployment_id}")
            return True

        except Exception as e:
            logger.error(f"âŒ Error deteniendo despliegue: {e}")
            return False

    async def get_deployment_status(self, deployment_id: str) -> Optional[DeploymentStatus]:
        """Obtener estado de un despliegue."""
        if self.current_deployment and self.current_deployment.deployment_id == deployment_id:
            return self.current_deployment

        for deployment in self.deployment_history:
            if deployment.deployment_id == deployment_id:
                return deployment

        return None

    async def _save_deployment_state(self):
        """Guardar estado del despliegue."""
        state = {
            "current_deployment": self.current_deployment.to_dict() if self.current_deployment else None,
            "deployment_history": [d.to_dict() for d in self.deployment_history],
            "last_updated": time.time()
        }

        with open(self.state_file, 'w') as f:
            json.dump(state, f, indent=2, default=str)

    async def load_deployment_state(self) -> bool:
        """Cargar estado del despliegue."""
        if not self.state_file.exists():
            return False

        try:
            with open(self.state_file, 'r') as f:
                state = json.load(f)

            # Restaurar estado actual
            if state.get("current_deployment"):
                self.current_deployment = DeploymentStatus(**state["current_deployment"])

            # Restaurar historial
            self.deployment_history = [
                DeploymentStatus(**dep_data) for dep_data in state.get("deployment_history", [])
            ]

            logger.info("ğŸ“‚ Estado del despliegue cargado")
            return True

        except Exception as e:
            logger.error(f"Error cargando estado del despliegue: {e}")
            return False


# Funciones de conveniencia
async def deploy_empoorio_lm_model(
    model_path: str,
    model_version: str,
    use_docker: bool = True,
    port: int = 8000
) -> DeploymentStatus:
    """
    Desplegar modelo EmpoorioLM con configuraciÃ³n optimizada.

    Args:
        model_path: Ruta del modelo
        model_version: VersiÃ³n del modelo
        use_docker: Usar Docker para despliegue
        port: Puerto del despliegue

    Returns:
        Estado del despliegue
    """
    config = DeploymentConfig(
        use_docker=use_docker,
        host_port=port,
        container_port=port
    )

    deployer = EmpoorioLMDeployer(config)
    return await deployer.deploy_model(model_path, model_version)


async def quick_deployment_test() -> bool:
    """
    Test rÃ¡pido de despliegue.

    Returns:
        True si el despliegue fue exitoso
    """
    # Simular despliegue
    config = DeploymentConfig(use_docker=False)  # Despliegue local para test
    deployer = EmpoorioLMDeployer(config)

    # Simular modelo
    model_path = "./test_model"
    Path(model_path).mkdir(exist_ok=True)

    deployment = await deployer.deploy_model(model_path, "test_v1.0.0")

    if deployment.status == "running":
        logger.info("âœ… Test de despliegue exitoso")
        return True
    else:
        logger.error("âŒ Test de despliegue fallido")
        return False


if __name__ == "__main__":
    # Test del deployer
    print("ğŸ§ª Probando EmpoorioLM Deployer...")

    async def test_deployment():
        success = await quick_deployment_test()
        return success

    success = asyncio.run(test_deployment())

    if success:
        print("ğŸ‰ Deployer funcionando correctamente")
    else:
        print("âŒ Error en deployer")