# Copyright (c) 2025 - 2026, HaiyangLi <quantocean.li at gmail dot com>
# SPDX-License-Identifier: Apache-2.0

"""
Pydantic Adapter Tests: Reference Implementation for Pydantic v2 Model Generation

**Core Implementation**:
- **PydanticSpecAdapter**: Concrete SpecAdapter implementation for Pydantic v2
- **Field Creation**: Spec → Pydantic FieldInfo (metadata mapping)
- **Validator Integration**: Spec validators → Pydantic field_validator decorators
- **Fuzzy Matching**: Case-insensitive, underscore-tolerant field key matching
- **Validation Strategies**: Strict (production) vs lenient (LLM) vs fuzzy (tolerance)

**Design Philosophy**:
- **Framework Isolation**: All Pydantic imports confined to this adapter
- **Metadata Mapping**: Spec metadata → Pydantic Field kwargs (framework translation layer)
- **Progressive Validation**: Strict for correctness, lenient for UX, fuzzy for tolerance
- **Pipeline Integration**: parse_json → fuzzy_match_fields → validate_model (3-stage processing)

**Testing Strategy**:
This test suite validates:
1. Field creation with all metadata types (defaults, validators, descriptions, constraints)
2. Validator execution (Pydantic field_validator integration and inheritance)
3. Fuzzy field matching (case normalization, underscore handling, sentinel filtering)
4. Validation pipeline (parse → match → validate with error handling)
5. Strict vs lenient error modes (raises vs returns None)
6. Model CRUD operations (create → validate → dump → update)
7. Nullable/listable annotation handling
8. Generic type preservation (SpecAdapter[BaseModel])

**Type System Context**:
PydanticSpecAdapter is **the reference adapter** for the type system:
- First adapter implemented (Pydantic most widely used validation framework)
- Establishes patterns for future adapters (attrs, dataclass, msgspec)
- Demonstrates all adapter protocol features (field creation, validation, fuzzy matching)
- Production-tested (used in LLM structured output workflows)

**Validation Strategies**:

### 1. Strict Validation (`strict=True`)

**Use Cases**: Production APIs, database writes, security-critical data, external sources

**Behavior**:
- **JSON Parsing**: Exact JSON only (no markdown, no fuzzy extraction)
- **Field Matching**: Exact key names (case-sensitive, no tolerance)
- **Error Handling**: All exceptions propagate (fail fast)
- **Extra Keys**: ValueError on unmatched keys (no silent ignoring)

**Example**:
```python
instance = PydanticSpecAdapter.validate_response(
    '{"username": "alice", "age": 30}',  # Must be exact JSON
    UserModel,
    strict=True,  # Raise on any error
    fuzzy_parse=False,  # No fuzzy extraction
)
# {"UserName": ...} → ValueError (case mismatch)
# "Here's the data: {...}" → ValueError (extra text)
```

**Trade-offs**:
- ✅ Correctness: Fail fast on any ambiguity
- ✅ Security: No silent data loss or type coercion
- ❌ UX: Requires perfectly formatted input (zero tolerance)

### 2. Lenient Validation (`strict=False`)

**Use Cases**: LLM responses, user input, graceful degradation, prototyping

**Behavior**:
- **JSON Parsing**: Fuzzy extraction (markdown code blocks, extra text OK)
- **Field Matching**: Fuzzy (case-insensitive, underscore variants, ignore extra keys)
- **Error Handling**: Returns None on error (no exceptions)
- **Extra Keys**: Silently ignored (lenient mode)

**Example**:
```python
instance = PydanticSpecAdapter.validate_response(
    '''
    Here's the user data:
    ```json
    {"UserName": "alice", "AGE": 30, "extra": "ignored"}
    ```
    ''',
    UserModel,
    strict=False,       # Return None on error
    fuzzy_parse=True    # Extract from markdown
)
# Result: UserModel(username="alice", age=30)
# "UserName" → "username" (fuzzy match)
# "extra" → ignored (lenient mode)
```

**Trade-offs**:
- ✅ UX: Tolerant of formatting variations
- ✅ LLM-friendly: Handles markdown, case variations
- ❌ Correctness: May silently ignore errors

### 3. Fuzzy Field Matching

**Use Cases**: LLM structured outputs, case-insensitive APIs, third-party integrations

**Behavior**:
- **Case Normalization**: `AGE` → `age`, `UserName` → `username`
- **Underscore Handling**: `user_name` → `username`, `user-name` → `username`
- **Levenshtein Distance**: `usernme` → `username` (if threshold met)
- **Sentinel Filtering**: Remove `Unset`/`Undefined` from output

**Example**:
```python
matched = PydanticSpecAdapter.fuzzy_match_fields(
    {"UserName": "alice", "AGE": 30, "extra_field": "ignored"},
    UserModel,
    strict=False
)
# Result: {"username": "alice", "age": 30}
# "extra_field" → ignored (lenient mode)
```

**Algorithm**:
1. Normalize keys (lowercase, remove underscores/hyphens)
2. Match normalized keys to model field names
3. Filter sentinels (Unset, Undefined)
4. Return matched fields only (extra keys ignored in lenient mode)

**Field Creation Metadata Mapping**:

| Spec Metadata | Pydantic Field | Notes |
|---------------|----------------|-------|
| `default` (static) | `default=value` | Direct assignment |
| `default_factory` | `default_factory=callable` | Sync factory only (async unsupported) |
| `nullable=True` | `default=None` | Auto-added if no other default |
| `validator` | `field_validator(field_name)` | Injected via intermediate base class |
| `description`, `title` | Direct pass-through | Pydantic native Field params |
| `min_length`, `max_length` | Field constraints | Pydantic v2 constraints |
| Custom metadata | `json_schema_extra[key]` | Preserved in JSON schema |

**Validator Integration Pattern**:

**Challenge**: Pydantic requires validators as class attributes (decorators), but `create_model()` doesn't support them directly

**Solution**: Intermediate base class with validators, inherited by generated model

**Example**:
```python
def nonneg(v: int) -> int:
    if v < 0:
        raise ValueError("must be non-negative")
    return v


spec = Spec(int, name="age", validator=nonneg)
op = Operable([spec])
Model = PydanticSpecAdapter.create_model(op, model_name="User")

# Generated class hierarchy:
# User(UserBase(BaseModel))
#   UserBase has: age_validator = field_validator("age")(nonneg)
#   User inherits validator from UserBase
```

**Why Intermediate Base Class?**
- Validators must be class attributes (Pydantic v2 requirement)
- `create_model()` creates class dynamically (can't add decorators)
- Inheritance propagates validators from base to generated class
- `check_fields=False` allows validators before field exists

**Design Rationale**:

**Why Fuzzy Matching in Adapter (not shared utility)?**
- Different frameworks store fields differently:
  - Pydantic: `model_fields` attribute
  - attrs: `__attrs_attrs__` attribute
  - dataclasses: `__dataclass_fields__` attribute
- Framework-specific field access logic isolated in adapter
- Common `fuzzy_match_keys` utility used by all adapters (shared algorithm)

**Why Three Validation Strategies (not one)?**
- Production needs strict (security, correctness, no surprises)
- LLMs need lenient (tolerance for markdown, case, extra text)
- APIs need fuzzy (case-insensitive, underscore variants)
- All three served by same adapter (configuration, not code duplication)

**Why check_fields=False in field_validator?**
- Allows validators in base class before field definition
- Enables validator inheritance (subclasses get validators)
- Pydantic v2 requirement for dynamic validator creation
- Without it: ValueError (validator for nonexistent field)

**Why Pydantic as Reference Adapter?**
- Most widely used validation framework in Python ecosystem
- Rich feature set (validators, constraints, JSON schema generation)
- Strong typing (v2 uses pydantic-core for performance)
- LLM structured output standard (OpenAI, Anthropic support)

**Performance Characteristics**:
- Field creation: O(metadata_count) (~10-50μs per field)
- Model creation: O(field_count) + Pydantic overhead (~1-5ms for 10 fields)
- Validation: O(field_count) + Pydantic validation (~0.5-2ms)
- Fuzzy matching: O(data_keys x model_fields) (~0.1-1ms for 100 keys)
- Validator execution: O(validator_complexity) (user-defined)

**Related Components**:
- `SpecAdapter`: Abstract protocol (defines contract)
- `Spec`: Field schema (input to create_field)
- `Operable`: Spec collection (input to create_model)
- `fuzzy_match_keys`: Common fuzzy matching logic (`ln._fuzzy_match`)
- `extract_json`: Fuzzy JSON parsing (`libs.string_handlers`)

**References**:
- Source: `src/lionpride/types/spec_adapters/pydantic_field.py`
- Protocol: `src/lionpride/types/spec_adapters/_protocol.py`
- Fuzzy matching: `src/lionpride/ln/_fuzzy_match.py`
- JSON extraction: `src/lionpride/libs/string_handlers/_extract_json.py`
- Related tests: `tests/types/test_spec.py`, `tests/types/test_operable.py`
"""

from __future__ import annotations

import pytest

# Skip pydantic-specific tests if pydantic isn't installed
pytest.importorskip("pydantic")

from lionpride.types import Operable, Spec
from lionpride.types.spec_adapters._protocol import SpecAdapter
from lionpride.types.spec_adapters.pydantic_field import PydanticSpecAdapter
from tests.types.conftest import create_spec, get_sample_validators

# -- SpecAdapter.parse_json ---------------------------------------------------


def test_parse_json_unwraps_singleton_list(monkeypatch):
    """
    Fuzzy JSON parsing unwraps singleton lists (common LLM response pattern)

    **Pattern**: Fuzzy parsing with singleton unwrapping

    **Scenario**: LLM returns single object wrapped in array
    ```python
    # LLM response: [{"user": "alice"}]  (unnecessary array)
    # Expected: {"user": "alice"}  (unwrapped dict)
    ```

    **Expected Behavior**:
    - Single-item list detected: `[{...}]`
    - List unwrapped to dict: `{...}`
    - Multi-item lists preserved: `[{...}, {...}]`

    **Design Rationale**:

    **Why Unwrap Singletons?**
    - LLMs often wrap single objects in arrays (training data artifact)
    - User expects dict, gets array → validation fails
    - Unwrapping provides better UX (forgive LLM formatting)
    - Multi-item lists preserved (genuine array response)

    **When This Happens**:
    - OpenAI function calling with single result
    - Claude structured output with single object
    - User prompt: "Return user data" (singular) → LLM returns `[{user}]`

    **Alternative Considered**: Strict parsing (reject wrapped singletons)
    **Rejected Because**: Poor UX for common LLM behavior; user must detect and unwrap manually

    **Performance**: O(1) (single length check + indexing)
    """
    # Mock extract_json to return a singleton list
    monkeypatch.setattr(
        "lionpride.libs.string_handlers.extract_json",
        lambda text, fuzzy_parse=True: [{"a": 1}],
    )
    out = PydanticSpecAdapter.parse_json("ignored", fuzzy=True)
    assert out == {"a": 1}


def test_parse_json_preserves_multi_item_list(monkeypatch):
    """Test that parse_json preserves multi-item lists."""
    monkeypatch.setattr(
        "lionpride.libs.string_handlers.extract_json",
        lambda text, fuzzy_parse=True: [{"a": 1}, {"b": 2}],
    )
    out = PydanticSpecAdapter.parse_json("ignored", fuzzy=True)
    assert out == [{"a": 1}, {"b": 2}]


# -- Pydantic model creation / validation / dump / update --------------------


def test_pydantic_create_validate_dump_update():
    """Test end-to-end Pydantic pipeline: create → validate → dump → update."""
    # Build an Operable with two fields
    name_spec = create_spec(str, name="name", default="n/a")
    age_spec = create_spec(int, name="age", default=18)
    op = Operable((name_spec, age_spec), name="User")

    # Create model
    Model = PydanticSpecAdapter.create_model(op, model_name="UserModel")

    # Validate with partial input (age default should apply)
    inst = PydanticSpecAdapter.validate_model(Model, {"name": "alice"})
    dumped = PydanticSpecAdapter.dump_model(inst)
    assert dumped == {"name": "alice", "age": 18}

    # Update + validate
    inst2 = PydanticSpecAdapter.update_model(inst, {"age": 21})
    assert PydanticSpecAdapter.dump_model(inst2) == {"name": "alice", "age": 21}


def test_pydantic_nullable_default_none():
    """Test nullable field with default=None."""
    nullable_score = create_spec(int, name="score", default=None, nullable=True)
    op = Operable((nullable_score,), name="Scored")

    Model = PydanticSpecAdapter.create_model(op, model_name="ScoredModel")
    inst = PydanticSpecAdapter.validate_model(Model, {})
    assert PydanticSpecAdapter.dump_model(inst) == {"score": None}


def test_pydantic_field_validator_executes():
    """
    Spec validators are executed as Pydantic field_validator decorators

    **Pattern**: Validator integration via intermediate base class

    **Scenario**: Spec contains validator callable, adapter converts to Pydantic field_validator
    ```python
    def nonneg(v: int) -> int:
        if v < 0:
            raise ValueError("must be non-negative")
        return v


    spec = Spec(int, name="age", validator=nonneg)
    # Adapter creates: field_validator("age")(nonneg) in base class
    # Generated model inherits validator
    ```

    **Expected Behavior**:
    - Valid value (age=0) passes validation
    - Invalid value (age=-1) raises Pydantic ValidationError
    - Validator executed at validation time (not model creation)
    - Error message from validator function propagated

    **Validator Integration Pattern**:

    **Challenge**: Pydantic requires validators as class attributes (decorators)
    - `create_model()` generates class dynamically (can't add decorators)
    - Validators must exist before class creation (decorator application)

    **Solution**: Intermediate base class with validators
    ```python
    # Step 1: Create base class with validators as class attributes
    class UserBase(BaseModel):
        age_validator = field_validator("age", check_fields=False)(nonneg)


    # Step 2: Generate model inheriting from base
    User = create_model("User", __base__=UserBase, age=(int, ...))

    # Result: User inherits age_validator from UserBase
    ```

    **Why check_fields=False?**
    - Allows validator in base class before field exists
    - Field defined in subclass (via create_model)
    - Validator applied when subclass is validated
    - Without it: ValueError (validator for nonexistent field)

    **Design Rationale**:

    **Why Not Direct Validator Injection?**
    - Pydantic v2 uses decorators (compile-time application)
    - `create_model()` is runtime class generation (post-decorator phase)
    - Can't apply decorators to dynamically created class
    - Inheritance is the workaround (validators in base, fields in subclass)

    **Alternative Considered**: Pydantic v1 __validators__ dict
    **Rejected Because**: Pydantic v2 removed __validators__ (uses decorators only)

    **Performance**:
    - Validator overhead: O(validator_complexity) (user-defined)
    - Inheritance overhead: Negligible (Python MRO lookup ~10ns)
    - Validation: Same as hand-written Pydantic model
    """
    validators = get_sample_validators()
    s = create_spec(int, name="age", validator=validators["nonneg"])
    op = Operable((s,), name="WithValidator")
    Model = PydanticSpecAdapter.create_model(op, model_name="WithValidatorModel")

    # Valid
    ok = PydanticSpecAdapter.validate_model(Model, {"age": 0})
    assert PydanticSpecAdapter.dump_model(ok) == {"age": 0}

    # Invalid
    from pydantic import ValidationError

    with pytest.raises(ValidationError):
        PydanticSpecAdapter.validate_model(Model, {"age": -1})


# -- validate_response pipeline (with monkeypatched fuzzy matching) ----------


def test_validate_response_pipeline(monkeypatch):
    """Test full validate_response pipeline: parse → fuzzy_match → validate."""
    # Return the JSON dict as-is (bypass real extract_json)
    monkeypatch.setattr(
        "lionpride.libs.string_handlers._extract_json.extract_json",
        lambda text, fuzzy_parse=True: {"name": "bob", "age": 33},
    )
    # Return data unchanged (bypass real fuzzy_match_keys)
    monkeypatch.setattr(
        "lionpride.ln._fuzzy_match.fuzzy_match_keys",
        lambda data, fields, handle_unmatched="ignore": data,
    )

    op = Operable((create_spec(str, name="name"), create_spec(int, name="age")), name="User")
    Model = PydanticSpecAdapter.create_model(op, model_name="UserModel2")

    inst = PydanticSpecAdapter.validate_response('{"name":"bob","age":33}', Model, strict=True)
    assert inst is not None
    assert PydanticSpecAdapter.dump_model(inst) == {"name": "bob", "age": 33}


def test_validate_response_returns_none_on_error_when_not_strict(monkeypatch):
    """
    Lenient validation returns None on error (graceful degradation for LLM responses)

    **Pattern**: Lenient validation (strict=False)

    **Scenario**: JSON parsing fails (malformed input, non-JSON text)
    ```python
    # Invalid input: "Here is some text without JSON"
    result = validate_response("invalid", Model, strict=False)
    # Returns: None (no exception)
    ```

    **Expected Behavior**:
    - Parse error occurs (JSON extraction fails)
    - No exception raised (lenient mode)
    - Returns None (signals "validation failed, but continue")
    - Caller can check `if result is None:` for error handling

    **Validation Strategy**: Lenient (`strict=False`)
    - **Error Handling**: Returns None (no exceptions)
    - **Use Cases**: LLM responses, user input, prototyping
    - **Trade-off**: Silently ignores errors (no debugging info)

    **Design Rationale**:

    **Why Return None (not raise)?**
    - LLM responses may occasionally fail parsing (rare but happens)
    - Raising exception breaks workflow (requires try/except everywhere)
    - None enables graceful degradation:
      ```python
      result = validate_response(llm_text, Model, strict=False)
      if result is None:
          # Fallback: retry, use default, log warning
          result = retry_llm() or use_default()
      ```
    - Better UX for LLM workflows (don't crash on single failure)

    **When to Use Lenient Mode?**
    - LLM structured outputs (may have formatting issues)
    - User input forms (may have typos, case mismatches)
    - Prototyping (want to see what works, ignore errors)
    - Non-critical paths (logging, analytics, optional features)

    **When NOT to Use Lenient Mode?**
    - Production APIs (need validation guarantees)
    - Database writes (silent errors = data corruption)
    - Security-critical (must reject malformed input)
    - External data sources (need to know about format changes)

    **Comparison with Strict Mode**:
    | Aspect | Strict | Lenient |
    |--------|--------|---------|
    | Error handling | Raise exception | Return None |
    | Use case | Production | LLM/User input |
    | Debugging | Clear errors | Silent failures |
    | UX | Strict (crashes) | Forgiving (continues) |

    **Alternative Considered**: Return `Result[T, Error]` (Rust-style)
    **Rejected Because**: Python convention is None for "no result"; exceptions for errors; Result[T, E] adds complexity

    **Performance**: O(1) (single None return, no stack unwinding)
    """
    # Make parse_json raise an error
    monkeypatch.setattr(
        "lionpride.libs.string_handlers._extract_json.extract_json",
        lambda text, fuzzy_parse=True: _raise_value_error(),
    )

    def _raise_value_error():
        raise ValueError("parse error")

    op = Operable((create_spec(str, name="name"),), name="Simple")
    Model = PydanticSpecAdapter.create_model(op, model_name="SimpleModel")

    # strict=False: should return None on error
    result = PydanticSpecAdapter.validate_response("invalid", Model, strict=False)
    assert result is None


def test_validate_response_raises_on_error_when_strict(monkeypatch):
    """Test validate_response raises on error when strict=True."""

    def _raise_value_error():
        raise ValueError("parse error")

    # Make parse_json raise an error
    monkeypatch.setattr(
        "lionpride.libs.string_handlers.extract_json",
        lambda text, fuzzy_parse=True: _raise_value_error(),
    )

    op = Operable((create_spec(str, name="name"),), name="Simple")
    Model = PydanticSpecAdapter.create_model(op, model_name="SimpleModel")

    # strict=True: should raise on error
    with pytest.raises(ValueError, match="parse error"):
        PydanticSpecAdapter.validate_response("invalid", Model, strict=True)


# -- Fuzzy matching integration ----------------------------------------------


def test_fuzzy_match_fields_filters_sentinel_values():
    """Test that fuzzy_match_fields filters out sentinel values."""
    from lionpride.types import Unset

    # Create model with two fields
    op = Operable((create_spec(str, name="name"), create_spec(int, name="age")), name="Person")
    Model = PydanticSpecAdapter.create_model(op, model_name="PersonModel")

    # Data with sentinel value
    data = {"name": "charlie", "age": Unset}

    # Should filter out Unset
    matched = PydanticSpecAdapter.fuzzy_match_fields(data, Model, strict=False)
    assert "age" not in matched
    assert matched == {"name": "charlie"}


def test_fuzzy_match_fields_strict_mode():
    """
    Strict fuzzy matching rejects unmatched keys (production API correctness)

    **Pattern**: Strict validation with fuzzy matching

    **Scenario**: Data contains fields not defined in model schema
    ```python
    # Model fields: ["name"]
    # Data: {"name": "alice", "unknown_field": "value"}
    # Unknown: ["unknown_field"]
    # strict=True → ValueError
    ```

    **Expected Behavior**:
    - Unmatched keys detected: `["unknown_field"]`
    - ValueError raised immediately (fail fast)
    - Error message lists unmatched keys
    - No partial matching (all-or-nothing validation)

    **Validation Strategy**: Strict (`strict=True`)
    - **Extra Keys**: Raise ValueError (no silent ignoring)
    - **Error Handling**: Propagate exception (no None return)
    - **Use Cases**: Production APIs, database writes, security-critical

    **Design Rationale**:

    **Why Reject Extra Keys in Strict Mode?**
    - **Security**: Unknown fields could be injection attempts
      ```python
      # Attack: {"name": "alice", "__admin__": True}
      # Strict mode rejects → attack fails
      ```
    - **Correctness**: Extra fields indicate API version mismatch
      ```python
      # Client sends: {"name": "alice", "new_field": "value"}
      # Server expects: {"name": str}
      # Strict mode rejects → client is outdated
      ```
    - **Debugging**: Fail fast with clear error message
      ```python
      # Error: "Unmatched keys: ['new_field']"
      # Developer knows: schema mismatch, not silent data loss
      ```

    **Comparison: Strict vs Lenient**:
    | Aspect | Strict | Lenient |
    |--------|--------|---------|
    | Extra keys | ValueError | Ignore |
    | Use case | Production API | LLM response |
    | Security | High (reject unknown) | Low (accept anything) |
    | Debugging | Easy (explicit error) | Hard (silent ignore) |
    | Tolerance | Zero | High |

    **When to Use Strict Mode?**
    - REST API request validation (reject malformed requests)
    - Database ORM writes (schema enforcement)
    - External data sources (detect format changes)
    - Security-critical flows (no unexpected data)

    **When to Use Lenient Mode?**
    - LLM responses (may have extra explanation text)
    - User input forms (may have client-side fields)
    - Third-party APIs (may have extra metadata)
    - Prototyping (want to see what works)

    **Alternative Considered**: Warn on extra keys (log warning, continue)
    **Rejected Because**: Warnings often ignored; strict mode forces handling; production should fail fast

    **Performance**: O(data_keys x model_fields) for matching, then O(1) for error raise
    """
    # Create model
    op = Operable((create_spec(str, name="name"),), name="Simple")
    Model = PydanticSpecAdapter.create_model(op, model_name="SimpleModel2")

    # Data with unmatched key
    data = {"name": "alice", "unknown_field": "value"}

    # strict=True should raise ValueError for unmatched keys
    with pytest.raises(ValueError):
        PydanticSpecAdapter.fuzzy_match_fields(data, Model, strict=True)


# -- Generic type preservation -----------------------------------------------


def test_generic_type_annotations_preserved():
    """Test that Generic[M] type annotations are preserved in adapter protocol."""
    from typing import Generic, get_args, get_origin

    # Check that SpecAdapter inherits from Generic
    # __orig_bases__ contains both ABC and Generic[M]
    bases = SpecAdapter.__orig_bases__  # type: ignore[attr-defined]
    generic_bases = [b for b in bases if get_origin(b) is Generic]
    assert len(generic_bases) == 1, "SpecAdapter should inherit from Generic[M]"

    # Check that PydanticSpecAdapter binds the generic to BaseModel
    # This is compile-time only, but we can verify the inheritance
    assert issubclass(PydanticSpecAdapter, SpecAdapter)


def test_create_model_returns_correct_type():
    """Test that create_model returns the correct model class type."""
    op = Operable((create_spec(str, name="name"),), name="Test")
    Model = PydanticSpecAdapter.create_model(op, model_name="TestModel")

    # Should return a type (class)
    assert isinstance(Model, type)

    # Should be a Pydantic BaseModel subclass
    from pydantic import BaseModel

    assert issubclass(Model, BaseModel)


def test_validate_model_returns_instance():
    """Test that validate_model returns an instance of the model."""
    op = Operable((create_spec(str, name="name"),), name="Test")
    Model = PydanticSpecAdapter.create_model(op, model_name="TestModel2")

    inst = PydanticSpecAdapter.validate_model(Model, {"name": "test"})

    # Should return an instance
    assert isinstance(inst, Model)

    # Should have correct data
    assert inst.name == "test"  # type: ignore[attr-defined]


def test_dump_model_returns_dict():
    """Test that dump_model returns a dictionary."""
    op = Operable((create_spec(str, name="name"), create_spec(int, name="age")), name="Test")
    Model = PydanticSpecAdapter.create_model(op, model_name="TestModel3")

    inst = PydanticSpecAdapter.validate_model(Model, {"name": "alice", "age": 30})
    dumped = PydanticSpecAdapter.dump_model(inst)

    # Should return a dict
    assert isinstance(dumped, dict)

    # Should have correct structure
    assert dumped == {"name": "alice", "age": 30}


# -- Coverage targets for pydantic_field.py ----------------------------------


def test_create_field_callable_default():
    """Test create_field converts callable defaults to default_factory.

    Design: Pydantic distinguishes between static defaults and factory functions.
    When a Spec has a callable default, PydanticSpecAdapter converts it to
    Pydantic's default_factory, ensuring the callable is invoked per-instance
    rather than being used as a static value.
    """
    from pydantic_core import PydanticUndefined

    # Create spec with callable default
    def get_default():
        return "generated"

    spec = Spec(str, name="field_with_callable", default=get_default)

    # Create field
    field_info = PydanticSpecAdapter.create_field(spec)

    # Should use default_factory for callable
    assert field_info.default_factory is get_default
    assert field_info.default is PydanticUndefined  # Pydantic's sentinel for "use default_factory"


def test_create_field_custom_pydantic_params():
    """Test create_field passes Pydantic-specific metadata to Field.

    Design: Spec metadata that matches Pydantic Field parameters (description,
    title, constraints like min_length) is forwarded to Pydantic's Field
    constructor. This enables full Pydantic validation without requiring
    Pydantic-specific Spec subclasses.
    """
    # Create spec with pydantic-specific metadata
    spec = Spec(
        str,
        name="field_with_params",
        description="A test field",
        title="Test Field",
        min_length=3,
        max_length=10,
    )

    # Create field
    field_info = PydanticSpecAdapter.create_field(spec)

    # Should preserve pydantic field params
    assert field_info.description == "A test field"
    assert field_info.title == "Test Field"
    # min_length and max_length might be in constraints
    assert hasattr(field_info, "metadata") or hasattr(field_info, "constraints")


def test_create_field_type_metadata_skipped():
    """Test create_field filters out type objects from metadata.

    Design: Type objects cannot be JSON-serialized and would break Pydantic's
    schema generation. PydanticSpecAdapter filters out type values when building
    json_schema_extra, keeping only serializable metadata. This prevents runtime
    errors while preserving useful metadata for documentation and validation.
    """
    # Create spec with type object in metadata
    spec = Spec(
        str,
        name="field_with_type_meta",
        custom_type=int,  # Type object that can't be serialized
        other_meta="value",
    )

    # Create field
    field_info = PydanticSpecAdapter.create_field(spec)

    # Type object should be skipped, other metadata should be in json_schema_extra
    if field_info.json_schema_extra:
        # Should not have the type object
        assert "custom_type" not in field_info.json_schema_extra
        # Should have other metadata
        assert field_info.json_schema_extra.get("other_meta") == "value"
