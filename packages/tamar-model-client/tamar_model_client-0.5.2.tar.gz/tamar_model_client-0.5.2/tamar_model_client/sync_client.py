"""
Tamar Model Client åŒæ­¥å®¢æˆ·ç«¯å®ç°

æœ¬æ¨¡å—å®ç°äº†åŒæ­¥çš„ gRPC å®¢æˆ·ç«¯ï¼Œç”¨äºä¸ Model Manager Server è¿›è¡Œé€šä¿¡ã€‚
æä¾›äº†ä¸å¼‚æ­¥å®¢æˆ·ç«¯ç›¸åŒçš„åŠŸèƒ½ï¼Œä½†ä½¿ç”¨åŒæ­¥ APIï¼Œé€‚åˆåœ¨åŒæ­¥ç¯å¢ƒä¸­ä½¿ç”¨ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- åŒæ­¥ gRPC é€šä¿¡
- JWT è®¤è¯
- è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†
- è¿æ¥æ± ç®¡ç†
- è¯¦ç»†çš„æ—¥å¿—è®°å½•

ä½¿ç”¨ç¤ºä¾‹ï¼š
    with TamarModelClient() as client:
        request = ModelRequest(...)
        response = client.invoke(request)
        
æ³¨æ„ï¼šå¯¹äºéœ€è¦é«˜å¹¶å‘çš„åœºæ™¯ï¼Œå»ºè®®ä½¿ç”¨ AsyncTamarModelClient
"""

import json
import logging
import random
import threading
import time
from typing import Optional, Union, Iterator

import grpc

from .core import (
    generate_request_id,
    set_request_id,
    set_origin_request_id,
    get_protected_logger,
    MAX_MESSAGE_LENGTH, 
    get_request_id,
    RequestIdManager
)
from .core.base_client import BaseClient
from .core.request_builder import RequestBuilder
from .core.response_handler import ResponseHandler
from .core.channel_pool import ChannelPool
from .exceptions import ConnectionError, TamarModelException
from .generated import model_service_pb2, model_service_pb2_grpc
from .schemas import BatchModelResponse, ModelResponse, TaskStatusResponse, BatchTaskStatusResponse
from .schemas.inputs import BatchModelRequest, ModelRequest
from .core.http_fallback import HttpFallbackMixin

# é…ç½®æ—¥å¿—è®°å½•å™¨ï¼ˆä½¿ç”¨å—ä¿æŠ¤çš„loggerï¼‰
logger = get_protected_logger(__name__)


class TamarModelClient(BaseClient, HttpFallbackMixin):
    """
    Tamar Model Client åŒæ­¥å®¢æˆ·ç«¯
    
    æä¾›ä¸ Model Manager Server çš„åŒæ­¥é€šä¿¡èƒ½åŠ›ï¼Œæ”¯æŒï¼š
    - å•ä¸ªå’Œæ‰¹é‡æ¨¡å‹è°ƒç”¨
    - æµå¼å’Œéæµå¼å“åº”  
    - è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯æ¢å¤
    - JWT è®¤è¯
    - è¿æ¥æ± ç®¡ç†
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # åŸºæœ¬ç”¨æ³•
        client = TamarModelClient()
        client.connect()
        
        request = ModelRequest(...)
        response = client.invoke(request)
        
        # ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç”¨æ³•ï¼ˆæ¨èï¼‰
        with TamarModelClient() as client:
            response = client.invoke(request)
    
    ç¯å¢ƒå˜é‡é…ç½®ï¼š
        MODEL_MANAGER_SERVER_ADDRESS: gRPC æœåŠ¡å™¨åœ°å€
        MODEL_MANAGER_SERVER_JWT_SECRET_KEY: JWT å¯†é’¥
        MODEL_MANAGER_SERVER_GRPC_USE_TLS: æ˜¯å¦ä½¿ç”¨ TLS
        MODEL_MANAGER_SERVER_GRPC_MAX_RETRIES: æœ€å¤§é‡è¯•æ¬¡æ•°
        MODEL_MANAGER_SERVER_GRPC_RETRY_DELAY: é‡è¯•å»¶è¿Ÿ
    """
    
    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ–åŒæ­¥å®¢æˆ·ç«¯
        
        å‚æ•°ç»§æ‰¿è‡ª BaseClientï¼ŒåŒ…æ‹¬ï¼š
        - server_address: gRPC æœåŠ¡å™¨åœ°å€
        - jwt_secret_key: JWT ç­¾åå¯†é’¥
        - jwt_token: é¢„ç”Ÿæˆçš„ JWT ä»¤ç‰Œ
        - default_payload: JWT ä»¤ç‰Œçš„é»˜è®¤è½½è·
        - token_expires_in: JWT ä»¤ç‰Œè¿‡æœŸæ—¶é—´
        - max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        - retry_delay: åˆå§‹é‡è¯•å»¶è¿Ÿ
        """
        super().__init__(logger_name=__name__, **kwargs)

        # === è¿æ¥æ±  ===
        self.channel_pool: Optional[ChannelPool] = None
        self._pool_enabled = self._should_use_pool()

        # === å•è¿æ¥æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰===
        if not self._pool_enabled:
            self.channel: Optional[grpc.Channel] = None
            self.stub: Optional[model_service_pb2_grpc.ModelServiceStub] = None
            self._channel_error_count = 0
            self._last_channel_error_time = None
            self._channel_lock = threading.Lock()

        # === Request ID ç®¡ç† ===
        self._request_id_manager = RequestIdManager()

    def close(self):
        """
        å…³é—­å®¢æˆ·ç«¯è¿æ¥

        ä¼˜é›…åœ°å…³é—­ gRPC é€šé“å¹¶æ¸…ç†èµ„æºã€‚
        å»ºè®®åœ¨ç¨‹åºç»“æŸå‰è°ƒç”¨æ­¤æ–¹æ³•ï¼Œæˆ–ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†ã€‚
        """
        if self._closed:
            return

        if self._pool_enabled and self.channel_pool:
            self.channel_pool.close()
            logger.info("ğŸ”’ Connection pool closed",
                        extra={"log_type": "pool_close", "data": {"mode": "pool"}})
        elif self.channel:
            self.channel.close()
            logger.info("ğŸ”’ gRPC channel closed",
                        extra={"log_type": "channel_close", "data": {"mode": "single"}})

        self._closed = True

    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.connect()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()

    def connect(self):
        """
        æ˜¾å¼è¿æ¥åˆ°æœåŠ¡å™¨
        
        å»ºç«‹ä¸ gRPC æœåŠ¡å™¨çš„è¿æ¥ã€‚é€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨ï¼Œ
        å› ä¸º invoke æ–¹æ³•ä¼šè‡ªåŠ¨ç¡®ä¿è¿æ¥å·²å»ºç«‹ã€‚
        """
        self._ensure_initialized()

    def _ensure_initialized(self):
        """
        åˆå§‹åŒ–gRPCé€šé“æˆ–è¿æ¥æ± 

        æ ¹æ®é…ç½®å†³å®šä½¿ç”¨è¿æ¥æ± æ¨¡å¼è¿˜æ˜¯å•è¿æ¥æ¨¡å¼
        """
        if self._pool_enabled:
            self._ensure_pool_initialized()
        else:
            self._ensure_single_channel_initialized()

    def _ensure_pool_initialized(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        if self.channel_pool is not None:
            return

        try:
            self.channel_pool = ChannelPool(
                pool_size=self.pool_size,
                server_address=self.server_address,
                channel_options=self.build_channel_options(),
                use_tls=self.use_tls,
                stub_class=model_service_pb2_grpc.ModelServiceStub,
                logger=logger
            )
            logger.info(
                f"âœ… Connection pool initialized with {self.pool_size} channels",
                extra={
                    "log_type": "pool_init",
                    "data": {
                        "pool_size": self.pool_size,
                        "server_address": self.server_address
                    }
                }
            )
        except Exception as e:
            logger.error(f"âŒ Failed to initialize connection pool: {e}", exc_info=True)
            raise ConnectionError(f"Failed to initialize connection pool: {e}")

    def _ensure_single_channel_initialized(self):
        """
        åˆå§‹åŒ–å•ä¸ªgRPCé€šé“ï¼ˆå‘åå…¼å®¹ï¼‰

        Raises:
            ConnectionError: å½“è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ä»æ— æ³•è¿æ¥æ—¶
        """
        if self.channel and self.stub and self._is_channel_healthy():
            return

        # å¦‚æœ channel å­˜åœ¨ä½†ä¸å¥åº·ï¼Œè®°å½•æ—¥å¿—
        if self.channel and self.stub:
            logger.warning(
                "âš ï¸ Channel exists but unhealthy, will recreate",
                extra={
                    "log_type": "channel_recreate",
                    "data": {
                        "channel_error_count": self._channel_error_count,
                        "time_since_last_error": time.time() - self._last_channel_error_time if self._last_channel_error_time else None
                    }
                }
            )
            self._recreate_channel()

        retry_count = 0
        options = self.build_channel_options()

        while retry_count <= self.max_retries:
            try:
                if self.use_tls:
                    credentials = grpc.ssl_channel_credentials()
                    self.channel = grpc.secure_channel(
                        self.server_address,
                        credentials,
                        options=options
                    )
                    logger.info("ğŸ” Using secure gRPC channel (TLS enabled)",
                                extra={"log_type": "info",
                                       "data": {"tls_enabled": True, "server_address": self.server_address}})
                else:
                    self.channel = grpc.insecure_channel(
                        f"dns:///{self.server_address}",
                        options=options
                    )
                    logger.info("ğŸ”“ Using insecure gRPC channel (TLS disabled)",
                                extra={"log_type": "info",
                                       "data": {"tls_enabled": False, "server_address": self.server_address}})

                # ç­‰å¾…é€šé“å°±ç»ª
                grpc.channel_ready_future(self.channel).result(timeout=10)
                self.stub = model_service_pb2_grpc.ModelServiceStub(self.channel)
                logger.info(f"âœ… gRPC channel initialized to {self.server_address}",
                            extra={"log_type": "info",
                                   "data": {"status": "success", "server_address": self.server_address}})
                return

            except grpc.FutureTimeoutError as e:
                logger.error(f"âŒ gRPC channel initialization timed out: {str(e)}", exc_info=True,
                             extra={"log_type": "info",
                                    "data": {"error_type": "timeout", "server_address": self.server_address}})
            except grpc.RpcError as e:
                logger.error(f"âŒ gRPC channel initialization failed: {str(e)}", exc_info=True,
                             extra={"log_type": "info",
                                    "data": {"error_type": "grpc_error", "server_address": self.server_address}})
            except Exception as e:
                logger.error(f"âŒ Unexpected error during gRPC channel initialization: {str(e)}", exc_info=True,
                             extra={"log_type": "info",
                                    "data": {"error_type": "unknown", "server_address": self.server_address}})

            retry_count += 1
            if retry_count <= self.max_retries:
                time.sleep(self.retry_delay * retry_count)

        raise ConnectionError(f"Failed to connect to {self.server_address} after {self.max_retries} retries")
    
    def _is_channel_healthy(self) -> bool:
        """
        æ£€æŸ¥ channel æ˜¯å¦å¥åº·
        
        Returns:
            bool: True å¦‚æœ channel å¥åº·ï¼ŒFalse å¦‚æœéœ€è¦é‡å»º
        """
        if not self.channel:
            return False
            
        try:
            # æ£€æŸ¥ channel çŠ¶æ€
            state = self.channel._channel.check_connectivity_state(False)
            
            # å¦‚æœå¤„äºå…³é—­æˆ–å¤±è´¥çŠ¶æ€ï¼Œéœ€è¦é‡å»º
            if state in [grpc.ChannelConnectivity.SHUTDOWN, 
                        grpc.ChannelConnectivity.TRANSIENT_FAILURE]:
                logger.warning(f"âš ï¸ Channel in unhealthy state: {state}",
                             extra={"log_type": "info", 
                                   "data": {"channel_state": str(state)}})
                return False
                
            # å¿«é€Ÿå¤±è´¥æ£€æµ‹ï¼šå¦‚æœè¿ç»­ç«‹å³å¤±è´¥ï¼Œè¯´æ˜è¿æ¥å·²å
            # é™ä½é˜ˆå€¼ï¼Œæ›´å¿«æ ‡è®°é—®é¢˜è¿æ¥
            if self._channel_error_count > 2 and self._last_channel_error_time:
                time_since_error = time.time() - self._last_channel_error_time
                # 30ç§’å†…è¶…è¿‡2æ¬¡é”™è¯¯ï¼Œè¯´æ˜è¿æ¥æœ‰é—®é¢˜
                if time_since_error < 30:
                    logger.warning(
                        "âš ï¸ Too many channel errors recently, marking as unhealthy",
                        extra={
                            "log_type": "info",
                            "data": {
                                "error_count": self._channel_error_count,
                                "time_window": time_since_error
                            }
                        }
                    )
                    return False
                    
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error checking channel health: {e}",
                        extra={"log_type": "info", 
                              "data": {"error": str(e)}})
            return False
    
    def _recreate_channel(self):
        """
        é‡å»º gRPC channel
        
        å…³é—­æ—§çš„ channel å¹¶åˆ›å»ºæ–°çš„è¿æ¥
        """
        with self._channel_lock:
            # å…³é—­æ—§ channel
            if self.channel:
                try:
                    self.channel.close()
                    logger.info("ğŸ”š Closed unhealthy channel",
                              extra={"log_type": "info"})
                except Exception as e:
                    logger.warning(f"âš ï¸ Error closing channel: {e}",
                                 extra={"log_type": "info"})
                    
            # æ¸…ç©ºå¼•ç”¨
            self.channel = None
            self.stub = None
            
            # é‡ç½®é”™è¯¯è®¡æ•°
            self._channel_error_count = 0
            self._last_channel_error_time = None
            
            logger.info("ğŸ”„ Recreating gRPC channel...",
                       extra={"log_type": "info"})
    
    def _record_channel_error(self, error: grpc.RpcError):
        """
        è®°å½• channel é”™è¯¯ï¼Œç”¨äºå¥åº·æ£€æŸ¥

        Args:
            error: gRPC é”™è¯¯
        """
        if self._pool_enabled and self.channel_pool:
            # è¿æ¥æ± æ¨¡å¼ï¼šè®°å½•åˆ°è¿æ¥æ± 
            self.channel_pool.record_error(error)
        elif not self._pool_enabled:
            # å•è¿æ¥æ¨¡å¼ï¼šè®°å½•åˆ°å•è¿æ¥ç»Ÿè®¡
            self._channel_error_count += 1
            self._last_channel_error_time = time.time()

            # è·å–å½“å‰ channel çŠ¶æ€
            channel_state = None
            if self.channel:
                try:
                    channel_state = self.channel._channel.check_connectivity_state(False)
                except:
                    channel_state = "UNKNOWN"

            # å¯¹äºä¸¥é‡é”™è¯¯ï¼Œå¢åŠ é”™è¯¯æƒé‡
            if error.code() in [grpc.StatusCode.INTERNAL,
                               grpc.StatusCode.UNAVAILABLE]:
                self._channel_error_count += 2

            # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            logger.warning(
                f"âš ï¸ Channel error recorded: {error.code().name}",
                extra={
                    "log_type": "channel_error",
                    "data": {
                        "error_code": error.code().name,
                        "error_count": self._channel_error_count,
                        "channel_state": str(channel_state) if channel_state else "NO_CHANNEL",
                        "time_since_last_error": time.time() - self._last_channel_error_time if self._last_channel_error_time else 0,
                        "error_details": error.details() if hasattr(error, 'details') else "",
                        "debug_string": error.debug_error_string() if hasattr(error, 'debug_error_string') else ""
                    }
                }
            )

    def _retry_request(self, func, *args, **kwargs):
        """
        ç®€åŒ–çš„é‡è¯•é€»è¾‘ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

        æ ¸å¿ƒèŒè´£ï¼š
        1. æ‰§è¡Œè¯·æ±‚å¹¶åœ¨å¤±è´¥æ—¶é‡è¯•
        2. è®°å½•é”™è¯¯å’Œé‡è¯•æ—¥å¿—
        3. åœ¨æ‰€æœ‰é‡è¯•å¤±è´¥åå°è¯•é™çº§ï¼ˆå¦‚æœå¯ç”¨ï¼‰

        é™çº§é€»è¾‘å·²ç§»å‡ºé‡è¯•å¾ªç¯ï¼Œé¿å…åµŒå¥—å¤æ‚åº¦
        """
        method_start_time = time.time()
        request_id = kwargs.pop('request_id', None) or get_request_id()

        context = {
            'method': func.__name__ if hasattr(func, '__name__') else 'unknown',
            'client_version': 'sync',
            'request_id': request_id,
        }

        last_error = None

        for attempt in range(self.max_retries + 1):
            try:
                context['retry_count'] = attempt
                return func(*args, **kwargs)

            except grpc.RpcError as e:
                last_error = e
                context['retry_count'] = attempt
                current_duration = time.time() - method_start_time

                # è®°å½•channelé”™è¯¯ï¼ˆç”¨äºå¥åº·æ£€æŸ¥ï¼‰
                try:
                    self._record_channel_error(e)
                except Exception:
                    pass  # ä¸è®©å¥åº·æ£€æŸ¥å¤±è´¥å½±å“é‡è¯•

                # åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»§ç»­é‡è¯•
                should_retry = self._should_retry(e, attempt)

                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                if not should_retry or attempt >= self.max_retries:
                    context['duration'] = current_duration

                    # å°è¯•é™çº§ï¼ˆåœ¨æ‰€æœ‰é‡è¯•å¤±è´¥åï¼‰
                    fallback_result = self._try_fallback_on_final_failure(e, attempt, context)
                    if fallback_result is not None:
                        return fallback_result

                    # é™çº§ä¹Ÿå¤±è´¥ï¼Œè®°å½•æœ€ç»ˆå¤±è´¥æ—¥å¿—
                    self._log_final_failure(e, attempt, current_duration, context)
                    raise self.error_handler.handle_error(e, context)

                # è¿˜å¯ä»¥é‡è¯•ï¼Œè®°å½•æ—¥å¿—å¹¶ç­‰å¾…
                self._log_retry_attempt(e, attempt, current_duration, context)

                if attempt < self.max_retries:
                    delay = self._calculate_backoff(attempt, e.code())
                    time.sleep(delay)

        # ä¸åº”è¯¥åˆ°è¿™é‡Œ
        if last_error:
            raise self.error_handler.handle_error(last_error, context)
        raise TamarModelException("Unexpected retry loop exit")

    def _try_fallback_on_final_failure(self, error: grpc.RpcError, attempt: int, context: dict):
        """
        åœ¨æ‰€æœ‰é‡è¯•å¤±è´¥åå°è¯•é™çº§

        Returns:
            é™çº§æˆåŠŸè¿”å›ç»“æœï¼Œå¦åˆ™è¿”å› None
        """
        if not self._should_try_fallback(error.code(), attempt):
            return None

        logger.warning(
            f"ğŸš€ Attempting fallback after {attempt + 1} failed attempts",
            extra={
                "log_type": "fallback_attempt",
                "request_id": context.get('request_id'),
                "data": {
                    "error_code": error.code().name,
                    "attempts": attempt + 1
                }
            }
        )

        try:
            # å°è¯•ä»ä¸´æ—¶å­˜å‚¨è·å–è¯·æ±‚ä¿¡æ¯
            if hasattr(self, '_current_model_request'):
                model_request = self._current_model_request
                origin_request_id = getattr(self, '_current_origin_request_id', None)
                timeout = getattr(self, '_current_timeout', None)

                result = self._invoke_http_fallback(
                    model_request, timeout,
                    context.get('request_id'),
                    origin_request_id
                )

                logger.info(
                    "âœ… Fallback to HTTP succeeded",
                    extra={
                        "log_type": "fallback_success",
                        "request_id": context.get('request_id'),
                        "data": {"grpc_attempts": attempt + 1}
                    }
                )
                return result

            elif hasattr(self, '_current_batch_request'):
                batch_request = self._current_batch_request
                origin_request_id = getattr(self, '_current_origin_request_id', None)
                timeout = getattr(self, '_current_timeout', None)

                result = self._invoke_batch_http_fallback(
                    batch_request, timeout,
                    context.get('request_id'),
                    origin_request_id
                )

                logger.info(
                    "âœ… Batch fallback to HTTP succeeded",
                    extra={
                        "log_type": "fallback_success",
                        "request_id": context.get('request_id'),
                        "data": {"grpc_attempts": attempt + 1}
                    }
                )
                return result

        except Exception as fallback_error:
            logger.warning(
                f"âš ï¸ Fallback to HTTP failed: {str(fallback_error)}",
                extra={
                    "log_type": "fallback_failed",
                    "request_id": context.get('request_id'),
                    "data": {"error": str(fallback_error)}
                }
            )

        return None

    def _log_retry_attempt(self, error: grpc.RpcError, attempt: int, duration: float, context: dict):
        """è®°å½•é‡è¯•æ—¥å¿—"""
        error_detail = f" - {error.details()}" if error.details() else ""
        logger.warning(
            f"ğŸ”„ Attempt {attempt + 1}/{self.max_retries + 1} failed: {error.code()}{error_detail} (will retry)",
            extra={
                "log_type": "retry",
                "request_id": context.get('request_id'),
                "duration": duration,
                "data": {
                    "error_code": error.code().name,
                    "error_details": error.details() if hasattr(error, 'details') else '',
                    "attempt": attempt,
                    "max_retries": self.max_retries
                }
            }
        )

    def _log_final_failure(self, error: grpc.RpcError, attempt: int, duration: float, context: dict):
        """è®°å½•æœ€ç»ˆå¤±è´¥æ—¥å¿—"""
        error_detail = f" - {error.details()}" if error.details() else ""
        logger.error(
            f"âŒ All {attempt + 1} attempts failed: {error.code()}{error_detail}",
            extra={
                "log_type": "final_failure",
                "request_id": context.get('request_id'),
                "duration": duration,
                "data": {
                    "error_code": error.code().name,
                    "error_details": error.details() if hasattr(error, 'details') else '',
                    "total_attempts": attempt + 1,
                    "max_retries": self.max_retries
                }
            }
        )

    def _should_retry(self, error: grpc.RpcError, attempt: int) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•

        Args:
            error: gRPCé”™è¯¯
            attempt: å½“å‰é‡è¯•æ¬¡æ•°

        Returns:
            bool: æ˜¯å¦åº”è¯¥é‡è¯•
        """
        error_code = error.code()
        from .exceptions import get_retry_policy, ErrorContext
        policy = get_retry_policy(error_code)

        # ç‰¹æ®Šå¤„ç† UNAUTHENTICATED é”™è¯¯ï¼šå°è¯•åˆ·æ–° token
        if error_code == grpc.StatusCode.UNAUTHENTICATED:
            # å°è¯•åˆ·æ–° token
            token_refreshed = self.force_refresh_token()
            if token_refreshed:
                # Token åˆ·æ–°æˆåŠŸï¼Œå…è®¸é‡è¯•ï¼ˆåªé‡è¯•ä¸€æ¬¡ï¼‰
                return attempt < 1
            else:
                # Token æ— æ³•åˆ·æ–°ï¼ˆä½¿ç”¨é¢„ç”Ÿæˆ tokenï¼‰ï¼Œä¸é‡è¯•
                return False

        # å…ˆæ£€æŸ¥é”™è¯¯çº§åˆ«çš„ max_attempts é…ç½®
        # max_attempts è¡¨ç¤ºæœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆä¸åŒ…æ‹¬åˆå§‹è¯·æ±‚ï¼‰
        error_max_attempts = policy.get('max_attempts', self.max_retries)
        if attempt >= error_max_attempts:
            return False

        # å†æ£€æŸ¥å…¨å±€çš„ max_retries
        if attempt >= self.max_retries:
            return False

        retryable = policy.get('retryable', False)

        if retryable == False:
            return False
        elif retryable == True:
            return True
        elif retryable == 'conditional':
            # æ¡ä»¶é‡è¯•ï¼Œç‰¹æ®Šå¤„ç†
            if error_code == grpc.StatusCode.CANCELLED:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œä¸­æ–­å¯¼è‡´çš„å–æ¶ˆ
                context = {'method': 'unknown', 'client_version': 'sync'}
                error_context = ErrorContext(error, context)
                return error_context.is_network_cancelled()
            else:
                return self._check_error_details_for_retry(error)

        return False
    
    def _check_error_details_for_retry(self, error: grpc.RpcError) -> bool:
        """
        æ£€æŸ¥é”™è¯¯è¯¦æƒ…å†³å®šæ˜¯å¦é‡è¯•
        
        Args:
            error: gRPCé”™è¯¯
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥é‡è¯•
        """
        error_message = error.details().lower() if error.details() else ""
        
        # å¯é‡è¯•çš„é”™è¯¯æ¨¡å¼
        retryable_patterns = [
            'temporary', 'timeout', 'unavailable', 
            'connection', 'network', 'try again'
        ]
        
        for pattern in retryable_patterns:
            if pattern in error_message:
                return True
                
        return False

    def _calculate_backoff(self, attempt: int, error_code: grpc.StatusCode = None) -> float:
        """
        è®¡ç®—é€€é¿æ—¶é—´ï¼Œæ”¯æŒä¸åŒçš„é€€é¿ç­–ç•¥
        
        Args:
            attempt: å½“å‰é‡è¯•æ¬¡æ•°
            error_code: gRPCé”™è¯¯ç ï¼Œç”¨äºç¡®å®šé€€é¿ç­–ç•¥
        """
        max_delay = 60.0
        base_delay = self.retry_delay
        
        # è·å–é”™è¯¯çš„é‡è¯•ç­–ç•¥
        if error_code:
            from .exceptions import get_retry_policy
            policy = get_retry_policy(error_code)
            backoff_type = policy.get('backoff', 'exponential')
            use_jitter = policy.get('jitter', False)
        else:
            backoff_type = 'exponential'
            use_jitter = False
        
        # æ ¹æ®é€€é¿ç±»å‹è®¡ç®—å»¶è¿Ÿ
        if backoff_type == 'linear':
            # çº¿æ€§é€€é¿ï¼šdelay * (attempt + 1)
            delay = min(base_delay * (attempt + 1), max_delay)
        else:
            # æŒ‡æ•°é€€é¿ï¼šdelay * 2^attempt
            delay = min(base_delay * (2 ** attempt), max_delay)
        
        # æ·»åŠ æŠ–åŠ¨
        if use_jitter:
            jitter_factor = 0.2  # å¢åŠ æŠ–åŠ¨èŒƒå›´ï¼Œå‡å°‘ç«äº‰
            jitter = random.uniform(0, delay * jitter_factor)
            delay += jitter
        else:
            # é»˜è®¤çš„å°é‡æŠ–åŠ¨ï¼Œé¿å…å®Œå…¨åŒæ­¥
            jitter_factor = 0.05
            jitter = random.uniform(0, delay * jitter_factor)
            delay += jitter
            
        return delay

    def _retry_request_stream(self, func, *args, **kwargs):
        """
        æµå¼è¯·æ±‚çš„é‡è¯•é€»è¾‘ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        å¯¹äºæµå¼å“åº”ï¼Œéœ€è¦ç‰¹æ®Šçš„é‡è¯•å¤„ç†ï¼Œå› ä¸ºæµä¸èƒ½ç®€å•åœ°é‡æ–°æ‰§è¡Œã€‚
        
        Args:
            func: ç”Ÿæˆæµçš„å‡½æ•°
            *args: å‡½æ•°å‚æ•°
            **kwargs: å‡½æ•°å…³é”®å­—å‚æ•°
            
        Yields:
            æµå¼å“åº”çš„æ¯ä¸ªå…ƒç´ 
        """
        # è®°å½•æ–¹æ³•å¼€å§‹æ—¶é—´
        method_start_time = time.time()
        
        # ä»kwargsä¸­æå–request_idï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œç„¶åç§»é™¤å®ƒ
        request_id = kwargs.pop('request_id', None) or get_request_id()
        
        last_exception = None
        context = {
            'method': 'stream',
            'client_version': 'sync',
            'request_id': request_id,
        }
        
        for attempt in range(self.max_retries + 1):
            try:
                context['retry_count'] = attempt
                # å°è¯•åˆ›å»ºæµ
                for item in func(*args, **kwargs):
                    yield item
                return
                
            except grpc.RpcError as e:
                # ä½¿ç”¨æ™ºèƒ½é‡è¯•åˆ¤æ–­
                context['retry_count'] = attempt
                
                # è®¡ç®—å½“å‰çš„è€—æ—¶
                current_duration = time.time() - method_start_time
                
                # åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•
                should_retry = self._should_retry(e, attempt)
                if not should_retry or attempt >= self.max_retries:
                    # ä¸é‡è¯•æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                    log_data = {
                        "log_type": "info",
                        "request_id": context.get('request_id'),
                        "data": {
                            "error_code": e.code().name if e.code() else 'UNKNOWN',
                            "error_details": e.details() if hasattr(e, 'details') else '',
                            "retry_count": attempt,
                            "max_retries": self.max_retries,
                            "method": "stream",
                            "will_retry": False
                        },
                        "duration": current_duration
                    }
                    error_detail = f" - {e.details()}" if e.details() else ""
                    logger.error(
                        f"âŒ Stream failed: {e.code()}{error_detail} (no retry)",
                        extra=log_data
                    )
                    context['duration'] = current_duration
                    last_exception = self.error_handler.handle_error(e, context)
                    break
                
                # è®°å½•é‡è¯•æ—¥å¿—
                log_data = {
                    "log_type": "info",
                    "request_id": context.get('request_id'),
                    "data": {
                        "error_code": e.code().name if e.code() else 'UNKNOWN',
                        "error_details": e.details() if hasattr(e, 'details') else '',
                        "retry_count": attempt,
                        "max_retries": self.max_retries,
                        "method": "stream"
                    },
                    "duration": current_duration
                }
                error_detail = f" - {e.details()}" if e.details() else ""
                logger.warning(
                    f"ğŸ”„ Stream attempt {attempt + 1}/{self.max_retries + 1} failed: {e.code()}{error_detail} (will retry)",
                    extra=log_data
                )
                
                # æ‰§è¡Œé€€é¿ç­‰å¾…
                if attempt < self.max_retries:
                    delay = self._calculate_backoff(attempt, e.code())
                    time.sleep(delay)
                    
                last_exception = e
                
            except Exception as e:
                context['retry_count'] = attempt
                raise TamarModelException(str(e)) from e
        
        if last_exception:
            if isinstance(last_exception, TamarModelException):
                raise last_exception
            else:
                raise self.error_handler.handle_error(last_exception, context)
        else:
            raise TamarModelException("Unknown streaming error occurred")

    def _stream(self, request, metadata, invoke_timeout, request_id=None, origin_request_id=None) -> Iterator[ModelResponse]:
        """
        å¤„ç†æµå¼å“åº”
        
        Args:
            request: gRPC è¯·æ±‚å¯¹è±¡
            metadata: è¯·æ±‚å…ƒæ•°æ®ï¼ˆä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼Œä½†ä¼šè¢«å¿½ç•¥ï¼‰
            invoke_timeout: æ€»ä½“è¶…æ—¶æ—¶é—´
            request_id: è¯·æ±‚ID
            origin_request_id: åŸå§‹è¯·æ±‚ID
            
        Yields:
            ModelResponse: æµå¼å“åº”çš„æ¯ä¸ªæ•°æ®å—
            
        Raises:
            TimeoutError: å½“ç­‰å¾…ä¸‹ä¸€ä¸ªæ•°æ®å—è¶…æ—¶æ—¶
        """
        # æ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°ç”Ÿæˆmetadataï¼Œç¡®ä¿JWT tokenæ˜¯æœ€æ–°çš„
        fresh_metadata = self._build_auth_metadata(
            request_id or get_request_id(),
            origin_request_id
        )
        import threading
        import queue

        # è·å– stubï¼ˆè¿æ¥æ± æˆ–å•è¿æ¥ï¼‰
        if self._pool_enabled:
            stub = self.channel_pool.get_stub()
        else:
            stub = self.stub

        # åˆ›å»ºé˜Ÿåˆ—ç”¨äºçº¿ç¨‹é—´é€šä¿¡
        response_queue = queue.Queue()
        exception_queue = queue.Queue()

        def fetch_responses():
            """åœ¨å•ç‹¬çº¿ç¨‹ä¸­è·å–æµå¼å“åº”"""
            try:
                for response in stub.Invoke(request, metadata=fresh_metadata, timeout=invoke_timeout):
                    response_queue.put(response)
                response_queue.put(None)  # æ ‡è®°æµç»“æŸ
            except Exception as e:
                exception_queue.put(e)
                response_queue.put(None)
        
        # å¯åŠ¨å“åº”è·å–çº¿ç¨‹
        fetch_thread = threading.Thread(target=fetch_responses)
        fetch_thread.daemon = True
        fetch_thread.start()
        
        chunk_timeout = self.stream_chunk_timeout  # å•ä¸ªæ•°æ®å—çš„è¶…æ—¶æ—¶é—´
        
        while True:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸
            if not exception_queue.empty():
                raise exception_queue.get()
            
            try:
                # ç­‰å¾…ä¸‹ä¸€ä¸ªå“åº”ï¼Œå¸¦è¶…æ—¶
                response = response_queue.get(timeout=chunk_timeout)
                
                if response is None:
                    # æµç»“æŸ
                    break
                    
                yield ResponseHandler.build_model_response(response)
                
            except queue.Empty:
                raise TimeoutError(f"æµå¼å“åº”åœ¨ç­‰å¾…ä¸‹ä¸€ä¸ªæ•°æ®å—æ—¶è¶…æ—¶ ({chunk_timeout}s)")

    def _stream_with_logging(self, request, metadata, invoke_timeout, start_time, model_request, request_id=None, origin_request_id=None) -> Iterator[
        ModelResponse]:
        """æµå¼å“åº”çš„åŒ…è£…å™¨ï¼Œç”¨äºè®°å½•å®Œæ•´çš„å“åº”æ—¥å¿—å¹¶å¤„ç†é‡è¯•"""
        total_content = ""
        final_usage = None
        error_occurred = None
        chunk_count = 0

        try:
            for response in self._stream(request, metadata, invoke_timeout, request_id, origin_request_id):
                chunk_count += 1
                if response.content:
                    total_content += response.content
                if response.usage:
                    final_usage = response.usage
                if response.error:
                    error_occurred = response.error
                yield response

            # æµå¼å“åº”å®Œæˆï¼Œè®°å½•æ—¥å¿—
            duration = time.time() - start_time
            if error_occurred:
                # æµå¼å“åº”ä¸­åŒ…å«é”™è¯¯
                logger.warning(
                    f"âš ï¸ Stream completed with errors | chunks: {chunk_count}",
                    extra={
                        "log_type": "response",
                        "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                        "duration": duration,
                        "data": ResponseHandler.build_log_data(
                            model_request,
                            stream_stats={
                                "chunks_count": chunk_count,
                                "total_length": len(total_content),
                                "usage": final_usage,
                                "error": error_occurred
                            }
                        )
                    }
                )
            else:
                # æµå¼å“åº”æˆåŠŸå®Œæˆ
                logger.info(
                    f"âœ… Stream completed successfully | chunks: {chunk_count}",
                    extra={
                        "log_type": "response",
                        "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                        "duration": duration,
                        "data": ResponseHandler.build_log_data(
                            model_request,
                            stream_stats={
                                "chunks_count": chunk_count,
                                "total_length": len(total_content),
                                "usage": final_usage
                            }
                        )
                    }
                )
        except Exception as e:
            # æµå¼å“åº”å‡ºé”™ï¼Œè®°å½•é”™è¯¯æ—¥å¿—
            duration = time.time() - start_time
            logger.error(
                f"âŒ Stream failed after {chunk_count} chunks: {str(e)}",
                exc_info=True,
                extra={
                    "log_type": "response",
                    "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                    "duration": duration,
                    "data": ResponseHandler.build_log_data(
                        model_request,
                        error=e,
                        stream_stats={
                            "chunks_count": chunk_count,
                            "partial_content_length": len(total_content)
                        }
                    )
                }
            )
            raise

    def _invoke_request(self, request, metadata, invoke_timeout, request_id=None, origin_request_id=None):
        """æ‰§è¡Œå•ä¸ªéæµå¼è¯·æ±‚

        Args:
            request: gRPCè¯·æ±‚å¯¹è±¡
            metadata: è¯·æ±‚å…ƒæ•°æ®ï¼ˆä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼Œä½†ä¼šè¢«å¿½ç•¥ï¼‰
            invoke_timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
            request_id: è¯·æ±‚ID
            origin_request_id: åŸå§‹è¯·æ±‚ID
        """
        # æ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°ç”Ÿæˆmetadataï¼Œç¡®ä¿JWT tokenæ˜¯æœ€æ–°çš„
        fresh_metadata = self._build_auth_metadata(
            request_id or get_request_id(),
            origin_request_id
        )

        # è·å– stubï¼ˆè¿æ¥æ± æˆ–å•è¿æ¥ï¼‰
        if self._pool_enabled:
            stub = self.channel_pool.get_stub()
        else:
            stub = self.stub

        response = stub.Invoke(request, metadata=fresh_metadata, timeout=invoke_timeout)
        for response in response:
            return ResponseHandler.build_model_response(response)

    def invoke(self, model_request: ModelRequest, timeout: Optional[float] = None, request_id: Optional[str] = None) -> \
            Union[ModelResponse, Iterator[ModelResponse]]:
        """
       é€šç”¨è°ƒç”¨æ¨¡å‹æ–¹æ³•ã€‚

        Args:
            model_request: ModelRequest å¯¹è±¡ï¼ŒåŒ…å«è¯·æ±‚å‚æ•°ã€‚
            timeout: Optional[float]
            request_id: Optional[str]
        Yields:
            ModelResponse: æ”¯æŒæµå¼æˆ–éæµå¼çš„æ¨¡å‹å“åº”

        Raises:
            ValidationError: è¾“å…¥éªŒè¯å¤±è´¥ã€‚
            ConnectionError: è¿æ¥æœåŠ¡ç«¯å¤±è´¥ã€‚
        """
        # å¦‚æœå¯ç”¨äº†ç†”æ–­ä¸”ç†”æ–­å™¨æ‰“å¼€ï¼Œç›´æ¥èµ° HTTP
        if self.resilient_enabled and self.circuit_breaker and self.circuit_breaker.is_open:
            if self.http_fallback_url:
                logger.warning("ğŸ”» Circuit breaker is OPEN, using HTTP fallback")
                # åœ¨è¿™é‡Œè¿˜æ²¡æœ‰è®¡ç®—origin_request_idï¼Œæ‰€ä»¥å…ˆè®¡ç®—
                temp_origin_request_id = None
                temp_request_id = request_id
                if request_id:
                    temp_request_id, temp_origin_request_id = self._request_id_manager.get_composite_id(request_id)
                return self._invoke_http_fallback(model_request, timeout, temp_request_id, temp_origin_request_id)
                
        self._ensure_initialized()

        if not self.default_payload:
            self.default_payload = {
                "org_id": model_request.user_context.org_id or "",
                "user_id": model_request.user_context.user_id or ""
            }

        # å¤„ç† request_id
        origin_request_id = None
        if request_id:
            # ç”¨æˆ·æä¾›äº† request_idï¼Œç”Ÿæˆç»„åˆ ID
            request_id, origin_request_id = self._request_id_manager.get_composite_id(request_id)
        else:
            # æ²¡æœ‰æä¾›ï¼Œç”Ÿæˆæ–°çš„
            request_id = generate_request_id()
            
        set_request_id(request_id)
        if origin_request_id:
            set_origin_request_id(origin_request_id)
        metadata = self._build_auth_metadata(request_id, origin_request_id)

        # æ„å»ºæ—¥å¿—æ•°æ®
        log_data = ResponseHandler.build_log_data(model_request)
        if origin_request_id:
            log_data['origin_request_id'] = origin_request_id

        # è®°å½•å¼€å§‹æ—¥å¿—
        start_time = time.time()
        logger.info(
            f"ğŸ”µ Request Start | request_id: {request_id} | provider: {model_request.provider} | invoke_type: {model_request.invoke_type}",
            extra={
                "log_type": "request",
                "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                "data": log_data
            })

        try:
            # æ„å»º gRPC è¯·æ±‚
            request = RequestBuilder.build_single_request(model_request)
            payload_size = request.ByteSize()
            logger.info(
                "ğŸ“¦ gRPC request payload size (bytes)",
                extra={
                    "log_type": "request_payload",
                    "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                    "data": {
                        "request_id": request_id,
                        "payload_bytes": payload_size,
                        "is_stream": bool(model_request.stream)
                    }
                }
            )
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ Request build failed: {str(e)}",
                exc_info=True,
                extra={
                    "log_type": "response",
                    "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                    "duration": duration,
                    "data": {
                        "provider": model_request.provider.value,
                        "invoke_type": model_request.invoke_type.value,
                        "model": getattr(model_request, 'model', None),
                        "error_type": "build_error",
                        "error_message": str(e)
                    }
                }
            )
            raise ValueError(f"æ„å»ºè¯·æ±‚å¤±è´¥: {str(e)}") from e

        try:
            invoke_timeout = timeout or self.default_invoke_timeout
            if model_request.stream:
                # å¯¹äºæµå¼å“åº”ï¼Œä½¿ç”¨é‡è¯•åŒ…è£…å™¨
                return self._retry_request_stream(
                    self._stream_with_logging,
                    request, metadata, invoke_timeout, start_time, model_request,
                    request_id=request_id, origin_request_id=origin_request_id
                )
            else:
                # å­˜å‚¨è¯·æ±‚ä¿¡æ¯ä¾›é™çº§ä½¿ç”¨
                self._current_model_request = model_request
                self._current_origin_request_id = origin_request_id
                self._current_timeout = invoke_timeout
                try:
                    result = self._retry_request(self._invoke_request, request, metadata, invoke_timeout, request_id=request_id, origin_request_id=origin_request_id)
                finally:
                    # æ¸…ç†ä¸´æ—¶å­˜å‚¨
                    if hasattr(self, '_current_model_request'):
                        delattr(self, '_current_model_request')
                    if hasattr(self, '_current_origin_request_id'):
                        delattr(self, '_current_origin_request_id')
                    if hasattr(self, '_current_timeout'):
                        delattr(self, '_current_timeout')

                # è®°å½•éæµå¼å“åº”çš„æˆåŠŸæ—¥å¿—
                duration = time.time() - start_time
                content_length = len(result.content) if result.content else 0
                
                # æ„å»ºå“åº”æ—¥å¿—æ•°æ®
                response_log_data = ResponseHandler.build_log_data(model_request, result)
                if origin_request_id:
                    response_log_data['origin_request_id'] = origin_request_id
                    
                logger.info(
                    f"âœ… Request completed | content_length: {content_length}",
                    extra={
                        "log_type": "response",
                        "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                        "duration": duration,
                        "data": response_log_data
                    }
                )
                
                # è®°å½•æˆåŠŸï¼ˆå¦‚æœå¯ç”¨äº†ç†”æ–­ï¼‰
                if self.resilient_enabled and self.circuit_breaker:
                    self.circuit_breaker.record_success()
                    
                return result
                
        except (ConnectionError, grpc.RpcError) as e:
            duration = time.time() - start_time
            error_message = f"âŒ Invoke gRPC failed: {str(e)}"
            
            # æ„å»ºé”™è¯¯æ—¥å¿—æ•°æ®
            error_log_data = ResponseHandler.build_log_data(model_request, error=e)
            if origin_request_id:
                error_log_data['origin_request_id'] = origin_request_id
                
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                             "duration": duration,
                             "data": error_log_data
                         })
            
            # è®°å½• channel é”™è¯¯
            if isinstance(e, grpc.RpcError):
                self._record_channel_error(e)
            
            # è®°å½•å¤±è´¥ï¼ˆå¦‚æœå¯ç”¨äº†ç†”æ–­ï¼‰
            if self.resilient_enabled and self.circuit_breaker:
                # å°†é”™è¯¯ç ä¼ é€’ç»™ç†”æ–­å™¨ï¼Œç”¨äºæ™ºèƒ½å¤±è´¥ç»Ÿè®¡
                error_code = e.code() if hasattr(e, 'code') else None
                self.circuit_breaker.record_failure(error_code)
            
            raise e
        except Exception as e:
            duration = time.time() - start_time
            error_message = f"âŒ Invoke other error: {str(e)}"
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": f"/invoke/{model_request.provider.value}/{model_request.invoke_type.value}",
                             "duration": duration,
                             "data": ResponseHandler.build_log_data(
                                 model_request,
                                 error=e
                             )
                         })
            raise e

    def invoke_batch(self, batch_request_model: BatchModelRequest, timeout: Optional[float] = None,
                     request_id: Optional[str] = None) -> BatchModelResponse:
        """
        æ‰¹é‡æ¨¡å‹è°ƒç”¨æ¥å£

        Args:
            batch_request_model: å¤šæ¡ BatchModelRequest è¾“å…¥
            timeout: è°ƒç”¨è¶…æ—¶ï¼Œå•ä½ç§’
            request_id: è¯·æ±‚id
        Returns:
            BatchModelResponse: æ‰¹é‡è¯·æ±‚çš„ç»“æœ
        """
        # å¦‚æœå¯ç”¨äº†ç†”æ–­ä¸”ç†”æ–­å™¨æ‰“å¼€ï¼Œç›´æ¥èµ° HTTP
        if self.resilient_enabled and self.circuit_breaker and self.circuit_breaker.is_open:
            if self.http_fallback_url:
                logger.warning("ğŸ”» Circuit breaker is OPEN, using HTTP fallback for batch request")
                # åœ¨è¿™é‡Œè¿˜æ²¡æœ‰è®¡ç®—origin_request_idï¼Œæ‰€ä»¥å…ˆè®¡ç®—
                temp_origin_request_id = None
                temp_request_id = request_id
                if request_id:
                    temp_request_id, temp_origin_request_id = self._request_id_manager.get_composite_id(request_id)
                return self._invoke_batch_http_fallback(batch_request_model, timeout, temp_request_id, temp_origin_request_id)
                
        self._ensure_initialized()

        if not self.default_payload:
            self.default_payload = {
                "org_id": batch_request_model.user_context.org_id or "",
                "user_id": batch_request_model.user_context.user_id or ""
            }

        # å¤„ç† request_id
        origin_request_id = None
        if request_id:
            # ç”¨æˆ·æä¾›äº† request_idï¼Œç”Ÿæˆç»„åˆ ID
            request_id, origin_request_id = self._request_id_manager.get_composite_id(request_id)
        else:
            # æ²¡æœ‰æä¾›ï¼Œç”Ÿæˆæ–°çš„
            request_id = generate_request_id()
            
        set_request_id(request_id)
        if origin_request_id:
            set_origin_request_id(origin_request_id)
        metadata = self._build_auth_metadata(request_id, origin_request_id)

        # æ„å»ºæ—¥å¿—æ•°æ®
        batch_log_data = {
            "batch_size": len(batch_request_model.items),
            "org_id": batch_request_model.user_context.org_id,
            "user_id": batch_request_model.user_context.user_id,
            "client_type": batch_request_model.user_context.client_type
        }
        if origin_request_id:
            batch_log_data['origin_request_id'] = origin_request_id

        # è®°å½•å¼€å§‹æ—¥å¿—
        start_time = time.time()
        logger.info(
            f"ğŸ”µ Batch Request Start | request_id: {request_id} | batch_size: {len(batch_request_model.items)}",
            extra={
                "log_type": "request",
                "uri": "/batch_invoke",
                "data": batch_log_data
            })

        try:
            # æ„å»ºæ‰¹é‡è¯·æ±‚
            batch_request = RequestBuilder.build_batch_request(batch_request_model)
            payload_size = batch_request.ByteSize()
            logger.info(
                "ğŸ“¦ Batch gRPC request payload size (bytes)",
                extra={
                    "log_type": "request_payload",
                    "uri": "/batch_invoke",
                    "data": {
                        "request_id": request_id,
                        "payload_bytes": payload_size,
                        "batch_size": len(batch_request_model.items)
                    }
                }
            )
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(
                f"âŒ Batch request build failed: {str(e)}",
                exc_info=True,
                extra={
                    "log_type": "response",
                    "uri": "/batch_invoke",
                    "duration": duration,
                    "data": {
                        "batch_size": len(batch_request_model.items),
                        "error_type": "build_error",
                        "error_message": str(e)
                    }
                }
            )
            raise ValueError(f"æ„å»ºæ‰¹é‡è¯·æ±‚å¤±è´¥: {str(e)}") from e

        try:
            invoke_timeout = timeout or self.default_invoke_timeout

            # ä¿å­˜æ‰¹é‡è¯·æ±‚ä¿¡æ¯ç”¨äºé™çº§
            self._current_batch_request = batch_request_model
            self._current_origin_request_id = origin_request_id
            self._current_timeout = invoke_timeout

            try:
                # è¿æ¥æ± æ¨¡å¼éœ€è¦åŒ…è£… BatchInvoke è°ƒç”¨
                if self._pool_enabled:
                    def batch_invoke_wrapper(*args, **kwargs):
                        stub = self.channel_pool.get_stub()
                        return stub.BatchInvoke(*args, **kwargs)

                    batch_response = self._retry_request(
                        batch_invoke_wrapper,
                        batch_request,
                        metadata=metadata,
                        timeout=invoke_timeout,
                        request_id=request_id
                    )
                else:
                    batch_response = self._retry_request(
                        self.stub.BatchInvoke,
                        batch_request,
                        metadata=metadata,
                        timeout=invoke_timeout,
                        request_id=request_id
                    )
            finally:
                # æ¸…ç†ä¸´æ—¶å­˜å‚¨
                if hasattr(self, '_current_batch_request'):
                    delattr(self, '_current_batch_request')
                if hasattr(self, '_current_origin_request_id'):
                    delattr(self, '_current_origin_request_id')
                if hasattr(self, '_current_timeout'):
                    delattr(self, '_current_timeout')

            # æ„å»ºå“åº”å¯¹è±¡
            result = ResponseHandler.build_batch_response(batch_response)

            # è®°å½•æˆåŠŸæ—¥å¿—
            duration = time.time() - start_time
            logger.info(
                f"âœ… Batch Request completed | batch_size: {len(result.responses)}",
                extra={
                    "log_type": "response",
                    "uri": "/batch_invoke",
                    "duration": duration,
                    "data": {
                        "batch_size": len(result.responses),
                        "success_count": sum(1 for item in result.responses if not item.error),
                        "error_count": sum(1 for item in result.responses if item.error)
                    }
                })

            return result

        except grpc.RpcError as e:
            duration = time.time() - start_time
            error_message = f"âŒ Batch invoke gRPC failed: {str(e)}"
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": "/batch_invoke",
                             "duration": duration,
                             "data": {
                                 "error_type": "grpc_error",
                                 "error_code": str(e.code()) if hasattr(e, 'code') else None,
                                 "batch_size": len(batch_request_model.items)
                             }
                         })
            
            # è®°å½•å¤±è´¥ï¼ˆå¦‚æœå¯ç”¨äº†ç†”æ–­ï¼‰
            if self.resilient_enabled and self.circuit_breaker:
                # å°†é”™è¯¯ç ä¼ é€’ç»™ç†”æ–­å™¨ï¼Œç”¨äºæ™ºèƒ½å¤±è´¥ç»Ÿè®¡
                error_code = e.code() if hasattr(e, 'code') else None
                self.circuit_breaker.record_failure(error_code)
            
            raise e
        except Exception as e:
            duration = time.time() - start_time
            error_message = f"âŒ Batch invoke other error: {str(e)}"
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": "/batch_invoke",
                             "duration": duration,
                             "data": {
                                 "error_type": "other_error",
                                 "batch_size": len(batch_request_model.items)
                             }
                         })
            raise e

    def get_task_status(self, task_id: str, timeout: Optional[float] = None) -> TaskStatusResponse:
        """
        æŸ¥è¯¢å¼‚æ­¥ä»»åŠ¡çŠ¶æ€

        Args:
            task_id: ä»»åŠ¡ID
            timeout: è°ƒç”¨è¶…æ—¶ï¼Œå•ä½ç§’

        Returns:
            TaskStatusResponse: ä»»åŠ¡çŠ¶æ€å“åº”
        """
        self._ensure_initialized()

        # ç”Ÿæˆ request_id
        request_id = generate_request_id()
        set_request_id(request_id)
        metadata = self._build_auth_metadata(request_id, None)

        # è®°å½•å¼€å§‹æ—¥å¿—
        start_time = time.time()
        logger.info(
            f"ğŸ”µ GetTaskStatus Start | request_id: {request_id} | task_id: {task_id}",
            extra={
                "log_type": "request",
                "uri": "/get_task_status",
                "data": {"task_id": task_id}
            })

        try:
            # æ„å»ºè¯·æ±‚
            request = model_service_pb2.GetTaskStatusRequest(task_id=task_id)
            invoke_timeout = timeout or self.default_invoke_timeout

            # æ‰§è¡Œè¯·æ±‚ï¼ˆå¸¦é‡è¯•ï¼‰
            if self._pool_enabled:
                def get_task_status_wrapper(*args, **kwargs):
                    stub = self.channel_pool.get_stub()
                    return stub.GetTaskStatus(*args, **kwargs)

                response = self._retry_request(
                    get_task_status_wrapper,
                    request,
                    metadata=metadata,
                    timeout=invoke_timeout,
                    request_id=request_id
                )
            else:
                response = self._retry_request(
                    self.stub.GetTaskStatus,
                    request,
                    metadata=metadata,
                    timeout=invoke_timeout,
                    request_id=request_id
                )

            # æ„å»ºå“åº”å¯¹è±¡
            result = ResponseHandler.build_task_status_response(response)

            # è®°å½•æˆåŠŸæ—¥å¿—
            duration = time.time() - start_time
            logger.info(
                f"âœ… GetTaskStatus completed | status: {result.status}",
                extra={
                    "log_type": "response",
                    "uri": "/get_task_status",
                    "duration": duration,
                    "data": {
                        "task_id": task_id,
                        "status": result.status,
                        "provider": result.provider,
                        "model": result.model
                    }
                })

            return result

        except grpc.RpcError as e:
            duration = time.time() - start_time
            error_message = f"âŒ GetTaskStatus gRPC failed: {str(e)}"
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": "/get_task_status",
                             "duration": duration,
                             "data": {
                                 "error_type": "grpc_error",
                                 "error_code": str(e.code()) if hasattr(e, 'code') else None,
                                 "task_id": task_id
                             }
                         })
            raise e
        except Exception as e:
            duration = time.time() - start_time
            error_message = f"âŒ GetTaskStatus other error: {str(e)}"
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": "/get_task_status",
                             "duration": duration,
                             "data": {
                                 "error_type": "other_error",
                                 "task_id": task_id
                             }
                         })
            raise e

    def batch_get_task_status(self, task_ids: list[str], timeout: Optional[float] = None) -> BatchTaskStatusResponse:
        """
        æ‰¹é‡æŸ¥è¯¢å¼‚æ­¥ä»»åŠ¡çŠ¶æ€

        Args:
            task_ids: ä»»åŠ¡IDåˆ—è¡¨
            timeout: è°ƒç”¨è¶…æ—¶ï¼Œå•ä½ç§’

        Returns:
            BatchTaskStatusResponse: æ‰¹é‡ä»»åŠ¡çŠ¶æ€å“åº”
        """
        self._ensure_initialized()

        # ç”Ÿæˆ request_id
        request_id = generate_request_id()
        set_request_id(request_id)
        metadata = self._build_auth_metadata(request_id, None)

        # è®°å½•å¼€å§‹æ—¥å¿—
        start_time = time.time()
        logger.info(
            f"ğŸ”µ BatchGetTaskStatus Start | request_id: {request_id} | task_count: {len(task_ids)}",
            extra={
                "log_type": "request",
                "uri": "/batch_get_task_status",
                "data": {"task_count": len(task_ids), "task_ids": task_ids}
            })

        try:
            # æ„å»ºè¯·æ±‚
            request = model_service_pb2.BatchGetTaskStatusRequest(task_ids=task_ids)
            invoke_timeout = timeout or self.default_invoke_timeout

            # æ‰§è¡Œè¯·æ±‚ï¼ˆå¸¦é‡è¯•ï¼‰
            if self._pool_enabled:
                def batch_get_task_status_wrapper(*args, **kwargs):
                    stub = self.channel_pool.get_stub()
                    return stub.BatchGetTaskStatus(*args, **kwargs)

                response = self._retry_request(
                    batch_get_task_status_wrapper,
                    request,
                    metadata=metadata,
                    timeout=invoke_timeout,
                    request_id=request_id
                )
            else:
                response = self._retry_request(
                    self.stub.BatchGetTaskStatus,
                    request,
                    metadata=metadata,
                    timeout=invoke_timeout,
                    request_id=request_id
                )

            # æ„å»ºå“åº”å¯¹è±¡
            result = ResponseHandler.build_batch_task_status_response(response)

            # è®°å½•æˆåŠŸæ—¥å¿—
            duration = time.time() - start_time
            logger.info(
                f"âœ… BatchGetTaskStatus completed | task_count: {len(result.tasks)}",
                extra={
                    "log_type": "response",
                    "uri": "/batch_get_task_status",
                    "duration": duration,
                    "data": {
                        "task_count": len(result.tasks),
                        "status_summary": {
                            "processing": sum(1 for t in result.tasks if t.status == "processing"),
                            "completed": sum(1 for t in result.tasks if t.status == "completed"),
                            "failed": sum(1 for t in result.tasks if t.status == "failed")
                        }
                    }
                })

            return result

        except grpc.RpcError as e:
            duration = time.time() - start_time
            error_message = f"âŒ BatchGetTaskStatus gRPC failed: {str(e)}"
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": "/batch_get_task_status",
                             "duration": duration,
                             "data": {
                                 "error_type": "grpc_error",
                                 "error_code": str(e.code()) if hasattr(e, 'code') else None,
                                 "task_count": len(task_ids)
                             }
                         })
            raise e
        except Exception as e:
            duration = time.time() - start_time
            error_message = f"âŒ BatchGetTaskStatus other error: {str(e)}"
            logger.error(error_message, exc_info=True,
                         extra={
                             "log_type": "response",
                             "uri": "/batch_get_task_status",
                             "duration": duration,
                             "data": {
                                 "error_type": "other_error",
                                 "task_count": len(task_ids)
                             }
                         })
            raise e
