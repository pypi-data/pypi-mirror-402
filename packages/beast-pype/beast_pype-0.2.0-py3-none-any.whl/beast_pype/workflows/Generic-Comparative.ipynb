{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b302d9fa98fb0b",
   "metadata": {},
   "source": [
    "# Workflow Generic Comparative Notebook\n",
    "\n",
    "\n",
    "This Workflow Notebook is for Comparing BEAST runs were the settings in the xml are the same but the sequences are different.\n",
    "\n",
    "<details>\n",
    "    <summary>Click Here to See a Decription of Parameters</summary>\n",
    "        <pre>\n",
    "            <code>\n",
    "\n",
    "Running an Instance of this Workflow\n",
    "-------------------------------------------\n",
    "overall_save_dir:  str\n",
    "    Path to where you are saving all the runs of this workflow.\n",
    "    This creates a folder by the name you specify here e.g. creates a folder named\n",
    "    folder in the root folder to save all the files produced when running the workflow.\n",
    "\n",
    "specific_run_save_dir:  str, (optional, can be missing from yml)\n",
    "    Sub-directory of overall_save_dir you wish to save all the files from this instance of this workflow.\n",
    "    If not given a timestamp of format 'YYYY-MM-DD_hour-min-sec' is used instead.\n",
    "\n",
    "max_threads:  int, (default, can be missing from yml)\n",
    "    The maximum number of threads to use when calling gnu parallel in phases 2i and 4. If not given and BEAST_pype is running\n",
    "    in a SLURM job the SLURM environment variable `SLURM_CPUS_PER_TASK` is used. If not given and BEAST_pype is NOT running in\n",
    "    a SLURM job the number of cores available minus 1 is used (`multiprocessing.cpu_count() - 1`).\n",
    "\n",
    "kernel_name: str, default 'beast_pype'\n",
    "    Name of Jupyter python kernel to use when running workflow. This is also the name of the conda environment to use in phases 4 &\n",
    "    phase 2ii (as these Jupyter notebooks use the `bash` kernel).\n",
    "\n",
    "General Inputs\n",
    "----------------\n",
    "template_xml_path:  str, (required)\n",
    "    Path to template BEAST 2 xml.\n",
    "\n",
    "fasta_path:  str, (required)\n",
    "    Path to fasta file containing sequences to be placed into template xml.\n",
    "\n",
    "metadata_path:  str, (required)\n",
    "      Path to csv or tsv containing metadata for sequences in fasta_path.\n",
    "\n",
    "sample_id_field:  str, (required)\n",
    "    Name of field in metadata_db containing sequence IDs.\n",
    "\n",
    "collection_date_field:  str, (required)\n",
    "    Name of field in metadata_db containing collection dates of sequences. Should be formatted YYYY-MM-DD.\n",
    "\n",
    "   Defining XML Sets (Partitioning/Segregating Data)\n",
    "   --------------------------------------------\n",
    "xml_set_definitions :  dict {str: str}, (required)\n",
    "   The definitions for the xml_sets you wish to use.\n",
    "       Keys: str\n",
    "               The name used for the xml_set. Will be used to name directories so certain characters should be\n",
    "               avoided see https://www.mtu.edu/umc/services/websites/writing/characters-avoid/.\n",
    "       Values: str\n",
    "               Will be used with pandas `DataFrame.query` to separate out your data.\n",
    "               Must conform to pandas `DataFrame.query` format see:\n",
    "               * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "               * https://sparkbyexamples.com/pandas/pandas-dataframe-query-examples/\n",
    "               * https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/\n",
    "\n",
    "data_filter:  str, (can be commented out)\n",
    "    Optional can be an empy string, null (None in python) or 'null (None in python)'.\n",
    "    Additional filter applied to metadata_db when selecting\n",
    "    sequences and metadata to be used on pipeline.\n",
    "    Must conform to pandas `DataFrame.query` format see:\n",
    "        * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "        * https://sparkbyexamples.com/pandas/pandas-dataframe-query-examples/\n",
    "        * https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/\n",
    "\n",
    "Initial Tree Building & Downsampling\n",
    "------------------\n",
    "use_initial_tree:  bool, default True\n",
    "    If False an initial tree will not be generated skipping Phases 2i and 2ii. As such, in phase 4 BEAST 2 generate its own\n",
    "    initial tree.\n",
    "\n",
    "initial_tree_type: str (either 'Distance' or 'Temporal') or None, default 'Temporal'\n",
    "    Intial tree type to use.\n",
    "    If 'Distance' the IQtree tree from Phase-2i-IQTree.ipynb is used for the\n",
    "    initial tree and phase 2ii is skipped.\n",
    "    if 'Temporal' the TreeTime tree from Phase-2ii-TreeTime-and-Down-Sampling.ipynb\n",
    "    is used for the initial tree.\n",
    "\n",
    "down_sample_to: int\n",
    "    If the number sequences in a fasta file is above this the number of sequences is cut to this number via downsampling.\n",
    "    If not given downsampling will not occur. When given down sampling only\n",
    "   occurs for a xml_set if there are more sequences than the value given.\n",
    "    If downsampling occurs the following are saved in  '{overall_save_dir}/{specific_run_save_dir}/{xml_set}' and used in generating\n",
    "    a BEAST 2 xml in phase 3:\n",
    "    *   initial_trees/down_sampled_time.nwk:  A downsampled temporal tree.\n",
    "    *    down_sampled_sequences.fasta:  Fasta file containing downsamplec sequences.\n",
    "    *    down_sampled_metadata.csv:  the down sampled metadata.\n",
    "\n",
    "\n",
    "MCMC Tree/Logfile names Chain-lengths & Save Steps\n",
    "------------------\n",
    "log_file_basename:  str, (required)\n",
    "    If provided .tree, .log and .state files from running BEAST 2 will have this name prefixed by 'run-with-seed-{seed}-',\n",
    "    number being that of the chain.\n",
    "    Must not contain whitespace.\n",
    "\n",
    "chain_length:  int, (optional)\n",
    "    Number of chains to use for BEAST runs (e.g. 50000000).\n",
    "    If not given value in template_xml_path will be used.\n",
    "\n",
    "trace_log_every:  int, (optional)\n",
    "    How often to save a log file during BEAST runs (e.g. 5000).\n",
    "    If not given value in template_xml_path will be used.\n",
    "\n",
    "tree_log_every:  int, (optional)\n",
    "    How often to save a tree file during BEAST runs (e.g. 5000).\n",
    "    If not given value in template_xml_path will be used.\n",
    "\n",
    "screen_log_every:  int, (optional)\n",
    "    How often to output to screen during BEAST runs (e.g. 5000).\n",
    "    If not given value in template_xml_path will be used.\n",
    "\n",
    "store_state_every:  int, (optional)\n",
    "    How often to store MCMC state during BEAST runs (e.g. 5000).\n",
    "    If not given value in template_xml_path will be used.\n",
    "\n",
    "\n",
    "Running BEAST 2\n",
    "--------------------\n",
    "number_of_beast_runs: int\n",
    "    Number of chains to use (number of parallel runs to do) when running BEAST (e.g. 9).\n",
    "\n",
    "seeds: list of ints\n",
    "    Seeds to use when running BEAST.\n",
    "    If given, length of list should be the same as the number of chains (so each run has a designated seed).\n",
    "\n",
    "beast_options_without_a_value: list of strs\n",
    "    Options not requiring a value to pass to BEAST 2.\n",
    "     For instance to use a GPU when running BEAST 2 this would be `['-beagle_GPU']`.\n",
    "    See https://www.beast2.org/2021/03/31/command-line-options.html.\n",
    "\n",
    "beast_options_needing_a_value: dict\n",
    "    Options requiring a value to pass to BEAST 2.\n",
    "    For instance to use 3 threads when running BEAST 2 this would be: `{'-threads': 3}`.\n",
    "    See https://www.beast2.org/2021/03/31/command-line-options.html.\n",
    "\n",
    "sbatch_options_without_a_value: list of strs\n",
    "   Options not requiring a value to pass to sbatch.\n",
    "    See https://slurm.schedmd.com/sbatch.html.\n",
    "\n",
    "sbatch_options_needing_a_value: dict\n",
    "    Options requiring a value to pass to sbatch.\n",
    "    See https://slurm.schedmd.com/sbatch.html.\n",
    "\n",
    "\n",
    "  </code>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75542394897ba",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "-------------\n",
    "'''\n",
    "# Running an Instance of this Workflow\n",
    "overall_save_dir = None\n",
    "specific_run_save_dir=None\n",
    "max_threads=None\n",
    "kernel_name = 'beast_pype'\n",
    "\n",
    "# General Inputs\n",
    "template_xml_path = None\n",
    "fasta_path = None\n",
    "metadata_path = None\n",
    "sample_id_field = 'strain'\n",
    "collection_date_field = 'date'\n",
    "\n",
    "# Defining XML Sets (Partitioning Data)\n",
    "xml_set_definitions = None\n",
    "data_filter = None\n",
    "\n",
    "# Initial Tree Building & Downsampling\n",
    "use_initial_tree = True\n",
    "initial_tree_type = 'Temporal'\n",
    "root_strain_names = None\n",
    "remove_root = False\n",
    "down_sample_to = None\n",
    "\n",
    "# MCMC Tree/Logfile names Chain-lengths & Save Steps\n",
    "log_file_basename=None\n",
    "chain_length = None\n",
    "trace_log_every = None\n",
    "tree_log_every = None\n",
    "screen_log_every = None\n",
    "store_state_every = None\n",
    "\n",
    "# Running BEAST 2\n",
    "number_of_beast_runs = None\n",
    "seeds = None\n",
    "beast_options_without_a_value=None\n",
    "beast_options_needing_a_value=None\n",
    "sbatch_options_without_a_value=None\n",
    "sbatch_options_needing_a_value=None\n",
    "\n",
    "# Choosing a specific report template\n",
    "report_template = None\n",
    "xml_set_label = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd99029b716e57d",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Creat Dictionary of Parameters\n",
    "\n",
    "This needs to be done before importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffde31ac6c4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = %who_ls\n",
    "parameters = {var: eval(var) for var in parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e34adadb6ac2d",
   "metadata": {},
   "source": [
    "Import packages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0881fed23d548ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beast_pype.nb_utils import execute_notebook\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "import importlib.resources as importlib_resources\n",
    "from beast_pype.workflow_params import GenericComparativeWorkflowParams\n",
    "from beast_pype.diagnostics import gen_beast_diagnostic_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a803abebe8ebff",
   "metadata": {},
   "source": [
    "## Check, Setup and Record parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21260468c0f1a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = GenericComparativeWorkflowParams(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9197b63a1b94b12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Creating a record for runtimes\n",
    "\n",
    "This record list of dictionaries will be turned into a pandas dataframe and saved as a csv at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb3f93570c1555",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5145cd0fbb811c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Set path to workflow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ed8424eef2dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow_modules = importlib_resources.path('beast_pype', 'workflow_modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53522c5b-0019-420f-84e7-21bb4b127043",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 1: Data Gathering\n",
    "\n",
    "### Placing Phase 1 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca15750-675b-4779-9713-b4a17401bce7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_1_start= perf_counter()\n",
    "phase_1_params = parameters.retrieve_phase_1_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e63d53e8d5d3b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 1."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#papermill_description=Phase-1-Metadata-and-Sequence-Separation.ipynb\n",
    "phase_1i_log =execute_notebook(input_path=f'{workflow_modules}/Phase-1-Metadata-and-Sequence-Separation.ipynb',\n",
    "                                  output_path=parameters.save_dir + '/Phase-1-Metadata-and-Sequence-Separation.ipynb',\n",
    "                                  parameters=phase_1_params,\n",
    "                                  progress_bar=True,\n",
    "                                  nest_asyncio=True,\n",
    "                                  kernel_name=kernel_name\n",
    "                                  )\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-1-Metadata-and-Sequence-Separation.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_1_start\n",
    "})"
   ],
   "id": "fa51444b27f06159"
  },
  {
   "cell_type": "markdown",
   "id": "fb1bfd2db9a24c7a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 2: Data Pre-Processing\n",
    "### Phase 2i: Building an IQ Tree tree.\n",
    "#### Placing Phase 2i Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280655f2bf2c404",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_initial_tree:\n",
    "    phase_2i_start = perf_counter()\n",
    "    phase_2i_params = parameters.retrieve_phase_2i_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9dd05080e75054",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 2i."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#papermill_description=Phase-2i-IQTree-Building\n",
    "if use_initial_tree:\n",
    "    phase_2i_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2i-IQTree-Building.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-2i-IQTree-Building.ipynb',\n",
    "                                      parameters=phase_2i_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True\n",
    "                                     )\n",
    "    for sub_dir in parameters.xml_set_directories.values(): # This loop could and should be in parallel\n",
    "        phase_2i_IQTree_Correction_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2i-IQTree-Correction.ipynb',\n",
    "                                                         output_path=parameters.save_dir + '/Phase-2i-IQTree-Correction.ipynb',\n",
    "                                                         parameters={\n",
    "                                                             'fasta_path': f'{sub_dir}/sequences.fasta',\n",
    "                                                             'tree_path': f'{sub_dir}/initial_trees/iqtree.nwk'\n",
    "                                                         },\n",
    "                                                         progress_bar=True,\n",
    "                                                         nest_asyncio=True,\n",
    "                                                         kernel_name=kernel_name\n",
    "                                                         )\n"
   ],
   "id": "803a9e86ba82859a"
  },
  {
   "cell_type": "markdown",
   "id": "270438d6-3e93-4219-8cb4-3edd883a77b0",
   "metadata": {},
   "source": [
    "### Record runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d14e4-cb73-43aa-862b-09398f0055ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_initial_tree:\n",
    "    runtime_records.append({\n",
    "        'Phase': 'Phase-2i-IQTree-Building.ipynb',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_2i_start\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404cc904-6b7c-46fa-8d62-952fa81b5c82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Phase 2ii: TreeTime & Down Sampling\n",
    "\n",
    "#### Placing Phase 2ii Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1231e6-7d1d-4af1-b98d-4c18e31cb3c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_initial_tree and initial_tree_type=='Temporal':\n",
    "    phase_2ii_start = perf_counter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff97d05-e5ff-42e5-a019-e5e2fa336fd1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 2ii."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if use_initial_tree:\n",
    "    #papermill_description=Phase-2ii-TreeTime-and-Down-Sampling\n",
    "    for sub_dir in parameters.xml_set_directories.values(): # This loop could and should be in parallel\n",
    "        phase_2ii_params = parameters.retrieve_phase_2ii_params(sub_dir)\n",
    "        phase_2ii_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                            output_path=f'{sub_dir}/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                            parameters=phase_2ii_params,\n",
    "                                            progress_bar=True,\n",
    "                                            nest_asyncio=True,\n",
    "                                            kernel_name=kernel_name\n",
    "                                            )\n",
    "    runtime_records.append({\n",
    "        'Phase': 'Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_2ii_start\n",
    "    })"
   ],
   "id": "68d0fa762b2a242c"
  },
  {
   "cell_type": "markdown",
   "id": "a2f3f672959e2da4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 3 Generating BEAST xmls\n",
    "\n",
    "### Running Phase 3"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#papermill_description=Phase-3-Generating-XMLs\n",
    "phase_3_start = perf_counter()\n",
    "for sub_dir in parameters.xml_set_directories.values(): # This loop could and should be in parallel\n",
    "    phase_3_params = {\n",
    "        'save_dir': sub_dir,\n",
    "        **parameters.retrieve_params([\n",
    "            'template_xml_path',\n",
    "            'use_initial_tree',\n",
    "            'collection_date_field',\n",
    "            'sample_id_field',\n",
    "            'log_file_basename',\n",
    "            'chain_length',\n",
    "            'trace_log_every',\n",
    "            'tree_log_every',\n",
    "            'screen_log_every',\n",
    "            'store_state_every'])\n",
    "    }\n",
    "    phase_3_log = execute_notebook(input_path=f'{workflow_modules}/Phase-3-Gen-Generic-xml.ipynb',\n",
    "                                      output_path=f'{sub_dir}/Phase-3-Gen-Generic-xml.ipynb',\n",
    "                                      parameters=phase_3_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True,\n",
    "                                      kernel_name=kernel_name\n",
    "                                      )\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-3-Gen-Generic-xml.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_3_start\n",
    "})"
   ],
   "id": "37a2f1541c12faf6"
  },
  {
   "cell_type": "markdown",
   "id": "689c940e-a5fa-454f-a652-128f4ad19d6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 4 Running BEAST\n",
    "### Placing Phase 4 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50cba622866da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_4_start = perf_counter()\n",
    "phase_4_params = parameters.retrieve_phase_4_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7d043c49bfebc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Running Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a50a6f262adef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=Phase-4-Running-BEAST\n",
    "if 'sbatch_arg_string' in phase_4_params:\n",
    "    phase_4_log = execute_notebook(input_path=f'{workflow_modules }/Phase-4-SBATCH-Running-BEAST.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-4-SBATCH-Running-BEAST.ipynb',\n",
    "                                      parameters=phase_4_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True)\n",
    "else:\n",
    "    phase_4_log = execute_notebook(input_path=f'{workflow_modules }/Phase-4-GNU-Parallel-Running-BEAST.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-4-GNU-Parallel-Running-BEAST.ipynb',\n",
    "                                      parameters=phase_4_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True)\n",
    "runtime_records.append({\n",
    "        'Phase': 'Phase-4',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_4_start\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f089750-b059-4a5f-9e70-d896d75034ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Phase 5: Diagnosing Outputs and Generate Report\n",
    "\n",
    "Currently, this has to be performed manually. That being said, the code cell below will parameterize a copy of the notebook ready to run. See below for location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96ec73086d0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_5_params = parameters.retrieve_phase_5_params()\n",
    "gen_beast_diagnostic_nb(parameters.save_dir, **phase_5_params)\n",
    "print(f'Phase 5 notebook is ready for manual use at: \\n{parameters.save_dir}/Phase-5-Diagnosing-XML-sets-and-Generate-Report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494b9dd-bfbb-4fa3-bc4f-bf565fbf87d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Recording Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516d160-5840-443f-b236-174514d988fd",
   "metadata": {},
   "source": [
    "Converting to pandas DataFrame and saving as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c093c-1960-4adb-b1b3-c3175be05761",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame.from_records(runtime_records)\n",
    "runtime_df.to_csv(parameters.save_dir + \"/runtimes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beast_pype",
   "language": "python",
   "name": "beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
