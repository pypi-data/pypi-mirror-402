{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d1f3542ce21306",
   "metadata": {},
   "source": [
    "# Birth-Death Skyline (BDSKY) serial workflow\n",
    "\n",
    "\n",
    "This Workflow Notebook is for running BDSKY serial models in BEAST 2. **The template BEAST 2 xml (template_xml) or ready_to_go_xml provided must be for BDSKY serial!**\n",
    "\n",
    "<details>\n",
    "    <summary>Click To See A Decription of Parameters</summary>\n",
    "        <pre>\n",
    "            <code>\n",
    "\n",
    "Running an Instance of this Workflow\n",
    "-------------------------------------------\n",
    "overall_save_dir: str\n",
    "    Path to where you are saving all the runs of this workflow.\n",
    "\n",
    "specific_run_save_dir: str, optional\n",
    "    Sub-directory of overall_save_dir you wish to save the outputs from this workflow.\n",
    "    If None, 'None' or an empty string a timestamp of format 'YYYY-MM-DD_hour-min-sec' is used instead.\n",
    "\n",
    "max_threads: int, default None\n",
    "    The maximum number of threads to use when calling gnu parallel in phases 2i and 4. If None and BEAST_pype is running\n",
    "    in a SLURM job the SLURM environment variable `SLURM_CPUS_PER_TASK` is used. If None and BEAST_pype is NOT running in\n",
    "    a SLURM job the number of cores available minus 1 is used (`multiprocessing.cpu_count() - 1`).\n",
    "\n",
    "kernel_name: str, default 'beast_pype'\n",
    "    Name of Jupyter python kernel to use when running workflow. This is also the name of the conda environment to use in phases 4 &\n",
    "    phase 2ii (as these Jupyter notebooks use the `bash` kernel).\n",
    "\n",
    "General Inputs\n",
    "----------------\n",
    "ready_to_go_xml: str, optional\n",
    "    Path to a BEAST 2 xml that you wish to run unaltered. If provided phases 2i, 2ii and 3 are skipped.\n",
    "\n",
    "template_xml_path: str\n",
    "    Path to template BEAST 2 xml.\n",
    "\n",
    "fasta_path: str\n",
    "    Path to fasta file containing sequences to be placed into template xml.\n",
    "\n",
    "metadata_path: str\n",
    "      Path to csv or tsv containing metadata for sequences in fasta_path.\n",
    "\n",
    "sample_id_field: str\n",
    "    Name of field in metadata_db containing sequence IDs.\n",
    "\n",
    "collection_date_field: str\n",
    "    Name of field in metadata_db containing collection dates of sequences. Should be formatted YYYY-MM-DD.\n",
    "\n",
    "initial_tree_path: str, optional\n",
    "    Path to initial tree to use in generating a BEAST 2 xml. Should be .nwk file (Newick format).\n",
    "    If provided phases 2i and 2ii are skipped.\n",
    "    If a distance tree is used set initial_tree_type to 'Distance'.\n",
    "    If a temporal tree is used set initial_tree_type to 'Temporal'.\n",
    "\n",
    "Initial Tree Building & Downsampling\n",
    "------------------\n",
    "use_initial_tree:  bool, default True\n",
    "    If False an initial tree will not be generated skipping Phases 2i and 2ii. As such, in phase 4 BEAST 2 generate its own\n",
    "    initial tree.\n",
    "\n",
    "initial_tree_type: str (either 'Distance' or 'Temporal') or None, default 'Temporal'\n",
    "    Initial tree type to use.\n",
    "    If 'Distance' and initial_tree_path is not provided the IQtree tree from Phase-2i-IQTree.ipynb is used for the\n",
    "    initial tree and phase 2ii is skipped.\n",
    "    if 'Temporal' and initial_tree_path is not provided the TreeTime tree from Phase-2ii-TreeTime-and-Down-Sampling.ipynb\n",
    "    is used for the initial tree.\n",
    "\n",
    "initial_tree_path: str, optional\n",
    "    Path to initial tree to use in generating a BEAST 2 xml. Should be .nwk file (Newick format).\n",
    "    If provided phases 2i and 2ii are skipped.\n",
    "    If a distance tree is used set initial_tree_type to 'Distance'.\n",
    "    If a temporal tree is used set initial_tree_type to 'Temporal'.\n",
    "\n",
    "root_strain_names: list of strings, optional\n",
    "     IDs of sequences used to root 'Temporal' initial_tree. These sequences/nodes are removed from fasta file and initial tree file used to generate\n",
    "    the BEAST 2 xml.\n",
    "\n",
    "down_sample_to: int, optional\n",
    "    If provided the fasta file and initial tree file used to generate the BEAST 2 xml is downsampled to this amount.\n",
    "    If downsampling occurs the following are saved in  '{overall_save_dir}/{specific_run_save_dir}/' and used in generating\n",
    "    a BEAST 2 xml in phase 4:\n",
    "        down_sampled_time.nwk: A downsampled temporal tree.\n",
    "        down_sampled_sequences.fasta: Fasta file containing downsampled sequences.\n",
    "        down_sampled_metadata.csv: the down sampled metadata.\n",
    "\n",
    "\n",
    "BDSky Options\n",
    "------------------\n",
    "origin_start_addition: float\n",
    "    Suggested infection period of pathogen. **Should be in years.** This + initial MLE tree height is used as starting value of origin.\n",
    "\n",
    "origin_upper_addition: float/int\n",
    "    This + initial MLE tree height is used as upper value of origin prior.\n",
    "\n",
    "origin_prior: dict {'lower': float, 'upper': float, 'start': float}, optional\n",
    "    Details of the origin prior assumed to be uniformly distributed.\n",
    "\n",
    "rt_dims: int, optional\n",
    "    Number of Rt dimensions (time periods over which Rt is estimated).\n",
    "\n",
    "rt_partitions: dict of strings {'unit': 'days, weeks or years', 'every': int/float, 'end': date str YYYY-MM-DD}, optional\n",
    "    Instructions for setting rt_change date, going backwards from the youngest date in the metadata until rt_partitions[\"end\"]  is reached.\n",
    "    If rt_partitions[\"end\"] is not given the oldest date in metadata is used for this end point value instead.\n",
    "    rt_partitions[\"end\"] should be a datetime object or string of format 'YYYY-MM-DD'.\n",
    "    If given rt_dims must equal None.\n",
    "\n",
    "sampling_prop_dims: int, optional\n",
    "    Number of sampling proportion dimensions (time periods over which sampling proportion is estimated).\n",
    "\n",
    "sampling_prop_partitions: dict of strings {'unit': 'days, weeks or years', 'every': int/float, 'end': date str YYYY-MM-DD}, optional\n",
    "    Instructions for setting sampling_prop_change date, going backwards from the youngest date in metadata until sampling_prop_partitions[\"end\"]  is reached.\n",
    "    If sampling_prop_partitions[\"end\"] is not given the oldest date in metadata is used for this end point value instead.\n",
    "    sampling_prop_partitions[\"end\"] should be a datetime object or string of format 'YYYY-MM-DD'.\n",
    "    If given sampling_prop_dims must equal None.\n",
    "\n",
    "zero_sampling_before_first_sample: bool, default False\n",
    "    If true fix the sampling proportion to 0 for the period before the first sample.\n",
    "\n",
    "MCMC Tree/Logfile names Chain-lengths & Save Steps\n",
    "------------------\n",
    "log_file_basename: str, optional\n",
    "    If provided .tree, .log and .state files from running BEAST 2 will have this name prefixed by 'run-with-seed-{seed}-'.\n",
    "\n",
    "chain_length: int\n",
    "    Number of chains to use for BEAST runs.\n",
    "\n",
    "trace_log_every: int\n",
    "    How often to save a log file during BEAST runs.\n",
    "\n",
    "tree_log_every: int\n",
    "    How often to save a tree file during BEAST runs.\n",
    "\n",
    "screen_log_every: int\n",
    "    How often to output to screen during BEAST runs.\n",
    "\n",
    "store_state_every: int\n",
    "    How often to store MCMC state during BEAST runs.\n",
    "\n",
    "\n",
    "Running BEAST 2\n",
    "--------------------\n",
    "number_of_beast_runs: int\n",
    "    Number of chains to use (repeated runs to do) when running BEAST.\n",
    "\n",
    "seeds: list of ints\n",
    "    Seeds to use when running BEAST.\n",
    "\n",
    "beast_options_without_a_value: list of strs\n",
    "    Options not requiring a value to pass to BEAST 2.\n",
    "     For instance to use a GPU when running BEAST 2 this would be `['-beagle_GPU']`.\n",
    "    See https://www.beast2.org/2021/03/31/command-line-options.html.\n",
    "\n",
    "beast_options_needing_a_value: dict\n",
    "    Options requiring a value to pass to BEAST 2.\n",
    "    For instance to use 3 threads when running BEAST 2 this would be: `{'-threads': 3}`.\n",
    "    See https://www.beast2.org/2021/03/31/command-line-options.html.\n",
    "\n",
    "sbatch_options_without_a_value: list of strs\n",
    "   Options not requiring a value to pass to sbatch.\n",
    "    See https://slurm.schedmd.com/sbatch.html.\n",
    "\n",
    "sbatch_options_needing_a_value: dict\n",
    "    Options requiring a value to pass to sbatch.\n",
    "    See https://slurm.schedmd.com/sbatch.html.\n",
    "\n",
    "  </code>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaac70f870a3ec3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "-------------\n",
    "'''\n",
    "# Running an Instance of this Workflow\n",
    "overall_save_dir = None\n",
    "specific_run_save_dir=None\n",
    "max_threads=None\n",
    "kernel_name = 'beast_pype'\n",
    "\n",
    "# General Inputs\n",
    "ready_to_go_xml = None\n",
    "template_xml_path = None\n",
    "fasta_path= None\n",
    "metadata_path = None\n",
    "sample_id_field='strain'\n",
    "collection_date_field='date'\n",
    "initial_tree_path = None\n",
    "\n",
    "# Initial Tree Building & Downsampling\n",
    "use_initial_tree = True\n",
    "initial_tree_type = 'Temporal'\n",
    "root_strain_names=None\n",
    "remove_root = False\n",
    "down_sample_to=None\n",
    "\n",
    "# BDSky Options\n",
    "origin_start_addition = None\n",
    "origin_upper_addition = None\n",
    "origin_prior = None\n",
    "rt_dims=None\n",
    "rt_partitions=None\n",
    "sampling_prop_dims=None\n",
    "sampling_prop_partitions=None\n",
    "zero_sampling_before_first_sample=False\n",
    "\n",
    "# MCMC Tree/Logfile names Chain-lengths & Save Steps\n",
    "log_file_basename=None\n",
    "chain_length = None\n",
    "trace_log_every = None\n",
    "tree_log_every = None\n",
    "screen_log_every = None\n",
    "store_state_every = None\n",
    "\n",
    "# Running BEAST 2\n",
    "number_of_beast_runs = None\n",
    "seeds = None\n",
    "beast_options_without_a_value=None\n",
    "beast_options_needing_a_value=None\n",
    "sbatch_options_without_a_value=None\n",
    "sbatch_options_needing_a_value=None\n",
    "\n",
    "# Choosing a specific report template\n",
    "report_template = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad9442976c9616",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Creat Dictionary of Parameters\n",
    "\n",
    "This needs to be done before importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f59735bdf639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = %who_ls\n",
    "parameters = {var: eval(var) for var in parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fb2a4-ae8c-42db-a96f-e73675bd415a",
   "metadata": {},
   "source": [
    "## Import libraries and define functions:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd379001fecb8061",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from beast_pype.nb_utils import execute_notebook\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import importlib.resources as importlib_resources\n",
    "from beast_pype.workflow_params import BDSKYSerialWorkflowParams\n",
    "from beast_pype.diagnostics import gen_beast_diagnostic_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685b2844bd80236",
   "metadata": {},
   "source": [
    "## Check, Setup and Record parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a3f24e341a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = BDSKYSerialWorkflowParams(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9197b63a1b94b12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Creating a record for runtimes\n",
    "\n",
    "This record list of dictionaries will be turned into a pandas dataframe and saved as a csv at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb3f93570c1555",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c7107c7a63d66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Set path to workflow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9769dc07371196",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_modules = importlib_resources.path('beast_pype', 'workflow_modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1a451cd296447",
   "metadata": {},
   "source": [
    "## Phase 2: Data Pre-Processing\n",
    "### Phase 2i: Building an IQ Tree tree.\n",
    "#### Placing Phase 2i Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7268ebf677466",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ready_to_go_xml is None and \\\n",
    "    use_initial_tree and \\\n",
    "        (initial_tree_path is None and initial_tree_type is not None):\n",
    "    phase_2i_start = perf_counter()\n",
    "    phase_2i_params = parameters.retrieve_phase_2i_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67764fd8d3b3915",
   "metadata": {},
   "source": [
    "#### Running Phase 2i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1b379f5b32eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=Phase-2i-IQTree-Building\n",
    "if ready_to_go_xml is None and \\\n",
    "    use_initial_tree and \\\n",
    "        (initial_tree_path is None and initial_tree_type is not None):\n",
    "    phase_2i_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2i-IQTree-Building.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-2i-IQTree-Building.ipynb',\n",
    "                                      parameters=phase_2i_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True\n",
    "                                     )\n",
    "    phase_2i_IQTree_Correction_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2i-IQTree-Correction.ipynb',\n",
    "                                                         output_path=parameters.save_dir + '/Phase-2i-IQTree-Correction.ipynb',\n",
    "                                                         parameters={\n",
    "                                                             'fasta_path': parameters.fasta_path,\n",
    "                                                             'tree_path': f'{parameters.save_dir}/initial_trees/iqtree.nwk'},\n",
    "                                                         progress_bar=True,\n",
    "                                                         nest_asyncio=True,\n",
    "                                                         kernel_name=kernel_name\n",
    "                                                         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a7b3b-7dd1-4cd0-93f1-180d5a53630b",
   "metadata": {},
   "source": [
    "### Record runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93aef7-a869-425f-b4cf-a5d6eab0bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ready_to_go_xml is None and \\\n",
    "    use_initial_tree and \\\n",
    "        (initial_tree_path is None and initial_tree_type is not None):\n",
    "\n",
    "    runtime_records.append({\n",
    "        'Phase': 'Phase-2i-IQTree-Building.ipynb',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_2i_start\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ab22e07bc1d69",
   "metadata": {},
   "source": [
    "### Phase 2ii: Building an TreeTime tree and Downsampling.\n",
    "#### Placing Phase 2ii Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bb8defb8c2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ready_to_go_xml is None and \\\n",
    "    use_initial_tree and \\\n",
    "        (initial_tree_path is None and initial_tree_type =='Temporal'):\n",
    "    phase_2ii_start = perf_counter()\n",
    "    phase_2ii_params = parameters.retrieve_phase_2ii_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee70b1e226ef72",
   "metadata": {},
   "source": [
    "#### Running Phase 2ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323efa6440ea2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=Phase-2ii-TreeTime-and-Down-Sampling\n",
    "if ready_to_go_xml is None and \\\n",
    "        use_initial_tree and \\\n",
    "        (initial_tree_path is None and initial_tree_type =='Temporal'):\n",
    "    phase_2ii_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                        output_path=parameters.save_dir + '/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                        parameters=phase_2ii_params,\n",
    "                                        progress_bar=True,\n",
    "                                        nest_asyncio=True,\n",
    "                                        kernel_name=kernel_name\n",
    "                                        )\n",
    "\n",
    "    runtime_records.append({\n",
    "        'Phase': 'Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_2i_start\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3f672959e2da4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Phase 3 Generating BEAST xmls\n",
    "\n",
    "### Placing Phase 3 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0db5454b595013",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ready_to_go_xml is None:\n",
    "    phase_3_start = perf_counter()\n",
    "    phase_3_params = parameters.retrieve_phase_3_params()\n",
    "    if parameters.down_sample_to is None:\n",
    "        phase_3_params['fasta_path'] = fasta_path\n",
    "        phase_3_params['metadata_path'] = metadata_path\n",
    "    else:\n",
    "        phase_3_params['fasta_path'] = f'{parameters.save_dir}/down_sampled_sequences.fasta'\n",
    "        phase_3_params['metadata_path'] =  f'{parameters.save_dir}/down_sampled_metadata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38109bbeca2516f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Running Phase 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7145ca6f91b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=Phase-3-Generating-XML\n",
    "if ready_to_go_xml is None:\n",
    "    phase_3_log = execute_notebook(input_path=f'{workflow_modules}/Phase-3-Gen-BDSKY-Serial-xml.ipynb',\n",
    "                                   output_path=parameters.save_dir + '/Phase-3-Gen-BDSKY-Serial-xml.ipynb',\n",
    "                                   parameters=phase_3_params,\n",
    "                                   progress_bar=True,\n",
    "                                   nest_asyncio=True,\n",
    "                                   kernel_name=kernel_name)\n",
    "    runtime_records.append({\n",
    "        'Phase': 'Phase-3-Gen-BDSKY-Serial-xml.ipynb',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_3_start\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c940e-a5fa-454f-a652-128f4ad19d6b",
   "metadata": {},
   "source": [
    "## Phase 4 Running BEAST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8640ddf03679e6fb",
   "metadata": {},
   "source": [
    "### If ready_to_go_xml was provided save a copy for use as f'{parameters.save_dir}/beast.xml'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea9deb8c1ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_4_start = perf_counter()\n",
    "if parameters.ready_to_go_xml is not None:\n",
    "    shutil.copy(parameters.ready_to_go_xml, f'{parameters.save_dir}/beast.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1651ff3f101a85f",
   "metadata": {},
   "source": [
    "### Placing Phase 4 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee687e7ca93f2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_4_params = parameters.retrieve_phase_4_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7d043c49bfebc",
   "metadata": {},
   "source": [
    "### Running Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7c179ecf1f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=Phase-4-Running-BEAST\n",
    "if 'sbatch_arg_string' in phase_4_params:\n",
    "    phase_4_log = execute_notebook(input_path=f'{workflow_modules }/Phase-4-SBATCH-Running-BEAST.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-4-SBATCH-Running-BEAST.ipynb',\n",
    "                                      parameters=phase_4_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True)\n",
    "else:\n",
    "    phase_4_log = execute_notebook(input_path=f'{workflow_modules }/Phase-4-GNU-Parallel-Running-BEAST.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-4-GNU-Parallel-Running-BEAST.ipynb',\n",
    "                                      parameters=phase_4_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True)\n",
    "runtime_records.append({\n",
    "        'Phase': 'Phase-4-Running-BEAST',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_4_start\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "600fca04-3d24-45c1-bbb5-ac496a5e05a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Phase 5: Diagnosing Outputs and Generate Report\n",
    "\n",
    "Currently, this has to be performed manually. That being said, the code cell below will parameterize a copy of the notebook ready to run. See below for location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7d6d7cbdf293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parameters.save_dir + '/pipeline_run_info.yml', 'r') as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = yaml.safe_load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f01c5b4d87487",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_5_params = parameters.retrieve_phase_5_params()\n",
    "gen_beast_diagnostic_nb(parameters.save_dir, **phase_5_params)\n",
    "print(f'Phase 5 notebook is ready for manual use at: \\n{parameters.save_dir}/Phase-5-Diagnosing-Outputs-and-Generate-Report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73996f7cb93da2a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Recording Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5327106e3a7f45",
   "metadata": {},
   "source": [
    "Converting to pandas DataFrame and saving as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ce3afca8ba34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame.from_records(runtime_records)\n",
    "runtime_df.to_csv(parameters.save_dir + \"/runtimes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beast_pype",
   "language": "python",
   "name": "beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
