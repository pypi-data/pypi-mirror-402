{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ae65004f75cabd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Comparative BDSKY-serial Workflow\n",
    "\n",
    "\n",
    "This Workflow Notebook is for Comparing BDSKY-Serial BEAST 2 analysis performed on different sequences.\n",
    "\n",
    "<details>\n",
    "    <summary>Click Here to See a Decription of Parameters</summary>\n",
    "        <pre>\n",
    "            <code>\n",
    "\n",
    "Running an Instance of this Workflow\n",
    "-------------------------------------------\n",
    "overall_save_dir: str\n",
    "    Path to where you are saving all the runs of this workflow.\n",
    "\n",
    "specific_run_save_dir: str, optional\n",
    "    Sub-directory of overall_save_dir you wish to save the outputs from this workflow.\n",
    "    If None, 'None' or an empty string a timestamp of format 'YYYY-MM-DD_hour-min-sec' is used instead.\n",
    "\n",
    "max_threads: int, default None\n",
    "    The maximum number of threads to use when calling gnu parallel in phases 2i and 4. If None and BEAST_pype is running\n",
    "    in a SLURM job the SLURM environment variable `SLURM_CPUS_PER_TASK` is used. If None and BEAST_pype is NOT running in\n",
    "    a SLURM job the number of cores available minus 1 is used (`multiprocessing.cpu_count() - 1`).\n",
    "\n",
    "kernel_name: str, default 'beast_pype'\n",
    "    Name of Jupyter python kernel to use when running workflow. This is also the name of the conda environment to use in phases 4 &\n",
    "    phase 2ii (as these Jupyter notebooks use the `bash` kernel).\n",
    "\n",
    "General Inputs\n",
    "----------------\n",
    "template_xml_path: str\n",
    "    Path to template BEAST 2 xml.\n",
    "\n",
    "fasta_path: str\n",
    "    Path to fasta file containing sequences to be placed into template xml.\n",
    "\n",
    "metadata_path: str\n",
    "      Path to csv or tsv containing metadata for sequences in fasta_path.\n",
    "\n",
    "sample_id_field: str\n",
    "    Name of field in metadata_db containing sequence IDs.\n",
    "\n",
    "collection_date_field: str\n",
    "    Name of field in metadata_db containing collection dates of sequences. Should be formatted YYYY-MM-DD.\n",
    "\n",
    "Defining XML Sets (Partitioning Data)\n",
    "--------------------------------------------\n",
    "xml_set_definitions : dict {str: str}\n",
    "        The definitions for the xml_sets you wish to use.\n",
    "        Keys:   The name used for the xml_set. Will be used to name directories so certain characters should be\n",
    "                   avoided see https://www.mtu.edu/umc/services/websites/writing/characters-avoid/.\n",
    "        Values: Will be used with pandas `DataFrame.query` to separate out your data see:\n",
    "                        * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "                        * https://sparkbyexamples.com/pandas/pandas-dataframe-query-examples/\n",
    "                        * https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/\n",
    "\n",
    "data_filter: str\n",
    "    Optional can be an empy string, None or 'None'. Additional filter applieid to metadata_db when selecting \n",
    "    sequences and metadata to be used on pipeline. Must conform to [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html), see further [example](https://www.slingacademy.com/article/pandas-working-with-the-dataframe-query-method-5-examples/).\n",
    "\n",
    "Initial Tree Building & Downsampling\n",
    "------------------\n",
    "use_initial_tree:  bool, default True\n",
    "    If False an initial tree will not be generated skipping Phases 2i and 2ii. As such, in phase 4 BEAST 2 generate its own\n",
    "    initial tree.\n",
    "\n",
    "initial_tree_type: str (either 'Distance' or 'Temporal') or None, default 'Temporal'\n",
    "    Initial tree type to use.\n",
    "    If 'Distance' the IQtree tree from Phase-2i-IQTree.ipynb is used for the\n",
    "    initial tree and phase 2ii is skipped.\n",
    "    if 'Temporal' the TreeTime tree from Phase-2ii-TreeTime-and-Down-Sampling.ipynb\n",
    "    is used for the initial tree.\n",
    "\n",
    "down_sample_to: int\n",
    "    If the number sequences in a fasta file is above this the number of sequences is cut to this number via downsampling.\n",
    "\n",
    "BDSky Options\n",
    "------------------\n",
    "origin_start_addition: float, optional\n",
    "    Suggested infection period of pathogen. **Should be in years.** This + initial MLE tree height is used as starting value of origin.\n",
    "\n",
    "origin_upper_addition: float/int, optional\n",
    "    This + initial MLE tree height is used as upper value of origin prior.\n",
    "\n",
    "origin_prior: dict {'lower': float, 'upper': float, 'start': float}, optional\n",
    "    Details of the origin prior assumed to be uniformly distributed.\n",
    "\n",
    "rt_dims: int, optional\n",
    "    Number of Rt dimensions (time periods over which Rt is estimated).\n",
    "\n",
    "rt_partitions: dict of strings {'unit': 'days, weeks or years', 'every': int/float, 'end': date str YYYY-MM-DD}, optional\n",
    "    Instructions for setting rt_change date, going backwards from the youngest date provided in that xml_set's metadata until rt_partitions[\"end\"]  is reached.\n",
    "    If rt_partitions[\"end\"] is not given the oldest date provided in that xml_set's metadata is used for this end point value instead.\n",
    "    rt_partitions[\"end\"] should be a datetime object or string of format 'YYYY-MM-DD'.\n",
    "    If given rt_dims must equal None.\n",
    "\n",
    "sampling_prop_dims: int, optional\n",
    "    Number of sampling promotion dimensions (time periods over which sampling promotion is estimated).\n",
    "\n",
    "sampling_prop_partitions: dict of strings {'unit': 'days, weeks or years', 'every': int/float, 'end': date str YYYY-MM-DD}, optional\n",
    "    Instructions for setting sampling_prop_change date, going backwards from the youngest date provided in that xml_set's metadata until sampling_prop_partitions[\"end\"]  is reached.\n",
    "    If sampling_prop_partitions[\"end\"] is not given the oldest date provided in that xml_set's metadata is used for this end point value instead.\n",
    "    sampling_prop_partitions[\"end\"] should be a datetime object or string of format 'YYYY-MM-DD'.\n",
    "    If given sampling_prop_dims must equal None.\n",
    "\n",
    "zero_sampling_before_first_sample: bool, default False\n",
    "    If true fix the sampling proportion to 0 for the period before the first sample.\n",
    "\n",
    "\n",
    "MCMC Tree/Logfile names Chain-lengths & Save Steps\n",
    "------------------\n",
    "log_file_basename: str, optional\n",
    "    If provided .tree, .log and .state files from running BEAST 2 will have this name prefixed by 'run-with-seed-{seed}-'.\n",
    "\n",
    "chain_length: int\n",
    "    Number of chains to use for BEAST runs.\n",
    "\n",
    "trace_log_every: int\n",
    "    How often to save a log file during BEAST runs.\n",
    "\n",
    "tree_log_every: int\n",
    "    How often to save a tree file during BEAST runs.\n",
    "\n",
    "screen_log_every: int\n",
    "    How often to output to screen during BEAST runs.\n",
    "\n",
    "store_state_every: int \n",
    "    How often to store MCMC state during BEAST runs.\n",
    "\n",
    "\n",
    "Running BEAST 2\n",
    "--------------------\n",
    "number_of_beast_runs: int\n",
    "    Number of chains to use (repeated runs to do) when running BEAST.\n",
    "\n",
    "seeds: list of ints\n",
    "    Seeds to use when running BEAST.\n",
    "\n",
    "beast_options_without_a_value: list of strs\n",
    "    Options not requiring a value to pass to BEAST 2.\n",
    "     For instance to use a GPU when running BEAST 2 this would be `['-beagle_GPU']`.\n",
    "    See https://www.beast2.org/2021/03/31/command-line-options.html.\n",
    "\n",
    "beast_options_needing_a_value: dict\n",
    "    Options requiring a value to pass to BEAST 2.\n",
    "    For instance to use 3 threads when running BEAST 2 this would be: `{'-threads': 3}`.\n",
    "    See https://www.beast2.org/2021/03/31/command-line-options.html.\n",
    "\n",
    "sbatch_options_without_a_value: list of strs\n",
    "   Options not requiring a value to pass to sbatch.\n",
    "    See https://slurm.schedmd.com/sbatch.html.\n",
    "\n",
    "sbatch_options_needing_a_value: dict\n",
    "    Options requiring a value to pass to sbatch.\n",
    "    See https://slurm.schedmd.com/sbatch.html.\n",
    "\n",
    "  </code>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b251565ee44b841",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "-------------\n",
    "'''\n",
    "# Running an Instance of this Workflow\n",
    "overall_save_dir = None\n",
    "specific_run_save_dir=None\n",
    "max_threads=None\n",
    "kernel_name = 'beast_pype'\n",
    "\n",
    "# General Inputs\n",
    "template_xml_path = None\n",
    "fasta_path = None\n",
    "metadata_path = None\n",
    "sample_id_field = 'strain'\n",
    "collection_date_field = 'date'\n",
    "\n",
    "# Defining XML Sets (Partitioning Data)\n",
    "xml_set_definitions = None\n",
    "data_filter = None\n",
    "\n",
    "# Initial Tree Building & Downsampling\n",
    "use_initial_tree = True\n",
    "initial_tree_type = 'Temporal'\n",
    "root_strain_names = None\n",
    "remove_root = False\n",
    "down_sample_to = None\n",
    "\n",
    "\n",
    "# BDSky Options\n",
    "origin_start_addition = None\n",
    "origin_upper_addition = None\n",
    "origin_prior = None\n",
    "rt_dims = None\n",
    "rt_partitions = None\n",
    "sampling_prop_dims=None\n",
    "sampling_prop_partitions=None\n",
    "zero_sampling_before_first_sample=False\n",
    "\n",
    "\n",
    "# MCMC Tree/Logfile names Chain-lengths & Save Steps\n",
    "log_file_basename = None\n",
    "chain_length = None\n",
    "trace_log_every = None\n",
    "tree_log_every = None\n",
    "screen_log_every = None\n",
    "store_state_every = None\n",
    "\n",
    "# Running BEAST 2\n",
    "number_of_beast_runs = None\n",
    "seeds = None\n",
    "beast_options_without_a_value=None\n",
    "beast_options_needing_a_value=None\n",
    "sbatch_options_without_a_value=None\n",
    "sbatch_options_needing_a_value=None\n",
    "\n",
    "# Choosing a specific report template\n",
    "report_template = None\n",
    "xml_set_label = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f46c96ab1baab",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Creat Dictionary of Parameters\n",
    "\n",
    "This needs to be done before importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af53d1dcee29ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = %who_ls\n",
    "parameters = {var: eval(var) for var in parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc641d67921930",
   "metadata": {},
   "source": [
    "Import packages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853072562ec278f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from beast_pype.nb_utils import execute_notebook\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "import importlib.resources as importlib_resources\n",
    "from beast_pype.workflow_params import BDSKYSerialComparativeWorkflowParams\n",
    "from beast_pype.diagnostics import gen_beast_diagnostic_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b10e3e7631cb57",
   "metadata": {},
   "source": [
    "## Check, Setup and Record parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f819ba763b8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = BDSKYSerialComparativeWorkflowParams(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9197b63a1b94b12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Creating a record for runtimes\n",
    "\n",
    "This record list of dictionaries will be turned into a pandas dataframe and saved as a csv at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb3f93570c1555",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5145cd0fbb811c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Set path to workflow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ed8424eef2dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow_modules = importlib_resources.path('beast_pype', 'workflow_modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53522c5b-0019-420f-84e7-21bb4b127043",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 1: Data Gathering\n",
    "\n",
    "### Placing Phase 1 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca15750-675b-4779-9713-b4a17401bce7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_1_start= perf_counter()\n",
    "phase_1_params = parameters.retrieve_phase_1_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e63d53e8d5d3b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 1."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#papermill_description=Phase-1-Metadata-and-Sequence-Separation.ipynb\n",
    "phase_1i_log =execute_notebook(input_path=f'{workflow_modules}/Phase-1-Metadata-and-Sequence-Separation.ipynb',\n",
    "                                  output_path=parameters.save_dir + '/Phase-1-Metadata-and-Sequence-Separation.ipynb',\n",
    "                                  parameters=phase_1_params,\n",
    "                                  progress_bar=True,\n",
    "                                  nest_asyncio=True,\n",
    "                                  kernel_name=kernel_name\n",
    "                                  )\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-1-Metadata-and-Sequence-Separation.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_1_start\n",
    "})"
   ],
   "id": "c726924b4f901393"
  },
  {
   "cell_type": "markdown",
   "id": "fb1bfd2db9a24c7a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 2: Data Pre-Processing\n",
    "### Phase 2i: Building an IQ Tree tree.\n",
    "#### Placing Phase 2i Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280655f2bf2c404",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_initial_tree:\n",
    "    phase_2i_start = perf_counter()\n",
    "    phase_2i_params = parameters.retrieve_phase_2i_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9dd05080e75054",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 2i."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#papermill_description=Phase-2i-IQTree-Building\n",
    "if use_initial_tree:\n",
    "    phase_2i_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2i-IQTree-Building.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-2i-IQTree-Building.ipynb',\n",
    "                                      parameters=phase_2i_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True\n",
    "                                     )\n",
    "    for xml_set_directory in parameters.xml_set_directories.values(): # This loop could and should be in parallel\n",
    "        phase_2i_IQTree_Correction_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2i-IQTree-Correction.ipynb',\n",
    "                                                         output_path=parameters.save_dir + '/Phase-2i-IQTree-Correction.ipynb',\n",
    "                                                         parameters={\n",
    "                                                             'fasta_path': f'{xml_set_directory}/sequences.fasta',\n",
    "                                                             'tree_path': f'{xml_set_directory}/initial_trees/iqtree.nwk'\n",
    "                                                         },\n",
    "                                                         progress_bar=True,\n",
    "                                                         nest_asyncio=True,\n",
    "                                                         kernel_name=kernel_name\n",
    "                                                         )"
   ],
   "id": "7e472cbbd12d59c4"
  },
  {
   "cell_type": "markdown",
   "id": "404cc904-6b7c-46fa-8d62-952fa81b5c82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Phase 2ii: TreeTime & Down Sampling\n",
    "\n",
    "#### Placing Phase 2ii Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1231e6-7d1d-4af1-b98d-4c18e31cb3c4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_initial_tree:\n",
    "    phase_2ii_start = perf_counter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff97d05-e5ff-42e5-a019-e5e2fa336fd1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running Phase 2ii."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#papermill_description=Phase-2ii-TreeTime-and-Down-Sampling\n",
    "if use_initial_tree and initial_tree_type == 'Temporal':\n",
    "    for xml_set_directory in parameters.xml_set_directories.values(): # This loop could and should be in parallel\n",
    "        phase_2ii_params = parameters.retrieve_phase_2ii_params(xml_set_directory)\n",
    "        phase_2ii_log = execute_notebook(input_path=f'{workflow_modules}/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                            output_path=f'{xml_set_directory}/Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "                                            parameters=phase_2ii_params,\n",
    "                                            progress_bar=True,\n",
    "                                            nest_asyncio=True,\n",
    "                                            kernel_name=kernel_name\n",
    "                                            )\n",
    "    runtime_records.append({\n",
    "        'Phase': 'Phase-2ii-TreeTime-and-Down-Sampling.ipynb',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_2ii_start\n",
    "    })"
   ],
   "id": "b97c74f563e6233"
  },
  {
   "cell_type": "markdown",
   "id": "a2f3f672959e2da4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Phase 3 Generating BEAST xmls\n",
    "\n",
    "### Running Phase 3"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#papermill_description=Phase-3-Generating-XMLs\n",
    "phase_3_start = perf_counter()\n",
    "for xml_set, xml_set_directory in parameters.xml_set_directories.items(): # This loop could and should be in parallel\n",
    "    phase_3_params = parameters.retrieve_phase_3_params(xml_set, xml_set_directory)\n",
    "    phase_3_log = execute_notebook(input_path=f'{workflow_modules}/Phase-3-Gen-BDSKY-Serial-xml.ipynb',\n",
    "                                      output_path=f'{xml_set_directory}/Phase-3-Gen-BDSKY-Serial-xml.ipynb',\n",
    "                                      parameters=phase_3_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True,\n",
    "                                      kernel_name=kernel_name\n",
    "                                      )\n",
    "runtime_records.append({\n",
    "    'Phase': 'Phase-3-Gen-BDSKY-Serial-xml.ipynb',\n",
    "    'Sample': None,\n",
    "    'Chain': None,\n",
    "    'Runtime': perf_counter() - phase_3_start\n",
    "})"
   ],
   "id": "d51ab153083ac83a"
  },
  {
   "cell_type": "markdown",
   "id": "290cf00e-ef20-4afc-9198-8bb853efe062",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Phase 4 Running BEAST\n",
    "### Placing Phase 4 Parameters in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da6b4c2c2215d3",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase_4_start = perf_counter()\n",
    "phase_4_params = parameters.retrieve_phase_4_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7d043c49bfebc",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Running Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3298a0779f93b1a",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#papermill_description=Phase-4-Running-BEAST\n",
    "if 'sbatch_arg_string' in phase_4_params:\n",
    "    phase_4_log = execute_notebook(input_path=f'{workflow_modules }/Phase-4-SBATCH-Running-BEAST.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-4-SBATCH-Running-BEAST.ipynb',\n",
    "                                      parameters=phase_4_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True)\n",
    "else:\n",
    "    phase_4_log = execute_notebook(input_path=f'{workflow_modules }/Phase-4-GNU-Parallel-Running-BEAST.ipynb',\n",
    "                                      output_path=parameters.save_dir + '/Phase-4-GNU-Parallel-Running-BEAST.ipynb',\n",
    "                                      parameters=phase_4_params,\n",
    "                                      progress_bar=True,\n",
    "                                      nest_asyncio=True)\n",
    "runtime_records.append({\n",
    "        'Phase': 'Phase-4',\n",
    "        'Sample': None,\n",
    "        'Chain': None,\n",
    "        'Runtime': perf_counter() - phase_4_start\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f089750-b059-4a5f-9e70-d896d75034ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Phase 5: Diagnosing Outputs and Generate Report\n",
    "\n",
    "Currently, this has to be performed manually. That being said, the code cell below will parameterize a copy of the notebook ready to run. See below for location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ede948c65ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parameters.save_dir + '/pipeline_run_info.yml', 'r') as file:\n",
    "    data = file.read()\n",
    "file.close()\n",
    "pipeline_run_info = yaml.safe_load(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688e71e88ba96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_5_params = parameters.retrieve_phase_5_params()\n",
    "gen_beast_diagnostic_nb(parameters.save_dir, **phase_5_params)\n",
    "print(f'Phase 5 notebook is ready for manual use at: \\n{parameters.save_dir}/Phase-5-Diagnosing-XML-sets-and-Generate-Report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494b9dd-bfbb-4fa3-bc4f-bf565fbf87d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Recording Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516d160-5840-443f-b236-174514d988fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Converting to pandas DataFrame and saving as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c093c-1960-4adb-b1b3-c3175be05761",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame.from_records(runtime_records)\n",
    "runtime_df.to_csv(parameters.save_dir + \"/runtimes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ce10b-2e20-4481-9082-3a0ec5254711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beast_pype",
   "language": "python",
   "name": "beast_pype"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
