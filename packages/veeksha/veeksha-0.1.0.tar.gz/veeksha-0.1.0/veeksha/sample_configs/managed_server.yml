seed: 42

server:
  type: sglang
  env_path: sglang_env
  model: meta-llama/Llama-3.2-1B-Instruct
  host: localhost
  port: 30003

traffic_scheduler:
  type: rate
  interval_generator:
    type: poisson
    arrival_rate: 10
  cancel_session_on_failure: False

session_generator:
  type: synthetic
  session_graph:
    type: linear
    inherit_history: True
  channels:
    - type: text

client: # model, api base and key are set by the server
  type: openai_chat_completions
  request_timeout: 60
  max_tokens_param: max_completion_tokens
  min_tokens_param: min_tokens
  use_min_tokens_prompt_fallback: False

runtime:
  max_sessions: -1
  benchmark_timeout: 60

trace_recorder:
  enabled: True
  include_content: True
