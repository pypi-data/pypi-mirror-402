# openhands.sdk.event

> API reference for openhands.sdk.event module

### class ActionEvent

Bases: [`LLMConvertibleEvent`](#class-llmconvertibleevent)

#### Properties

* `action`: Action | None
* `llm_response_id`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `reasoning_content`: str | None
* `responses_reasoning_item`: ReasoningItemModel | None
* `security_risk`: SecurityRisk
* `source`: Literal\['agent', 'user', 'environment']
* `summary`: str | None
* `thinking_blocks`: list\[ThinkingBlock | RedactedThinkingBlock]
* `thought`: Sequence\[TextContent]
* `tool_call`: MessageToolCall
* `tool_call_id`: str
* `tool_name`: str
* `visualize`: Text
  Return Rich Text representation of this action event.

#### Methods

#### to\_llm\_message()

Individual message - may be incomplete for multi-action batches

### class AgentErrorEvent

Bases: [`ObservationBaseEvent`](#class-observationbaseevent)

Error triggered by the agent.

Note: This event should not contain model “thought” or “reasoning\_content”. It
represents an error produced by the agent/scaffold, not model output.

#### Properties

* `error`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `visualize`: Text
  Return Rich Text representation of this agent error event.

#### Methods

#### to\_llm\_message()

### class Condensation

Bases: [`Event`](#class-event)

This action indicates a condensation of the conversation history is happening.

#### Properties

* `forgotten_event_ids`: list\[str]
* `llm_response_id`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `summary`: str | None
* `summary_offset`: int | None
* `visualize`: Text
  Return Rich Text representation of this event.
  This is a fallback implementation for unknown event types.
  Subclasses should override this method to provide specific visualization.

### class CondensationRequest

Bases: [`Event`](#class-event)

This action is used to request a condensation of the conversation history.

#### Properties

* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `visualize`: Text
  Return Rich Text representation of this event.
  This is a fallback implementation for unknown event types.
  Subclasses should override this method to provide specific visualization.

#### Methods

#### action

The action type, namely ActionType.CONDENSATION\_REQUEST.

* Type:
  str

### class CondensationSummaryEvent

Bases: [`LLMConvertibleEvent`](#class-llmconvertibleevent)

This event represents a summary generated by a condenser.

#### Properties

* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `summary`: str
  The summary text.

#### Methods

#### to\_llm\_message()

### class ConversationStateUpdateEvent

Bases: [`Event`](#class-event)

Event that contains conversation state updates.

This event is sent via websocket whenever the conversation state changes,
allowing remote clients to stay in sync without making REST API calls.

All fields are serialized versions of the corresponding ConversationState fields
to ensure compatibility with websocket transmission.

#### Properties

* `key`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `value`: Any

#### Methods

#### classmethod from\_conversation\_state()

Create a state update event from a ConversationState object.

This creates an event containing a snapshot of important state fields.

* Parameters:
  * `state` – The ConversationState to serialize
  * `conversation_id` – The conversation ID for the event
* Returns:
  A ConversationStateUpdateEvent with serialized state data

#### classmethod validate\_key()

#### classmethod validate\_value()

### class Event

Bases: `DiscriminatedUnionMixin`, `ABC`

Base class for all events.

#### Properties

* `id`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `timestamp`: str
* `visualize`: Text
  Return Rich Text representation of this event.
  This is a fallback implementation for unknown event types.
  Subclasses should override this method to provide specific visualization.

### class LLMCompletionLogEvent

Bases: [`Event`](#class-event)

Event containing LLM completion log data.

When an LLM is configured with log\_completions=True in a remote conversation,
this event streams the completion log data back to the client through WebSocket
instead of writing it to a file inside the Docker container.

#### Properties

* `filename`: str
* `log_data`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `model_name`: str
* `source`: Literal\['agent', 'user', 'environment']
* `usage_id`: str

### class LLMConvertibleEvent

Bases: [`Event`](#class-event), `ABC`

Base class for events that can be converted to LLM messages.

#### Properties

* `id`: EventID
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: SourceType
* `timestamp`: str

#### Methods

#### static events\_to\_messages()

Convert event stream to LLM message stream, handling multi-action batches

#### abstractmethod to\_llm\_message()

### class MessageEvent

Bases: [`LLMConvertibleEvent`](#class-llmconvertibleevent)

Message from either agent or user.

This is originally the “MessageAction”, but it suppose not to be tool call.

#### Properties

* `activated_skills`: list\[str]
* `extended_content`: list\[TextContent]
* `id`: EventID
* `llm_message`: Message
* `llm_response_id`: str | None
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `reasoning_content`: str
* `sender`: str | None
* `source`: Literal\['agent', 'user', 'environment']
* `thinking_blocks`: Sequence\[ThinkingBlock | RedactedThinkingBlock]
  Return the Anthropic thinking blocks from the LLM message.
* `timestamp`: str
* `visualize`: Text
  Return Rich Text representation of this message event.

#### Methods

#### to\_llm\_message()

### class ObservationBaseEvent

Bases: [`LLMConvertibleEvent`](#class-llmconvertibleevent)

Base class for anything as a response to a tool call.

Examples include tool execution, error, user reject.

#### Properties

* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `tool_call_id`: str
* `tool_name`: str

### class ObservationEvent

Bases: [`ObservationBaseEvent`](#class-observationbaseevent)

#### Properties

* `action_id`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `observation`: Observation
* `visualize`: Text
  Return Rich Text representation of this observation event.

#### Methods

#### to\_llm\_message()

### class PauseEvent

Bases: [`Event`](#class-event)

Event indicating that the agent execution was paused by user request.

#### Properties

* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `visualize`: Text
  Return Rich Text representation of this pause event.

### class SystemPromptEvent

Bases: [`LLMConvertibleEvent`](#class-llmconvertibleevent)

System prompt added by the agent.

#### Properties

* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `source`: Literal\['agent', 'user', 'environment']
* `system_prompt`: TextContent
* `tools`: list\[ToolDefinition]
* `visualize`: Text
  Return Rich Text representation of this system prompt event.

#### Methods

#### to\_llm\_message()

### class TokenEvent

Bases: [`Event`](#class-event)

Event from VLLM representing token IDs used in LLM interaction.

#### Properties

* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `prompt_token_ids`: list\[int]
* `response_token_ids`: list\[int]
* `source`: Literal\['agent', 'user', 'environment']

### class UserRejectObservation

Bases: [`ObservationBaseEvent`](#class-observationbaseevent)

Observation when user rejects an action in confirmation mode.

#### Properties

* `action_id`: str
* `model_config`: ClassVar\[ConfigDict] = (configuration object)
  Configuration for the model, should be a dictionary conforming to \[ConfigDict]\[pydantic.config.ConfigDict].
* `rejection_reason`: str
* `visualize`: Text
  Return Rich Text representation of this user rejection event.

#### Methods

#### to\_llm\_message()


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.openhands.dev/llms.txt