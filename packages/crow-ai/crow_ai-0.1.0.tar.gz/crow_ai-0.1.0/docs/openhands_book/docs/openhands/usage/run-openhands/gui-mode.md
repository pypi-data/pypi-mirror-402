# Configure

> High level overview of configuring the OpenHands Web interface.

## Prerequisites

* [OpenHands is running](/openhands/usage/run-openhands/local-setup)

## Launching the GUI Server

### Using the CLI Command

You can launch the OpenHands GUI server directly from the command line using the `serve` command:

<Info>
  **Prerequisites**: You need to have the [OpenHands CLI installed](/openhands/usage/cli/installation) first, OR have `uv`
  installed and run `uv tool install openhands --python 3.12` and `openhands serve`. Otherwise, you'll need to use Docker
  directly (see the [Docker section](#using-docker-directly) below).
</Info>

```bash  theme={null}
openhands serve
```

This command will:

* Check that Docker is installed and running
* Pull the required Docker images
* Launch the OpenHands GUI server at [http://localhost:3000](http://localhost:3000)
* Use the same configuration directory (`~/.openhands`) as the CLI mode

#### Mounting Your Current Directory

To mount your current working directory into the GUI server container, use the `--mount-cwd` flag:

```bash  theme={null}
openhands serve --mount-cwd
```

This is useful when you want to work on files in your current directory through the GUI. The directory will be mounted at `/workspace` inside the container.

#### Using GPU Support

If you have NVIDIA GPUs and want to make them available to the OpenHands container, use the `--gpu` flag:

```bash  theme={null}
openhands serve --gpu
```

This will enable GPU support via nvidia-docker, mounting all available GPUs into the container. You can combine this with other flags:

```bash  theme={null}
openhands serve --gpu --mount-cwd
```

**Prerequisites for GPU support:**

* NVIDIA GPU drivers must be installed on your host system
* [NVIDIA Container Toolkit (nvidia-docker2)](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) must be installed and configured

#### Requirements

Before using the `openhands serve` command, ensure that:

* Docker is installed and running on your system
* You have internet access to pull the required Docker images
* Port 3000 is available on your system

The CLI will automatically check these requirements and provide helpful error messages if anything is missing.

### Using Docker Directly

Alternatively, you can run the GUI server using Docker directly. See the [local setup guide](/usage/run-openhands/local-setup) for detailed Docker instructions.

## Overview

### Initial Setup

1. Upon first launch, you'll see a settings popup.
2. Select an `LLM Provider` and `LLM Model` from the dropdown menus. If the required model does not exist in the list,
   select `see advanced settings`. Then toggle `Advanced` options and enter it with the correct prefix in the
   `Custom Model` text box.
3. Enter the corresponding `API Key` for your chosen provider.
4. Click `Save Changes` to apply the settings.

### Settings

You can use the Settings page at any time to:

* [Setup the LLM provider and model for OpenHands](/openhands/usage/settings/llm-settings).
* [Setup the search engine](/openhands/usage/advanced/search-engine-setup).
* [Configure MCP servers](/openhands/usage/settings/mcp-settings).
* [Connect to GitHub](/openhands/usage/settings/integrations-settings#github-setup),
  [connect to GitLab](/openhands/usage/settings/integrations-settings#gitlab-setup)
  and [connect to Bitbucket](/openhands/usage/settings/integrations-settings#bitbucket-setup).
* Set application settings like your preferred language, notifications and other preferences.
* [Manage custom secrets](/openhands/usage/settings/secrets-settings).

### Key Features

For an overview of the key features available inside a conversation, please refer to the
[Key Features](/openhands/usage/key-features) section of the documentation.

## Other Ways to Run Openhands

* [Run OpenHands in a scriptable headless mode.](/openhands/usage/cli/headless)
* [Run OpenHands with a friendly CLI.](/openhands/usage/cli/terminal)


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.openhands.dev/llms.txt