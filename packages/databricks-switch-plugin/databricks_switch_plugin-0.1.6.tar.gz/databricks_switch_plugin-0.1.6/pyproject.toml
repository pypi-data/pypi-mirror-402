[project]
name = "databricks-switch-plugin"
dynamic = ["version"]
description = "LLM-powered tool to convert SQL, code, and workflow files into Databricks notebooks."
license-files = { paths = ["LICENSE", "NOTICE"] }
keywords = ["Databricks", "SQL", "Migration", "LLM", "Conversion"]
readme = "README.md"
requires-python = ">=3.10"
maintainers = [
    { name = "Databricks Labs", email = "labs-oss@databricks.com" },
]
classifiers = [
    "Development Status :: 4 - Beta",
    "License :: Other/Proprietary License",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: Implementation :: CPython",
    "Environment :: Console",
    "Framework :: Pytest",
    "Intended Audience :: Developers",
    "Intended Audience :: System Administrators",
    "Operating System :: MacOS",
    "Operating System :: Microsoft :: Windows",
    "Topic :: Software Development :: Libraries",
    "Topic :: Utilities",
]

# PyPI package has no runtime dependencies
# All workspace execution dependencies are in optional-dependencies.runtime
dependencies = []

[project.optional-dependencies]
runtime = [
    "anytree==2.13.0",
    "chardet==5.2.0",
    "databricks-sdk~=0.67.0",
    "httpx==0.28.1",
    "omegaconf==2.3.0",
    "PyYAML==6.0.2",
    "tenacity==9.1.2",
    "tiktoken==0.9.0",
]

[project.urls]
Documentation = "https://databrickslabs.github.io/lakebridge"
Issues = "https://github.com/databrickslabs/lakebridge/issues"
Source = "https://github.com/databrickslabs/lakebridge"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build]
sources = ["src"]
include = ["src", "lsp"]

[tool.hatch.version]
path = "src/databricks/labs/switch/__about__.py"

[tool.hatch.envs.default]
python = "3.10"

# store virtual env as the child of this folder. Helps VSCode to run better
path = ".venv"

dependencies = [
  "databricks-switch-plugin[runtime]",
  "pylint~=3.2.2",
  "pylint-pytest==2.0.0a0",
  "coverage[toml]~=7.8.0",
  "pytest~=8.3.5",
  "pytest-cov>=5.0.0,<6.0.0",
  "pytest-asyncio~=0.26.0",
  "pytest-xdist~=3.5.0",
  "black~=25.1.0",
  "ruff~=0.11.6",
  "databricks-connect>=15.0.1",
  "types-pyYAML~=6.0.12",
  "types-pytz~=2025.2",
  "databricks-labs-pylint~=0.4.0",
  "databricks-labs-pytester>=0.3.0",
  "mypy~=1.10.0",
  "python-dotenv>=1.0.0",
  "mlflow~=2.9.2",
  "tomli>=2.0.0",
  "click<8.3.0",
]

[tool.hatch.envs.default.scripts]
test         = "pytest --cov --cov-report=xml tests/unit/"
coverage     = "pytest --cov --cov-report=html tests/unit/"
fmt          = ["black .",
                   "ruff check . --fix",
                   "mypy .",
                   "pylint --output-format=colorized -j 0 src tests scripts"]
verify       = ["black --check .",
                   "ruff check .",
                   "mypy .",
                   "pylint --output-format=colorized -j 0 src tests scripts"]

[tool.pytest.ini_options]
addopts = "-s -vv --cache-clear --import-mode=importlib"
cache_dir = ".venv/pytest-cache"
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"

[tool.mypy]
exclude = [
    "examples/",
    "lsp/",
    # Exclude Databricks notebooks from mypy
    "src/databricks/labs/switch/notebooks/.*\\.py$",
    "src/databricks/labs/switch/notebooks/processors/.*",
    "src/databricks/labs/switch/notebooks/exporters/.*",
    "src/databricks/labs/switch/notebooks/orchestrators/.*",
]

[tool.black]
target-version = ["py310"]
line-length = 120
skip-string-normalization = true
extend-exclude = '''
/(
    examples
  | lsp
)/
'''

[tool.ruff]
cache-dir = ".venv/ruff-cache"
target-version = "py310"
line-length = 120

lint.ignore = [
    # Allow non-abstract empty methods in abstract base classes
    "B027",
    # Allow boolean positional values in function calls, like `dict.get(... True)`
    "FBT003",
    # Ignore checks for possible passwords and SQL statement construction
    "S105", "S106", "S107", "S603", "S608",
    # Allow print statements
    "T201",
    # Allow asserts
    "S101",
    # Allow standard random generators
    "S311",
    # Ignore complexity
    "C901", "PLR0911", "PLR0912", "PLR0913", "PLR0915",
    # Ignore Exception must not use a string literal, assign to variable first
    "EM101",
    "PLR2004",
    "UP038", # Use `X | Y` in `isinstance` call instead of `(X, Y)`
]
extend-exclude = [
    "examples",
    "lsp",
    # Exclude Databricks notebooks from ruff
    "src/databricks/labs/switch/notebooks/*.py",
    "src/databricks/labs/switch/notebooks/processors",
    "src/databricks/labs/switch/notebooks/exporters",
    "src/databricks/labs/switch/notebooks/orchestrators",
]

[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = "all"

[tool.ruff.lint.per-file-ignores]
"tests/**/*" = [
    "PLR2004", "S101", "TID252", # tests can use magic values, assertions, and relative imports
    "ARG001" # tests may not use the provided fixtures
]

[tool.pylint.main]
# PyLint configuration is adapted from Google Python Style Guide with modifications.
# Sources https://google.github.io/styleguide/pylintrc
# License: https://github.com/google/styleguide/blob/gh-pages/LICENSE

fail-under = 10.0
ignore-patterns = ["^\\.#"]
ignore-paths = [
    # Exclude Databricks notebooks from pylint
    "src/databricks/labs/switch/notebooks/00_main",
    "src/databricks/labs/switch/notebooks/notebook_utils",
    "src/databricks/labs/switch/notebooks/validation_utils",
    "src/databricks/labs/switch/notebooks/processors",
    "src/databricks/labs/switch/notebooks/exporters",
    "src/databricks/labs/switch/notebooks/orchestrators",
]
jobs = 0
limit-inference-results = 100
load-plugins = [
    "pylint.extensions.bad_builtin",
    "pylint.extensions.broad_try_clause",
    "pylint.extensions.check_elif",
    "pylint.extensions.code_style",
    "pylint.extensions.confusing_elif",
    "pylint.extensions.comparison_placement",
    "pylint.extensions.consider_refactoring_into_while_condition",
    "pylint.extensions.dict_init_mutate",
    "pylint.extensions.docparams",
    "pylint.extensions.dunder",
    "pylint.extensions.for_any_all",
    "pylint.extensions.mccabe",
    "pylint.extensions.overlapping_exceptions",
    "pylint.extensions.private_import",
    "pylint.extensions.redefined_variable_type",
    "pylint.extensions.set_membership",
    "pylint.extensions.typing",
]
persistent = true
py-version = "3.10"
suggestion-mode = true

[tool.pylint.basic]
argument-naming-style = "snake_case"
argument-rgx = "[a-z_][a-z0-9_]{2,30}$"
attr-naming-style = "snake_case"
attr-rgx = "[a-z_][a-z0-9_]{2,}$"
bad-names = ["foo", "bar", "baz", "toto", "tutu", "tata"]
class-attribute-naming-style = "any"
class-attribute-rgx = "([A-Za-z_][A-Za-z0-9_]{2,30}|(__.*__))$"
class-const-naming-style = "UPPER_CASE"
class-naming-style = "PascalCase"
class-rgx = "[A-Z_][a-zA-Z0-9]+$"
const-naming-style = "UPPER_CASE"
const-rgx = "(([A-Z_][A-Z0-9_]*)|(__.*__))$"
docstring-min-length = -1
function-naming-style = "snake_case"
function-rgx = "[a-z_][a-z0-9_]{2,}$"
good-names = [
    "f",            # use for file handles
    "i", "j", "k",  # use for loops
    "df",           # use for pyspark.sql.DataFrame
    "ex", "e",      # use for exceptions
    "fn", "cb",     # use for callbacks
    "_",            # use for ignores
    "a",            # use for databricks.sdk.AccountClient
    "w", "ws"       # use for databricks.sdk.WorkspaceClient
]
inlinevar-naming-style = "any"
inlinevar-rgx = "[A-Za-z_][A-Za-z0-9_]*$"
method-naming-style = "snake_case"
method-rgx = "[a-z_][a-z0-9_]{2,}$"
module-naming-style = "snake_case"
module-rgx = "(([a-z_][a-z0-9_]*)|([A-Z][a-zA-Z0-9]+))$"
no-docstring-rgx = "__.*__"
property-classes = ["abc.abstractproperty"]
variable-naming-style = "snake_case"
variable-rgx = "[a-z_][a-z0-9_]{2,30}$"

[tool.pylint.broad_try_clause]
max-try-statements = 7

[tool.pylint.classes]
defining-attr-methods = ["__init__", "__new__", "setUp", "__post_init__"]
exclude-protected = ["_asdict", "_fields", "_replace", "_source", "_make"]
valid-classmethod-first-arg = ["cls"]
valid-metaclass-classmethod-first-arg = ["mcs"]

[tool.pylint.deprecated_builtins]
bad-functions = ["map", "input"]

[tool.pylint.design]
max-args = 12
max-attributes = 13
max-bool-expr = 5
max-branches = 20
max-locals = 19
max-parents = 7
max-public-methods = 20
max-returns = 11
max-statements = 50
min-public-methods = 2

[tool.pylint.exceptions]
overgeneral-exceptions = ["builtins.Exception"]

[tool.pylint.format]
ignore-long-lines = "^\\s*(# )?<?https?://\\S+>?$"
indent-after-paren = 4
indent-string = "    "
max-line-length = 100
max-module-lines = 2100

[tool.pylint.imports]
deprecated-modules = ["regsub", "TERMIOS", "Bastion", "rexec"]
known-third-party = ["enchant"]

[tool.pylint.logging]
logging-format-style = "new"
logging-modules = ["logging"]

[tool.pylint."messages control"]
confidence = ["HIGH", "CONTROL_FLOW", "INFERENCE", "INFERENCE_FAILURE", "UNDEFINED"]
disable = [
    "prefer-typing-namedtuple",
    "attribute-defined-outside-init",
    "missing-module-docstring",
    "missing-class-docstring",
    "missing-function-docstring",
    "too-few-public-methods",
    "line-too-long",
    "trailing-whitespace",
    "missing-final-newline",
    "trailing-newlines",
    "unnecessary-semicolon",
    "mixed-line-endings",
    "unexpected-line-ending-format",
    "fixme",
    "consider-using-assignment-expr",
    "logging-fstring-interpolation",
    "consider-using-any-or-all"
]
enable = ["useless-suppression", "use-symbolic-message-instead"]

[tool.pylint.method_args]
timeout-methods = ["requests.api.delete", "requests.api.get", "requests.api.head", "requests.api.options", "requests.api.patch", "requests.api.post", "requests.api.put", "requests.api.request"]

[tool.pylint.miscellaneous]
notes = ["FIXME", "XXX", "TODO"]

[tool.pylint.parameter_documentation]
accept-no-param-doc = true
accept-no-raise-doc = true
accept-no-return-doc = true
accept-no-yields-doc = true
default-docstring-type = "default"

[tool.pylint.refactoring]
max-nested-blocks = 5
never-returning-functions = ["sys.exit", "argparse.parse_error"]

[tool.pylint.reports]
evaluation = "max(0, 0 if fatal else 10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10))"
score = true

[tool.pylint.similarities]
ignore-comments = true
ignore-docstrings = true
ignore-imports = true
ignore-signatures = true
min-similarity-lines = 6

[tool.pylint.spelling]
max-spelling-suggestions = 2
spelling-ignore-comment-directives = "fmt: on,fmt: off,noqa:,noqa,nosec,mypy:,pragma:,# noinspection"
spelling-private-dict-file = ".pyenchant_pylint_custom_dict.txt"

[tool.pylint.typecheck]
contextmanager-decorators = ["contextlib.contextmanager"]
generated-members = "REQUEST,acl_users,aq_parent,argparse.Namespace"
ignore-none = true
ignore-on-opaque-inference = true
ignored-checks-for-mixins = ["no-member", "not-async-context-manager", "not-context-manager", "attribute-defined-outside-init"]
ignored-classes = ["SQLObject", "optparse.Values", "thread._local", "_thread._local"]
missing-member-hint = true
missing-member-hint-distance = 1
missing-member-max-choices = 1
mixin-class-rgx = ".*MixIn"

[tool.pylint.variables]
allow-global-unused-variables = true
callbacks = ["cb_", "_cb"]
dummy-variables-rgx = "_+$|(_[a-zA-Z0-9_]*[a-zA-Z0-9]+?$)|dummy|^ignored_|^unused_"
ignored-argument-names = "_.*|^ignored_|^unused_"
redefining-builtins-modules = ["six.moves", "past.builtins", "future.builtins", "builtins", "io"]

[tool.coverage.run]
source = ["databricks.labs.switch.notebooks.pyscripts"]
omit = ["*/tests/*", "*/test_*.py"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError"
]
