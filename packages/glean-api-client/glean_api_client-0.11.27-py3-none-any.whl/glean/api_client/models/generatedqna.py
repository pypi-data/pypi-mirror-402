"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .followupaction import FollowupAction, FollowupActionTypedDict
from enum import Enum
from glean.api_client.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Optional, TYPE_CHECKING
from typing_extensions import Annotated, NotRequired, TypedDict

if TYPE_CHECKING:
    from .textrange import TextRange, TextRangeTypedDict


class GeneratedQnaStatus(str, Enum):
    r"""Status of backend generating the answer"""

    COMPUTING = "COMPUTING"
    DISABLED = "DISABLED"
    FAILED = "FAILED"
    NO_ANSWER = "NO_ANSWER"
    SKIPPED = "SKIPPED"
    STREAMING = "STREAMING"
    SUCCEEDED = "SUCCEEDED"
    TIMEOUT = "TIMEOUT"


class GeneratedQnaTypedDict(TypedDict):
    question: NotRequired[str]
    r"""Search query rephrased into a question."""
    answer: NotRequired[str]
    r"""Answer generated for the given query or the generated question."""
    follow_up_prompts: NotRequired[List[str]]
    r"""List of all follow-up prompts generated for the given query or the generated question."""
    followup_actions: NotRequired[List[FollowupActionTypedDict]]
    r"""List of follow-up actions generated for the given query or the generated question."""
    ranges: NotRequired[List["TextRangeTypedDict"]]
    r"""Answer subsections to mark with special formatting (citations, bolding etc)"""
    status: NotRequired[GeneratedQnaStatus]
    r"""Status of backend generating the answer"""
    cursor: NotRequired[str]
    r"""An opaque cursor representing the search request"""
    tracking_token: NotRequired[str]
    r"""An opaque token that represents this particular result in this particular query. To be used for /feedback reporting."""


class GeneratedQna(BaseModel):
    question: Optional[str] = None
    r"""Search query rephrased into a question."""

    answer: Optional[str] = None
    r"""Answer generated for the given query or the generated question."""

    follow_up_prompts: Annotated[
        Optional[List[str]], pydantic.Field(alias="followUpPrompts")
    ] = None
    r"""List of all follow-up prompts generated for the given query or the generated question."""

    followup_actions: Annotated[
        Optional[List[FollowupAction]], pydantic.Field(alias="followupActions")
    ] = None
    r"""List of follow-up actions generated for the given query or the generated question."""

    ranges: Optional[List["TextRange"]] = None
    r"""Answer subsections to mark with special formatting (citations, bolding etc)"""

    status: Optional[GeneratedQnaStatus] = None
    r"""Status of backend generating the answer"""

    cursor: Optional[str] = None
    r"""An opaque cursor representing the search request"""

    tracking_token: Annotated[Optional[str], pydantic.Field(alias="trackingToken")] = (
        None
    )
    r"""An opaque token that represents this particular result in this particular query. To be used for /feedback reporting."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "question",
                "answer",
                "followUpPrompts",
                "followupActions",
                "ranges",
                "status",
                "cursor",
                "trackingToken",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
