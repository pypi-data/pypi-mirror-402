"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .sidebysideimplementation import (
    SideBySideImplementation,
    SideBySideImplementationTypedDict,
)
from enum import Enum
from glean.api_client.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class ManualFeedbackSideBySideInfoSource(str, Enum):
    r"""The source associated with the side-by-side feedback event."""

    LIVE_EVAL = "LIVE_EVAL"
    CHAT = "CHAT"
    SEARCH = "SEARCH"


class ManualFeedbackSideBySideInfoVote(str, Enum):
    r"""The vote for this specific implementation."""

    UPVOTE = "UPVOTE"
    DOWNVOTE = "DOWNVOTE"
    NEUTRAL = "NEUTRAL"


class ManualFeedbackSideBySideInfoTypedDict(TypedDict):
    email: NotRequired[str]
    r"""The email address of the user who submitted the side-by-side feedback."""
    source: NotRequired[ManualFeedbackSideBySideInfoSource]
    r"""The source associated with the side-by-side feedback event."""
    query: NotRequired[str]
    r"""The query or prompt that was evaluated across multiple implementations."""
    implementations: NotRequired[List[SideBySideImplementationTypedDict]]
    r"""Array of implementations that were compared side-by-side."""
    evaluation_session_id: NotRequired[str]
    r"""Unique identifier for this evaluation session to group related feedback events."""
    implementation_id: NotRequired[str]
    r"""The ID of the implementation this specific feedback event is for."""
    vote: NotRequired[ManualFeedbackSideBySideInfoVote]
    r"""The vote for this specific implementation."""
    comments: NotRequired[str]
    r"""Specific feedback comments for this implementation."""


class ManualFeedbackSideBySideInfo(BaseModel):
    email: Optional[str] = None
    r"""The email address of the user who submitted the side-by-side feedback."""

    source: Optional[ManualFeedbackSideBySideInfoSource] = None
    r"""The source associated with the side-by-side feedback event."""

    query: Optional[str] = None
    r"""The query or prompt that was evaluated across multiple implementations."""

    implementations: Optional[List[SideBySideImplementation]] = None
    r"""Array of implementations that were compared side-by-side."""

    evaluation_session_id: Annotated[
        Optional[str], pydantic.Field(alias="evaluationSessionId")
    ] = None
    r"""Unique identifier for this evaluation session to group related feedback events."""

    implementation_id: Annotated[
        Optional[str], pydantic.Field(alias="implementationId")
    ] = None
    r"""The ID of the implementation this specific feedback event is for."""

    vote: Optional[ManualFeedbackSideBySideInfoVote] = None
    r"""The vote for this specific implementation."""

    comments: Optional[str] = None
    r"""Specific feedback comments for this implementation."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "email",
                "source",
                "query",
                "implementations",
                "evaluationSessionId",
                "implementationId",
                "vote",
                "comments",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
