"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from glean.api_client.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import Dict, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class ResponseMetadataTypedDict(TypedDict):
    r"""Metadata about the response (e.g., latency, token count)."""

    latency_ms: NotRequired[int]
    r"""Time taken to generate the response in milliseconds."""
    token_count: NotRequired[int]
    r"""Number of tokens in the response."""
    model_used: NotRequired[str]
    r"""The specific model version used."""


class ResponseMetadata(BaseModel):
    r"""Metadata about the response (e.g., latency, token count)."""

    latency_ms: Annotated[Optional[int], pydantic.Field(alias="latencyMs")] = None
    r"""Time taken to generate the response in milliseconds."""

    token_count: Annotated[Optional[int], pydantic.Field(alias="tokenCount")] = None
    r"""Number of tokens in the response."""

    model_used: Annotated[Optional[str], pydantic.Field(alias="modelUsed")] = None
    r"""The specific model version used."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["latencyMs", "tokenCount", "modelUsed"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class SideBySideImplementationTypedDict(TypedDict):
    implementation_id: NotRequired[str]
    r"""Unique identifier for this implementation variant."""
    implementation_name: NotRequired[str]
    r"""Human-readable name for this implementation (e.g., \"Variant A\", \"GPT-4\", \"Claude\")."""
    search_params: NotRequired[Dict[str, str]]
    r"""The search/chat parameters used for this implementation."""
    response: NotRequired[str]
    r"""The full response generated by this implementation."""
    response_metadata: NotRequired[ResponseMetadataTypedDict]
    r"""Metadata about the response (e.g., latency, token count)."""


class SideBySideImplementation(BaseModel):
    implementation_id: Annotated[
        Optional[str], pydantic.Field(alias="implementationId")
    ] = None
    r"""Unique identifier for this implementation variant."""

    implementation_name: Annotated[
        Optional[str], pydantic.Field(alias="implementationName")
    ] = None
    r"""Human-readable name for this implementation (e.g., \"Variant A\", \"GPT-4\", \"Claude\")."""

    search_params: Annotated[
        Optional[Dict[str, str]], pydantic.Field(alias="searchParams")
    ] = None
    r"""The search/chat parameters used for this implementation."""

    response: Optional[str] = None
    r"""The full response generated by this implementation."""

    response_metadata: Annotated[
        Optional[ResponseMetadata], pydantic.Field(alias="responseMetadata")
    ] = None
    r"""Metadata about the response (e.g., latency, token count)."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "implementationId",
                "implementationName",
                "searchParams",
                "response",
                "responseMetadata",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
