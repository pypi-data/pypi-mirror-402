"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .connectortype import ConnectorType
from .documentcontent import DocumentContent, DocumentContentTypedDict
from .documentsection import DocumentSection, DocumentSectionTypedDict
from glean.api_client.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Optional, TYPE_CHECKING
from typing_extensions import Annotated, NotRequired, TypedDict

if TYPE_CHECKING:
    from .documentmetadata import DocumentMetadata, DocumentMetadataTypedDict


class DocumentTypedDict(TypedDict):
    id: NotRequired[str]
    r"""The Glean Document ID."""
    datasource: NotRequired[str]
    r"""The app or other repository type from which the document was extracted"""
    connector_type: NotRequired[ConnectorType]
    r"""The source from which document content was pulled, e.g. an API crawl or browser history"""
    doc_type: NotRequired[str]
    r"""The datasource-specific type of the document (e.g. for Jira issues, this is the issue type such as Bug or Feature Request)."""
    content: NotRequired[DocumentContentTypedDict]
    container_document: NotRequired[DocumentTypedDict]
    parent_document: NotRequired[DocumentTypedDict]
    title: NotRequired[str]
    r"""The title of the document."""
    url: NotRequired[str]
    r"""A permalink for the document."""
    metadata: NotRequired["DocumentMetadataTypedDict"]
    sections: NotRequired[List[DocumentSectionTypedDict]]
    r"""A list of content sub-sections in the document, e.g. text blocks with different headings in a Drive doc or Confluence page."""


class Document(BaseModel):
    id: Optional[str] = None
    r"""The Glean Document ID."""

    datasource: Optional[str] = None
    r"""The app or other repository type from which the document was extracted"""

    connector_type: Annotated[
        Optional[ConnectorType], pydantic.Field(alias="connectorType")
    ] = None
    r"""The source from which document content was pulled, e.g. an API crawl or browser history"""

    doc_type: Annotated[Optional[str], pydantic.Field(alias="docType")] = None
    r"""The datasource-specific type of the document (e.g. for Jira issues, this is the issue type such as Bug or Feature Request)."""

    content: Optional[DocumentContent] = None

    container_document: Annotated[
        Optional[Document], pydantic.Field(alias="containerDocument")
    ] = None

    parent_document: Annotated[
        Optional[Document], pydantic.Field(alias="parentDocument")
    ] = None

    title: Optional[str] = None
    r"""The title of the document."""

    url: Optional[str] = None
    r"""A permalink for the document."""

    metadata: Optional["DocumentMetadata"] = None

    sections: Optional[List[DocumentSection]] = None
    r"""A list of content sub-sections in the document, e.g. text blocks with different headings in a Drive doc or Confluence page."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "id",
                "datasource",
                "connectorType",
                "docType",
                "content",
                "containerDocument",
                "parentDocument",
                "title",
                "url",
                "metadata",
                "sections",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
