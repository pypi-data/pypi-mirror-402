"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .bulkuploadhistoryevent import (
    BulkUploadHistoryEvent,
    BulkUploadHistoryEventTypedDict,
)
from .datasourceobjecttypedocumentcountentry import (
    DatasourceObjectTypeDocumentCountEntry,
    DatasourceObjectTypeDocumentCountEntryTypedDict,
)
from .debugdatasourcestatusidentityresponsecomponent import (
    DebugDatasourceStatusIdentityResponseComponent,
    DebugDatasourceStatusIdentityResponseComponentTypedDict,
)
from .processinghistoryevent import (
    ProcessingHistoryEvent,
    ProcessingHistoryEventTypedDict,
)
from enum import Enum
from glean.api_client.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class DebugDatasourceStatusResponseCountsTypedDict(TypedDict):
    uploaded: NotRequired[List[DatasourceObjectTypeDocumentCountEntryTypedDict]]
    r"""A list of object types and corresponding upload counts. Note: This data may be cached and could be up to 3 hours stale.

    """
    indexed: NotRequired[List[DatasourceObjectTypeDocumentCountEntryTypedDict]]
    r"""The number of documents indexed, grouped by objectType"""


class DebugDatasourceStatusResponseCounts(BaseModel):
    uploaded: Optional[List[DatasourceObjectTypeDocumentCountEntry]] = None
    r"""A list of object types and corresponding upload counts. Note: This data may be cached and could be up to 3 hours stale.

    """

    indexed: Optional[List[DatasourceObjectTypeDocumentCountEntry]] = None
    r"""The number of documents indexed, grouped by objectType"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["uploaded", "indexed"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DocumentsTypedDict(TypedDict):
    bulk_upload_history: NotRequired[List[BulkUploadHistoryEventTypedDict]]
    r"""Information about active and recent successful uploads for the datasource"""
    counts: NotRequired[DebugDatasourceStatusResponseCountsTypedDict]
    processing_history: NotRequired[List[ProcessingHistoryEventTypedDict]]
    r"""Information about processing history for the datasource"""


class Documents(BaseModel):
    bulk_upload_history: Annotated[
        Optional[List[BulkUploadHistoryEvent]],
        pydantic.Field(alias="bulkUploadHistory"),
    ] = None
    r"""Information about active and recent successful uploads for the datasource"""

    counts: Optional[DebugDatasourceStatusResponseCounts] = None

    processing_history: Annotated[
        Optional[List[ProcessingHistoryEvent]],
        pydantic.Field(alias="processingHistory"),
    ] = None
    r"""Information about processing history for the datasource"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["bulkUploadHistory", "counts", "processingHistory"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class IdentityTypedDict(TypedDict):
    processing_history: NotRequired[List[ProcessingHistoryEventTypedDict]]
    r"""Information about processing history for the datasource"""
    users: NotRequired[DebugDatasourceStatusIdentityResponseComponentTypedDict]
    groups: NotRequired[DebugDatasourceStatusIdentityResponseComponentTypedDict]
    memberships: NotRequired[DebugDatasourceStatusIdentityResponseComponentTypedDict]


class Identity(BaseModel):
    processing_history: Annotated[
        Optional[List[ProcessingHistoryEvent]],
        pydantic.Field(alias="processingHistory"),
    ] = None
    r"""Information about processing history for the datasource"""

    users: Optional[DebugDatasourceStatusIdentityResponseComponent] = None

    groups: Optional[DebugDatasourceStatusIdentityResponseComponent] = None

    memberships: Optional[DebugDatasourceStatusIdentityResponseComponent] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["processingHistory", "users", "groups", "memberships"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class DatasourceVisibility(str, Enum):
    r"""The visibility of the datasource, an enum of VISIBLE_TO_ALL, VISIBLE_TO_TEST_GROUP, NOT_VISIBLE"""

    ENABLED_FOR_ALL = "ENABLED_FOR_ALL"
    ENABLED_FOR_TEST_GROUP = "ENABLED_FOR_TEST_GROUP"
    NOT_ENABLED = "NOT_ENABLED"


class DebugDatasourceStatusResponseTypedDict(TypedDict):
    r"""Describes the response body of the /debug/{datasource}/status API call"""

    documents: NotRequired[DocumentsTypedDict]
    identity: NotRequired[IdentityTypedDict]
    datasource_visibility: NotRequired[DatasourceVisibility]
    r"""The visibility of the datasource, an enum of VISIBLE_TO_ALL, VISIBLE_TO_TEST_GROUP, NOT_VISIBLE"""


class DebugDatasourceStatusResponse(BaseModel):
    r"""Describes the response body of the /debug/{datasource}/status API call"""

    documents: Optional[Documents] = None

    identity: Optional[Identity] = None

    datasource_visibility: Annotated[
        Optional[DatasourceVisibility], pydantic.Field(alias="datasourceVisibility")
    ] = None
    r"""The visibility of the datasource, an enum of VISIBLE_TO_ALL, VISIBLE_TO_TEST_GROUP, NOT_VISIBLE"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["documents", "identity", "datasourceVisibility"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
