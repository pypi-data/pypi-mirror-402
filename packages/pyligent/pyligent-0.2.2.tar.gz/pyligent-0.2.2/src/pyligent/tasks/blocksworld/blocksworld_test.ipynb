{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b190f6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/khalikov_diligent_learner/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from architecture.blocksworld import adapter\n",
    "from architecture.blocksworld.validator import BlocksworldValidator\n",
    "\n",
    "path = Path(\"./blocksworld/task_1_plan_generation.json\")\n",
    "instances_path = Path(\"./instances_basic\")\n",
    "val_path = Path(\"./VAL/validate\")\n",
    "domain_path = Path(\"./domain.pddl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359582ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = adapter.BlocksworldAdapter(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb6e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_basic_usage(path)\n",
    "# example_with_gold_paths(path)\n",
    "# example_multi_phase(path)\n",
    "# example_save_files(path)\n",
    "# example_phase_breakdown(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea399af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: 500 pairs\n",
      "Phase 2: 500 pairs\n"
     ]
    }
   ],
   "source": [
    "dataset = test.build_diligent_dataset(t_values=[1, 2], check_unique=True)\n",
    "encode_object = {\n",
    "    \"a\": \"red\",\n",
    "    \"b\": \"blue\",\n",
    "    \"c\": \"orange\",\n",
    "    \"d\": \"yellow\",\n",
    "    \"e\": \"white\",\n",
    "    \"f\": \"magenta\",\n",
    "    \"g\": \"black\",\n",
    "    \"h\": \"cyan\",\n",
    "    \"i\": \"green\",\n",
    "    \"j\": \"violet\",\n",
    "    \"k\": \"silver\",\n",
    "    \"l\": \"gold\",\n",
    "}\n",
    "\n",
    "decode_object = {v: k for k, v in encode_object.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df2d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<node>0 Blocks state: the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the yellow block is on top of the orange block, the blue block is on the table and the orange block is on the table.\n",
      "Goal: the orange block is on top of the red block.</node> | <node>1 (unstack yellow orange)</node> | <node>2 (put-down yellow)</node> | <node>3 (pick-up orange)</node> | <node>4 (stack orange red)</node>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ced00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_instances = {}\n",
    "target_plans = {}\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)[\"instances\"]\n",
    "\n",
    "for ex in data:\n",
    "    query = adapter.BlocksworldAdapter.format_query(ex[\"query\"])\n",
    "    target = ex[\"ground_truth_plan\"].strip()\n",
    "    instance_num = ex[\"instance_id\"]\n",
    "    target_instances[query] = instance_num\n",
    "    target_plans[query] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a685f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = BlocksworldValidator(\n",
    "    target_plans,\n",
    "    target_instances,\n",
    "    instances_path=instances_path,\n",
    "    val_path=val_path,\n",
    "    domain_path=domain_path,\n",
    "    plan_buf_path=Path(\"./buffer.pddl\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40534b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0][1]._text = '(stack orange orange)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c50366d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(unstack d c)\n",
      "(put-down d)\n",
      "(pick-up c)\n",
      "(stack c a)\n",
      "(unstack a b)\n"
     ]
    }
   ],
   "source": [
    "with open(Path(\"./buffer.pddl\"), \"r\") as f:\n",
    "    test = f.read()\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e846e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VAL/validate -v domain.pddl instances_basic/instance-2.pddl buffer.pddl'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3ba1187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Checking plan: buffer.pddl\\nPlan to validate:\\n\\nPlan size: 5\\n1:\\n(unstack d c)\\n \\n2:\\n(put-down d)\\n \\n3:\\n(pick-up c)\\n \\n4:\\n(stack c a)\\n \\n5:\\n(unstack a b)\\n \\n\\nPlan Validation details\\n-----------------------\\n\\nChecking next happening (time 1)\\nDeleting (on d c)\\nDeleting (clear d)\\nDeleting (handempty)\\nAdding (holding d)\\nAdding (clear c)\\n\\nChecking next happening (time 2)\\nDeleting (holding d)\\nAdding (clear d)\\nAdding (handempty)\\nAdding (ontable d)\\n\\nChecking next happening (time 3)\\nDeleting (clear c)\\nDeleting (ontable c)\\nDeleting (handempty)\\nAdding (holding c)\\n\\nChecking next happening (time 4)\\nDeleting (clear a)\\nDeleting (holding c)\\nAdding (handempty)\\nAdding (clear c)\\nAdding (on c a)\\n\\nChecking next happening (time 5)\\nPlan failed because of unsatisfied precondition in:\\n(unstack a b)\\n\\nPlan failed to execute\\n\\nPlan Repair Advice:\\n\\n(unstack a b) has an unsatisfied precondition at time 5\\n(Set (clear a) to true)\\n\\n\\nFailed plans:\\n buffer.pddl \\n',\n",
       " '')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = f\"{val_path} -v {domain_path} {instances_path / 'instance-2.pddl'} {Path('./buffer.pddl')}\"\n",
    "result = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "output, error = result.communicate()\n",
    "output = output.decode(\"CP866\")\n",
    "error = error.decode(\"CP866\")\n",
    "output, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c93e6941",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationExecutionError",
     "evalue": "/bin/sh: 1: VAL/validate/validate: not found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationExecutionError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m result = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (context, action) \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     result.append(\u001b[43mvalidator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/khalikov/diligent-learner/src/architecture/core/validator.py:110\u001b[39m, in \u001b[36mValidator.validate\u001b[39m\u001b[34m(self, action, context)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action_type, scope \u001b[38;5;129;01min\u001b[39;00m type_scope_map.items():\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action, action_type):\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_handlers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown action type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(action)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/khalikov/diligent-learner/src/architecture/core/validator.py:118\u001b[39m, in \u001b[36mValidator._run_handlers\u001b[39m\u001b[34m(self, scope, *args)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute all handlers for a scope\"\"\"\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handlers[scope]:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     result = \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result.valid:\n\u001b[32m    120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/khalikov/diligent-learner/src/architecture/blocksworld/validator.py:133\u001b[39m, in \u001b[36mBlocksworldValidator._validate_done_action\u001b[39m\u001b[34m(self, action, context)\u001b[39m\n\u001b[32m    131\u001b[39m text = \u001b[38;5;28mstr\u001b[39m(action)\n\u001b[32m    132\u001b[39m actions = \u001b[38;5;28mself\u001b[39m.parse_actions(text, decode_object=\u001b[38;5;28mself\u001b[39m.decode_object)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_plan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_success\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/khalikov/diligent-learner/src/architecture/blocksworld/validator.py:102\u001b[39m, in \u001b[36mBlocksworldValidator._validate_plan\u001b[39m\u001b[34m(self, plan, task, check_success, decode)\u001b[39m\n\u001b[32m    100\u001b[39m validation, error = \u001b[38;5;28mself\u001b[39m._val_call(\u001b[38;5;28mself\u001b[39m.plan_buf_path, instance_path)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error):\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationExecutionError(error)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mPlan failed to execute\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m validation:\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m HandlerResult(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mplan failed to execute\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValidationExecutionError\u001b[39m: /bin/sh: 1: VAL/validate/validate: not found\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for context, action in dataset:\n",
    "    result.append(validator.validate(action, context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2df6a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All valid\n"
     ]
    }
   ],
   "source": [
    "if all(result):\n",
    "    print(\"All valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2cd63",
   "metadata": {},
   "source": [
    "# Checkpoint check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f64601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "prompts = [\n",
    "    \"\"\"You must output exactly ONE next action using one of these\n",
    "forms:\n",
    "\n",
    "<node>ID STEP_TEXT</node>\n",
    "\n",
    "<done>FINAL_ANSWER</done>\n",
    "\n",
    "<backtrack>NODE_ID</backtrack>\n",
    "\n",
    "Emit ONLY the tag. No commentary or reasoning. <node>0 I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do\n",
    "\n",
    "Pick up a block\n",
    "Unstack a block from on top of another block\n",
    "Put down a block\n",
    "Stack a block on top of another block\n",
    "\n",
    "I have the following restrictions on my actions:\n",
    "I can only pick up or unstack one block at a time.\n",
    "I can only pick up or unstack a block if my hand is empty.\n",
    "I can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up.\n",
    "I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\n",
    "I can only unstack a block from on top of another block if the block I am unstacking is clear.\n",
    "Once I pick up or unstack a block, I am holding the block.\n",
    "I can only put down a block that I am holding.\n",
    "I can only stack a block on top of another block if I am holding the block being stacked.\n",
    "I can only stack a block on top of another block if the block onto which I am stacking the block is clear.\n",
    "Once I put down or stack a block, my hand becomes empty.\n",
    "Once you stack a block on top of a second block, the second block is no longer clear.\n",
    "\n",
    "As initial conditions I have that, the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the yellow block is on top of the orange block, the blue block is on the table and the orange block is on the table.\n",
    "My goal is to have that the orange block is on top of the red block.</node> | <node>1 (unstack yellow orange)</node> | <node>2 (put-down yellow)</node> | <node>3 (pick-up orange)</node> | <node>4 (stack orange red)</node>\"\"\"\n",
    "]\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.7, top_p=0.8, max_tokens=300, stop=[\"</done>\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dd44a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 17:23:19 [utils.py:253] non-default args: {'disable_log_stats': True, 'model': '/home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model'}\n",
      "INFO 12-02 17:23:19 [model.py:631] Resolved architecture: Qwen3ForCausalLM\n",
      "INFO 12-02 17:23:19 [model.py:1745] Using max model len 40960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 17:23:21,202\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 17:23:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from '/home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='/home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model', speculative_config=None, tokenizer='/home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:26 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.233.220.180:44637 backend=nccl\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:27 [gpu_model_runner.py:3259] Starting to load model /home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m [2025-12-02 17:23:28] INFO _optional_torch_c_dlpack.py:119: JIT-compiling torch-c-dlpack-ext to cache...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m /home/jovyan/miniconda3/envs/khalikov_diligent_learner/lib/python3.13/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:161: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:42 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:42 [cuda.py:427] Using FLASH_ATTN backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:05<00:05,  5.06s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:08<00:00,  4.05s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:08<00:00,  4.20s/it]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:51 [default_loader.py:314] Loading weights took 8.50 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:23:52 [gpu_model_runner.py:3338] Model loading took 7.5023 GiB memory and 23.315299 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:04 [backends.py:631] Using cache directory: /home/jovyan/.cache/vllm/torch_compile_cache/89507c50bd/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:04 [backends.py:647] Dynamo bytecode transform time: 12.19 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:13 [backends.py:251] Cache the graph for dynamic shape for later use\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:23 [backends.py:282] Compiling a graph for dynamic shape takes 18.72 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:30 [monitor.py:34] torch.compile takes 30.91 s in total\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:31 [gpu_worker.py:359] Available KV cache memory: 59.55 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:32 [kv_cache_utils.py:1229] GPU KV cache size: 433,648 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:32 [kv_cache_utils.py:1234] Maximum concurrency for 40,960 tokens per request: 10.59x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 18.45it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:37 [gpu_model_runner.py:4244] Graph capturing finished in 5 secs, took 2.62 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m INFO 12-02 17:24:37 [core.py:250] init engine (profile, create kv cache, warmup model) took 45.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=814036)\u001b[0;0m The tokenizer you are loading from '/home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-02 17:24:38 [llm.py:352] Supported tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "llm = LLM(\n",
    "    model=\"/home/jovyan/khalikov/diligent-learner-detached/output/blocksworld_test/run_2025-12-01_23-09-22/final_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8872daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 521.87it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it, est. speed input: 155.77 toks/s, output: 96.35 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Outputs:\n",
      "------------------------------------------------------------\n",
      "Prompt:    'You must output exactly ONE next action using one of these\\nforms:\\n\\n<node>ID STEP_TEXT</node>\\n\\n<done>FINAL_ANSWER</done>\\n\\n<backtrack>NODE_ID</backtrack>\\n\\nEmit ONLY the tag. No commentary or reasoning. <node>0 I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do\\n\\nPick up a block\\nUnstack a block from on top of another block\\nPut down a block\\nStack a block on top of another block\\n\\nI have the following restrictions on my actions:\\nI can only pick up or unstack one block at a time.\\nI can only pick up or unstack a block if my hand is empty.\\nI can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up.\\nI can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\\nI can only unstack a block from on top of another block if the block I am unstacking is clear.\\nOnce I pick up or unstack a block, I am holding the block.\\nI can only put down a block that I am holding.\\nI can only stack a block on top of another block if I am holding the block being stacked.\\nI can only stack a block on top of another block if the block onto which I am stacking the block is clear.\\nOnce I put down or stack a block, my hand becomes empty.\\nOnce you stack a block on top of a second block, the second block is no longer clear.\\n\\nAs initial conditions I have that, the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the yellow block is on top of the orange block, the blue block is on the table and the orange block is on the table.\\nMy goal is to have that the orange block is on top of the red block.</node> | <node>1 (unstack yellow orange)</node> | <node>2 (put-down yellow)</node> | <node>3 (pick-up orange)</node> | <node>4 (stack orange red)</node>'\n",
      "Output:    ' | <node>5 (pick-up yellow)</node> | <node>6 (unstack yellow orange)</node> | <node>7 (stack yellow orange)</node> | <node>8 (unstack red blue)</node> | <node>9 (put-down red)</node> | <node>10 (pick-up blue)</node> | <node>11 (stack blue orange)</node> | <node>12 (pick-up red)</node> | <node>13 (stack red yellow)</node> | <node>14 (unstack yellow orange)</node> | <node>15 (stack yellow blue)</node> | <node>16 (pick-up orange)</node> | <node>17 (stack orange red)</node> | <node>18 (pick-up yellow)</node> | <node>19 (unstack yellow orange)</node> | <node>20 (stack yellow red)</node> | <node>21 (pick-up blue)</node> | <node>22 (stack blue yellow)</node> | <node>23 (pick-up orange)</node> | <node>24 (stack orange red)</node> | <node>25 (pick-up yellow)</node> | <node>26 (unstack yellow orange)</node> | <node>27 (stack yellow blue)</node> |'\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = llm.generate(prompts, sampling_params)\n",
    "# Print the outputs.\n",
    "print(\"\\nGenerated Outputs:\\n\" + \"-\" * 60)\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt:    {prompt!r}\")\n",
    "    print(f\"Output:    {generated_text!r}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca005511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do\n",
      "\n",
      "Pick up a block\n",
      "Unstack a block from on top of another block\n",
      "Put down a block\n",
      "Stack a block on top of another block\n",
      "\n",
      "I have the following restrictions on my actions:\n",
      "I can only pick up or unstack one block at a time.\n",
      "I can only pick up or unstack a block if my hand is empty.\n",
      "I can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up.\n",
      "I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\n",
      "I can only unstack a block from on top of another block if the block I am unstacking is clear.\n",
      "Once I pick up or unstack a block, I am holding the block.\n",
      "I can only put down a block that I am holding.\n",
      "I can only stack a block on top of another block if I am holding the block being stacked.\n",
      "I can only stack a block on top of another block if the block onto which I am stacking the block is clear.\n",
      "Once I put down or stack a block, my hand becomes empty.\n",
      "Once you stack a block on top of a second block, the second block is no longer clear.\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the red block is clear, the blue block is clear, the hand is empty, the blue block is on top of the yellow block, the yellow block is on top of the white block, the white block is on top of the orange block, the red block is on the table and the orange block is on the table.\n",
      "My goal is to have that the red block is on top of the blue block and the blue block is on top of the yellow block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "pick up the red block\n",
      "stack the red block on top of the blue block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the red block is clear, the orange block is clear, the white block is clear, the hand is empty, the yellow block is on top of the blue block, the white block is on top of the yellow block, the red block is on the table, the blue block is on the table and the orange block is on the table.\n",
      "My goal is to have that the blue block is on top of the orange block, the orange block is on top of the white block and the yellow block is on top of the blue block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n"
     ]
    }
   ],
   "source": [
    "test = \"I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do\\n\\nPick up a block\\nUnstack a block from on top of another block\\nPut down a block\\nStack a block on top of another block\\n\\nI have the following restrictions on my actions:\\nI can only pick up or unstack one block at a time.\\nI can only pick up or unstack a block if my hand is empty.\\nI can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up.\\nI can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\\nI can only unstack a block from on top of another block if the block I am unstacking is clear.\\nOnce I pick up or unstack a block, I am holding the block.\\nI can only put down a block that I am holding.\\nI can only stack a block on top of another block if I am holding the block being stacked.\\nI can only stack a block on top of another block if the block onto which I am stacking the block is clear.\\nOnce I put down or stack a block, my hand becomes empty.\\nOnce you stack a block on top of a second block, the second block is no longer clear.\\n\\n[STATEMENT]\\nAs initial conditions I have that, the red block is clear, the blue block is clear, the hand is empty, the blue block is on top of the yellow block, the yellow block is on top of the white block, the white block is on top of the orange block, the red block is on the table and the orange block is on the table.\\nMy goal is to have that the red block is on top of the blue block and the blue block is on top of the yellow block.\\n\\nMy plan is as follows:\\n\\n[PLAN]\\npick up the red block\\nstack the red block on top of the blue block\\n[PLAN END]\\n\\n[STATEMENT]\\nAs initial conditions I have that, the red block is clear, the orange block is clear, the white block is clear, the hand is empty, the yellow block is on top of the blue block, the white block is on top of the yellow block, the red block is on the table, the blue block is on the table and the orange block is on the table.\\nMy goal is to have that the blue block is on top of the orange block, the orange block is on top of the white block and the yellow block is on top of the blue block.\\n\\nMy plan is as follows:\\n\\n[PLAN]\"\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c03e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"привет\"\n",
    "test.rfind(\"вет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f3569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khalikov_diligent_learner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
