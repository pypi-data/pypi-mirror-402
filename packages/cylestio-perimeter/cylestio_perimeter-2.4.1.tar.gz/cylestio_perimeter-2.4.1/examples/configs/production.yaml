# Production Configuration with Full Features
# Usage: python -m src.main --config examples/configs/production.yaml

server:
  port: 4000
  host: "127.0.0.1"
  workers: 4

llm:
  base_url: "https://api.openai.com"
  type: "openai"
  api_key: "${OPENAI_API_KEY}"
  timeout: 60
  max_retries: 5

interceptors:
      
  # Minimal printer middleware for production
  - type: "printer"
    enabled: true
    config:
      log_requests: true
      log_responses: true
      log_body: false  # Don't log bodies in production

logging:
  level: "INFO"
  format: "json"  # Structured logging for production
  file: "/var/log/llm-proxy/app.log"
  max_file_size: "50MB"
  backup_count: 10