# Tier 4 API Contract

## Feature 1: Latency Metrics

### New Event Types

```python
# Emitted after each LLM call
{
    "type": "llm_call",
    "chunk_index": int,
    "total_chunks": int,
    "latency_ms": float,  # Duration of this call in milliseconds
}

# Updated "complete" event now includes latency summary
{
    "type": "complete",
    "chunk_index": int,
    "total_chunks": int,
    "latency_stats": {
        "call_count": int,
        "total_ms": float,
        "min_ms": float,
        "max_ms": float,
        "avg_ms": float,
    }
}
```

### Internal State

```python
# Added to DataCleaner
self._latency_stats = {
    "call_count": 0,
    "total_ms": 0.0,
    "min_ms": float("inf"),
    "max_ms": 0.0,
}
```

---

## Feature 2: Import Consolidation

### Enhanced Output Functions

```python
def consolidate_imports(imports: list[str]) -> list[str]:
    """
    Merge and deduplicate imports.

    Args:
        imports: Raw import statements from all functions

    Returns:
        Consolidated, sorted import statements

    Behavior:
        - Duplicate `import x` → single `import x`
        - `from x import a` + `from x import b` → `from x import a, b`
        - `import x` + `from x import y` → both kept
    """
```

### Output File Format

```python
"""Auto-generated data cleaning functions."""

# Consolidated imports (alphabetically sorted)
import json
import re
from typing import Any, Dict, List

# Functions (dependency-ordered)
def function_one(data):
    ...

def function_two(data):
    ...

# Entrypoint
def clean_data(data):
    ...
```

---

## Feature 3: Cleaning Report

### New Parameter

```python
class DataCleaner:
    def __init__(
        self,
        ...
        report_path: str | None = "cleaning_report.md",  # None = no report
    ):
```

### Report Format

```markdown
# Data Cleaning Report

## Summary

- **File**: {file_path}
- **Chunks processed**: {total_chunks}
- **Functions generated**: {function_count}
- **Processing time**: {total_latency_ms}ms

## Functions Generated

| # | Name | Description |
|---|------|-------------|
| 1 | normalize_phone | Normalize phone numbers to E.164 format |
| 2 | fix_status | Fix typos in status field |

## Quality Metrics

*(Only if track_metrics=True)*

| Metric | Before | After | Change |
|--------|--------|-------|--------|
| Null values | 150 | 12 | -92% |
| Empty strings | 45 | 0 | -100% |

---

*Generated by Recursive Data Cleaner v0.6.0*
```

### New Module

```python
# recursive_cleaner/report.py

def generate_report(
    file_path: str,
    total_chunks: int,
    functions: list[dict],
    latency_stats: dict | None = None,
    quality_before: QualityMetrics | None = None,
    quality_after: QualityMetrics | None = None,
) -> str:
    """Generate markdown cleaning report."""
```

---

## Feature 4: Dry-Run Mode

### New Parameter

```python
class DataCleaner:
    def __init__(
        self,
        ...
        dry_run: bool = False,
    ):
```

### Behavior When `dry_run=True`

1. Chunks are processed normally
2. LLM is called to analyze issues
3. Issues are extracted from response
4. **No functions are added** to registry
5. **No output file is written**
6. Events emitted for observability

### New Event Type

```python
# Emitted when issues detected (dry_run mode only)
{
    "type": "issues_detected",
    "chunk_index": int,
    "total_chunks": int,
    "issues": [
        {"id": "1", "solved": False, "description": "Phone numbers inconsistent"},
        {"id": "2", "solved": False, "description": "Dates in wrong format"},
    ]
}
```

### Dry-Run Summary Event

```python
# Emitted at end of dry run
{
    "type": "dry_run_complete",
    "chunk_index": int,
    "total_chunks": int,
    "total_issues_found": int,
    "unique_issue_types": int,  # Deduplicated by description similarity
}
```
