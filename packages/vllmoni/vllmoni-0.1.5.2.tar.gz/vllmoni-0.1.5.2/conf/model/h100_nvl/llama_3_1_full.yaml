defaults:
  - _default
  - _self_

model_name: "meta-llama/Llama-3.1-70B"
model_name_short: "Llama-3.1-70B"
gpu_memory_utilization: 0.9
max_tokens: 1000
max_model_len: 40000
tool_call_parser: llama3_json
